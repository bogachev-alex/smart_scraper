[
  {
    "title": "How AI is driving innovation in the automotive industry",
    "date": "September 25, 2025",
    "link": "https://www.servicenow.com/blogs/2025/ai-automotive-industry",
    "source": "Servicenow_blog",
    "main_ideas": [
      "AI is transforming the automotive industry by enhancing customer experiences and streamlining operations.",
      "Many automakers face challenges in implementing AI strategies effectively due to talent shortages and governance issues.",
      "Pacesetter companies excel in AI maturity by prioritizing talent development and establishing clear governance frameworks."
    ],
    "tags": [
      "artificial-intelligence",
      "automotive-industry",
      "customer-experience",
      "data-governance",
      "operational-efficiency",
      "predictive-maintenance",
      "ai-strategy",
      "talent-development",
      "innovation"
    ],
    "original_text": "How AI is driving innovation in the automotive industry\nJürgen Schön\nSeptember 25, 2025\nAI is transforming every aspect of the automotive industry, from manufacturing to driver experience to insurance claims reporting. In fact, 83% of automakers plan to increase their AI spending in the next fiscal year, according to the ServiceNow\nEnterprise AI Maturity Index 2025\n.\nAs AI continues to revolutionize the sector, modern vehicles are evolving into intelligent partners rather than mere modes of transportation.\nAI in the automotive industry\nThe profound impact of\nAI in the automotive industry\nthrough smart vehicles, back-office automation, and predictive maintenance cannot be overstated. As AI technologies become more sophisticated, automakers are exploring new ways to enhance customer experiences, streamline operations, and drive innovation.\nAs an example, 51% of the automotive companies we surveyed plan to embrace\nagentic AI\nin the next year. The advanced technology is designed to autonomously help predict maintenance needs, manage inventory, and optimize supply chains.\n\"AI has become a critical tool in enhancing customer loyalty and retention,” says the chief information officer of a leading Canadian automaker. “By leveraging AI-powered personalization and predictive maintenance, we've seen a significant increase in customer satisfaction and repeat business.\"\nFrom plans to practical implementation\nOne of the most significant hurdles facing the automotive industry is the gap between AI strategy formulation and execution.\nAlthough more than half (55%) of the automakers we surveyed have rolled out more than 100 AI use cases in the past year, only 36% strongly agree they’re operating with a clear, shared AI vision. And only 18% of automakers are currently using agentic AI.\nThis disconnect leaves auto businesses at a significant disadvantage, unable to fully harness AI's potential.\nCompounding these challenges are talent shortages and governance misalignments. A mere 31% of automakers report having sufficient AI talent, and only 44% have made necessary updates to their data governance frameworks.\nTo transition AI projects from testing phases to transformative initiatives, industry leaders must confront these obstacles head-on and bridge the gap between planning and practical implementation.\nAs the CEO of a leading European automaker notes, \"Investing in AI talent and establishing clear governance frameworks have been game changers for our organization. We've seen a dramatic increase in operational efficiency and have been able to make more informed, data-driven decisions across the board.\"\nSteering the industry forward\nDespite the challenges, a group of automakers are excelling in AI maturity. We call them Pacesetters.\nThese organizations prioritize talent development, robust governance, and scalable AI approaches. By focusing on these key areas, Pacesetters have seen improvements in efficiency, and 74% have reaped increases in gross margins.\nFor automotive companies to get the most out of AI, they must develop cohesive strategies that combine AI technology with operational and workforce transformation. Aligning AI strategies is crucial for organizations wishing to scale beyond pilot projects and achieve meaningful results.\nTo advance their AI maturity, automotive leaders should consider following Pacesetters’ proactive steps:\nBreak down silos and connect the enterprise\nPrioritize scalable AI approaches, such as embracing an AI platform\nInvest in AI talent development and acquisition\nEstablish a clear data governance framework\nFoster a culture of innovation and experimentation\nAccelerating AI maturity\nReady to accelerate your AI maturity journey? Start by gauging your organization's current standing with the\nEnterprise AI Maturity Benchmarking Assessment\n. This valuable resource will provide insights into your strengths, weaknesses, and opportunities for growth so that you can make informed decisions and drive meaningful change.\nAs the automotive industry continues to evolve, embracing AI will be crucial to staying competitive and meeting the ever-changing needs of customers. The future of the automotive industry is smart, connected, and powered by AI.\nFind out how ServiceNow can help you\nput AI to work for automotive\n.\n© 2025 ServiceNow, Inc. All rights reserved. ServiceNow, the ServiceNow logo, Now, and other ServiceNow marks are trademarks and/or registered trademarks of ServiceNow, Inc. in the United States and/or other countries. Other company names, product names, and logos may be trademarks of the respective companies with which they are associated.\n17\nShares\nTopics\nAI and Automation\nApplication Development\nCareers\nCrisis Management\nCulture\nCustomer Experience\nCustomer Stories\nCybersecurity and Risk\nEducation\nEmployee Experience\nEvents\nFinancial Services\nGovernment\nHealthcare\nIT Management\nManufacturing\nNow on Now\nServiceNow AI Platform\nTelecommunications\nFeatured\nOur shared table: Honoring service through food\nHow culture landed ServiceNow on Fortune World’s Best Workplaces list\nGetting real results from AI: Managing an agentic workforce\nTrends & Research\nServiceNow is again a Gartner-named Leader in CRM Customer Engagement Center\nServiceNow named a Leader by Gartner® in business orchestration and automation\nServiceNow is an IDC MarketScape Leader in AI-enabled aftermarket/service lifecycle and FSM\nYear\n2025\n2024\n2023\n2022"
  },
  {
    "title": "Banking on AI: 8 essentials for unshakable operational resilience",
    "date": "September 24, 2025",
    "link": "https://www.servicenow.com/blogs/2025/banking-ai-operational-resilience",
    "source": "Servicenow_blog",
    "main_ideas": [
      "Banks face significant losses due to disconnected legacy systems and operational failures.",
      "AI can enhance operational resilience by predicting failures and mapping dependencies.",
      "Proactive management of dependencies and vulnerabilities is crucial for regulatory compliance."
    ],
    "tags": [
      "operational-resilience",
      "artificial-intelligence",
      "banking",
      "regulatory-compliance",
      "cybersecurity",
      "business-continuity",
      "incident-response",
      "third-party-management"
    ],
    "original_text": "Banking on AI: 8 essentials for unshakable operational resilience\nAnna Mazzone\nSeptember 24, 2025\nBetween 2018 and 2023, major global banks lost more than $170 billion in total due to operational failures, according to an\nEY report\n. This alarming figure proves that resilience gaps can destroy decades of growth overnight. The culprit? Most banks are running their\noperational resilience\nprograms on thousands of disconnected, legacy systems across teams and departments.\nThis creates a dangerous paradox: Every department has green-light dashboards, but no one can confidently answer critical questions such as “What happens if our electronic funds transfer (EFT) processor fails during month-end?” or “Which services depend on that mainframe we're decommissioning?” These unanswered questions expose the fragility of banks' operational resilience programs, leaving them vulnerable to catastrophic losses and regulatory scrutiny.\nSiloed systems make it impossible to see cascading failures before they happen. When one system goes down, teams scramble to manually trace dependencies through spreadsheets and tribal knowledge, turning what should be a one-minute fix into a five-hour outage.\nWithout real-time visibility across interconnected services, banks can't proactively isolate problems, redirect traffic, or accurately communicate impact to customers and regulators. Although\nAI is ready to help banks\npredict failure patterns and automatically map hidden dependencies across systems, most banks still rely on outdated manual processes, meaning their\nAI maturity\nremains low.\nThe AI-driven operational resilience advantage\nThe difference between banks that thrive and those that merely survive goes beyond capital reserves—it lies in a strong,\nAI-driven operational resilience\nprogram. Future-proof banks can instantly map critical dependencies, predict cascade failures, and recover services in minutes while their competitors are still assembling crisis teams.\nTo drive differentiation for your bank, you must excel across eight AI-driven, interconnected operational resilience competencies. At ServiceNow, we've worked with hundreds of banks and have identified common challenges. Let's examine some critical questions to ask yourself across these eight competencies.\n1. Continuous service & enterprise asset mapping\nWhen regulators ask to review the mapped dependencies for your EFT processing within 72 hours, can you actually deliver? Advanced banks use AI-driven configuration management with a common taxonomy to instantly map and trace every connection—tech infrastructure, third parties, people dependencies, critical data flows, required skills, and essential facilities.\nHowever, most financial institutions still discover phantom dependencies during outages, when a forgotten legacy interface blocks wire transfers and regulators start asking uncomfortable questions about operational control. This reactive approach exposes banks to regulatory scrutiny, financial losses, and reputational damage.\nTo meet regulatory demands and maintain operational resilience, banks must proactively map and manage their complex web of dependencies. AI-driven tools can automate this process, providing real-time visibility and enabling rapid response to regulatory inquiries.\n2. Autonomous IT operations\nPicture this: Your core banking platform experiences a critical error at 2 a.m. on a Sunday. Will your team be able to fix it before Monday's opening bell? Best-in-class banks see their autonomous\nAI agents\ndiagnose root causes, orchestrate remediation, and restore services without customers knowing about the issues.\nMeanwhile, many operations teams are paging through business continuity playbooks on conference calls, watching helplessly as batch processing failures start affecting customers.\n3. Risk and compliance\nHow quickly can you translate new regulatory guidance into tested controls? Future-proof institutions deploy AI that automatically maps new regulatory requirements and framework updates directly into their control libraries, complete with testing protocols and attestation workflows.\nWithout this approach, compliance teams may find themselves drowning in spreadsheets, racing against implementation deadlines, and hoping nothing falls through the cracks before the next exam.\n4. Vulnerabilities\nWhen a critical vulnerability affecting your digital channels is discovered, can you quickly identify all the potentially impacted components across your IT systems? Banks with resilient operations have real-time vulnerability correlation and automated patching based on business importance, and they can provide comprehensive impact assessments to the board within hours. Banks that are not as well equipped may still be searching for vulnerabilities when the first attack hits their firewall.\nSimilarly, in operations, are you identifying control failures before they escalate into significant issues? Continuous monitoring is crucial for wire transfer limits, dual control overrides, and privileged access to production systems. Forward-thinking banks integrate AI automation into these workflows to catch limit breaches and segregation failures automatically.\nBanks that are less prepared uncover control gaps only when auditors or examiners discover them first—or worse, when they appear in a suspicious activity report.\n5. Business continuity\nWhen cloud providers experience issues during critical processing periods, can you quickly assess the impact on your essential business services and functions? AI-enabled banks automatically simulate disruptions, invoke alternate routes, and maintain operations within approved impact tolerances while continuously testing vendor patches against established thresholds.\nIn less advanced business continuity management programs, stakeholders gather in war rooms. There, they discover that their quarterly exercises missed critical changes, their applications' dependencies remain unmapped, and their recovery time objectives for payment processing and securities settlement are unrealistic under actual stress.\n6. Incident response and service recovery\nCritical incidents instantly reveal operational maturity. During your next critical incident, can you confidently inform clients, the board, and regulators when service will resume?\nSophisticated banks use AI orchestration that prioritizes recovery by actual business impact, dynamically allocates resources based on real-time recovery time objective analysis, and provides executives with minute-by-minute recovery projections they can share with regulators.\nBanks that lag behind are left fielding status requests every 10 minutes while profit and loss impact climbs each hour and no one can definitively say when service will resume.\n7. Third-party management\nDoes AI monitor your vendors' ISO compliance and test their patches?\nForward-thinking banks use AI agents to track certification validity, simulate patch impacts on critical services, predict downstream failures across geographies, and generate executive-ready dashboards with human approval. Banks that are not as well prepared often discover expired certifications during incidents, lacking the automated vendor monitoring that regulators increasingly expect as proof of extended enterprise oversight.\n8. Governance, AI, and reporting\nIs your\nAI governance\nframework supported by an integrated, end-to-end view of AI development and use? This includes real-time model key performance indicators, complete algorithmic audit trails, and embedded approval workflows. With such a framework, board conversations can shift from incident postmortems to strategic discussions about automation investments at the strategy, execution, and portfolio levels.\nAlternatively, are directors still questioning why fragmented AI risk dashboards showed all green until models failed miserably, while regulators demand evidence of your controls? Banks that lack a comprehensive AI governance framework may struggle to provide satisfactory answers and, consequently, face increased scrutiny.\nHow does your operational resilience measure up?\nThese hard-hitting questions expose the challenges within the eight key competencies of operational resilience. How does your program stack up? Mastering these competencies can create a best-in-class, interconnected operational resilience ecosystem. Investing in these areas can help shield your bank from threats, position it for long-term success, deliver unrivaled customer value, and cement your firm as an industry leader.\nThe\nServiceNow\n®\nAI Platform\nprovides a centralized data foundation,\nagentic AI\nworkflows, and single-platform approach to help break down silos, foster collaboration, and connect people, processes, and data. This powerful combination can drive business growth, increase regulator and customer confidence, lower capital requirements, and ultimately create a resilient organization ready to withstand any disruption.\nFind out more about how ServiceNow can help you\nimprove operational resilience and drive growth\n.\n© 2025 ServiceNow, Inc. All rights reserved. ServiceNow, the ServiceNow logo, Now, and other ServiceNow marks are trademarks and/or registered trademarks of ServiceNow, Inc. in the United States and/or other countries. Other company names, product names, and logos may be trademarks of the respective companies with which they are associated.\n84\nShares\nTopics\nAI and Automation\nApplication Development\nCareers\nCrisis Management\nCulture\nCustomer Experience\nCustomer Stories\nCybersecurity and Risk\nEducation\nEmployee Experience\nEvents\nFinancial Services\nGovernment\nHealthcare\nIT Management\nManufacturing\nNow on Now\nServiceNow AI Platform\nTelecommunications\nFeatured\nOur shared table: Honoring service through food\nHow culture landed ServiceNow on Fortune World’s Best Workplaces list\nGetting real results from AI: Managing an agentic workforce\nTrends & Research\nServiceNow is again a Gartner-named Leader in CRM Customer Engagement Center\nServiceNow named a Leader by Gartner® in business orchestration and automation\nServiceNow is an IDC MarketScape Leader in AI-enabled aftermarket/service lifecycle and FSM\nYear\n2025\n2024\n2023\n2022"
  },
  {
    "title": "How to govern and scale AI effectively",
    "date": "September 17, 2025",
    "link": "https://www.servicenow.com/blogs/2025/how-govern-scale-ai-effectively",
    "source": "Servicenow_blog",
    "main_ideas": [
      "Organizations need a unified approach to AI governance that considers diverse perspectives.",
      "AI Control Tower serves as a central hub for managing AI strategy and compliance.",
      "Balancing innovation with oversight is crucial for successful AI adoption across businesses."
    ],
    "tags": [
      "ai-governance",
      "service-now",
      "ai-control-tower",
      "risk-management",
      "compliance",
      "enterprise-architecture",
      "cross-functional-teams",
      "business-transformation",
      "automation"
    ],
    "original_text": "How to govern and scale AI effectively\nVasant Balasubramanian\nSeptember 17, 2025\nThere’s an old Indian parable about a group of blind people who encounter an elephant for the first time. Each person touches a different part of the animal. One feels the leg and thinks it’s a pillar. Another calls the trunk a tree branch. And a third describes the ear as a fan. While each interpretation is true in its own way, none reflects the full reality.\nThis parable is a useful analogy for how organizations approach\nAI governance\n. Different groups—customers, partners, product and engineering teams, and internal governance functions—examine AI through their own lens and reach conclusions shaped by their immediate needs.\nAt ServiceNow, we frequently hear different expectations about managing AI. Customers are concerned about their ability to\nscale AI\nwhile preventing security and risk issues. Engineering teams want best practices guidance for managing AI risks, such as hallucinations and data leakage. Internal functions are trying to understand how AI governance affects their daily work and the cross-functional projects accelerating AI adoption.\nProject managers ask how to connect demand management to AI, investments, and roadmaps. Risk and compliance teams are focused on managing risks and complying with regulations, such as the\nEU AI Act\n. Security teams seek to establish controls and monitoring for AI and AI-related risks, such as data poisoning and leakage. Enterprise architecture teams need to establish standards for in-house AI use.\nEach group’s perspective is shaped by its own priorities, but collectively, these viewpoints form the complex landscape that defines how AI should be governed. How do you move faster with AI and not just focus on one team’s narrow scope? That leads to a much bigger question: How can teams link arms and individually contribute to an organization with the goal of transforming its business with AI?\nEstablish a control tower to manage AI\nTo address business adoption of AI, many organizations have established an AI Center of Excellence (CoE) led by a chief AI officer who reports to a chief technology officer or a chief information officer. The AI CoE works with product teams and various corporate functions to oversee the organization’s AI-related activities, including AI strategy, governance, execution, monitoring, and value.\nCoEs generally approach oversight in one of two ways. Some opt for point solutions focused on compliance, inventory, discovery, and/or large language model (\nLLM\n) monitoring. These point solutions operate in isolation, making it difficult to unify workstreams or scale adoption. More importantly, they often don’t connect AI to a technology system of record—a configuration management database (\nCMDB\n)—limiting the impact of AI.\nTo scale AI, you need an integrated set of capabilities that take into account the various aspects of AI planning, deployment, and monitoring across the enterprise. I think of it this way: Just as railroad companies, laborers, investors, and engineers worked to lay down tracks, provide coal, build railway stations, and plot train routes to win the West, organizations need to orchestrate many resources and capabilities to get the most out of AI.\nThat’s why ServiceNow built\nAI Control Tower\n—a central hub for managing, monitoring, and measuring AI strategy, governance, and compliance. Individual teams are empowered to independently implement AI, but a control tower approach enables them to align and support broader organizational transformation and not be slowed down by onerous and disconnected governance.\nUsing AI Control Tower, a CoE can embed AI governance across the organization’s AI ecosystem while aligning with business goals and diverse needs:\nAI Control Tower provides a central space to manage, monitor, measure, and oversee all AI activities.\nThe AI inventory (contained in the\nCMDB\n) supports both manual entry and automated AI discovery and links AI to the organization’s business applications, services, and infrastructure.\nThe onboarding process automatically identifies relevant risks and establishes the necessary controls to govern each\nAI agent\n, model, or asset.\nEngineering teams have the systems and guidance to create, embed, and use AI solutions in their daily work.\nProgram management, risk, compliance, security, IT, data governance, legal, and other teams can connect and align their AI-related activities to a corporate AI strategy that’s managed by the AI CoE.\nBalance innovation and oversight\nServiceNow\n®\nAI Control Tower caters to and connects different voices and priorities in a way that scales, delivers value, and evolves along with organizational change. It goes beyond governance to balance innovation with responsible oversight while encouraging collaboration, adaptability, and long-term transformation.\nAI is the new language of business. Siloed solutions or a single executive champion can't solve the challenges of governing AI throughout the corners of your business. You need a cross-functional team with centralized oversight using a single platform and a single data model. You must manage conversations about AI strategy, governance, execution, and value with key stakeholders—customers, partners, and third parties.\nSuccessful organizations that build a thriving AI ecosystem will do so by empowering their people to champion AI adoption so that they can reach and surpass business goals together. In other words, they can visualize the elephant and its legs, trunk, and ears.\nFind out how ServiceNow AI Control Tower can help you\nscale AI confidently and responsibly\n.\n© 2025 ServiceNow, Inc. All rights reserved. ServiceNow, the ServiceNow logo, Now, and other ServiceNow marks are trademarks and/or registered trademarks of ServiceNow, Inc. in the United States and/or other countries. Other company names, product names, and logos may be trademarks of the respective companies with which they are associated.\n95\nShares\nTopics\nAI and Automation\nApplication Development\nCareers\nCrisis Management\nCulture\nCustomer Experience\nCustomer Stories\nCybersecurity and Risk\nEducation\nEmployee Experience\nEvents\nFinancial Services\nGovernment\nHealthcare\nIT Management\nManufacturing\nNow on Now\nServiceNow AI Platform\nTelecommunications\nFeatured\nOur shared table: Honoring service through food\nHow culture landed ServiceNow on Fortune World’s Best Workplaces list\nGetting real results from AI: Managing an agentic workforce\nTrends & Research\nServiceNow is again a Gartner-named Leader in CRM Customer Engagement Center\nServiceNow named a Leader by Gartner® in business orchestration and automation\nServiceNow is an IDC MarketScape Leader in AI-enabled aftermarket/service lifecycle and FSM\nYear\n2025\n2024\n2023\n2022"
  },
  {
    "title": "How AI is redefining tech industry leadership",
    "date": "September 04, 2025",
    "link": "https://www.servicenow.com/blogs/2025/how-ai-is-redefining-tech-industry",
    "source": "Servicenow_blog",
    "main_ideas": [
      "AI is transforming tech leadership by enhancing operational efficiency and decision-making.",
      "Agentic AI is being adopted to improve workflows, customer interactions, and cybersecurity.",
      "Successful tech organizations deploy AI as an enterprise-wide system rather than isolated solutions."
    ],
    "tags": [
      "artificial-intelligence",
      "agentic-ai",
      "tech-industry",
      "operational-efficiency",
      "customer-experience",
      "cybersecurity",
      "innovation",
      "data-analysis",
      "enterprise-ai"
    ],
    "original_text": "How AI is redefining tech industry leadership\nServiceNow Blog\nSeptember 04, 2025\nExperienced human writers and editors used AI to help research and draft this blog post. These humans then edited and fact-checked the post to ensure it meets our rigorous editorial standards.\nEnterprise AI has arrived, yet many tech organizations find themselves caught in a paradox: They’re pioneering AI solutions for their customers while struggling to harness AI's transformative power in their internal operations.\nAI is evolving faster than most tech providers can effectively deploy it, according to new ServiceNow research about\nAI in the tech industry\n. This is widening the gap between promise and implementation.\nOrganizations face fragmented data landscapes across hundreds of applications, talent constraints that limit vision, and a tendency to simply \"lift and shift\" past processes rather than boldly reimagining the future.\nDespite these challenges, tech organizations are embracing AI to reinvent their operating models—and drive experiences and outcomes that were previously unattainable. Let's explore how today's technology trailblazers are using AI to unlock new possibilities and create a decisive competitive advantage in an increasingly dynamic marketplace.\nTable of contents\nWhat does AI in tech mean?\nWhat is the role of agentic AI in tech?\nWhat does AI do in technology?\nHow is AI used in the tech industry?\nIs AI taking over the tech industry?\nWhat is the future of AI in tech?\nWhat does AI in tech mean?\nAI in tech\nis the linchpin of modern enterprise architecture—systems that learn, adapt, and evolve to solve increasingly complex business challenges. AI is reshaping every aspect of tech, from software and hardware development to IT services.\nUnlike traditional automation, which simply executes preprogrammed instructions, AI technologies actively interpret data, recognize patterns, and make decisions with minimal human intervention. By embedding AI across the technology stack, organizations can create an intelligent foundation that actively drives change instead of merely responding to it.\nAI isn’t new to the tech industry. In fact, tech has the highest AI maturity score, according to our research. And 87% of the tech firms we surveyed plan to increase their AI investment in the next fiscal year.\nWhat is the role of agentic AI in tech?\nAgentic AI\n—advanced AI with the ability to learn, adapt, and make sophisticated decisions autonomously—is making a huge impact on the tech industry. Nearly 40% of the tech firms in our study are already using agentic AI. Another 36% are considering adopting it within the next year.\nTech organizations are using agentic AI to:\nInteract with internal systems:\n47% are creating seamless workflows that transcend traditional departmental boundaries.\nAct on customer inquiries:\n47% are enhancing customer interactions with AI agents that deliver personalized, contextually relevant experiences across every channel.\nWrite and edit code:\n46% are revamping software development through AI-powered code writing and editing capabilities that accelerate innovation cycles.\nAddress cybersecurity alerts:\n43% are strengthening their security posture by autonomously detecting and responding to cybersecurity threats in real time.\nEarly agentic AI adopters saw on average an 11.9% increase in gross margin, compared to 8.9% for organizations not using agentic AI. Organizations using agentic AI also report enhanced productivity, superior experiences, and accelerated growth.\nThe ability to create seamlessly connected interactions across every touch point is transforming both customer and employee engagement. By handling complex tasks autonomously, agentic AI systems free human talent to focus on innovation and strategy.\nWhat does AI do in technology?\nAI in tech processes vast quantities of data at speeds impossible for human teams, identifies patterns that are difficult to detect, and generates insights that propel innovation.\nIn a world where data volumes are increasing exponentially, AI serves as the connective tissue that transforms disparate information into a unified source of truth. By linking previously isolated systems, AI helps enable tech leaders to make decisions based on complete information rather than fragmented views.\nAI is changing how humans and technologies collaborate. By handling routine tasks, surfacing insights, and recommending actions based on comprehensive analysis, AI empowers tech leaders and their teams to focus on strategic innovation rather than maintenance and troubleshooting.\nMost of the tech firms we surveyed report big gains from AI adoption:\nHigher productivity: 90%\nBetter experiences: 88%\nBoosted revenue: 86%\nHow is AI used in the tech industry?\nThe most successful tech organizations deploy AI as an enterprisewide system of intelligence, not isolated point solutions. Leading companies are implementing AI-powered transformation across critical areas, including:\nRevenue and cost improvements\nDynamic pricing\nFraud detection\nFast decision-making\nNew business opportunities\nCustomer service and engagement\nRapid response\nCustomer feedback\nData analysis\nMarketing strategy\nCustomer success\nAdoption monitoring\nProactive engagement\nRenewal intelligence\nRisk mitigation/churn prevention\nSuccess playbooks\nInternal operations\nHR processes\nProduct safety\nPredictive maintenance\nSupply chain optimization\nIT foundation and risk\nCase resolution\nCase deflection\nReduced incident escalation\nProduct support and operations\nSelf-service\nSelf-healing\nEvent noise reduction\nManaged services\nLabor-intensive-process elimination\nProactive management\nSeamless connectivity\nIs AI taking over the tech industry?\nAI is not taking over the tech industry. It's augmenting and elevating human potential across the landscape. Forward-thinking companies recognize that AI serves as a force multiplier for human creativity, strategic thinking, and innovation.\nAs an example, tech Pacesetters—the most AI-mature tech firms in our study—are more likely than other organizations to have AI innovation centers that put people to work to pilot next-generation AI solutions (54% versus 39%).\nPacesetters are paying close attention to the human side of AI adoption and taking measures to prioritize talent. The majority have launched upskilling initiatives to help ensure they have qualified talent to carry out their AI strategies. In addition:\n87% have implemented training and support programs\n69% host AI learning events\n60% have identified AI champions to spearhead AI adoption\nWhat is the future of AI in tech?\nThe future belongs to enterprises that can seamlessly integrate AI into their operating fabric. We're beyond the experimental phase and have entered the era of enterprise-grade AI—where systems of AI agents work in concert to address complex business challenges.\nTomorrow's market leaders are building AI strategies that align with their financial position and growth objectives to strengthen customer relationships, enhance brand loyalty, and scale efficiently—all while optimizing margins.\nAs AI continues its exponential evolution, the tech industry stands at the threshold of unprecedented transformation. The winners will be those that recognize that AI is a fundamental reimagining of how enterprises operate, compete, and create value.\nFind out how ServiceNow can help you\nput AI to work in tech\n.\n© 2025 ServiceNow, Inc. All rights reserved. ServiceNow, the ServiceNow logo, Now, and other ServiceNow marks are trademarks and/or registered trademarks of ServiceNow, Inc. in the United States and/or other countries. Other company names, product names, and logos may be trademarks of the respective companies with which they are associated.\n29\nShares\nTopics\nAI and Automation\nApplication Development\nCareers\nCrisis Management\nCulture\nCustomer Experience\nCustomer Stories\nCybersecurity and Risk\nEducation\nEmployee Experience\nEvents\nFinancial Services\nGovernment\nHealthcare\nIT Management\nManufacturing\nNow on Now\nServiceNow AI Platform\nTelecommunications\nFeatured\nOur shared table: Honoring service through food\nHow culture landed ServiceNow on Fortune World’s Best Workplaces list\nGetting real results from AI: Managing an agentic workforce\nTrends & Research\nServiceNow is again a Gartner-named Leader in CRM Customer Engagement Center\nServiceNow named a Leader by Gartner® in business orchestration and automation\nServiceNow is an IDC MarketScape Leader in AI-enabled aftermarket/service lifecycle and FSM\nYear\n2025\n2024\n2023\n2022"
  },
  {
    "title": "One unified AI platform, ready for anything",
    "date": "October 27, 2025",
    "link": "https://www.servicenow.com/blogs/2025/unified-ai-platform-ready-anything",
    "source": "Servicenow_blog",
    "main_ideas": [
      "ServiceNow AI Platform integrates AI, data, workflows, and governance for business transformation.",
      "The platform supports real-time AI-driven decisions through advanced data integration and querying.",
      "AI agents and orchestration enable coordinated workflows across various business functions."
    ],
    "tags": [
      "artificial-intelligence",
      "servicenow",
      "workflow-automation",
      "data-integration",
      "ai-agents",
      "business-transformation",
      "cloud-computing",
      "enterprise-ai",
      "machine-learning"
    ],
    "original_text": "One unified AI platform, ready for anything\nMichael Park\nOctober 27, 2025\nEvery day, I work with ServiceNow customers and partners who are putting AI to work to solve complex business challenges and drive measurable, sustainable value.\nSuccess starts with understanding how to activate the\nServiceNow AI Platform\n—where AI, data, workflows, and governance come together to turn potential into performance. This is how organizations are transforming their businesses today, on one unified AI platform built for the AI era.\nI’d like to break down how all the components of the ServiceNow AI Platform—including task and configuration item objects, RaptorDB, Workflow Data Fabric,\nagentic AI\n, and AI Control Tower—work together to deliver business value based on a\nwhiteboard session\nI recently led. Let’s walk through how ServiceNow fits into the three layers of enterprise AI architecture.\nData layer and integration\nWe built a single data model that connects multiple data sources and every system of engagement to integrate seamlessly across industries and departments.\nIntegration Hub\nlinks ServiceNow to more than 200 transactional systems (such as SAP and Salesforce), synchronizing master data and enabling seamless workflow integration.\nThe addition of analytical data, including zero copy and indexing, allows the ServiceNow AI Platform to access external datasets (such as Snowflake and Databricks) without importing all the data. Essentially, we’re able to support remote data queries.\nRaptorDB\n, a column store database, enables us to query the data much faster, which is critical for AI-driven operations. In simple terms, that’s what makes real-time, AI-led decisions possible without adding data debt.\nKnowledge Graph\nprovides a navigation map that guides AI agents to efficiently access and relate data both inside and outside ServiceNow. As we build more integrations, the navigation map is expanded.\nAll this together makes up\nWorkflow Data Fabric\n, designed to provide agility for how ServiceNow activates workflow capabilities. For customers and partners, this means faster insights, less complexity, and more connected workflows that fuel AI-driven outcomes.\nAI and workflow tooling layer\nOur\nService Catalog\n, flows, playbooks, and other capabilities let teams build and automate workflows without writing code. To that, we added predictive intelligence, AIOps, and machine learning to glean insights from the single data model through pattern recognition. Then on top of that, we added automation in the form of\nProcess and Task Mining\n,\nrobotic process automation\n(RPA), and large language model (LLM) skills.\nBuilding on that foundation, we introduced\nNow Assist\n—prebuilt AI skills, including summarization, automatic knowledge base article creation, and code generation, that turn everyday work into intelligent workflows. This means customers and partners can simply activate AI within their existing applications and even bring in third-party LLMs to build new AI skills.\nAI agents are designed to carry out assigned tasks. Each AI agent has a single purpose and is really good at what it does. But they need help to work together.\nThat’s why we created\nAI Agent Orchestrator\n—the all-seeing, all-knowing super AI agent that can coordinate individual AI agents to fulfill complex workflows and autonomous processes. It’s how enterprises move from isolated AI tasks to autonomous, coordinated business processes at scale.\nThis AI agent orchestration requires governance, so we built\nAI Control Tower\n. It incorporates organizations’ risk policies into their workflows to help meet security and regulatory compliance.\nAI Agent Studio\nlets customers and partners build custom AI agents using third-party LLMs to extend and differentiate their AI agent capabilities. That means customers and partners have flexibility in how they use the ServiceNow AI Platform to drive AI transformation in their businesses through a single pane of glass.\nWorkflow experience layer\nFrom IT to security operations to HR to finance to customer relationship management (CRM), every workflow runs on one platform. Because our research and development and product teams build on the same architecture, we innovate faster—with no technical debt.\nWe’ve made it even easier for employees to deliver great customer experiences through a single AI interface. ServiceNow\nAI Experience\nbrings together voice, text, image, web, and build agents into one multimodal workspace—powered by enterprise data and connected workflows.\nInstead of navigating multiple systems, employees can simply ask questions through natural conversation. The system understands context, retrieves the right information, and takes action across departments to resolve customer issues fast. This is AI in action—an everyday use case where AI drives outcomes.\nIt’s also how we’re helping organizations boost service quality, shorten resolution times, and ensure customers get what they need, when they need it.\nWith AI woven across every workflow, customers and partners can augment, add, replace, and coexist with autonomous AI agents on one unified architecture and one data model. ServiceNow isn’t just another AI assistant or summarization tool. It’s the operating system for agentic AI.\nWatch the whiteboard session\nto see how it all connects. The ServiceNow AI Platform gives you the blueprint to simplify integration, accelerate innovation, and scale transformation—today.\nWhether you’re a partner designing AI-powered solutions or a customer reimagining how work gets done, now is the moment to\nmake AI, data, and workflows work together in every corner of your business\n.\n© 2025 ServiceNow, Inc. All rights reserved. ServiceNow, the ServiceNow logo, Now, and other ServiceNow marks are trademarks and/or registered trademarks of ServiceNow, Inc. in the United States and/or other countries. Other company names, product names, and logos may be trademarks of the respective companies with which they are associated.\n118\nShares\nTopics\nAI and Automation\nApplication Development\nCareers\nCrisis Management\nCulture\nCustomer Experience\nCustomer Stories\nCybersecurity and Risk\nEducation\nEmployee Experience\nEvents\nFinancial Services\nGovernment\nHealthcare\nIT Management\nManufacturing\nNow on Now\nServiceNow AI Platform\nTelecommunications\nFeatured\nOur shared table: Honoring service through food\nHow culture landed ServiceNow on Fortune World’s Best Workplaces list\nGetting real results from AI: Managing an agentic workforce\nTrends & Research\nServiceNow is again a Gartner-named Leader in CRM Customer Engagement Center\nServiceNow named a Leader by Gartner® in business orchestration and automation\nServiceNow is an IDC MarketScape Leader in AI-enabled aftermarket/service lifecycle and FSM\nYear\n2025\n2024\n2023\n2022"
  },
  {
    "title": "The new GBS frontier: Orchestration, scale, and AI by design",
    "date": "October 15, 2025",
    "link": "https://www.servicenow.com/blogs/2025/new-gbs-ai-design",
    "source": "Servicenow_blog",
    "main_ideas": [
      "Global business services (GBS) is evolving into a strategic platform for growth.",
      "Orchestration of workflows is essential for improving efficiency and customer experience.",
      "AI must be embedded in service delivery to enhance productivity and adaptability."
    ],
    "tags": [
      "global-business-services",
      "orchestration",
      "artificial-intelligence",
      "automation",
      "service-delivery",
      "customer-experience",
      "flexibility",
      "scalability",
      "service-now"
    ],
    "original_text": "The new GBS frontier: Orchestration, scale, and AI by design\nAlex August\nOctober 15, 2025\nAcross industries, one theme keeps coming up in my conversations with customers: Global business services (\nGBS\n) is no longer a back-office department—it’s a strategic platform for growth.\nToday’s enterprises need more than departmental consolidation or a shared services model. They require connected workflows built for global scale and powered by AI at every layer.\nForward-looking GBS leaders are focused on:\nOrchestrating work across fragmented systems\nDesigning for global scale with local nuance\nEmbedding AI into the core of service delivery, a necessity to scale\nLet’s take a closer look at what this means.\nFrom integration to orchestration\nAccording to\nEY\n, a lot of GBS models are stuck in integration mode, meaning they’re linking systems but leaving work fragmented. Employees and vendors are navigating multiple portals, entering the same data multiples times, and finding themselves stuck in a never-ending bottlenecked cycle.\nLeaders want to improve their processes. A GBS survey by\nDeloitte\nfound that 35% of respondents are intent on enhancing GBS customer experience over the next three years.\nThis new frontier is all about orchestration—streamlining workflows across the business and scaling tools and global locations with a single platform that enables automation, visibility, and consistency.\nThe\nServiceNow AI Platform\nis helping customers accelerate time to value by automating handoffs, creating consumer-grade experiences, and giving leaders real-time insights into workflow performance. It’s not just a better experience; it’s better governance and measurable efficiency.\nGlobal scale with local nuance\nGBS organizations are growing at a rapid pace in India, the U.S., and Poland, and emerging in Mexico and Portugal for continued development, according to Deloitte.\nAs enterprises expand globally, workflows and processes need to scale to match the needs of their growing organizations. But it’s not just about scaling. It’s about scaling smart. Processes and workflows must be streamlined and standardized—and have enough flexibility to support regional and cultural nuances, such as hiring laws and compliance needs.\nThe strongest GBS models are flexible and adaptable to meet localization in areas such as onboarding, procurement, payroll, and HR compliance, streamlining experiences for both employees and teams behind the scenes.\nGBS AI by design\nThere’s no question that AI is changing the game, but only when it’s implemented thoughtfully.\nAccording to Deloitte, 50% of organizations plan to prioritize next-generation capabilities, such as\ngenerative AI\n(GenAI) and intelligent automation.\nTrue value comes when AI is built into workflows, not bolted on after the fact. That’s why we focus on AI by design at ServiceNow, embedding both deterministic workflows (those that need a more predictable outcome, such as onboarding) and\nagentic AI\n(a more flexible output) into the service model itself.\nExamples include:\nUsing GenAI to draft knowledge base articles or policies\nEmploying intelligent agents to route or resolve cases based on real-time signals\nProviding predictive insights on where friction can be eliminated or resolution can be accelerated\nThis is what enables transformation and moves GBS from reactive to proactive.\nWhy it matters now\nThe business case for GBS is evolving. What was once thought of as a centralizing function to lower costs is now about driving better, faster, smarter outcomes across the enterprise.\nWhen orchestrated effectively, GBS becomes a platform that:\nConnects fragmented systems into unified experiences\nScales globally with built-in flexibility\nUses AI to increase productivity, accuracy, and satisfaction\nThis is the transformation we’re helping our customers lead, and it’s what we’re designing our product strategy around.\nFind out how ServiceNow can help\ncentralize your organization and streamline service delivery\n.\n© 2025 ServiceNow, Inc. All rights reserved. ServiceNow, the ServiceNow logo, Now, and other ServiceNow marks are trademarks and/or registered trademarks of ServiceNow, Inc. in the United States and/or other countries. Other company names, product names, and logos may be trademarks of the respective companies with which they are associated.\n132\nShares\nTopics\nAI and Automation\nApplication Development\nCareers\nCrisis Management\nCulture\nCustomer Experience\nCustomer Stories\nCybersecurity and Risk\nEducation\nEmployee Experience\nEvents\nFinancial Services\nGovernment\nHealthcare\nIT Management\nManufacturing\nNow on Now\nServiceNow AI Platform\nTelecommunications\nFeatured\nOur shared table: Honoring service through food\nHow culture landed ServiceNow on Fortune World’s Best Workplaces list\nGetting real results from AI: Managing an agentic workforce\nTrends & Research\nServiceNow is again a Gartner-named Leader in CRM Customer Engagement Center\nServiceNow named a Leader by Gartner® in business orchestration and automation\nServiceNow is an IDC MarketScape Leader in AI-enabled aftermarket/service lifecycle and FSM\nYear\n2025\n2024\n2023\n2022"
  },
  {
    "title": "In the Presence of the Minister of Energy, Cisco and King Abdullah University of Science and Technology (KAUST) launch landmark AI Institute to accelerate AI research, development, and talent in Saudi Arabia",
    "date": "Oct 29, 2025",
    "link": "https://newsroom.cisco.com/content/r/newsroom/en/us/a/y2025/m10/cisco-and-king-abdullah-university-of-science-and-technology-kaust-launch-landmark-ai-institute-to-accelerate-ai-research-development-and-talent-in-saudi-arabia.html",
    "description": "Cisco and KAUST launch a new AI Institute in Saudi Arabia, as a co-innovation center dedicated to AI research, development and education, to power the Kingdom’s AI future.",
    "source": "Cisco",
    "main_ideas": [
      "Cisco and KAUST launched an AI Institute to enhance AI research and education in Saudi Arabia.",
      "The initiative aims to support Saudi Arabia's Vision 2030 through innovation and talent development.",
      "The Institute will focus on applied research in AI, addressing critical sectors like energy and healthcare."
    ],
    "tags": [
      "artificial-intelligence",
      "cisco",
      "kaust",
      "saudi-arabia",
      "digital-transformation",
      "education",
      "innovation",
      "technology",
      "vision-2030"
    ],
    "original_text": "RIYADH, KSA – October 29, 2025 – In the presence of His Royal Highness Prince Abdulaziz bin Salman bin Abdulaziz, Minister of Energy and Chairman of the King Abdullah University of Science and Technology (KAUST) Board of Trustees, Cisco (NASDAQ: CSCO), the global leader in networking and security, and KAUST, the international graduate-level research university, today announced a significant expansion of their strategic collaboration with the establishment of a cutting-edge AI Institute. This initiative will bring together Cisco’s global leadership in networking, cybersecurity and cloud-scale artificial intelligence infrastructure with KAUST’s world-class academic research, advanced facilities, and pivotal role in education. The attendance of His Royal Highness underscores the national significance of the initiative in supporting Saudi Arabia’s ambitions in research, innovation, and talent development. Located at the KAUST campus in Saudi Arabia, the Institute will be dedicated to advancing AI research, development and education, representing a major milestone in fostering innovation and developing a highly skilled AI workforce within the Kingdom. Building on more than two decades of collaboration between Cisco and Saudi Arabia — and a shared vision for digital transformation — the new AI Institute at KAUST aims to become a cornerstone for AI innovation in the Kingdom, in alignment with Vision 2030. \"Our long-standing partnership with Cisco has been instrumental in realizing KAUST's vision,\" said KAUST President, Sir Edward Byrne AC. \"Since our inception, we have pioneered a digital-first approach, leveraging advanced technologies to redefine how our campus community connects, collaborates, and conducts research. The new AI Institute is crucial for equipping our students with the vital skills needed for the jobs of the future, directly aligning with the Kingdom’s Vision 2030, and reinforces our leadership in scientific and technological education and research.\" “To unlock the promise of AI, we must upskill the workforce to keep up with the rapid pace of innovation,” said Chuck Robbins, Cisco Chair and CEO. “AI is poised to unlock groundbreaking opportunities for economic growth, accelerating KSA's Vision 2030. The Cisco AI Institute at KAUST builds on our 25-year partnership with the Kingdom, with a shared vision to ensure everyone can harness AI's limitless potential in Saudi Arabia.” The Institute's agenda will focus on applied research for AI-native communication systems, advanced edge infrastructure for Industry 5.0, including intelligent factories, as well as autonomous mobility and intelligent transport systems. It will also prioritize AI-driven use cases addressing vital public-interest sectors including water, energy, food, and health. Cisco’s contributions to the Institute will include the donation of its latest technology, including a Cisco AI POD. This is a modular, pre-validated AI infrastructure solution, a ready-to-go AI “factory” that streamlines the process of building data centers to run complex AI workloads, enabling innovation to happen faster and more securely at scale. This initiative also aims to develop local AI talent, building on Cisco's recent commitment to provide free digital upskilling for 500,000 learners in Saudi Arabia over five years through Cisco Networking Academy, focusing on AI, cybersecurity, data science, and programming. This builds on the Academy's strong track record, having trained over 480,000 learners in KSA, with 36% female participation. The AI Institute is part of Cisco's Country Digital Acceleration (CDA) program that has been a driving force for digital transformation in Saudi Arabia since 2016, delivering 23 high-impact projects across vital sectors like healthcare, education, smart cities, and government services. The Institute will be overseen by a joint governing board comprising representatives from KAUST and Cisco, to provide strategic direction and collaborative oversight. About Cisco Cisco (NASDAQ: CSCO) is the worldwide technology leader that is revolutionizing the way organizations connect and protect in the AI era. For more than 40 years, Cisco has securely connected the world. With its industry leading AI-powered solutions and services, Cisco enables its customers, partners and communities to unlock innovation, enhance productivity and strengthen digital resilience. With purpose at its core, Cisco remains committed to creating a more connected and inclusive future for all. Discover more on The Newsroom and follow us on X at @Cisco . Cisco and the Cisco logo are trademarks or registered trademarks of Cisco and/or its affiliates in the U.S. and other countries. A listing of Cisco’s trademarks can be found at http://www.cisco.com/go/trademarks . Third-party trademarks mentioned are the property of their respective owners. The use of the word ‘partner’ does not imply a partnership relationship between Cisco and any other company. About King Abdullah University of Science and Technology (KAUST) Established in 2009, KAUST is a graduate research university devoted to finding solutions for some of the world’s most pressing scientific and technological challenges in the areas of food and health, water, energy, environment, and the digital domain. The University brings together the best minds and ideas from around the world with the goal of advancing science and technology through distinctive, collaborative research. KAUST is a catalyst for innovation, economic development and social prosperity in Saudi Arabia and the world. Visit www.kaust.edu.sa to learn more. For further information, please contact: Abdullah Alsobahi Director of Strategic Communications KAUST Global Branding and Communications +966(0) 54 027 2550 abdullah.alsobahi@kaust.edu.sa Media Contacts Rasha Zaki Public Relations +971 4 390 7804 razaki@cisco.com Justin Chinich Public Relations +1 908-812-7839 jchinich@cisco.com"
  },
  {
    "title": "Cisco & NVIDIA Deliver Neocloud, Enterprise & Telecom Innovation",
    "date": "Oct 28, 2025",
    "link": "https://newsroom.cisco.com/content/r/newsroom/en/us/a/y2025/m10/cisco-delivers-ai-networking-innovations-across-neocloud-enterprise-and-telecom-with-nvidia.html",
    "description": "Cisco becomes the first partner to offer a NVIDIA Cloud Partner compliant reference architecture with new data center switching solutions.",
    "source": "Cisco",
    "main_ideas": [
      "Cisco introduces the N9100 series switch, compliant with NVIDIA Cloud Partner architecture.",
      "The collaboration enhances AI infrastructure flexibility for enterprises and telecom providers.",
      "Cisco and NVIDIA unveil the first AI-native wireless stack for 6G networks."
    ],
    "tags": [
      "cisco",
      "nvidia",
      "ai-infrastructure",
      "cloud-computing",
      "telecom",
      "data-centers",
      "6g",
      "networking",
      "security",
      "neocloud"
    ],
    "original_text": "Cisco becomes the first partner to offer a NVIDIA Cloud Partner compliant reference architecture with new data center switching solutions. Together, Cisco and NVIDIA provide customers ultimate flexibility as they build critical AI infrastructure. News Summary: With the new Cisco N9100 series switch, Cisco now offers neocloud and sovereign cloud customers a NVIDIA Cloud Partner-compliant reference architecture, delivering a unified operating model with the flexibility of NX-OS or SONiC. Cisco is introducing the Cisco Cloud Reference Architecture for neocloud and sovereign cloud customers; the new offering is based on the tenets of the NVIDIA Cloud Partner reference architecture and utilizes Cisco Silicon One-based switches with embedded NVIDIA Spectrum-X capabilities. For enterprises, Cisco strengthens the Secure AI Factory with NVIDIA through advancements in compute, security, networking, observability, and new ecosystem partnerships. Cisco, NVIDIA, and other telecom industry partners unveil the first AI-native wireless stack for 6G, empowering telecom providers with a network transition path for the AI era. GTC, Washington D.C., Oct 28, 2025 — Cisco (NASDAQ: CSCO) today introduced major advancements to accelerate secure, scalable AI across market segments. Leading the announcements is the Cisco N9100 , the first NVIDIA partner-developed data center switch based on NVIDIA Spectrum-X Ethernet switch silicon. With this switch, Cisco is offering a NVIDIA Cloud Partner-compliant reference architecture for neocloud and sovereign cloud deployments. For enterprise customers, Cisco Secure AI Factory with NVIDIA , strengthened protection and visibility across AI deployments with new security and observability integrations. To pave the way for next-generation connectivity in the telecom industry, Cisco, NVIDIA and additional partners unveiled the industry’s first AI-native wireless stack for 6G . Together, these innovations offer neocloud, enterprise, and telecom customers the flexibility and interoperability to efficiently build, manage and secure AI infrastructure at scale. \"We're at the beginning of the largest data center build-out in history,” said Jeetu Patel, President and Chief Product Officer, Cisco. \"The infrastructure that will power the agentic AI applications and innovation of the future requires new architectures designed to overcome today's constraints in power, computing, and network performance. Together, Cisco and NVIDIA are leading the way in defining the technologies that will power these AI-ready data centers in all their varieties, from emerging neoclouds, to global service providers, to enterprises, and beyond.\" “NVIDIA Spectrum-X Ethernet delivers the performance of accelerated networking for Ethernet,” said Gilad Shainer, SVP of Networking at NVIDIA. “Working with Cisco’s Cloud Reference Architectures and NVIDIA Cloud Partner design principles, customers can choose to deploy Spectrum-X Ethernet using the newest Cisco N9100 series or Cisco Silicon One based switches to build open, high-performance AI networks.” A Portfolio for Any AI Workload Back-end and front-end Ethernet-based networks must be flexible enough to keep pace with rapid AI innovation, integrate seamlessly with existing infrastructure, and be simple to deploy and manage. Orderable before the end of the year, the Cisco N9100 series switches offer a choice of Cisco NX-OS or SONiC operating systems, advancing Ethernet for AI networks and offering greater flexibility in how neocloud and sovereign cloud customers build their AI infrastructure. With the N9100 as a foundation, Cisco will offer a NVIDIA Cloud Partner-compliant reference architecture. Cisco’s portfolio of Nexus data center switching solutions provides a unified operating model through Cisco Nexus Dashboard, across Silicon One, Cloud-scale ASICs, and now switches built on Spectrum-X Ethernet switch silicon. Additionally, for neocloud and sovereign cloud customers, the Cisco Cloud Reference Architecture is based on the design tenets of NVIDIA’s Cloud Partner reference architecture and utilizes Cisco’s Silicon One and Cloud-scale ASIC offerings. The reference architecture will also include the recently introduced Cisco 8223 based on the Silicon One P200 for scale-across networks, NVIDIA BlueField-4 DPUs, and NVIDIA ConnectX-9 SuperNICs . Cisco Secure AI Factory with NVIDIA: Built for performance, security, resiliency Since its unveiling at GTC in March 2025, the Cisco Secure AI Factory with NVIDIA has led the industry in offering enterprises a comprehensive architecture for AI infrastructure that puts security and observability at the forefront without sacrificing performance. With Cisco AI PODs and Cisco Silicon One-powered Nexus switching as a foundation, Cisco today is delivering new capabilities and features across: Security and Observability: Cisco AI Defense now integrates with NVIDIA NeMo Guardrails to deliver robust cybersecurity for AI applications. Cisco AI Defense is orderable for on-premises data-plane deployment enabling security and AI teams to protect AI models and applications, limiting the sensitive data that leaves their organization’s data centers. Also available, Splunk Observability Cloud helps teams to monitor the performance, quality, security, and cost of their AI application stack—including real-time insights into AI infrastructure health with Cisco AI PODs—while Splunk Enterprise Security extends this visibility to protect AI workloads. Core AI Infrastructure: Cisco Isovalent is now validated for inference workloads on AI PODs, enabling enterprise grade, high-performance Kubernetes networking. Cisco Nexus Hyperfabric AI with a new cloud-managed Cisco G200 Silicon One switch that delivers high-density 800G Ethernet, is now orderable as a deployment option in AI PODs. Cisco UCS 880A M8 rack servers with NVIDIA HG X B300 , and the Cisco UCS X-Series modular servers with NVIDIA RTX PRO 6000 Blackwell S erver Edition GPUs are also now orderable as part of AI PODs. This enables high-performance GPU support for a wide range of workloads including generative AI fine-tuning, inference and more. Ecosystem Expansion: NVIDIA Run:ai software is available through Cisco and its partners, enabling intelligent AI workload and GPU orchestration capabilities. Nutanix Kubernetes Platform (NKP) solution is now a supported Kubernetes platform, and Nutanix Unified Storage (NUS) solution is now a supported storage option, with Nutanix Enterprise AI (NAI) solution as the interoperable software component that simplifies building and operating containerized inference services. Government Readiness: Cisco is collaborating with NVIDIA and aligning to the new NVIDIA AI Factory for Government , a full-stack end-to-end reference design for AI workloads deployed in highly regulated environments. The First AI-native Wireless Stack – with Cisco at its Core As AI moves from smartphones to more connected things – augmented reality glasses, connected cars and robotics – wireless networks face mounting demand to support billions of connections at unprecedented scale and efficiency. To meet this challenge, Cisco, NVIDIA, and additional telecom partners have developed the first American AI-RAN stack for mobile networks that integrates sensing and communication, with multiple pre-6G applications being showcased at NVIDIA GTC DC. It allows telecom providers to infuse AI into their mobile networks, starting with 5G advanced services and establishes the groundwork for 6G. The stack combines Cisco’s user plane function and 5G core software with the NVIDIA AI Aerial platform , creating a foundation that enables physical AI and integrated sensing with unmatched efficiency and security. Cisco and NVIDIA: Moving AI Forward, Together Cisco and NVIDIA’s collaboration continues to accelerate, driven by a shared vision of an AI-powered future that is scalable, observable, and secure. The advancements announced today are a testament to Cisco’s relentless pursuit of innovation, that will accelerate AI adoption across enterprises, neoclouds and telecom providers. Industry Reactions: \"The real challenge in AI infrastructure isn't just performance—it's maintaining operational sanity as you scale from dozens to thousands of GPUs. Cisco's approach with NX-OS and Nexus Dashboard creates a single pane of glass across our entire AI fabric, whether we're optimizing inference latency in the front-end or maximizing training throughput in the back-end. That operational simplicity translates directly to faster deployments and lower TCO.\" – Xiaohe Hu, CEO, Infrawaves “Cisco’s N9100 series powered by NVIDIA Spectrum-X Ethernet switch silicon, provides a solution for high-performance, open infrastructure to meet our AI cloud demands. The capability to run NX-OS or SONiC under a unified operating model on Nexus Dashboard delivers more flexibility to our customers with operational simplicity. Its enterprise-grade networking with the scale and agility of the cloud — exactly what the next generation of AI workloads requires.” – Yih Leong Sun, Head of Infra, GMI Cloud \"As the demand for computing power continues to grow, our GPU clusters are expanding rapidly in scale. In ultra-large-scale GPU networks, we face various challenges such as congestion management and load balance. Cisco's NCP compliant reference architecture with N9100 Series switch provides us with the desired performance and openness out of the box. With the Cisco Nexus platform, we can fully leverage the AI networking capabilities of NVIDIA Spectrum-X Ethernet switch silicon without incurring additional operational or development costs and seamlessly integrate with our existing systems. We look forward to partnering with Cisco on this exciting journey ahead.” – Junfeng Cheng, Head of Networking Infrastructure, Xiaohongshu (RedNote) “World Wide Technology (WWT) clients know and trust Cisco networking in the enterprise data center. Bringing that together with the innovation of NVIDIA Spectrum-X Ethernet technology extends the value of our clients’ investment in the data center to now include AI workloads. This will be critical as our clients look to scale AI in the enterprise data center.” — Neil Anderson, VP and CTO Cloud, Infrastructure and AI Solutions at World Wide Technology (WWT) “BlueSky Compute is excited to be one of the first Neoclouds to deploy Cisco’s N9100 series switches for the scale-out fabric in our AI training clusters- powering our vision to turn AI into ROI for the world’s enterprises by building larger, more interconnected B300 clusters, faster. Cisco's NCP compliant reference architecture based on N9100 Series switch while maintaining the operational simplicity with Nexus Dashboard is a game-changer.” – Ian Hartley, CEO Bluesky Compute \"We've deployed thousands of GPUs across our customers' AI infrastructure, and network complexity has been our biggest scaling challenge. Cisco's Nexus N9100 series platform based on NVIDIA Spectrum-X Ethernet switch silicon directly addresses this with NCP RA compliance - giving us the performance we need with the openness we require. The unified Nexus operating model is particularly compelling as it maintains consistent operations. This flexibility to meet customers where they are, rather than forcing architectural decisions, is reshaping how customers approach AI infrastructure.\" – Thomas Berger, Computacenter “Shanghaj Lichan Co., Ltd., as an NVIDIA Cloud Partner, offers a comprehensive full-stack solution that integrates both hardware and software to power AI-driven cloud services. Our services include end-to-end capabilities, from consulting and planning, to testing, deployment, and implementation, as well as ongoing operations and maintenance. We are excited about the upcoming launch of the Cisco N9100 Series . We believe its unified operating model with Nexus Dashboard and NCP-compliant reference architecture will simplify deployments and scale our AI infrastructure more efficiently. This solution is designed to accelerate innovation, reduce costs, and deliver large-scale capabilities to our customers faster than ever before.” – Wendy Wu, Chairman, Shanghai Lichan Technology Co., Ltd. Additional Resources: Executive blog: Cisco Drives AI Networking Innovation with NVIDIA by Will Eatherton, SVP, Data Center, Internet & Cloud Infrastructure Engineering, Cisco Executive Blog: Cisco Nexus Delivers New AI Innovations with NVIDIA by Murali Gandluru, VP , Data Center Networking, Cisco Executive Blog: From AI Pilots to Production: Building Infrastructure That Makes AI Real by Jeremy Foster, SVP, Data Center Compute, Cisco Executive Blog: Leading the Next Era of Intelligent Connectivity by Masum Mir, SVP & GM, Cisco Provider Mobility Product blog: Cisco AI Defense Integrates with NVIDIA AI Enterprise Software to Secure AI Applications Using NVIDIA NeMo Guardrails Product blog: Unlocking AI Performance: Splunk Observability for Cisco Secure AI Factory with NVIDIA For more information on Cisco Cloud Reference Architectures, please visit: Cisco Hyperfabric AI Cloud Partner Reference Architecture Cisco Nexus 9000 Cloud Partner Reference Architecture ​​​​​​​ For more information on NVIDIA products and solutions, please visit: NVIDIA AI Factory for Government NVIDIA RTX PRO 6000 Blackwell Server Edition Series GPUs NVIDIA HGX B300 NVIDIA BlueField DPUs About Cisco Cisco (NASDAQ: CSCO) is the worldwide technology leader that is revolutionizing the way organizations connect and protect in the AI era. For more than 40 years, Cisco has securely connected the world. With its industry leading AI-powered solutions and services, Cisco enables its customers, partners and communities to unlock innovation, enhance productivity and strengthen digital resilience. With purpose at its core, Cisco remains committed to creating a more connected and inclusive future for all. Discover more on The Newsroom and follow us on X at @Cisco . Cisco and the Cisco logo are trademarks or registered trademarks of Cisco and/or its affiliates in the U.S. and other countries. A listing of Cisco’s trademarks can be found at http://www.cisco.com/go/trademarks. Third-party trademarks mentioned are the property of their respective owners. The use of the word ‘partner’ does not imply a partnership relationship between Cisco and any other company. Disclaimer: Many of the products and features mentioned are still in development and will be made available as they are finalized, subject to ongoing evolution in development and innovation. The timeline for their release is subject to change. Media Contacts Taylor Hassman Public Relations +1 415-610-6075 thassman@cisco.com"
  },
  {
    "title": "Cisco and G42 Deepen US-UAE Technology Partnership to Build  Secure, End-to-End AI Infrastructure in the UAE",
    "date": "Oct 28, 2025",
    "link": "https://newsroom.cisco.com/content/r/newsroom/en/us/a/y2025/m10/cisco-and-g42-deepen-us-uae-technology-partnership-to-build-secure-end-to-end-ai-infrastructure-in-the-uae.html",
    "description": "The announcement represents a significant step towards advancing secure AI infrastructure across UAE, aligned with the US-UAE AI Acceleration Partnership.",
    "source": "Cisco",
    "main_ideas": [
      "Cisco and G42 are enhancing secure AI infrastructure in the UAE.",
      "The partnership aligns with the US-UAE AI Acceleration Partnership goals.",
      "Cisco will integrate advanced AMD GPUs into G42's AI cluster.",
      "This initiative aims to close the GPU capacity gap in UAE organizations.",
      "The collaboration emphasizes transparency and compliance in AI technology."
    ],
    "tags": [
      "cisco",
      "g42",
      "artificial-intelligence",
      "us-uae-partnership",
      "amd",
      "ai-infrastructure",
      "digital-transformation",
      "gpu-capacity",
      "technology-partnership"
    ],
    "original_text": "News Summary: The announcement represents a significant step towards advancing secure AI infrastructure across UAE, aligned with the US-UAE AI Acceleration Partnership. Cisco will power, connect, and secure a large-scale AI cluster deployed by G42, featuring AMD’s advanced MI350X GPUs. The collaboration further embeds trusted US technology partners into G42’s AI infrastructure roadmap. SAN JOSE, Calif., ABU DHABI, UAE – October 28, 2025 – Cisco, the worldwide leader in networking and security, and G42, the UAE-based global leader in artificial intelligence, today announced a major expansion of their collaboration to advance secure AI infrastructure. This initiative is further evidence of Cisco’s long-term commitment to driving digital advances across the region, building secure, trusted and high-performance infrastructure for the AI era. A Trusted Foundation for the UAE’s AI Economy Cisco will power, connect, and secure a large-scale AI cluster deployed by G42, featuring AMD’s advanced MI350X GPUs. This deployment integrates Cisco’s full-stack, secure AI infrastructure, including compute, networking, security, storage, optics, as well as observability and analytics tools, delivering scalable performance and unified management for the region’s most advanced AI workloads. Cisco will also act as the technology integrator within G42’s Regulated Technology Environment (RTE), a gold-standard compliance and security framework designed to ensure that advanced compute infrastructure operates with the highest levels of protection, transparency, and governance, preventing unauthorized access, transfer, or misuse of advanced compute systems. The collaboration builds on joint efforts under the broader US–UAE AI Acceleration Partnership, a key program advancing bilateral technology goals, whose flagship projects include the 1GW Stargate UAE cluster undergoing construction in Abu Dhabi and the 5GW UAE-US AI technology campus that was announced during President Trump’s state visit to the UAE in May 2025. Peng Xiao, Group CEO of G42, said: “This collaboration with Cisco represents the next phase of deepening trust and technological alignment between the US and UAE under the AI Acceleration Partnership. It reinforces our shared commitment to building high-performance, secure, sovereign and compliant AI infrastructure that enables global innovation while upholding the highest standards of governance.” Chuck Robbins, Chair and CEO of Cisco, said: “Cisco is proud to deepen our partnership with G42, powering the UAE’s next wave of AI innovation by delivering secure, trusted, high-performance infrastructure. This collaboration strengthens the US-UAE AI Acceleration Partnership and underscores Cisco’s role in the UAE’s digital transformation journey. Together, we are building the foundation for a future driven by responsible and impactful innovation.” Dr. Lisa Su, Chair and CEO, AMD, said: “AMD is proud to partner with Cisco and G42 to power the next generation of AI infrastructure in the UAE. Our AMD Instinct MI350X accelerators deliver the performance, efficiency, and scalability needed to advance secure, sovereign AI innovation. This initiative strengthens the UAE’s position as a global leader in innovative AI development and demonstrates how technology initiatives like the US-UAE AI Acceleration Partnership can drive national digital ambitions.\" Driving the Region’s Digital Momentum According to Cisco’s latest AI research, 92% of organizations in the UAE plan to deploy AI agents, and 41% expect them to work alongside employees within a year. Yet only 25% have robust GPU capacity. It is a gap that this partnership aims to close by delivering scalable, secure AI infrastructure built for growth. With AI rapidly becoming the main driver of innovation, Cisco’s engagement in digital transformation across the UAE has never been more vital. This collaboration represents another bold step in Cisco’s strategy - turning innovation into impact and accelerating the region's digital future. Cisco’s Secure, End-to-End AI Infrastructure Cisco uniquely delivers an end-to-end AI-ready data center solution, combining compute, networking, security, automation and optics. The deployment will leverage Cisco’s end-to-end AI-ready data center portfolio , featuring Cisco UCS 885A servers equipped with AMD MI350X GPUs for compute, high-speed Nexus 9K 800G switches for networking, the VAST AI Operating System hosted on UCS servers, Firepower 4200 next-generation firewalls for security, Nexus Dashboard and Intersight for network automation and compute management. In addition, it will feature the latest Cisco optics to enable the highest performing and most reliable networks, and Cisco Advanced Services for planning, design, and implementation. The collaboration further strengthens G42’s network of trusted US technology partners contributing to the Regulated Technology Environment (RTE) framework, reinforcing a model grounded in transparency and accountability. G42 and Cisco will work in close coordination with relevant U.S. government agencies to obtain the necessary licenses and regulatory clearances for deployment, which is expected to advance in the coming months pending final approvals. About Cisco Cisco (NASDAQ: CSCO) is the worldwide technology leader that is revolutionizing the way organizations connect and protect in the AI era. For more than 40 years, Cisco has securely connected the world. With its industry leading AI-powered solutions and services, Cisco enables its customers, partners and communities to unlock innovation, enhance productivity and strengthen digital resilience. With purpose at its core, Cisco remains committed to creating a more connected and inclusive future for all. Discover more on The Newsroom and follow us on X at @Cisco . Cisco and the Cisco logo are trademarks or registered trademarks of Cisco and/or its affiliates in the U.S. and other countries. A listing of Cisco’s trademarks can be found at http://www.cisco.com/go/trademarks . Third-party trademarks mentioned are the property of their respective owners. The use of the word ‘partner’ does not imply a partnership relationship between Cisco and any other company. About G42 G42 is a technology holding group and a global leader in creating visionary artificial intelligence for a better tomorrow. Born in Abu Dhabi and operating worldwide, G42 champions AI as a powerful force for good across industries. From molecular biology to space exploration and everything in between, G42 realizes exponential possibilities today. To know more, visit www.g42.ai Media Contact For more information, please contact: G42@trailrunnerint.com Media Contacts Rasha Zaki Public Relations +971 4 390 7804 razaki@cisco.com Justin Chinich Public Relations +1 908-812-7839 jchinich@cisco.com"
  },
  {
    "title": "IBM Storage Scale 6000: Powering the AI Factory by Eliminating Data Silos and Delivering Breakthrough Performance",
    "date": "November 18, 2025",
    "link": "https://newsroom.ibm.com/blog-ibm-storage-scale-6000-powering-the-ai-factory-by-eliminating-data-silos-and-delivering-breakthrough-performance",
    "description": "An AI factory without data is like an engine without fuel; it simply can’t run. IBM Storage Scale System 6000 solves this by unifying data across edge, core, and cloud through its global...",
    "source": "Ibm",
    "main_ideas": [],
    "tags": [],
    "original_text": ""
  },
  {
    "title": "IBM Consulting Advantage Integrates with Microsoft Copilot to Drive Smarter, Faster Workflows with Enterprise AI",
    "date": "November 18, 2025",
    "link": "https://newsroom.ibm.com/blog-ibm-consulting-advantage-integrates-with-microsoft-copilot-to-drive-smarter,-faster-workflows-with-enterprise-ai",
    "description": "At the beginning of the year, I shared my belief that successful AI adoption depends on making AI easy to use within the processes and tools employees rely on every day. Today, I’m pleased to...",
    "source": "Ibm",
    "main_ideas": [],
    "tags": [],
    "original_text": ""
  },
  {
    "title": "Unanimous Decision: UFC and IBM Introduce New AI-Driven In-Fight Insights",
    "date": "November 14, 2025",
    "link": "https://newsroom.ibm.com/ufc-and-ibm-introduce-ai-driven-in-fight-insights",
    "description": "IBM (NYSE: IBM) and UFC, the world's premier mixed martial arts organization, today announced the next phase of their technological evolution with the launch of In-Fight Insights, an AI-driven live alert platform that monitors and reports in real time when notable milestones, streaks and records occur during UFC events. It is slated to debut at UFC® 322: DELLA MADDALENA vs. MAKHACHEV, which takes place at New York's Madison Square Garden this Saturday, November 15.",
    "source": "Ibm",
    "main_ideas": [],
    "tags": [],
    "original_text": ""
  },
  {
    "title": "IBM Study: Chief Data Officers Redefine Strategies as AI Ambitions Outpace Readiness",
    "date": "November 13, 2025",
    "link": "https://newsroom.ibm.com/2025-11-13-IBM-Study-Chief-Data-Officers-Redefine-Strategies-as-AI-Ambitions-Outpace-Readiness",
    "description": "A new global study by the IBM (NYSE: IBM) Institute for Business Value reveals enterprise data strategies are rapidly evolving as organizations race to scale AI across their business. The findings suggest that while Chief Data Officers (CDOs) are at the helm of this transformation, many say their data is still not ready to unlock AI's full potential.",
    "source": "Ibm",
    "main_ideas": [],
    "tags": [],
    "original_text": ""
  },
  {
    "title": "IBM Delivers New Quantum Processors, Software, and Algorithm Breakthroughs on Path to Advantage and Fault Tolerance",
    "date": "November 12, 2025",
    "link": "https://newsroom.ibm.com/2025-11-12-ibm-delivers-new-quantum-processors,-software,-and-algorithm-breakthroughs-on-path-to-advantage-and-fault-tolerance",
    "description": "At the annual Quantum Developer Conference, IBM (NYSE: IBM) today unveiled fundamental progress on its path to delivering both quantum advantage by the end of 2026 and fault-tolerant quantum computing by 2029.",
    "source": "Ibm",
    "main_ideas": [],
    "tags": [],
    "original_text": ""
  },
  {
    "title": "Getting real results from AI: Managing an agentic workforce",
    "date": "November 12, 2025",
    "link": "https://www.servicenow.com/blogs/2025/managing-agentic-workforce",
    "source": "Servicenow_blog",
    "main_ideas": [
      "AI has the potential to unlock over $4 trillion in global productivity gains.",
      "The agentic workforce is already present in enterprises, automating tasks and improving efficiency.",
      "Effective governance and leadership are essential for successful AI integration in organizations."
    ],
    "tags": [
      "artificial-intelligence",
      "agentic-workforce",
      "productivity",
      "governance",
      "automation",
      "service-now",
      "business-transformation",
      "enterprise-ai",
      "risk-management"
    ],
    "original_text": "Getting real results from AI: Managing an agentic workforce\nChris Bedi\nNovember 12, 2025\nAI has the potential to unlock more than $4 trillion in global productivity gains, according to\nMcKinsey\n. It can make us more efficient, help us scale faster, and ensure our talent has ample career growth pathways.\nYet the ServiceNow\nEnterprise AI Maturity Index 2025\nfound that the average AI maturity score slipped. While executives are excited about the technology's potential to boost productivity across the enterprise, only about one-third of respondents have reached at least the piloting stage for any\nagentic AI\nuse case.\nThe barrier isn’t technical. The models are good—and getting better. The barrier is structural. It’s mindset, leadership, and adoption.\nIt’s time to move the conversation from what could be to what is: The agentic workforce is here. It’s not in the future. It’s not in development. It’s in the enterprise today. Organizations pulling ahead in the AI race recognize this and are adapting the ways their businesses are structured, measured, and governed.\nThe agentic workforce, deployed\nThe agentic workforce is comprised of specialized\nAI agents\nthat are embedded in roles across functions. These AI agents automate tasks, yes. They also take on defined roles, complete workflows, make decisions, and improve with feedback.\nAI agents are part of the broad team that makes up the enterprise. They’re a core part of how business results are delivered.\nThat said, like any part of a team, they require structure, oversight, and direction. Although they’re not “co-workers” you’ll find at the watercooler, they still need managers.\nThe shift from tools to team\nIn this new hybrid working model, there’s no such thing as an individual contributor anymore. Every contributor is going to be managing a team of agents.\nAt ServiceNow, we’re handing off decisions to our AI models when reliability, risk, and oversight permit. This isn’t about an intriguing conversational AI agent with a great user interface. We power complex businesses. Data integration that takes into account multiple systems and workflows is a must.\nTaking this approach, we’ve reached a fully agentic\nautonomous IT service desk\n. We’ve long said that when 80% of a role could be done by the agentic workforce, talent and resources would be freed to work on more strategic efforts. We’ve blown past that goal and have reached 90% of IT support work fulfilled by AI agents.\nWe have not, as popular media would suggest, sent our service talent to the unemployment line. We’ve redeployed those workers to help our company grow. The company is better off, and the talent is happier.\nIn addition, since deploying our agentic workforce:\nLegal support requests have been\nresolved 80% faster\n. This has saved hours for our highly valuable legal talent, freeing teams to focus on more complex issues.\nSecurity risk assessments are\n66% more efficient\n. More than half of false positive phishing cases are resolved within 20 seconds, and incidents are closing seven times faster than without AI agents, significantly cutting downtime and business disruption.\nWe’ve reached\n99% speed gains\non our sellers’ commissions questions, nearly eliminating the need for request tickets. Instead of waiting up to four days, sellers can get answers in eight seconds, freeing them to focus on talking to customers.\nThis transformation is happening across sectors.\nIn healthcare, AI agents support scheduling and billing.\nIn finance, they streamline client onboarding and monitor risk.\nIn logistics, they rebalance inventory and reroute shipments in real time.\nGovernance and risk: Constraint to accelerator\nThe agentic workforce is powerful—but without structure, it’s also risky.\nGovernance\ncan‘t be an afterthought. It must be the foundation. If we expect these systems to carry business-critical responsibilities, we must treat them with the same care and discipline we apply to human teams.\nPoorly governed AI agents won’t fail dramatically; they’ll degrade quietly. They won’t call in sick, but as data shifts and conditions evolve, performance can slip. That’s why regular feedback loops, monitoring, and retraining are essential.\nAt ServiceNow, we’ve built\nAI Control Tower\nto help manage exactly that. It gives managers full visibility into which agents are active, what they’re doing, and how they’re performing. Metrics such as throughput, accuracy, sentiment, and system health are tracked.\nManagers can see when retraining is needed, when escalation is appropriate, and when agents are no longer adding value. This isn’t a tech feature. It’s workforce management. As on any team, quality doesn’t come from “set it and forget it.” It comes from leadership.\nToday, oversight might live with chief AI or analytics officers. In time, however, AI agent management will be part of every manager’s daily workflow, just like checking team dashboards or reviewing key performance indicators. Agentic performance will become part of our operating rhythm.\nSlow adoption isn’t conservatism. It’s risk.\nThe urgency isn’t just technical—it’s strategic.\nDeloitte\nfound that an incredible “89% of CEOs are exploring, piloting, or implementing agentic AI within their organizations.” Yet many organizations haven’t built the foundational governance or enterprise strategy to\nscale AI\nsafely. They haven’t started to address the mindset needed in their company cultures, either.\nMIT’s State of AI in Business study\ngot a few things right: The majority of businesses often try implementing AI without cohesion, get stuck in experimentation or limited deployment, and have poor integration of AI tools into their company workflows.\nEach of those scenarios is avoidable when leadership steps up. Many businesses are limiting themselves to easy use cases to drive quick value—but not transformation.\nThere are no shortcuts\nThis is not a case of “think bigger.” It’s a case of “do bigger.” It takes time and resources to deconstruct what each department and role does on a day-to-day basis and then reimagine it with the agentic workforce in mind. It’s time for leaders to see the possible, build alignment, and make it happen.\nThat said, business transformation isn’t only top-down work. The bottom-up work is building and embracing an AI culture for career growth. Talent will always play a critical role—defining responsibilities, training the systems, reviewing outputs, and stepping in when performance changes. Talent that isn’t open to AI or\nskilled in the tools\nmay get left behind.\nThis isn’t a call for rash and hurried adoption. It’s a call for deliberate readiness. The organizations pulling ahead aren’t waiting for a perfect use case. They’re building the infrastructure, accountability, and leadership mindset to support agentic teams at scale.\nThey’re picking a strategic metric that will boost their top line and reduce friction internally—such as revenue per employee—and running at it. They’re treating AI as a fully embedded part of their operating model, not simply a tool. They’re remembering the goals:\nStop using employees’ time for lower-order, repeatable tasks.\nBuild capacity and operational efficiency.\nPut AI to work for people.\nThe organizations defining the next era are building and embracing agentic AI that delivers. That’s how we power the future of work.\nFind out how ServiceNow can help you\nput AI agents to work for people\n.\n© 2025 ServiceNow, Inc. All rights reserved. ServiceNow, the ServiceNow logo, Now, and other ServiceNow marks are trademarks and/or registered trademarks of ServiceNow, Inc. in the United States and/or other countries. Other company names, product names, and logos may be trademarks of the respective companies with which they are associated.\n102\nShares\nTopics\nAI and Automation\nApplication Development\nCareers\nCrisis Management\nCulture\nCustomer Experience\nCustomer Stories\nCybersecurity and Risk\nEducation\nEmployee Experience\nEvents\nFinancial Services\nGovernment\nHealthcare\nIT Management\nManufacturing\nNow on Now\nServiceNow AI Platform\nTelecommunications\nFeatured\nOur shared table: Honoring service through food\nHow culture landed ServiceNow on Fortune World’s Best Workplaces list\nAutonomous IT at scale: How ServiceNow reengineered its service desk\nTrends & Research\nServiceNow is again a Gartner-named Leader in CRM Customer Engagement Center\nServiceNow named a Leader by Gartner® in business orchestration and automation\nServiceNow is an IDC MarketScape Leader in AI-enabled aftermarket/service lifecycle and FSM\nYear\n2025\n2024\n2023\n2022"
  },
  {
    "title": "Unipol Assicurazioni Leverages IBM watsonx to Build a New AI-driven Automation Platform",
    "date": "November 11, 2025",
    "link": "https://newsroom.ibm.com/2025-11-11-Unipol-Assicurazioni-Leverages-IBM-watsonx-to-Build-a-New-AI-driven-Automation-Platform",
    "description": "IBM and Unipol Assicurazioni, one of Europe’s largest insurance groups and leader in Italy in the non-life sector, are renewing their collaboration to continue the Company's digital transformation journey they embarked on over a year ago. This journey, starting with the adoption of hybrid cloud by design, is evolving towards strengthening the IT infrastructure with the new z17 technology and expanding AI capabilities directly onto production mainframe data.",
    "source": "Ibm",
    "main_ideas": [],
    "tags": [],
    "original_text": ""
  },
  {
    "title": "IBM and Web Summit to Launch Sports Tech Startup Challenge to Fuel Next Wave of Innovation in Sports",
    "date": "November 10, 2025",
    "link": "https://newsroom.ibm.com/ibm-x-web-summit-sports-tech-startup-challenge",
    "description": "IBM (NYSE: IBM) and Web Summit today unveiled a new global sports-tech competition proposal. The Sports Tech Startup Challenge will spotlight startups using AI to revolutionize sports — from athlete performance and stadium operations to fan engagement — with regional events planned for Qatar, Vancouver, and Rio, culminating with global winners being selected during Web Summit Lisbon 2026. Participation will be subject to local laws and official rules to be published before each regional competition.",
    "source": "Ibm",
    "main_ideas": [],
    "tags": [],
    "original_text": ""
  },
  {
    "title": "IBM Advances to Next Phase of DARPA Quantum Benchmarking Initiative",
    "date": "November 06, 2025",
    "link": "https://newsroom.ibm.com/2025-11-06-ibm-advances-to-next-phase-of-darpa-quantum-benchmarking-initiative",
    "description": "IBM (NYSE: IBM) today announced it has been selected for Stage B, the second of three stages of the Quantum Benchmarking Initiative led by DARPA, the United States Defense Advanced Research Projects Agency.",
    "source": "Ibm",
    "main_ideas": [],
    "tags": [],
    "original_text": ""
  },
  {
    "title": "IBM and Agassi Sports Entertainment Announce AI-Powered Platform to Advance Global Racquet Sports",
    "date": "November 05, 2025",
    "link": "https://newsroom.ibm.com/2025-11-05-ibm-and-agassi-sports-entertainment-announce-ai-powered-platform-to-advance-global-racquet-sports",
    "description": "Agassi Sports Entertainment (ASE) Corp. (OTC PINK: AASP) and IBM (NYSE: IBM) today announce a multi-year collaboration to transform the global racquet sports landscape through next generation artificial intelligence and digital innovation. They have signed a partnership agreement to bring together IBM’s technology and expertise with ASE’s vision for an innovative digital community across racquet sports.",
    "source": "Ibm",
    "main_ideas": [],
    "tags": [],
    "original_text": ""
  },
  {
    "title": "IBM Consulting Collaborates with Red Hat to Help Clients Usher in Era of Hybrid Cloud and AI Transformation at IBM Client Innovation Center",
    "date": "November 05, 2025",
    "link": "https://newsroom.ibm.com/blog-ibm-consulting-collaborates-with-red-hat-to-unveil-new-innovation-center-to-help-clients-usher-in-era-of-hybrid-cloud-and-ai-transformation",
    "description": "Today, IBM Consulting is excited to announce the opening of the inaugural Innovation Hub powered by Red Hat at IBM’s Client Innovation Center in Bengaluru, India. Clients across the globe can now experience the benefits of Red Hat technologies at the new Innovation Hub, designed to provide a state-of-the-art experience to help our mutual clients accelerate their enterprise transformation through hybrid cloud and AI.",
    "source": "Ibm",
    "main_ideas": [],
    "tags": [],
    "original_text": ""
  },
  {
    "title": "Autonomous IT at scale: How ServiceNow reengineered its service desk",
    "date": "November 05, 2025",
    "link": "https://www.servicenow.com/blogs/2025/autonomous-it-reengineered-service-desk",
    "source": "Servicenow_blog",
    "main_ideas": [
      "ServiceNow transformed its service desk into a fully autonomous IT engine.",
      "Achieved zero-touch Level 1 IT support, reducing resolution time significantly.",
      "Unified dashboard provides real-time insights across multiple departments."
    ],
    "tags": [
      "servicenow",
      "autonomous-it",
      "ai-platform",
      "workflow-automation",
      "it-management",
      "employee-experience",
      "business-agility",
      "data-driven",
      "customer-experience"
    ],
    "original_text": "Autonomous IT at scale: How ServiceNow reengineered its service desk\nSankha Nagchoudhury\nNovember 05, 2025\nIn today’s enterprise, IT leaders face a dual mandate: drive operational efficiency and enable strategic agility. At ServiceNow, we’ve embraced this challenge by transforming our\nservice desk\ninto a fully\nautonomous IT\nengine—one that both helps resolve issues and redefines how work flows across the business.\nOur journey began with modernizing IT for the IT team—streamlining operations, automating workflows, and proving the value of the\nServiceNow AI Platform\ninternally. But the real transformation started when we scaled horizontally into HR, legal, and finance, and then vertically into every function.\nThe autonomous IT service desk\nAs of September 2025, we’ve achieved zero-touch Level 1 IT support. This is much more than automation—it’s a strategic shift. Here’s how we got here:\nBusiness alignment:\nWe mapped IT objectives directly to enterprise goals, ensuring relevance and impact.\nPersona-based design:\nWe tailored our support solutions to user segments, improving accuracy and satisfaction.\nData-driven assessment:\nWe evaluated all interactions (T1 incidents and requests) and existing support systems to identify gaps and automation opportunities.\nRoadmap development:\nWe defined a clear path to move from reactive support to proactive service delivery.\nPrioritization of automation:\nWe targeted high-volume, low-effort tasks first to maximize our return on investment.\nWorkflow automation:\nWe built intelligent workflows and deployed them incrementally across departments.\nIncremental rollout:\nWe managed change in phases to ensure adoption and minimize disruption.\nThe result? All level 1 interactions—both incidents and requests—are resolved autonomously, freeing agents for strategic work and reducing resolution time from 75 minutes to less than 10.\nOne system of engagement for every employee\nIT leaders know that uptime is currency. The ServiceNow\nIT Operations Management\nsuite—\nService Observability\n,\nHealth Log Analytics\n,\nMetric Intelligence\n, and\nEvent Management\n—streams real-time signals from more than 12,000 apps, more than 5,000 servers, and 30,000 employees into a unified dashboard.\nThis enables predictive insight, root cause analysis, and proactive resolution—before issues affect business continuity.\nWe’ve consolidated fragmented service channels into a single, intuitive interface. Employees, from interns to executives, can ask anything and get fast, accurate support.\nNow Assist\nanswers questions, guides next steps, summarizes tickets, and prioritizes work.\nHyperpersonalization\ntailors support to individual roles and needs, improving satisfaction and productivity.\nCross-functional reach\nacross IT, HR, legal, procurement, and other areas is accessible through one front door.\nAn autonomous IT service desk isn’t a future vision—it’s a present reality at ServiceNow. For IT leaders, it’s a blueprint for transforming service delivery, amplifying human potential, and building an enterprise that runs smarter, faster, and more resiliently.\nFind out more about how ServiceNow can help you\nput AI to work with autonomous IT\n.\n© 2025 ServiceNow, Inc. All rights reserved. ServiceNow, the ServiceNow logo, Now, and other ServiceNow marks are trademarks and/or registered trademarks of ServiceNow, Inc. in the United States and/or other countries. Other company names, product names, and logos may be trademarks of the respective companies with which they are associated.\n31\nShares\nTopics\nAI and Automation\nApplication Development\nCareers\nCrisis Management\nCulture\nCustomer Experience\nCustomer Stories\nCybersecurity and Risk\nEducation\nEmployee Experience\nEvents\nFinancial Services\nGovernment\nHealthcare\nIT Management\nManufacturing\nNow on Now\nServiceNow AI Platform\nTelecommunications\nFeatured\nOur shared table: Honoring service through food\nHow culture landed ServiceNow on Fortune World’s Best Workplaces list\nGetting real results from AI: Managing an agentic workforce\nTrends & Research\nServiceNow is again a Gartner-named Leader in CRM Customer Engagement Center\nServiceNow named a Leader by Gartner® in business orchestration and automation\nServiceNow is an IDC MarketScape Leader in AI-enabled aftermarket/service lifecycle and FSM\nYear\n2025\n2024\n2023\n2022"
  },
  {
    "title": "When great minds collide: AI partnerships that spark joy",
    "date": "November 03, 2025",
    "link": "https://www.servicenow.com/blogs/2025/ai-partnerships-spark-joy",
    "source": "Servicenow_blog",
    "main_ideas": [
      "ServiceNow partners with tech giants to enhance AI capabilities for customers.",
      "Agentic AI is being adopted by executives to improve efficiency and innovation.",
      "The collaboration with AWS, Google Cloud, Microsoft, and NVIDIA drives AI transformation."
    ],
    "tags": [
      "ai",
      "automation",
      "cloud-computing",
      "servicenow",
      "nvidia",
      "google-cloud",
      "aws",
      "microsoft",
      "agentic-ai"
    ],
    "original_text": "When great minds collide: AI partnerships that spark joy\nServiceNow Blog\nNovember 03, 2025\nAt ServiceNow, we've forged powerful alliances with technology organizations that share our vision of limitless possibilities. Why? The reason is simple: to empower our customers with access to the best solutions.\nThese partnerships transcend traditional boundaries, combining the capabilities of the\nServiceNow AI Platform\nwith the expertise of industry giants to create a vibrant\npartner ecosystem\nin which innovation flourishes.\nAnswers to your burning AI questions\nWe recently sat down with leaders from four of our partners—\nAWS\n,\nGoogle Cloud\n,\nMicrosoft\n, and\nNVIDIA\n—to break down the most compelling possibilities of AI that can take workdays from mundane to magnificent.\nWatch this rapid-fire question-and-answer session for answers to:\nWhat do people really want from AI? (Hint: It’s not more buzzwords.)\nHow does cloud adoption supercharge AI transformation?\nWhat ingredients make a great AI solution?\nWhy are some enterprises hesitant to adopt AI?\nAI agents: Your workflow accelerators\nImagine AI that doesn’t just respond—it anticipates, acts, and accomplishes. That’s the power of\nagentic AI\n. The technology works autonomously on your behalf while you focus on what humans do best: creating and innovating.\nThe ServiceNow\nEnterprise AI Maturity Index 2025\nreveals that 43% of executives worldwide are doing more than just thinking about agentic AI. They're planning to adopt agentic solutions within the coming year to increase efficiency, enhance experiences, and empower employees.\nDiscover what happens when ServiceNow joins forces with visionary tech companies in this exciting space with answers to:\nHow does NVIDIA enhance\nServiceNow AI Agents\n?\nWhat makes ServiceNow and Google Cloud a dynamic duo?\nHow does the partnership between ServiceNow and AWS multiply benefits?\nHow is the ServiceNow-Microsoft partnership changing day-to-day work?\nThe future of work isn’t coming—it's here. And it offers new levels of simplicity and efficiency while delivering measurable outcomes that transform enterprises.\nFind out how ServiceNow can help\nput AI to work for your people\n.\n© 2025 ServiceNow, Inc. All rights reserved. ServiceNow, the ServiceNow logo, Now, and other ServiceNow marks are trademarks and/or registered trademarks of ServiceNow, Inc. in the United States and/or other countries. Other company names, product names, and logos may be trademarks of the respective companies with which they are associated.\nShares\nTopics\nAI and Automation\nApplication Development\nCareers\nCrisis Management\nCulture\nCustomer Experience\nCustomer Stories\nCybersecurity and Risk\nEducation\nEmployee Experience\nEvents\nFinancial Services\nGovernment\nHealthcare\nIT Management\nManufacturing\nNow on Now\nServiceNow AI Platform\nTelecommunications\nFeatured\nOur shared table: Honoring service through food\nHow culture landed ServiceNow on Fortune World’s Best Workplaces list\nGetting real results from AI: Managing an agentic workforce\nTrends & Research\nServiceNow is again a Gartner-named Leader in CRM Customer Engagement Center\nServiceNow named a Leader by Gartner® in business orchestration and automation\nServiceNow is an IDC MarketScape Leader in AI-enabled aftermarket/service lifecycle and FSM\nYear\n2025\n2024\n2023\n2022"
  },
  {
    "title": "Cisco To Participate in Wells Fargo TMT Summit",
    "date": "Nov 14, 2025",
    "link": "https://newsroom.cisco.com/content/r/newsroom/en/us/a/y2025/m11/cisco-to-participate-in-wells-fargo-tmt-summit.html",
    "description": "Cisco (NASDAQ: CSCO) today announced that it will participate in the Wells Fargo 9th Annual TMT Summit",
    "source": "Cisco",
    "main_ideas": [
      "Cisco will participate in the Wells Fargo 9th Annual TMT Summit.",
      "No new financial information will be discussed during the event.",
      "Cisco's EVP & CFO Mark Patterson will speak at the summit."
    ],
    "tags": [
      "cisco",
      "tmt-summit",
      "investor-relations",
      "technology",
      "ai",
      "financial-event",
      "mark-patterson"
    ],
    "original_text": "SAN JOSE, Calif., Nov 14, 2025\n– Cisco (NASDAQ: CSCO) today announced that it will participate in the Wells Fargo 9th Annual TMT Summit.\nNo new financial information will be discussed at this event\nFireside Chat\nTuesday, November 18, 2025\n9:30am-10:05am PST (webcast will be available on\ninvestor.cisco.com\n)\nCisco Speakers:\nMark Patterson, EVP & Chief Financial Officer\nDuring the conference, Cisco management and Investor Relations will also participate in Investor Meetings.\nAbout Cisco\nCisco (NASDAQ: CSCO) is the worldwide technology leader that is revolutionizing the way organizations connect and protect in the AI era. For more than 40 years, Cisco has securely connected the world. With its industry leading AI-powered solutions and services, Cisco enables its customers, partners and communities to unlock innovation, enhance productivity and strengthen digital resilience.  With purpose at its core, Cisco remains committed to creating a more connected and inclusive future for all. Discover more on\nThe Newsroom\nand follow us on X at\n@Cisco\n.\nCisco and the Cisco logo are trademarks or registered trademarks of Cisco and/or its affiliates in the U.S. and other countries. A listing of Cisco’s trademarks can be found at\nhttp://www.cisco.com/go/trademarks\n. Third-party trademarks mentioned are the property of their respective owners. The use of the word ‘partner’ does not imply a partnership relationship between Cisco and any other company.\n# # #\nMedia Contacts\nSami Badri\nInvestor Relations\n+1 469-420-4834\nsambadri@cisco.com\nRobyn Blum\nPublic Relations\nrojenkin@cisco.com"
  },
  {
    "title": "Cisco Reports First Quarter Earnings",
    "date": "Nov 12, 2025",
    "link": "https://newsroom.cisco.com/content/r/newsroom/en/us/a/y2025/m11/cisco-reports-first-quarter-earnings.html",
    "description": "Cisco reported first quarter revenue of $14.9 billion, net income on a generally accepted accounting principles (GAAP) basis of $2.9 billion or $0.72 per share, and non-GAAP net income of $4.0 billion or $1.00 per share.",
    "source": "Cisco",
    "main_ideas": [
      "Cisco reported first quarter revenue of $14.9 billion, an 8% increase year over year.",
      "GAAP net income was $2.9 billion, or $0.72 per share, reflecting a 6% increase.",
      "Strong demand for Cisco's technologies, particularly in AI infrastructure and networking products."
    ],
    "tags": [
      "cisco",
      "earnings",
      "financial-results",
      "ai-infrastructure",
      "networking",
      "revenue-growth",
      "technology",
      "stock-market",
      "gaap"
    ],
    "original_text": "SAN JOSE, Calif., November 12, 2025 -- News Summary: Strong top and bottom-line growth, exceeding our guidance and delivering continued operating leverage Revenue of $14.9 billion, up 8% year over year; GAAP EPS of $0.72, up 6% year over year; and Non-GAAP EPS of $1.00, up 10% year over year, above the high end of our guidance ranges and demonstrating solid operating leverage GAAP gross margin of 65.5% and Non-GAAP gross margin of 68.1%; GAAP operating margin of 22.6% and Non-GAAP operating margin of 34.4%, both above the high end of our guidance ranges Growth in product orders across all geographies and customer markets, demonstrating strong demand for Cisco's technologies Product orders up 13% year over year, with double-digit growth in Networking product orders for the fifth consecutive quarter AI Infrastructure orders taken from hyperscaler customers totaled $1.3 billion, reflecting a significant acceleration in growth Major multi-year, multi-billion-dollar campus networking refresh cycle underway All technologies within campus networking (switching, routing, wireless and IoT) saw accelerated order growth in Q1 All next-generation solutions including smart switches, secure routers and WiFi 7 products are ramping faster than prior product launches Q1 FY 2026 Results: Revenue: $14.9 billion Increase of 8% year over year Earnings per Share: GAAP: $0.72; Non-GAAP: $1.00 GAAP EPS increased 6% year over year Non-GAAP EPS increased 10% year over year Q2 FY 2026 Guidance (1) : Revenue: $15.0 billion to $15.2 billion Earnings per Share: GAAP: $0.69 to $0.74; Non-GAAP: $1.01 to $1.03 FY 2026 Guidance (1) : Revenue: $60.2 billion to $61.0 billion Earnings per Share: GAAP: $2.87 to $2.98; Non-GAAP: $4.08 to $4.14 (1) Margin and EPS guidance includes the estimated impact of tariffs based on current trade policy. Cisco today reported first quarter results for the period ended October 25, 2025. Cisco reported first quarter revenue of $14.9 billion, net income on a generally accepted accounting principles (GAAP) basis of $2.9 billion or $0.72 per share, and non-GAAP net income of $4.0 billion or $1.00 per share. \"We had a solid start to fiscal 2026, and Cisco is on track to deliver our strongest year yet,\" said Chuck Robbins, chair and CEO of Cisco. \"The widespread demand for our technologies highlights the critical role of secure networking and the value of our portfolio as customers move quickly to unlock the potential of AI.\" \"We delivered a strong quarter, with top and bottom-line performance exceeding our guidance, as well as solid margins and operating cash flow,\" said Mark Patterson, CFO of Cisco. \"Our relevance in AI continues to build and we have a multi-year, multi-billion-dollar campus refresh opportunity starting to ramp, with strong demand for our refreshed networking products. Looking ahead, you can expect a continued focus on profitable growth, capital returns, and strategic investments to capture the significant opportunities ahead.\" GAAP Results Q1 FY 2026 Q1 FY 2025 Vs. Q1 FY 2025 Revenue $ 14.9 billion $ 13.8 billion 8 % Net Income $ 2.9 billion $ 2.7 billion 5 % Diluted Earnings per Share (EPS) $ 0.72 $ 0.68 6 % Non-GAAP Results Q1 FY 2026 Q1 FY 2025 Vs. Q1 FY 2025 Net Income $ 4.0 billion $ 3.7 billion 9 % EPS $ 1.00 $ 0.91 10 % Reconciliations between net income, EPS, and other measures on a GAAP and non-GAAP basis are provided in the tables located in the section entitled \"Reconciliations of GAAP to non-GAAP Measures.\" Cisco Declares Quarterly Dividend Cisco has declared a quarterly dividend of $0.41 per common share to be paid on January 21, 2026, to all stockholders of record as of the close of business on January 2, 2026. Future dividends will be subject to Board approval. Financial Summary All comparative percentages are on a year-over-year basis unless otherwise noted. Q1 FY 2026 Highlights Revenue -- Total revenue was $14.9 billion, up 8%, with product revenue up 10% and services revenue up 2%. Revenue by geographic segment was: Americas up 9%, EMEA up 5%, and APJC up 5%. Product revenue performance reflected growth in Networking up 15% and Observability up 6%. Security was down 2% and Collaboration was down 3%. Gross Margin -- On a GAAP basis, total gross margin, product gross margin, and services gross margin were 65.5%, 64.5%, and 68.4%, respectively, as compared with 65.9%, 65.1%, and 68.0%, respectively, in the first quarter of fiscal 2025. On a non-GAAP basis, total gross margin, product gross margin, and services gross margin were 68.1%, 67.2%, and 70.7%, respectively, as compared with 69.3%, 68.9%, and 70.3%, respectively, in the first quarter of fiscal 2025. Total gross margins by geographic segment were: 66.8% for the Americas, 71.9% for EMEA and 66.9% for APJC. Operating Expenses -- On a GAAP basis, operating expenses were $6.4 billion, down 6% year over year, and were 42.9% of revenue. Non-GAAP operating expenses were $5.0 billion, up 3%, and were 33.7% of revenue. Operating Income -- GAAP operating income was $3.4 billion, up 43%, with GAAP operating margin of 22.6%. Non-GAAP operating income was $5.1 billion, up 8%, with non-GAAP operating margin at 34.4%. Provision for Income Taxes -- The GAAP tax provision rate was 15.7%. The non-GAAP tax provision rate was 19.0%. Net Income and EPS -- On a GAAP basis, net income was $2.9 billion, an increase of 5%, and EPS was $0.72, an increase of 6%. On a non-GAAP basis, net income was $4.0 billion, an increase of 9%, and EPS was $1.00, an increase of 10%. Cash Flow from Operating Activities -- $3.2 billion for the first quarter of fiscal 2026, a decrease of 12%, compared with $3.7 billion for the first quarter of fiscal 2025. Balance Sheet and Other Financial Highlights Cash and Cash Equivalents and Investments -- $15.7 billion at the end of the first quarter of fiscal 2026, compared with $16.1 billion at the end of fiscal 2025. Remaining Performance Obligations (RPO) -- $42.9 billion, up 7% in total. Product RPO was up 10%, of which long-term RPO was $11.8 billion, up 13%. Services RPO was up 4%. Deferred Revenue -- $28.0 billion, up 2% in total, with deferred product revenue up 2% and deferred services revenue up 1%. Capital Allocation -- In the first quarter of fiscal 2026, we returned $3.6 billion to stockholders through share buybacks and dividends. We declared and paid a cash dividend of $0.41 per common share, or $1.6 billion, and repurchased approximately 29 million shares of common stock under our stock repurchase program at an average price of $68.28 per share for an aggregate purchase price of $2.0 billion. The remaining authorized amount for stock repurchases under the program is $12.2 billion with no termination date. Acquisitions In the first quarter of fiscal 2026, we closed the acquisition of Aura Asset Intelligence, an asset and risk intelligence (ARI) solution created by Discovered Intelligence, a privately held company based in Toronto, Canada. Guidance Cisco estimates the following results for the second quarter of fiscal 2026: Q2 FY 2026 Revenue $15.0 billion - $15.2 billion Non-GAAP gross margin 67.5% - 68.5% Non-GAAP operating margin 33.5% - 34.5% Non-GAAP EPS $1.01 - $1.03 Margin and EPS guidance includes the estimated impact of tariffs based on current trade policy. Cisco estimates that GAAP EPS will be $0.69 to $0.74 for the second quarter of fiscal 2026. Cisco estimates the following results for fiscal 2026: FY 2026 Revenue $60.2 billion - $61.0 billion Non-GAAP EPS $4.08 - $4.14 Margin and EPS guidance includes the estimated impact of tariffs based on current trade policy. Cisco estimates that GAAP EPS will be $2.87 to $2.98 for fiscal 2026. Our Q2 FY 2026 guidance assumes an effective tax provision rate of approximately 16% for GAAP and approximately 19% for non-GAAP results. Our FY 2026 guidance assumes an effective tax provision rate of approximately 17% for GAAP and approximately 19% for non-GAAP results. A reconciliation between the guidance on a GAAP and non-GAAP basis is provided in the tables entitled \"GAAP to non-GAAP Guidance\" located in the section entitled \"Reconciliations of GAAP to non-GAAP Measures.\" Editor's Notes: Q1 fiscal year 2026 conference call to discuss Cisco's results along with its guidance will be held on Wednesday, November 12, 2025 at 1:30 p.m. Pacific Time. Conference call number is 1-888-848-6507 (United States) or 1-212-519-0847 (international). Conference call replay will be available from 4:00 p.m. Pacific Time, November 12, 2025 to 10:00 p.m. Pacific Time, November 18, 2025 at 1-800-839-2232 (United States) or 1-203-369-3662 (international). The replay will also be available via webcast on the Cisco Investor Relations website at https://investor.cisco.com. Additional information regarding Cisco's financials, as well as a webcast of the conference call with visuals designed to guide participants through the call, will be available at 1:30 p.m. Pacific Time, November 12, 2025. Text of the conference call's prepared remarks will be available within 24 hours of completion of the call. The webcast will include both the prepared remarks and the question-and-answer session. This information, along with the GAAP to non-GAAP reconciliation information, will be available on the Cisco Investor Relations website at https://investor.cisco.com. CISCO SYSTEMS, INC. CONSOLIDATED STATEMENTS OF OPERATIONS (In millions, except per-share amounts) (Unaudited) Three Months Ended October 25, 2025 October 26, 2024 REVENUE: Product $ 11,077 $ 10,114 Services 3,806 3,727 Total revenue 14,883 13,841 COST OF SALES: Product 3,934 3,526 Services 1,204 1,194 Total cost of sales 5,138 4,720 GROSS MARGIN 9,745 9,121 OPERATING EXPENSES: Research and development 2,400 2,286 Sales and marketing 2,871 2,752 General and administrative 733 795 Amortization of purchased intangible assets 231 265 Restructuring and other charges 147 665 Total operating expenses 6,382 6,763 OPERATING INCOME 3,363 2,358 Interest income 222 286 Interest expense (350) (418) Other income (loss), net 156 41 Interest and other income (loss), net 28 (91) INCOME BEFORE PROVISION FOR INCOME TAXES 3,391 2,267 Provision for (benefit from) income taxes 531 (444) NET INCOME $ 2,860 $ 2,711 Net income per share: Basic $ 0.72 $ 0.68 Diluted $ 0.72 $ 0.68 Shares used in per-share calculation: Basic 3,956 3,990 Diluted 3,993 4,013 CISCO SYSTEMS, INC. REVENUE BY SEGMENT (In millions, except percentages) Three Months Ended October 25, 2025 Amount Y/Y % Revenue : Americas $ 8,989 9 % EMEA 3,784 5 % APJC 2,111 5 % Total $ 14,883 8 % Amounts may not sum and percentages may not recalculate due to rounding. CISCO SYSTEMS, INC. GROSS MARGIN PERCENTAGE BY SEGMENT (In percentages) Three Months Ended October 25, 2025 Gross Margin Percentage : Americas 66.8 % EMEA 71.9 % APJC 66.9 % CISCO SYSTEMS, INC. REVENUE FOR GROUPS OF SIMILAR PRODUCTS AND SERVICES (In millions, except percentages) Three Months Ended October 25, 2025 Amount Y/Y % Revenue : Networking $ 7,768 15 % Security 1,980 (2) % Collaboration 1,055 (3) % Observability 274 6 % Total Product 11,077 10 % Services 3,806 2 % Total $ 14,883 8 % Amounts may not sum and percentages may not recalculate due to rounding. CISCO SYSTEMS, INC. CONDENSED CONSOLIDATED BALANCE SHEETS (In millions) (Unaudited) October 25, 2025 July 26, 2025 ASSETS Current assets: Cash and cash equivalents $ 8,400 $ 8,346 Investments 7,336 7,764 Accounts receivable, net of allowance of $62 at October 25, 2025 and $69 at July 26, 2025 4,827 6,701 Inventories 3,395 3,164 Financing receivables, net 3,085 3,061 Other current assets 5,833 5,950 Total current assets 32,876 34,986 Property and equipment, net 2,248 2,113 Financing receivables, net 3,719 3,466 Goodwill 59,119 59,136 Purchased intangible assets, net 8,713 9,175 Deferred tax assets 7,314 7,356 Other assets 7,113 6,059 TOTAL ASSETS $ 121,102 $ 122,291 LIABILITIES AND EQUITY Current liabilities: Short-term debt $ 6,725 $ 5,232 Accounts payable 2,418 2,528 Income taxes payable 2,471 1,857 Accrued compensation 3,064 3,611 Deferred revenue 15,801 16,416 Other current liabilities 4,972 5,420 Total current liabilities 35,451 35,064 Long-term debt 21,364 22,861 Income taxes payable 2,172 2,165 Deferred revenue 12,168 12,363 Other long-term liabilities 3,074 2,995 Total liabilities 74,229 75,448 Total equity 46,873 46,843 TOTAL LIABILITIES AND EQUITY $ 121,102 $ 122,291 CISCO SYSTEMS, INC. CONSOLIDATED STATEMENTS OF CASH FLOWS (In millions) (Unaudited) Three Months Ended October 25, 2025 October 26, 2024 Cash flows from operating activities: Net income $ 2,860 $ 2,711 Adjustments to reconcile net income to net cash provided by operating activities: Depreciation, amortization, and other 606 789 Share-based compensation expense 1,055 827 Provision for (benefit from) receivables (3) (1) Deferred income taxes 25 (281) (Gains) losses on divestitures, investments and other, net (178) (60) Change in operating assets and liabilities, net of effects of acquisitions and divestitures: Accounts receivable 1,857 2,227 Inventories (234) 229 Financing receivables (312) 173 Other assets (592) (190) Accounts payable (108) (269) Income taxes, net (128) (806) Accrued compensation (539) (754) Deferred revenue (723) (971) Other liabilities (374) 37 Net cash provided by operating activities 3,212 3,661 Cash flows from investing activities: Purchases of investments (1,984) (1,775) Proceeds from sales of investments 1,269 1,490 Proceeds from maturities of investments 1,222 1,164 Acquisitions, net of cash and cash equivalents acquired and divestitures (7) (217) Purchases of investments in privately held companies (18) (42) Return of investments in privately held companies 19 77 Acquisition of property and equipment (323) (217) Other (22) (1) Net cash provided by investing activities 156 479 Cash flows from financing activities: Repurchases of common stock - repurchase program (1,992) (2,003) Shares repurchased for tax withholdings on vesting of restricted stock units (284) (165) Short-term borrowings, original maturities of 90 days or less, net 1,260 68 Issuances of debt 1,559 5,732 Repayments of debt (2,788) (4,821) Dividends paid (1,617) (1,592) Other (1) (3) Net cash used in financing activities (3,863) (2,784) Effect of foreign currency exchange rate changes on cash, cash equivalents, restricted cash and restricted cash equivalents (14) 10 Net increase (decrease) in cash, cash equivalents, restricted cash and restricted cash equivalents (509) 1,366 Cash, cash equivalents, restricted cash and restricted cash equivalents, beginning of period 8,910 8,842 Cash, cash equivalents, restricted cash and restricted cash equivalents, end of period $ 8,401 $ 10,208 Supplemental cash flow information: Cash paid for interest $ 616 $ 545 Cash paid for income taxes, net $ 634 $ 643 CISCO SYSTEMS, INC. REMAINING PERFORMANCE OBLIGATIONS (In millions, except percentages) October 25, 2025 July 26, 2025 October 26, 2024 Amount Y/Y% Amount Y/Y% Amount Y/Y% Product (1) $ 21,904 10 % $ 21,572 8 % $ 19,882 24 % Services 20,969 4 % 21,961 5 % 20,108 7 % Total $ 42,873 7 % $ 43,533 6 % $ 39,990 15 % (1) As of the end of the first quarter of fiscal 2026, long-term product RPO was $11.8B, up 13% year over year. CISCO SYSTEMS, INC. DEFERRED REVENUE (In millions) October 25, 2025 July 26, 2025 October 26, 2024 Deferred revenue: Product $ 13,252 $ 13,490 $ 12,941 Services 14,717 15,289 14,561 Total $ 27,969 $ 28,779 $ 27,502 Reported as: Current $ 15,801 $ 16,416 $ 15,615 Noncurrent 12,168 12,363 11,887 Total $ 27,969 $ 28,779 $ 27,502 CISCO SYSTEMS, INC. DIVIDENDS PAID AND REPURCHASES OF COMMON STOCK (In millions, except per-share amounts) DIVIDENDS STOCK REPURCHASE PROGRAM TOTAL Quarter Ended Per Share Amount Shares Weighted- Average Price per Share Amount Amount Fiscal 2026 October 25, 2025 $ 0.41 $ 1,617 29 $ 68.28 $ 2,001 $ 3,618 Fiscal 2025 July 26, 2025 $ 0.41 $ 1,625 19 $ 64.65 $ 1,252 $ 2,877 April 26, 2025 $ 0.41 $ 1,627 25 $ 59.78 $ 1,504 $ 3,131 January 25, 2025 $ 0.40 $ 1,593 21 $ 58.58 $ 1,236 $ 2,829 October 26, 2024 $ 0.40 $ 1,592 40 $ 49.56 $ 2,003 $ 3,595 CISCO SYSTEMS, INC. RECONCILIATIONS OF GAAP TO NON-GAAP MEASURES GAAP TO NON-GAAP NET INCOME (In millions) Three Months Ended October 25, 2025 October 26, 2024 GAAP net income $ 2,860 $ 2,711 Adjustments to cost of sales: Share-based compensation expense 150 131 Amortization of acquisition-related intangible assets 233 319 Acquisition/divestiture-related costs 8 19 Total adjustments to GAAP cost of sales 391 469 Adjustments to operating expenses: Share-based compensation expense 884 679 Amortization of acquisition-related intangible assets 231 265 Acquisition/divestiture-related costs 103 285 Significant asset impairments and restructurings 147 665 Total adjustments to GAAP operating expenses 1,365 1,894 Adjustments to interest and other income (loss), net: (Gains) and losses on investments (195) (98) Total adjustments to GAAP interest and other income (loss), net (195) (98) Total adjustments to GAAP income before provision for income taxes 1,561 2,265 Income tax effect of non-GAAP adjustments (337) (476) Significant tax matters (73) (829) Total adjustments to GAAP provision for income taxes (410) (1,305) Non-GAAP net income $ 4,011 $ 3,671 CISCO SYSTEMS, INC. RECONCILIATIONS OF GAAP TO NON-GAAP MEASURES GAAP TO NON-GAAP EPS Three Months Ended October 25, 2025 October 26, 2024 GAAP EPS $ 0.72 $ 0.68 Adjustments to GAAP: Share-based compensation expense 0.26 0.20 Amortization of acquisition-related intangible assets 0.12 0.15 Acquisition/divestiture-related costs 0.03 0.08 Significant asset impairments and restructurings 0.04 0.17 (Gains) and losses on investments (0.05) (0.02) Income tax effect of non-GAAP adjustments (0.08) (0.12) Significant tax matters (0.02) (0.21) Non-GAAP EPS $ 1.00 $ 0.91 Amounts may not sum due to rounding. CISCO SYSTEMS, INC. RECONCILIATIONS OF GAAP TO NON-GAAP MEASURES GROSS MARGINS, OPERATING EXPENSES, OPERATING MARGINS, INTEREST AND OTHER INCOME (LOSS), NET, AND NET INCOME (In millions, except percentages) Three Months Ended October 25, 2025 Product Gross Margin Services Gross Margin Total Gross Margin Operating Expenses Y/Y Operating Income Y/Y Interest and other income (loss), net Net Income Y/Y GAAP amount $ 7,143 $ 2,602 $ 9,745 $ 6,382 (6) % $ 3,363 43 % $ 28 $ 2,860 5 % % of revenue 64.5 % 68.4 % 65.5 % 42.9 % 22.6 % 0.2 % 19.2 % Adjustments to GAAP amounts: Share-based compensation expense 68 82 150 884 1,034 — 1,034 Amortization of acquisition-related intangible assets 233 — 233 231 464 — 464 Acquisition/divestiture-related costs 2 6 8 103 111 — 111 Significant asset impairments and restructurings — — — 147 147 — 147 (Gains) and losses on investments — — — — — (195) (195) Income tax effect/significant tax matters — — — — — — (410) Non-GAAP amount $ 7,446 $ 2,690 $ 10,136 $ 5,017 3 % $ 5,119 8 % $ (167) $ 4,011 9 % % of revenue 67.2 % 70.7 % 68.1 % 33.7 % 34.4 % (1.1) % 27.0 % Three Months Ended October 26, 2024 Product Gross Margin Services Gross Margin Total Gross Margin Operating Expenses Operating Income Interest and other income (loss), net Net Income GAAP amount $ 6,588 $ 2,533 $ 9,121 $ 6,763 $ 2,358 $ (91) $ 2,711 % of revenue 65.1 % 68.0 % 65.9 % 48.9 % 17.0 % (0.7) % 19.6 % Adjustments to GAAP amounts: Share-based compensation expense 57 74 131 679 810 — 810 Amortization of acquisition-related intangible assets 319 — 319 265 584 — 584 Acquisition/divestiture-related costs 5 14 19 285 304 — 304 Significant asset impairments and restructurings — — — 665 665 — 665 (Gains) and losses on investments — — — — — (98) (98) Income tax effect/significant tax matters — — — — — — (1,305) Non-GAAP amount $ 6,969 $ 2,621 $ 9,590 $ 4,869 $ 4,721 $ (189) $ 3,671 % of revenue 68.9 % 70.3 % 69.3 % 35.2 % 34.1 % (1.4) % 26.5 % Amounts may not sum and percentages may not recalculate due to rounding. CISCO SYSTEMS, INC. RECONCILIATIONS OF GAAP TO NON-GAAP MEASURES EFFECTIVE TAX RATE (In percentages) Three Months Ended October 25, 2025 October 26, 2024 GAAP effective tax rate 15.7 % (19.6) % Total adjustments to GAAP provision for income taxes 3.3 % 38.6 % Non-GAAP effective tax rate 19.0 % 19.0 % GAAP TO NON-GAAP GUIDANCE Q2 FY 2026 Gross Margin Rate Operating Margin Rate Earnings per Share (1) GAAP 65% - 66% 22.5% - 23.5% $0.69 - $0.74 Estimated adjustments for: Share-based compensation expense 1.0 % 7.0 % $0.18 - $0.19 Amortization of acquisition-related intangible assets and acquisition/divestiture-related costs 1.5 % 3.5 % $0.11 - $0.12 Significant asset impairments and restructurings — 0.5 % $0.00 - $0.01 Non-GAAP 67.5% - 68.5% 33.5% - 34.5% $1.01 - $1.03 FY 2026 Earnings per Share (1) GAAP $2.87 - $2.98 Estimated adjustments for: Share-based compensation expense $0.75 - $0.77 Amortization of acquisition-related intangible assets and acquisition/divestiture-related costs $0.43 - $0.45 Significant asset impairments and restructurings $0.03 - $0.04 (Gains) and losses on investments ($0.03) Significant tax matters ($0.02) Non-GAAP $4.08 - $4.14 (1) Estimated adjustments to GAAP earnings per share are shown after income tax effects. Margin and EPS guidance includes the estimated impact of tariffs based on current trade policy. Except as noted above, this guidance does not include the effects of any future acquisitions/divestitures, significant asset impairments and restructurings, significant litigation settlements and other contingencies, gains and losses on investments, significant tax matters, or other items, which may or may not be significant. Forward Looking Statements, Non-GAAP Information and Additional Information This release may be deemed to contain forward-looking statements, which are subject to the safe harbor provisions of the Private Securities Litigation Reform Act of 1995. These forward-looking statements include, among other things, statements regarding future events (such as the widespread demand for our technologies highlighting the critical role of secure networking and the value of our portfolio as customers move quickly to unlock the potential of AI, our campus refresh opportunity, and our continued focus on profitable growth, capital returns, and strategic investments to capture the significant opportunities ahead) and the future financial performance of Cisco (including the guidance for Q2 FY 2026 and full year FY 2026) that involve risks and uncertainties, such as the actual impact of tariffs on our guidance for Q2 FY2026 and full year FY2026. Readers are cautioned that these forward-looking statements are only predictions and may differ materially from actual future events or results due to a variety of factors, including: business and economic conditions and growth trends in the networking industry, our customer markets and various geographic regions; global economic conditions and uncertainties in the geopolitical environment; our development and use of artificial intelligence; overall information technology spending; the growth and evolution of the Internet and levels of capital spending on Internet-based systems; variations in customer demand for products and services, including sales to the service provider market, cloud, enterprise and other customer markets; the return on our investments in certain key priority areas, and in certain geographical locations, as well as maintaining leadership in Networking and services; the timing of orders and manufacturing and customer lead times; supply constraints; changes in customer order patterns or customer mix; insufficient, excess or obsolete inventory; variability of component costs; variations in sales channels, product costs or mix of products sold; our ability to successfully acquire businesses and technologies and to successfully integrate and operate these acquired businesses and technologies; our ability to achieve expected benefits of our partnerships; increased competition in our product and services markets, including the data center market; dependence on the introduction and market acceptance of new product offerings and standards; rapid technological and market change; manufacturing and sourcing risks; product defects and returns; litigation involving patents, other intellectual property, antitrust, stockholder and other matters, and governmental investigations; our ability to achieve the benefits of restructurings and possible changes in the size and timing of related charges; cyber attacks, data breaches or other incidents; vulnerabilities and critical security defects; our ability to protect personal data; evolving regulatory uncertainty; terrorism; natural catastrophic events (including as a result of global climate change); any pandemic or epidemic; our ability to achieve the benefits anticipated from our investments in sales, engineering, service, marketing and manufacturing activities; our ability to recruit and retain key personnel; our ability to manage financial risk, and to manage expenses during economic downturns; risks related to the global nature of our operations, including our operations in emerging markets; currency fluctuations and other international factors; changes in provision for income taxes, including changes in tax laws and regulations or adverse outcomes resulting from examinations of our income tax returns; potential volatility in operating results; and other factors listed in Cisco's most recent report on Form 10-K filed on September 3, 2025. The financial information contained in this release should be read in conjunction with the consolidated financial statements and notes thereto included in Cisco's most recent report on Form 10-K as it may be amended from time to time. Cisco's results of operations for the three months ended October 25, 2025 are not necessarily indicative of Cisco's operating results for any future periods. Any projections in this release are based on limited information currently available to Cisco, which is subject to change. Although any such projections and the factors influencing them will likely change, Cisco will not necessarily update the information, since Cisco will only provide guidance at certain points during the year. Such information speaks only as of the date of this release. This release includes non-GAAP net income, non-GAAP gross margins, non-GAAP operating expenses, non-GAAP operating income and margin, non-GAAP effective tax rates, non-GAAP interest and other income (loss), net, and non-GAAP net income per share data for the periods presented. It also includes future estimated ranges for gross margin, operating margin, tax provision rate and EPS on a non-GAAP basis. These non-GAAP measures are not in accordance with, or an alternative for, measures prepared in accordance with generally accepted accounting principles (GAAP) and may be different from non-GAAP measures used by other companies. In addition, these non-GAAP measures are not based on any comprehensive set of accounting rules or principles. Cisco believes that non-GAAP measures have limitations in that they do not reflect all of the amounts associated with Cisco's results of operations as determined in accordance with GAAP and that these measures should only be used to evaluate Cisco's results of operations in conjunction with the corresponding GAAP measures. Cisco believes that the presentation of non-GAAP measures when shown in conjunction with the corresponding GAAP measures, provides useful information to investors and management regarding financial and business trends relating to its financial condition and its historical and projected results of operations. For its internal budgeting process, Cisco's management uses financial statements that do not include, when applicable, share-based compensation expense, amortization of acquisition-related intangible assets, acquisition/divestiture-related costs, significant asset impairments and restructurings, significant litigation settlements and other contingencies, gains and losses on investments, the income tax effects of the foregoing and significant tax matters. Cisco's management also uses the foregoing non-GAAP measures, in addition to the corresponding GAAP measures, in reviewing the financial results of Cisco. In prior periods, Cisco has excluded other items that it no longer excludes for purposes of its non-GAAP financial measures. From time to time in the future there may be other items that Cisco may exclude for purposes of its internal budgeting process and in reviewing its financial results. For additional information on the items excluded by Cisco from one or more of its non-GAAP financial measures, refer to the Form 8-K regarding this release furnished today to the Securities and Exchange Commission. About Cisco Cisco (Nasdaq: CSCO) is the worldwide technology leader that securely connects everything to make anything possible. Our purpose is to power an inclusive future for all by helping our customers reimagine their applications, power hybrid work, secure their enterprise, transform their infrastructure, and meet their sustainability goals. Discover more at newsroom.cisco.com and follow us on X at @Cisco . Copyright © 2024 Cisco and/or its affiliates. All rights reserved. Cisco and the Cisco logo are trademarks or registered trademarks of Cisco and/or its affiliates in the U.S. and other countries. To view a list of Cisco trademarks, go to: www.cisco.com/go/trademarks . Third-party trademarks mentioned in this document are the property of their respective owners. The use of the word partner does not imply a partnership relationship between Cisco and any other company. This document is Cisco Public Information. RSS Feed for Cisco: https://newsroom.cisco.com/rss-feeds"
  },
  {
    "title": "Cisco Schedules Call for Q1 Fiscal Year 2026 Financial Results",
    "date": "Nov 10, 2025",
    "link": "https://newsroom.cisco.com/content/r/newsroom/en/us/a/y2025/m11/cisco-schedules-conference-call-for-q1-fiscal-year-2026-financial-results.html",
    "description": "Cisco has scheduled a conference call for Wednesday, Nov 12, 2025, at 1:30 PM (PT); 4:30 PM (ET) to announce its 1Q26 financial results",
    "source": "Cisco",
    "main_ideas": [
      "Cisco has scheduled a conference call for Q1 FY2026 financial results.",
      "The call will take place on November 12, 2025, at 1:30 PM PT.",
      "Financial results will be released after market close on the same day.",
      "Live audio broadcast and replay options will be available for the conference call.",
      "Cisco continues to lead in technology and AI-powered solutions for organizations."
    ],
    "tags": [
      "cisco",
      "financial-results",
      "conference-call",
      "ai",
      "technology",
      "investor-relations",
      "business",
      "financial-services",
      "market"
    ],
    "original_text": "SAN JOSE, Calif., November 3, 2025 – Cisco (NASDAQ: CSCO) has scheduled a conference call for Wednesday, Nov 12, 2025, at 1:30 PM (PT); 4:30 PM (ET) to announce its first quarter fiscal year 2026 financial results for the period ending Saturday, October 25, 2025. Financial results will be released over PR Newswire via US National and European Financial distribution, after the close of the market on Wednesday, Nov 12, 2025. Cisco's quarterly earnings press release will be posted at https://newsroom.cisco.com . Date: Wednesday, Nov 12, 2025 Time: 1:30 PM (PT); 4:30 PM (ET) To Listen via Telephone: 888-848-6507 212-519-0847 (for International Callers) To Listen via the Internet: We are pleased to offer a live and replay audio broadcast of the conference call with corresponding slides at https://investor.cisco.com . Replay: A telephone playback of the Q1 FY2026 conference call is scheduled to be available beginning at 4:00 PM (PT) on Nov 12, 2025, through 10:00 PM (PT) Nov 18, 2025. The replay will be accessible by calling 800-839-2232 (International callers: 203-369-3662). The call runs 24 hours/day, including weekends. An archived version of the webcast will be available on Cisco's Investor Relations website at https://investor.cisco.com . About Cisco Cisco (NASDAQ: CSCO) is the worldwide technology leader that is revolutionizing the way organizations connect and protect in the AI era. For more than 40 years, Cisco has securely connected the world. With its industry leading AI-powered solutions and services, Cisco enables its customers, partners and communities to unlock innovation, enhance productivity and strengthen digital resilience. With purpose at its core, Cisco remains committed to creating a more connected and inclusive future for all. Discover more on The Newsroom and follow us on X at @Cisco . Cisco and the Cisco logo are trademarks or registered trademarks of Cisco and/or its affiliates in the U.S. and other countries. A listing of Cisco’s trademarks can be found at http://www.cisco.com/go/trademarks . Third-party trademarks mentioned are the property of their respective owners. The use of the word ‘partner’ does not imply a partnership relationship between Cisco and any other company. # # # Media Contacts Sami Badri Investor Relations +1 469-420-4834 sambadri@cisco.com Robyn Blum Public Relations rojenkin@cisco.com"
  },
  {
    "title": "Cisco 360 Partner Program Empowers Partners to Drive Profitability in an AI Era",
    "date": "Nov 04, 2025",
    "link": "https://newsroom.cisco.com/content/r/newsroom/en/us/a/y2025/m11/cisco-360-partner-program-empowers-partners-to-drive-profitability-in-an-ai-era.html",
    "description": "Co-designed with Cisco partners, the program introduces new specializations, bonuses, and resources to help partners deliver the full power of Cisco’s innovation",
    "source": "Cisco",
    "main_ideas": [
      "Cisco 360 Partner Program enhances partner profitability through new specializations and incentives.",
      "The program is co-designed with partners to meet customer demands in the AI era.",
      "New training and resources are provided to help partners accelerate growth and expertise."
    ],
    "tags": [
      "cisco",
      "partner-program",
      "artificial-intelligence",
      "profitability",
      "specializations",
      "training",
      "ecosystem",
      "customer-value",
      "innovation"
    ],
    "original_text": "Co-designed with Cisco partners, the program introduces new specializations, bonuses, and resources to help partners deliver the full power of Cisco’s innovation News summary: Program Evolution: Launching January 25, 2026, the Cisco 360 Partner Program builds on 20+ years of industry-leading partnerships and was co-designed with partners to enhance customer value. Profitability: New Cisco Partner Incentive bonuses reward portfolio breadth and depth of specialized expertise, with the Partner Value Index and enhanced Partner Experience Platform offering clear visibility into performance, predictability, and progress. Growth: New next generation of specializations, marketing investments, and AI certifications help partners differentiate, reach more customers, and accelerate durable growth across an agile ecosystem. CISCO PARTNER SUMMIT, SAN DIEGO, CA, November 4, 2025 —Today, Cisco (NASDAQ: CSCO) announced key elements to the Cisco 360 Partner Program launching January 25, 2026, co-designed with partners to help accelerate their profitability and deliver greater customer value. With partners expecting AI to drive the majority of their revenue within the next five years , the enhanced program incentivizes their efforts to help organizations harness this opportunity amid infrastructure constraints, data complexity, and skills gaps. The program strengthens collaboration across the global partner ecosystem and allows partners to unlock the full power of the Cisco portfolio to deliver the AI-ready data centers, future-proofed workplaces, and digital resilience their customers need to thrive in the AI era. Cisco 360 Partner Program: Driving customer impact and predictable partner profitability Building on the Cisco 360 Partner Program announced at Partner Summit last year , today's updates introduce new paths to profitability for solutions that drive customer value—campus refresh, AI, security, collaboration, and mass-scale infrastructure—helping partners to potentially earn as much or more than through the existing program. Preferred Partners can also earn new specializations aligned with Cisco's critical infrastructure for the AI era. Cisco is also deepening its investment in Partner enablement with new training, tools, resources, including a marketing Launchpad and Branding Toolkit to support partners for the Cisco 360 Partner Program. \"This program is critical to our mutual success with partners. The Cisco 360 Partner Program serves the agile partner ecosystem that reacts and adapts quickly, innovates continuously, and scales efficiently through platform and ecosystem effects,\" said Tim Coogan, Senior Vice President of Global Partner Sales at Cisco. “We appreciate that Cisco invited partners to co-design the new program and listened to ideas along the way. This program is a true reflection of partnership and we’re confident it will help set us up for success,” said Nicko Roussos, Senior Vice President, Cisco Strategy & Transformation, TD Synnex. New Cisco 360 Partner Program elements announced at Cisco’s Partner Summit event today: Enhanced partner incentive tied to customer priorities The Cisco Partner Incentive introduces the Eligible Offers list and rebate rates aligned to accelerate growth and incentivize adoption in key innovation areas—campus refresh, AI, security and premium services, adopt and renew. Partners can model profitability using the Cisco Partner Incentive Estimator and unlock two additional bonuses as they advance expertise and accelerate portfolio growth. Cross Sell Bonus – rewarding portfolio breadth; and a Next Generation Specialization Bonus – rewarding deep expertise or greater value and predictable growth. Together, these levers deliver predictable growth while positioning partners to earn as much or more than with the previous program by focusing on integrated solutions that drive customer outcomes. New specializations recognizing AI infrastructure expertise In February 2026, Cisco Preferred Partners can earn two new specializations – Secure AI Infrastructure and Secure Networking – recognizing partners who deliver comprehensive solutions from design through ongoing customer engagement using Cisco’s integrated hardware, software, and services. Both specializations unlock an additional Cisco Partner Incentive bonus, increasing profitability for partners building deep expertise in the era of AI. Expanded partner enablement: Training, tools, and demo environments Partners gain access to new resources designed to accelerate expertise and time to revenue: Cisco Partner Learning Journeys - clear, role-based training paths for both technical and sales professionals at every level, with recognition through the Cisco 360 Partner Value Index accelerating the ability to build the skills that drive business growth. Cisco AI Assistant for Partners - streamlined access to high-quality, multi-language content and training, available in Learning Journeys and Partner Experience Platform. Advanced dCloud Demo Experiences - customizable virtual labs that replicate real customer environments, allowing Preferred Partners to demonstrate Cisco’s full capabilities alongside their own solutions, while reducing physical equipment needs and lowering training and sales costs. Cisco U. AI Skills Expansion - practical training in AI skills, data analysis, and AI APIs usage for designing AI pilot projects, fostering an agile ecosystem that supports partner success, and innovation in a rapidly evolving technology landscape. \"Learn with Cisco\" now includes an all-new Cisco AI Infrastructure Specialist Certification within the CCNP Data Center Certification track to help partners build and validate skills on Cisco data center infrastructure. Marketing investment for program launch Partners preparing for launch can access a Launchpad and a Branding Toolkit plus high-touch, one-on-one marketing support to customize marketing assets with their new brand and ensure readiness for January 25, 2026. Quotes: “The Cisco 360 Partner Program is about more than recognition—it’s about empowering every partner to thrive at the center of Cisco’s innovation. By investing in our partners’ capabilities and giving them the tools and resources they need, we’re enabling our ecosystem to deliver greater customer outcomes and lead in an AI-powered world.”​ - Elisabeth De Dobbeleer, Senior Vice President, Cisco Partner Program “Cisco engaged partners early in the process and took our feedback along the way. We’re excited to see the new program come to life and believe now is the right time for these changes which position us all for the opportunities in the market. We appreciate Cisco’s continued commitment to our mutual success and growth.” - Brian Ortbals, SVP, WWT “As a long-time Splunk partner and new member of the Cisco Partner Program, we see tremendous opportunity in how the Cisco 360 program aligns incentives directly to customer outcomes. It demands that we execute with the same discipline our customers expect of themselves and should help to redefine what partnership means in the subscription era. Customers no longer buy software, they rent it, and renewal is earned every year through real results. For organizations like Blackwood who aspire to make an impact with the customers we serve, this program is a clear sign that Cisco is committed to driving industry standards in the channel.” - Ryan Morris, President of Blackwood \"Cisco's partner program stands out for rewarding partners with clear recognition and meaningful incentives, making every investment count and driving stronger engagement.\"- Jay McBain, Canalys Additional Resources: For more information on Cisco Partner Summit, please visit here For an overview of the Cisco 360 Partner Program, please visit here For details on the Cisco 360 Partner Program, partners can visit here About Cisco Cisco (NASDAQ: CSCO) is the worldwide technology leader that is revolutionizing the way organizations connect and protect in the AI era. For more than 40 years, Cisco has securely connected the world. With its industry leading AI-powered solutions and services, Cisco enables its customers, partners and communities to unlock innovation, enhance productivity and strengthen digital resilience. With purpose at its core, Cisco remains committed to creating a more connected and inclusive future for all. Discover more on The Newsroom and follow us on X at @Cisco . Cisco and the Cisco logo are trademarks or registered trademarks of Cisco and/or its affiliates in the U.S. and other countries. A listing of Cisco’s trademarks can be found at http://www.cisco.com/go/trademarks . Third-party trademarks mentioned are the property of their respective owners. The use of the word ‘partner’ does not imply a partnership relationship between Cisco and any other company. Disclaimer: Many of the products and features mentioned are still in development and will be made available as they are finalized, subject to ongoing evolution in development and innovation. The timeline for their release is subject to change. Media Contacts Alexa Halloran Public Relations ahallora@cisco.com"
  },
  {
    "title": "Cisco launches Cisco IQ",
    "date": "Nov 04, 2025",
    "link": "https://newsroom.cisco.com/content/r/newsroom/en/us/a/y2025/m11/cisco-launches-cisco-iq-the-unified-ai-powered-experience-that-connects-the-entire-customer-journey.html",
    "description": "Cisco launches Cisco IQ, a unified, AI-powered experience that connects the entire customer journey, boosting resiliency and accelerating time-to-value",
    "source": "Cisco",
    "main_ideas": [
      "Cisco IQ is an AI-powered interface that enhances customer journey management.",
      "The platform offers real-time insights and personalized support for IT teams.",
      "Cisco IQ aims to reduce operational complexity and improve technology investment outcomes."
    ],
    "tags": [
      "cisco",
      "ai",
      "customer-experience",
      "it-support",
      "automation",
      "technology",
      "digital-transformation",
      "cloud-computing",
      "agentic-ai"
    ],
    "original_text": "New interface accelerates time-to-value, boosts resiliency, and delivers unparalleled simplicity for under-pressure IT teams News Summary: Cisco IQ brings real-time insights, on-demand assessments, troubleshooting and personalized learning, automation and agents from across professional services and support together in a single AI-powered interface, helping customers plan, deploy, manage, secure and optimize technology investments with greater speed and simplicity. With Cisco IQ's purpose-built agentic-AI foundation, agents continually adapt to each customer's unique operational environment, enabling them to deliver personalized, contextual insights, recommendations and actions. Flexible deployment options – SaaS, on-prem tethered, or on-prem air-gapped – and secure API integration help ensure Cisco IQ fits seamlessly into any environment and existing workflows. CISCO PARTNER SUMMIT, SAN DIEGO, Calif., Nov 4, 2025 — Today, Cisco (NASDAQ: CSCO) announced the launch of Cisco IQ, a breakthrough AI-powered digital interface that brings real-time insights, on-demand assessments, troubleshooting and personalized learning, automation and agents from across professional services and support into one powerful experience. Purpose-built for the AI era, where technology complexity can hinder essential operational agility, Cisco IQ brings together automation, AI-powered intelligence, and decades of deep Cisco expertise in a single digital experience, helping customers to plan, deploy, manage, secure, and optimize technology investments faster and more easily. Its proactive, predictive, and highly personalized features put customers a step ahead, helping them to reduce complexity, boost resiliency, and deliver measurable business outcomes. “Cisco IQ is our boldest step yet in reimagining how customers interact with Cisco — from planning and design to optimization and transformation,” said Liz Centoni, Executive Vice President and Chief Customer Experience Officer, Cisco. “With AI at its core, Cisco IQ doesn’t just react. It intelligently anticipates, personalizes and transforms how you assess, deploy and operate, providing one connected experience to reduce complexity and empower IT teams to act with clarity and confidence.” Turning Complexity into Crystal-Clear Clarity In an era defined by rapid technology shifts and rising expectations, today’s IT teams face a high-stakes mix of challenges: Disjointed automation and fragmented visibility can leave teams firefighting across multiple tools, struggling with blind spots and missed signals. Services and support experiences are often complex and inconsistent, slowing resolution and consuming valuable bandwidth. A widening skills gap makes it harder to keep pace with innovation, while escalating demands for proactive, measurable outcomes can compound the strain. Together, these pressures create fertile ground for costly outages, security gaps, delayed implementations, and eroded trust. Put simply, yesterday’s service and support models are not designed to keep up with today’s AI-powered world. Cisco IQ helps to address this reality by transforming services and support from reactive fixes to strategic, predictive enablers — helping to reduce operational friction and cognitive load and enable earlier intervention. For customers, the result is a more resilient IT operation that can help focus resources on innovation and business transformation. Cisco IQ is an important step in realizing Cisco’s vision for agentic AI-led customer experience, where interactions are personalized, proactive, and predictive. At a time when 92% of business and IT leaders say that the support and services provided by B2B technology vendors are becoming more important due to growing technological complexity, Cisco is forging a new standard for customer experience for the AI era. From Firefighting to Foresight Cisco IQ unlocks a new level of simplicity, resiliency and time to value, helping ensure trust and security via Cisco’s transparent AI architecture and human oversight by design. It helps IT teams to: Anticipate and prevent issues with on-demand assessments covering security advisories, configurations, compliance, regulatory, quantum readiness and custom checks. Simplify operations and provide dynamic, real-time visibility of entire asset inventory with planning for last day of support and lifecycle management. Accelerate resolution using AI-supported troubleshooting and streamlined case management. Benefit from hyper-personalized support with AI that adapts to each customer's unique environment. Realize deployment flexibility — SaaS, on-prem tethered, or on-prem air-gapped — with the ability to integrate Cisco IQ into existing systems. “Cisco IQ is more than a technology: it’s a shift in how IT delivers value in an AI-driven era. By reducing operational friction, lowering cognitive load, and enabling proactive action, Cisco IQ frees teams to focus on innovation and resilience rather than firefighting,” added Zeus Kerravala, founder and principal analyst, ZK Research. \"This latest launch is another clear indication from Cisco that it intends to lead the way in agentic-led services.\" Empowering partners to win in the AI era Partners are at the heart of how Cisco delivers services and support to customers worldwide. With Cisco IQ, partners can address their customer needs across deployment modes and across the entire technology lifecycle. By equipping partners with advanced AI-powered capabilities, Cisco IQ can help them deliver more value to customers. Together, Cisco and its partners can help customers reduce complexity, make better-informed decisions, and keep pace with change — turning technology management into a strategic driver of business success. “It’s great to see Cisco leveraging AI and building out API stacks that enable partners to deliver even better outcomes for customers. Cisco IQ enhances the traditional services and support model into something that's far more proactive and predictive, meaning we can help customers identify and solve issues before they impact operations, build digital resiliency, and optimize operations,” says John Tan, Chief Customer Officer, Data#3. “We’re excited to integrate Cisco IQ into our custom application stack to deliver the modern, proactive and hyper-personalized customer experience that organizations need today.” Availability Cisco IQ is expected to be generally available in Cisco’s H2, FY2026. Additional Resources Liz Centoni Executive Blog: Cisco IQ: Redefining customer experience while driving partner value Cisco IQ deep-dive blog – Bhaskar Jayakrishnan: From tool to intelligence, the engineering philosophy of Cisco IQ The Race to an Agentic Future – Research Report 2025: The Race to an agentic future: how agentic AI will transform customer experience Liz Centoni Executive Blog: Agentic AI Poised to Handle 68% of Customer Service and Support Interactions by 2028 Cisco TechBeat Podcast: How Cisco CX & AI Are Transforming Customer Experience: Insights with Carlos Pereira About Cisco Cisco (NASDAQ: CSCO) is the worldwide technology leader that is revolutionizing the way organizations connect and protect in the AI era. For more than 40 years, Cisco has securely connected the world. With its industry leading AI-powered solutions and services, Cisco enables its customers, partners and communities to unlock innovation, enhance productivity, and strengthen digital resilience. With purpose at its core, Cisco remains committed to creating a more connected and inclusive future for all. Discover more on The Newsroom and follow us on X at @Cisco . Cisco and the Cisco logo are trademarks or registered trademarks of Cisco and/or its affiliates in the U.S. and other countries. A listing of Cisco’s trademarks can be found at http://www.cisco.com/go/trademarks . Third-party trademarks mentioned are the property of their respective owners. The use of the word ‘partner’ does not imply a partnership relationship between Cisco and any other company. Media Contacts Clement Bonaud Public Relations +33 6 26 57 60 42 cbonaud@cisco.com Esther Andrews Analyst Relations esandrew@cisco.com"
  },
  {
    "title": "Cisco Debuts Unified Edge",
    "date": "Nov 03, 2025",
    "link": "https://newsroom.cisco.com/content/r/newsroom/en/us/a/y2025/m11/cisco-unified-edge-platform-for-distributed-agentic-ai-workloads.html",
    "description": "Today, Cisco announced Unified Edge, an integrated computing platform for distributed AI workloads.",
    "source": "Cisco",
    "main_ideas": [
      "Cisco launched Unified Edge, an integrated platform for distributed AI workloads.",
      "The platform enables real-time AI inferencing closer to data generation.",
      "Unified Edge combines compute, networking, storage, and security in a single system."
    ],
    "tags": [
      "cisco",
      "unified-edge",
      "artificial-intelligence",
      "edge-computing",
      "real-time-inferencing",
      "data-security",
      "modular-architecture",
      "enterprise-solutions",
      "ai-workloads"
    ],
    "original_text": "As an extension of Cisco’s leading AI compute and networking portfolio, Unified Edge enables real-time inferencing for agentic and physical AI workloads at the edge, where data is created and processed, bringing AI to life for enterprises News Summary: Cisco Unified Edge extends data center power and scale to the edge, enabling real-time applications and AI inferencing where data is generated. Cisco is first-to-market with an edge optimized platform that’s more than a server - integrating compute , networking, and storage into a single system backed by an extensive partner ecosystem. The new platform delivers AI-ready performance that’s modular and serviceable, simplifies operations for fleetwide deployments, delivers end-to-end observability and fuses security into every layer to protect the edge. CISCO PARTNER SUMMIT, SAN DIEGO, Calif., NOV 3, 2025 — Today, Cisco (NASDAQ: CSCO) announced Cisco Unified Edge , an integrated computing platform for distributed AI workloads. From retail stores to healthcare facilities to factory floors, Cisco Unified Edge brings together compute , networking, storage, and security closer to the data for real-time AI inferencing and agentic workloads. This is critical to turning the AI vision into reality, providing the foundational infrastructure needed to support both traditional and AI workloads. More than half of today’s AI pilots are stalling due to infrastructure constraints, highlighting an urgent need for a new decentralized network architecture. The edge is the new AI frontier where it’s forecasted that 75 percent of enterprise data will be created and processed this year. As AI workloads fast-track from centralized model training to real-time inference, traditional data centers struggle to accommodate the requirements of AI. AI agents are transforming network traffic from predictable bursts to relentless, high-intensity loads, with agentic AI queries generating up to 25 times more network traffic than a chatbot. Instead of pulling data to and from the data center, AI workloads require models and infrastructure to be closer to where the data is created, and decisions are made. \"Today’s infrastructure can’t meet the demands of powering AI at scale,” said Jeetu Patel, President and Chief Product Officer at Cisco. “As AI agents and experiences proliferate, they will naturally emerge closer to where customers interact and decisions are made – the branch office, retail store, factory floor, stadium, and more. That’s where compute needs to live. With our Unified Edge we’re making it easier to power AI in the real world with flexible, secure systems that are simple to deploy, operate, and scale as demand grows.” Reimagining Computing for Agentic AI Cisco Unified Edge enables real-time inferencing and agentic workloads from edge to core – so enterprises can confidently deploy and manage AI at scale. It is designed to grow and adapt without the need for rip-and-replace upgrades, protecting AI investments and powering use cases and services that have yet to be imagined. Performance and Modularity to Power Real-time AI: Full-stack, converged architecture unifies compute, storage, and even networking into a single platform, supported by an extensive partner ecosystem. The modular chassis offers CPU and GPU configurations, redundant power and cooling, high-performance SD-WAN networks and pre-validated designs to support today’s applications and those yet to be imagined. Operational Simplicity from Edge to Core: Zero-touch deployment and pre-validated blueprints deliver accelerated and predictable AI rollouts. Centralized management via Cisco Intersight and automated fleetwide operations simplify scaling, troubleshooting, and upgrades without needing on-site specialist skills. With Splunk and ThousandEyes integrations, customers can get end-to-end observability. Democratized edge management at scale. Built-in Security for Edge AI: Multi-layered, zero-trust security protects AI environments at every layer. Tamper-proof features, deep telemetry, consistent policies, and drift-free configurations help ensure resilience, while audit trails safeguard compliance as operations scale. Security is built-in at the device level and can extend to applying zero trust to every access, segmentation, and protect applications and AI models. This approach addresses the expanded attack surface at the edge, helping secure AI operations from physical and cyber threats. Unlocking Breakthrough Outcomes, Industry by Industry Cisco partnered closely with customers across retail, manufacturing, financial services, and healthcare to co-design a platform that reflects the complexity and constraints of the real world. This means supporting both the traditional workloads of today as well as the ambitious AI workloads of tomorrow. Enterprises need to still manage the realities of today (real-time applications that CPUs can handle), with the visions of tomorrow (GPU intensive AI workloads). Their input directly shaped everything from the system architecture to how the platform is deployed, secured, and managed at scale. From running AI workloads on the shop floor to delivering secure digital services in bank branches, the platform supports real-time decision-making where it matters most. Partners: The cornerstone of AI success As Cisco’s customers and partners continue to navigate an ever-changing and progressing AI landscape, Cisco is committed to working across the industry to drive openness, flexibility and choice. By honoring customers’ unique journeys to AI, Cisco and its extensive ecosystem of technology, managed services, ISV and reseller partners will together help organizations achieve their AI ambitions. AI will require new levels of expertise and integrated, simple solutions in the face of growing complexity. Cisco’s world-class partner ecosystem can lead the way for customers. Availability Cisco Unified Edge platforms are orderable now and are expected to be generally available by the end of the year. Industry Reactions \"The Intel-Cisco collaboration for Unified Edge represents a fundamental shift in how we think about distributed computing. By combining our silicon innovation with Cisco's networking and compute expertise, we're not just connecting edge locations - we're extending the full power of the data center to wherever data needs to be processed. The Intel Xeon 6 SoC provides a flexible, efficient foundation that edge systems need for high throughput, low latency workloads, while Cisco's modular compute design and unified operations model makes managing AI workloads easier and more secure.\" — Cristina Rodriguez, Vice President and General Manager of Intel’s Network & Edge Group “The importance of the Edge is more apparent now than ever before. Early adoption of AI at the Edge delivers a competitive advantage that can transform entire industries. Sitting on the sidelines is no longer an option. With the rapid pace of AI and technological advancement, the future remains unpredictable. Building flexibility into a future-proof Edge platform is essential. Verizon and Cisco share a common vision for innovation, and we approach this goal with a focus on simplicity, reliability, and consistency.” — Lee Field, Vice President of US Solution Architecture at Verizon \"To maximize AI’s productivity benefits in a manufacturing environment, connecting islands of automation is critical. Connecting multiple lines in a plant and then connecting multiple plants can generate petabytes of data. Some applications make sense to go back to the data center; that will continue to happen. But other decisions need to be made in real time at the edge—especially on a manufacturing floor. Edge computing requires an integrated platform approach where the compute , the networking, and of course, the security all come together. Performant, secure networking at the edge is absolutely essential.\" — Blake Moret, chairman and CEO of Rockwell Automation “As AI and data processing shift from centralized data centers to the on-premises edge, our customers will need solutions that deliver both agility and security right at the source. With Cisco Unified Edge we can seamlessly extend powerful secure cloud and AI infrastructure to wherever data is generated, empowering customers and their models to inference at the edge to make decisions faster than ever before. Offering this solution not only strengthens our customer relationships but also positions us at the forefront of future-ready technology adoption.\" — Brian Ortbals, SVP of Global Solutions and Architecture at World Wide Technology “The true power of AI will be unlocked when we can move the inferencing and analysis closer to where the data originates, making the edge the new frontier for the next wave of AI. Agentic and Physical AI will require compute at the edge to handle the substantial increase in network traffic and real-time analysis. Cisco Unified Edge simplifies adoption and operations for those enterprises that have struggled with how to implement AI to deliver true business impact.\" — Bob Laliberte, Principal Analyst at theCUBE Research Additional Resources: Executive blog post: AI isn’t waiting for the data center. The Edge is the new center of gravity by Jeremy Foster, SVP & GM, Cisco Compute Click here to view the Unified Edge Infographic For more information on Unified Edge, click here About Cisco Cisco (NASDAQ: CSCO) is the worldwide technology leader that is revolutionizing the way organizations connect and protect in the AI era. For more than 40 years, Cisco has securely connected the world. With its industry leading AI-powered solutions and services, Cisco enables its customers, partners and communities to unlock innovation, enhance productivity and strengthen digital resilience. With purpose at its core, Cisco remains committed to creating a more connected and inclusive future for all. Discover more on The Newsroom and follow us on X at @Cisco . Cisco and the Cisco logo are trademarks or registered trademarks of Cisco and/or its affiliates in the U.S. and other countries. A listing of Cisco’s trademarks can be found at http://www.cisco.com/go/trademarks . Third-party trademarks mentioned are the property of their respective owners. The use of the word ‘partner’ does not imply a partnership relationship between Cisco and any other company. Disclaimer: Many of the products and features mentioned are still in development and will be made available as they are finalized, subject to ongoing evolution in development and innovation. The timeline for their release is subject to change. Media Contacts Taylor Hassman Public Relations +1 415-610-6075 thassman@cisco.com"
  },
  {
    "title": "Cisco Simplifies Security for MSPs",
    "date": "Nov 03, 2025",
    "link": "https://newsroom.cisco.com/content/r/newsroom/en/us/a/y2025/m11/cisco-simplifies-security-for-managed-service-providers-accelerating-their-hybrid-mesh-firewall-deployments-and-business-growth.html",
    "description": "Cisco introduces foundational multi-customer management capabilities within Cisco Security Cloud Control, purpose-built for MSPs",
    "source": "Cisco",
    "main_ideas": [
      "Cisco introduces multi-customer management capabilities within Security Cloud Control for MSPs.",
      "The new features streamline operations and reduce costs for Managed Service Providers.",
      "Cisco's Hybrid Mesh Firewall enhances security across distributed environments with AI-driven protection."
    ],
    "tags": [
      "cisco",
      "security",
      "managed-service-providers",
      "hybrid-mesh-firewall",
      "cloud-control",
      "ai",
      "cybersecurity",
      "multi-customer-management",
      "operational-efficiency"
    ],
    "original_text": "News Summary: Cisco introduces foundational multi-customer management capabilities within Cisco Security Cloud Control, purpose-built for Managed Service Providers (MSPs). The innovation streamlines operations, significantly reduces costs, and accelerates time-to-value for MSPs to deliver advanced managed security services. MSPs can efficiently deploy and manage Cisco's Hybrid Mesh Firewall and other security services from a single platform, addressing the complexities of today's hyper-distributed, AI-driven threat landscape. CISCO PARTNER SUMMIT, SAN DIEGO, Calif., NOV 3, 2025 – Cisco (NASDAQ: CSCO), the global leader in networking and security, today announced a significant platform advancement designed to empower Managed Service Providers (MSPs) to efficiently and profitably deliver security services. This innovation adds foundational multi-customer management capabilities within Security Cloud Control , Cisco’s unified, AI-powered management platform. This powerful console leverages advanced AIOps and AgenticOps to enable organizations to centrally manage a full suite of security solutions. This includes the Hybrid Mesh Firewall with AI Defense, and Secure Access, Cisco’s advanced security service edge (SSE) offering. By unifying these capabilities within Security Cloud Control, Cisco is streamlining operations and paving the way for MSPs to overcome fragmentation, reduce operating costs, and achieve accelerated, sustainable growth. \"MSPs are on the front lines, helping businesses navigate the complexities of modern cybersecurity, especially as AI makes threats more sophisticated,\" said Jeetu Patel, President and Chief Product Officer, Cisco. \"The new multi-customer management capabilities in Cisco Security Cloud Control, coupled with our Hybrid Mesh Firewall, are designed to eliminate operational friction, empower our partners to accelerate revenue growth, and ultimately deliver superior security outcomes for their customers.\" Unlocking Business Outcomes for MSPs with Hybrid Mesh Firewall and Security Cloud Control Cisco’s Hybrid Mesh Firewall is a distributed security solution optimized to block advanced threats, protect against vulnerabilities, including those in AI models, and enable zero-trust segmentation across data centers, clouds, and edge sites. It uses network and workload identities to create micro-perimeters, applying segmentation and AI-driven threat protection at the app edge and within workloads. This hyper-distributed security enables organizations to define policy and enforce it everywhere, across Cisco firewalls, Smart Switches, workload agents leveraging eBPF, and even third-party firewalls. Policies are managed centrally by Security Cloud Control, while telemetry integrates with Splunk. Now with built-in support for managing multiple customers extended to Hybrid Mesh Firewall, MSPs can offer comprehensive, advanced security solutions to their clients with unprecedented efficiency and proven efficacy. These include the new Cisco Secure Firewall 200 Series, which delivers advanced on-box threat inspection and integrated SD-WAN for distributed branches at up to 3x price-performance, and the Cisco Secure Firewall 6100 Series, offering extremely high-performance density for AI-ready data centers. Cisco’s latest firewall software, Secure Firewall Threat Defense 7.7, detected and stopped between 99.5% and 100% of threats in the most recent testing by NetSecOPEN, a non-profit organization that develops open, standardized testing methods for network security products. \"Testing the Cisco Secure Firewall 1200 Series, we found remarkable stability and capability for the price,” said Dustin Grimmeissen, VP, Network & Security, AHEAD. “This performance allows us to help clients modernize and simplify their security architecture all within budget.\" Key capabilities within Security Cloud Control that drive outcomes for MSPs include: Centralized Oversight and Management: An intuitive Manager View provides a single pane of glass for navigating across managed entities, subscriptions, and access controls, reducing administrative overhead. Multi-Org Management: Streamlined customer onboarding and configuration at scale, complete with safeguards and clear permission structures, enabling faster time-to-market. Granular Role-Based Access Control (RBAC): Precise control over administrator access for managed customers, ensuring engineers and support staff have only the necessary permissions, strengthening governance and compliance. Streamlined MSP Licensing & Management : Simplified license allocation, tracking, and auditing across multiple customers, supporting models like multi-architecture Managed Services Enterprise Agreement (MSEA) and consumption-based Managed Services License Agreement (MSLA), increasing profitability. Platform API: A standardized gateway provides a consistent developer experience to automate customer onboarding and provisioning, while accelerating time-to-value. Enhancing MSP Profitability and Efficiency Security Cloud Control for MSPs helps accelerate Hybrid Mesh Firewall adoption to deliver smarter, centrally managed protection across all environments, enabling MSPs to achieve: Faster Time-to-Market: Stand up new customers quicker and bundle multi-product services from one platform, increasing win rates and expansion. Lower Operational Costs: Consolidate consoles and automate repeatable tasks to cut manual effort, errors, and operational overhead, significantly reducing the cost-to-serve. Easier Upsell: Leverage a holistic approach to win and grow with highly repeatable motions, making it easier to expand offerings and increase customer lifetime value. “Being able to log into a single dashboard, with robust role-based access control and being able to manage multiple customers from a single place is really going to reduce the workload for our teams,” said Gísli Helgason, Chief Technologist – Network & Security, CAE Technology Services Ltd. \"The announcement on Security Cloud Control’s new capabilities for managing multiple customers is going to be key for our business,” said Justin Rice, Chief Product & Technology Officer, CBTS . “It gives us a single pane of glass to manage multi-customer environments, which is really a game changer for MSPs.\" \"We deal with 15-plus tools, platforms, and logins,” said Lucas Black, Cisco Security Services Architect, CDW Canada. “Having a single view—that single platform Cisco Security Cloud Control—will give us the ability to have all of our customers' data in one spot, and all the products and subscriptions that they have easily available to our SOC and NOC analysts.\" “Kyndryl welcomes the new multi‑customer features Cisco is bringing to Security Cloud Control,” said J eff Gatz, Vice President, Alliances, Kyndryl. “These capabilities help us simplify commercial and operational processes while accelerating innovation for our customers.” MSPs interested in transforming their security service delivery and unlocking new levels of profitability are encouraged to connect with their Cisco representative to explore the new multi-customer management capabilities in Security Cloud Control, which are expected to be generally available in February 2026. Additional Resources: Blog: Cisco Security Cloud Control to Enable MSPs to Securely Onboard Customers About Cisco Cisco (NASDAQ: CSCO) is the worldwide technology leader that is revolutionizing the way organizations connect and protect in the AI era. For more than 40 years, Cisco has securely connected the world. With its industry leading AI-powered solutions and services, Cisco enables its customers, partners and communities to unlock innovation, enhance productivity and strengthen digital resilience. With purpose at its core, Cisco remains committed to creating a more connected and inclusive future for all. Discover more on The Newsroom and follow us on X at @Cisco . Cisco and the Cisco logo are trademarks or registered trademarks of Cisco and/or its affiliates in the U.S. and other countries. A listing of Cisco’s trademarks can be found at http://www.cisco.com/go/trademarks . Third-party trademarks mentioned are the property of their respective owners. The use of the word ‘partner’ does not imply a partnership relationship between Cisco and any other company. Media Contacts Carro Halpin Public Relations +1 617-855-8310 carroh@cisco.com"
  },
  {
    "title": "Cisco Supercharges its Secure Enterprise Network Architecture",
    "date": "Nov 03, 2025",
    "link": "https://newsroom.cisco.com/content/r/newsroom/en/us/a/y2025/m11/cisco-supercharges-its-secure-enterprise-network-architecture-for-the-ai-era.html",
    "description": "Cisco builds on its secure network architecture for enterprises with new solutions that simplify operations across campus and branch deployments.",
    "source": "Cisco",
    "main_ideas": [
      "Cisco enhances its secure network architecture for enterprises with new AI-ready solutions.",
      "Innovations simplify operations and accelerate deployment across campus and branch networks.",
      "Cisco's AgenticOps approach integrates AI to streamline IT management and enhance security."
    ],
    "tags": [
      "cisco",
      "network-architecture",
      "ai",
      "cloud-computing",
      "security",
      "automation",
      "enterprise",
      "branch-deployments",
      "agenticops"
    ],
    "original_text": "News Summary Cisco builds on its secure network architecture for enterprises with new solutions that simplify operations across campus and branch deployments. Breakthroughs like cloud-managed fabrics and Cisco Unified Branch simplify complex network configuration—enabling users to provision sophisticated, secure networks with just a few clicks. Innovations in operational simplicity unlock new business opportunities for partners, increasing profitability through faster deployment and accelerating customers’ growing investments in AI. CISCO PARTNER SUMMIT, SAN DIEGO, Calif., NOV 3, 2025 – Following the launch of its AI-ready secure network architecture for enterprises, Cisco (NASDAQ: CSCO) is introducing innovations to modernize campus, branch, and industrial networks for the AI era. Cisco's solutions simplify operations, scale for evolving business needs, and enhance security—all critical for unlocking the full potential of enterprise AI. Designed to deliver automated deployment and security across highly distributed networks in minutes instead of months, these innovations meet the high-bandwidth, ultra-low latency, and intelligent traffic management demands of distributed AI workloads that are increasingly moving to the enterprise edge. \"The networks of the future not only need to power the massive compute and bandwidth demands of AI experiences that are surging into campus and branch networks, but also be easy to deploy and secure with powerful AI tools of their own,\" said Jeetu Patel, President and Chief Product Officer, Cisco. \"Cisco delivers the only networking infrastructure that can scale to AI's exponential growth, while also giving over-worked and under-resourced IT teams truly agentic tools for managing and securing deployments from core to edge.\" \"In partnership with Cisco, Presidio helps organizations meet the rising demands of security and AI by delivering secure, high-performance branch networks through Cisco’s Unified Branch,” said Brian Wisler, VP, Modern Networks, Presidio. “This fully managed, automated solution streamlines deployment, enabling new sites to go live in minutes, empowering customers to stay ahead of today’s AI-driven challenges and tomorrow’s opportunities.” Simplified Operations, Powered by AgenticOps Cisco is leading the transition to AgenticOps—the future of IT operations where AI-powered agents and human teams work together to solve complex problems before they impact users. This new approach to IT management uses advanced AI and automation to simplify even the most complex networks. By integrating Cisco’s proprietary Deep Network Model—a domain-specific large language model—with its advanced network technologies into a single, user-friendly platform, IT teams can automate routine tasks, quickly troubleshoot issues, and gain unified visibility across their entire infrastructure. Key advancements include: Unified network visibility. The new Global Overview in Meraki Dashboard provides direct visibility and access to Catalyst Center-managed networks for a single cloud dashboard experience. It radically simplifies network management across campus and branch, whether cloud-based or on-premises. Beta November 2025; generally available in calendar Q4 2025. Simplified campus management. Introducing cloud-managed fabric, a scalable and secure architecture to simplify network management. Cloud-managed fabrics reduce the steps required to provision, manage, and troubleshoot large sites, while enabling adaptive segmentation policies. Beta Q4 2025; generally available in calendar Q1 2026. Agentic workflow automation. Available today, workflows spanning Meraki, Catalyst Center, Catalyst SD-WAN Manager, ISE, Nexus and more can be automated and orchestrated with AI Assistant. With a simple prompt, AI Assistant can automate previously manual tasks, such as switch migration, Wi-Fi setup, and device onboarding. Collaborative AI-powered troubleshooting. Built to enable AgenticOps, AI Canvas expedites the speed at which NetOps, SecOps, and app teams can collaborate with AI Agents to solve cross-domain problems. Teams can use the AI Assistant within AI Canvas to troubleshoot a network issue using natural language in seconds by unifying real-time telemetry, AI insights, and collaboration into one intelligent workspace. Now in Alpha. Making It Easier for Partners and Customers to Deploy Branches IT teams are being asked to move faster than ever before, even as they face rising operational complexity and heightened security concerns caused by gaps between disparate products. With Cisco Unified Branch, new innovations make branch deployments faster and more reliable. With new automation toolkits, Cisco Validated Designs powered by Agentic Workflows empower Cisco partners to enable customer IT teams to deploy, scale, and secure branches in minutes instead of hours, minimizing errors and complexity. Leveraging over forty years of Cisco networking and security expertise, resilient branch networks can be rolled out quickly and confidently. For example, imagine a retailer opening 50 new stores across the country. Each location can simply plug in Cisco network devices with no manual configuration required. The central IT team then provisions connectivity, security, and monitoring in minutes using the cloud dashboard. Security policies and network segmentation are automatically enforced, while continuous monitoring ensures protection without the need for specialized staff onsite. The result: rapid, secure deployment and streamlined management at scale that reduces operational complexity to just a few clicks. Scalable Devices Purpose-Built for AI Introducing the latest innovations in secure, high-performance networking and wireless connectivity, designed to empower distributed organizations with advanced routing and next-generation Wi-Fi, including: Secure routing at scale. New 8200 and 8400 Series Secure Routers bring high-performance routing, advanced security with a built-in firewall, and ultra-low latency for branch and campus deployments for seamless, automated connectivity. Devices orderable in calendar Q4 2025. Ultra-fast, automated wireless connectivity. New Wi-Fi 7 access points (CW9171I, CW9174 Series) and the CW9800L Wireless Controller for low and medium-density deployments provide high throughput, low latency, and intelligent management for seamless scaling. New wireless assurance capabilities including Roaming Health and the upcoming Active Testing feature powered by Cisco ThousandEyes uses Wireless APs to deliver enhanced visibility, faster troubleshooting, and optimized performance. Devices orderable in calendar Q4 2025. Security Fused into the Network To empower IT teams with simplicity, visibility, and control, Cisco is delivering a cloud-managed, identity-driven architecture that unites access control and cloud security within the Meraki Dashboard. This new approach simplifies operations while strengthening defense across the branch, campus, and cloud, addressing the dual challenge of securing an expanding attack surface with limited resources. These new security solutions leverage unified policy enforcement to simplify operations and protect users, devices, and things across the entire campus-to-cloud environment, including: Security at the edge. Cisco Secure Access extends Zero Trust to the cloud, providing consistent protection for users and applications everywhere. All Cisco SD-WAN offerings, including Meraki, now integrate with Cisco Secure Access, enabling a complete secure access service edge (SASE) offering. This delivers secure, seamless access for hybrid workforces by applying unified identity-based policies across SaaS, internet, and private apps, eliminating policy gaps between on-prem and cloud environments, and ensuring one policy framework for every connection. Identity-based security. New Cisco Access Manager fuses identity into the network, delivering full identity-based access control natively through the Meraki Dashboard. Fueled by Cisco ISE, optimized for cloud-managed networks, and delivered as SaaS, Access Manager is designed for simple deployment with no hardware or complex setup. It enables adaptive segmentation to isolate users, devices, and IoT by identity and posture and ensures every connection in the branch is authenticated, segmented, and secure. Generally available in calendar Q4 2025. About Cisco Cisco (NASDAQ: CSCO) is the worldwide technology leader that is revolutionizing the way organizations connect and protect in the AI era. For more than 40 years, Cisco has securely connected the world. With its industry leading AI-powered solutions and services, Cisco enables its customers, partners and communities to unlock innovation, enhance productivity and strengthen digital resilience. With purpose at its core, Cisco remains committed to creating a more connected and inclusive future for all. Discover more on The Newsroom and follow us on X at @Cisco. Cisco and the Cisco logo are trademarks or registered trademarks of Cisco and/or its affiliates in the U.S. and other countries. A listing of Cisco’s trademarks can be found at http://www.cisco.com/go/trademarks . Third-party trademarks mentioned are the property of their respective owners. The use of the word ‘partner’ does not imply a partnership relationship between Cisco and any other company. Media Contacts Caroline Sprague Public Relations +1 713-377-1461 csprague@cisco.com"
  },
  {
    "title": "Reinventing CRM with an AI-first approach",
    "date": "June 17, 2025",
    "link": "https://www.servicenow.com/blogs/2025/reinventing-crm-ai-first-approach",
    "source": "Servicenow_blog",
    "main_ideas": [
      "The CRM market needs an AI-first approach for true innovation and customer-centricity.",
      "Traditional CRM systems are often fragmented and require extensive customization.",
      "AI integration in CRM can enhance customer experiences and streamline workflows."
    ],
    "tags": [
      "crm",
      "artificial-intelligence",
      "workflow-automation",
      "customer-experience",
      "service-now",
      "business-transformation",
      "innovation",
      "customer-journey"
    ],
    "original_text": "Reinventing CRM with an AI-first approach\nChris Bedi\nJune 17, 2025\nThe customer relationship management (\nCRM\n) market has long been filled with opportunities for innovation. Dominated by a few major players, the market has seen incremental improvements but few big, bold advancements. Many platforms still rely on fragmented, legacy architectures, with systems that require extensive customization and integration.\nAmit Zavery, chief product officer and chief operating officer at ServiceNow, framed it perfectly: “\nTraditional CRM is a patchwork\nof point solutions held together with duct tape and chewing gum. The result? More complexity, more cost, and less value.”\nThere may be buzz about dropping\nAI agents\ninto existing products, but that just adds to the patchwork. The opportunity instead is\nreinventing CRM\n—addressing real customer needs—through a true end-to-end AI-first approach on a single platform.\nDisrupting the CRM market\nTraditional CRM platforms have focused on sales pipeline management and customer support case intake, functioning as tools for forecasting and recordkeeping. At ServiceNow, we see CRM differently: We see a best-in-class, intuitive customer journey—a workflow-driven, AI-first orchestration of intelligent experiences—all on one platform.\nWith the promise of AI, customers expect better experiences across the enterprise, and their success in the era of AI-driven business transformation depends on it. The CRM market has to step up to the challenge, fast.\nHere’s how:\n1. Innovation is overdue\nFor too long, businesses have had limited choice with CRM providers. There are big names but too few options, stifling innovation. Competition fuels progress, pushing the industry to improve and ultimately benefiting customers. A new level of innovation, agility, and customer-centricity has been missing from the market and is desperately needed.\n2. A workflow-centric approach is a must\nTraditional CRM tools often center on building sales and customer support forecast systems—essentially, complex calculators that predict revenue. But the reality of customer engagement is far more dynamic and requires more than stacking systems on top of one another.\nOrganizations need to power hundreds of go-to-market (GTM) workflows that span the entire customer journey, from initial interest to ongoing support. ServiceNow’s strength in workflow automation fills this critical gap, enabling businesses to operate with greater speed, efficiency, and cohesion.\n3. CRM is a team sport\nCustomers don’t just interact with a single department. They engage with sales, marketing, customer service, and finance. Siloed applications that create fragmented customer experiences only increase the cost of serving customers and erode brand loyalty.\nA truly effective CRM system has an AI-first approach and unifies teams across the entire organization, ensuring seamless collaboration and a holistic customer view.\n4. AI is a game changer\nAI is top of mind for every organization, and its full potential in CRM has yet to be realized. Reinventing CRM on a platform that encompasses\nAI, data, and workflows\nwith an AI-first approach creates new opportunities for automation, intelligence, and customer engagement.\nBy embedding AI deeply into CRM workflows, we help businesses make smarter decisions, resolve customer issues faster, and provide personalized experiences at scale. That’s why\nGartner named us a leader in CRM customer engagement\n.\nDecades of excellence in customer relationships\nFred Luddy founded ServiceNow with the mindset that you put the customer first, second, and third. Every day since\nour humble beginning\n, we’ve dedicated ourselves to continuous and relentless innovation—transforming organizational workflows, optimizing business processes, and enhancing customer interactions.\nOur commitment to a human-centered approach in deploying our products and services has garnered the trust of companies across industries—including public sector, financial services, healthcare, and manufacturing—setting a benchmark for quality and reliability.\nThe pace of innovation is set by those in front. Currently, organizations helping customers harness the power of AI and navigate the complexities of AI-powered business transformation are leading the way.\nLooking ahead\nThe CRM space is ready for a new narrative. It’s time to say goodbye to incremental improvements and attempting to layer one solution on top of another. Instead, the only way forward is an end-to-end AI-first strategy, continuous improvement, strategic foresight, and relentless pursuit of excellence.\nServiceNow is hungry for new competitors to push us further. We’re eagerly working with our customers to drive value right now, addressing their real needs, always keeping an eye on what’s next. We’re taking big, bold steps. With our\nacquisition of Logik.ai\n, we’re reshaping the CRM landscape, offering businesses unprecedented opportunities for growth and success.\nMoving forward, our legacy of trust, innovation, and customer-centricity will continue to ground us as we pave the way for a new era in CRM.\nThis is just the beginning. We’re working with our customers to rethink what’s possible in CRM, using workflow automation, AI, and an integrated approach to customer relationships. The future of CRM isn’t just about managing relationships—it’s about transforming them.\nFind out more about how ServiceNow helps\npower customer experiences with CRM AI agents, data, and workflows\n.\n© 2025 ServiceNow, Inc. All rights reserved. ServiceNow, the ServiceNow logo, Now, and other ServiceNow marks are trademarks and/or registered trademarks of ServiceNow, Inc. in the United States and/or other countries. Other company names, product names, and logos may be trademarks of the respective companies with which they are associated.\n7.1k\nShares\nTopics\nAI and Automation\nApplication Development\nCareers\nCrisis Management\nCulture\nCustomer Experience\nCustomer Stories\nCybersecurity and Risk\nEducation\nEmployee Experience\nEvents\nFinancial Services\nGovernment\nHealthcare\nIT Management\nManufacturing\nNow on Now\nServiceNow AI Platform\nTelecommunications\nFeatured\nOur shared table: Honoring service through food\nHow culture landed ServiceNow on Fortune World’s Best Workplaces list\nGetting real results from AI: Managing an agentic workforce\nTrends & Research\nServiceNow is again a Gartner-named Leader in CRM Customer Engagement Center\nServiceNow named a Leader by Gartner® in business orchestration and automation\nServiceNow is an IDC MarketScape Leader in AI-enabled aftermarket/service lifecycle and FSM\nYear\n2025\n2024\n2023\n2022"
  },
  {
    "title": "ServiceNow and DXC: Building the future of insurance",
    "date": "June 16, 2025",
    "link": "https://www.servicenow.com/blogs/2025/dxc-building-future-insurance",
    "source": "Servicenow_blog",
    "main_ideas": [
      "Insurance must undergo rapid transformation to overcome outdated processes and technical debt.",
      "AI and cloud technologies are essential for modernizing insurance operations and enhancing customer experience.",
      "Successful AI adoption can significantly reduce process execution time and manual tasks in insurance."
    ],
    "tags": [
      "insurance",
      "artificial-intelligence",
      "cloud-computing",
      "digital-transformation",
      "customer-experience",
      "automation",
      "service-now",
      "dxc-technology",
      "process-improvement"
    ],
    "original_text": "ServiceNow and DXC: Building the future of insurance\nNIgel Walsh\nJune 16, 2025\nAI and cloud technologies are transforming all organizations. Insurance is no exception. These solutions are helping insurers embrace a digital-first approach and break free from outdated processes and legacy technical debt to improve customer experience and operational efficiency.\nAt Knowledge 2025, ServiceNow presented alongside our partner\nDXC Technology\nto offer insights on the role AI will play in the\nfuture of insurance\n. We also discussed why we’ve partnered to scale AI adoption across insurance organizations.\nHere are my key takeaways from the session.\n1. Failed transformations must end\nAlthough insurance was one of the first industries to adopt technology, it’s due for a material revolution. Antiquated processes, aging technical systems, and organizational inefficiencies have spawned capability debt and are holding insurers back.\nThe hornets’ nest of complexity created by dated workflows, multiple systems, and legacy technology is still working—for now. But if insurers want to accelerate growth and service delivery in the future, they’ll need a digital-first approach that emphasizes better workflows, insights, and business integration.\nAccording to HFS Research\n, “45% of insurers are already investing in technology-driven alignment of the front, middle, and back offices.” Yet not all of these attempts have been successful.\nThe insurance industry, like others, is littered with failed technology projects, preventing others from starting for fear they’ll be the next statistic. But doing nothing is not an option.\n“If you look at the insurance industry, it’s in desperate need of rapid transformation,” said Dan Stanovich, regional general manager of Americas insurance life business process services at DXC Technology.\n“There have been many different projects over the years—many failed projects—in which insurance companies have tried to transform themselves and just didn’t quite get there,” he added.\n2. AI and the cloud are streamlining service\nRip and replace is not always needed. There are other options. Despite the complexity compounded through years of mergers and acquisitions and a focus on growth, one common theme remains. Insurance organizations need to orchestrate their environments efficiently and effectively to expose the data that fuels an AI-enabled future, for internal teams and external customers alike.\n“\nAssure BPM\ngives insurers a practical way to modernize—without having to dismantle the systems they depend on,” said Ray August, president and EVP of DXC Insurance Software & BPS. “By exposing data and embedding AI into everyday workflows, we’re enabling insurers to deliver smarter, faster and more personalized customer experiences. With AI, we’re not just modernizing insurance operations; we’re redefining what’s possible.”\nSpecific use cases for AI in insurance include:\nPolicyholder self-service:\nAI-powered virtual assistants provide guided experiences for policyholders to self-serve common insurance tasks, such as making an address change.\nFraud detection:\nAI can analyze patterns in denied loan requests and call data to detect fraud and help live agents identify suspicious activity.\nProcess improvement:\nAI-driven process mining lets agents see how and why something happened. It also uses predictive analytics to compare, test, and improve processes.\nPolicy administration and billing:\nAI can be used to look at billing and beneficiary changes, check billing history, help with withdrawals and reinstatements, process payments, and seamlessly share in context with customers and agents.\n3. Process, meet AI\nThe insurance industry is reaping measurable results from embracing AI and the cloud.\n“We're seeing a 30% reduction in the amount of time it takes to actually execute a process,” said Jenna Colman, director of insurance solutions, insurance software, and BPS at DXC Technology. “We're also seeing a 30% reduction in the number of manual processes that exist out there.”\nThe combination of domain knowledge and powerful AI automation is key to building the most effective insurance workflows and creating a “force multiplier” effect.\n“Driving that automation with AI and prebuilt workflows, we're seeing an 80% reduction in how long it takes to build out the processes that you need in the insurance industry,” Colman summarized.\nWe couldn’t be more excited about this partnership. Together, we continue to drive transformation at scale across global carriers.\nFind out how ServiceNow can help you\nput AI to work for insurance\n.\n© 2025 ServiceNow, Inc. All rights reserved. ServiceNow, the ServiceNow logo, Now, and other ServiceNow marks are trademarks and/or registered trademarks of ServiceNow, Inc. in the United States and/or other countries. Other company names, product names, and logos may be trademarks of the respective companies with which they are associated.\n88\nShares\nTopics\nAI and Automation\nApplication Development\nCareers\nCrisis Management\nCulture\nCustomer Experience\nCustomer Stories\nCybersecurity and Risk\nEducation\nEmployee Experience\nEvents\nFinancial Services\nGovernment\nHealthcare\nIT Management\nManufacturing\nNow on Now\nServiceNow AI Platform\nTelecommunications\nFeatured\nOur shared table: Honoring service through food\nHow culture landed ServiceNow on Fortune World’s Best Workplaces list\nGetting real results from AI: Managing an agentic workforce\nTrends & Research\nServiceNow is again a Gartner-named Leader in CRM Customer Engagement Center\nServiceNow named a Leader by Gartner® in business orchestration and automation\nServiceNow is an IDC MarketScape Leader in AI-enabled aftermarket/service lifecycle and FSM\nYear\n2025\n2024\n2023\n2022"
  },
  {
    "title": "The future of CRM: Smarter, faster, and built to win",
    "date": "June 04, 2025",
    "link": "https://www.servicenow.com/blogs/2025/future-crm-smarter-faster",
    "source": "Servicenow_blog",
    "main_ideas": [
      "Modern CRM must connect teams and drive performance across the revenue lifecycle.",
      "Businesses seek intelligent platforms that automate processes and eliminate data silos.",
      "ServiceNow's CRM offers a unified solution for sales, marketing, and customer service."
    ],
    "tags": [
      "crm",
      "service-now",
      "ai",
      "automation",
      "customer-experience",
      "sales",
      "marketing",
      "data-integration",
      "revenue-operations"
    ],
    "original_text": "The future of CRM: Smarter, faster, and built to win\nTony Varaganti\nJune 04, 2025\nEmily Rust, CRM and industry expert services practice leader at ServiceNow, co-authored this blog post.\nCustomer relationship management (\nCRM\n) is no longer just about tracking records in a database with process flows. Modern CRM must be a connected, intelligent engine that drives performance across the entire revenue lifecycle, from marketing to quoting to fulfillment to customer servicing—all powered by CRM\nAI agents\n.\nAt ServiceNow, we’re helping customers move beyond disconnected tools to an intelligent, unified platform that connects every team in the revenue engine—from first touch to final invoice. It’s a complete\nCRM reinvention\n.\nMy conversations with customers over the past several months have echoed the same theme. Expectations for CRM are evolving fast, and traditional systems have not delivered on their promises. Businesses today want more than data storage; they want action.\nThey need a connected revenue platform that brings together sales force automation; configure, price, quote (CPQ); contract lifecycle management; and order management on one unified system.\nServiceNow\nCustomer Relationship Management\nhelps answer that call, providing an end-to-end experience, accelerating actions, automating complex processes, and aligning every team in the revenue engine.\nWhy today’s CRM isn’t cutting it\nSales teams want best-in-class tools that let them self-serve and find qualified leads so that they can quote high-value deals quickly without red tape. At the same time, revenue operations and finance are under pressure to streamline fulfillment, handle contract changes smoothly, and eliminate manual handoffs.\nOver the past two years, the most common friction points I’ve heard from customers are:\nData silos between marketing and sales systems\nChallenges with order fulfillment\nComplex mid-contract changes\nSiloed marketing systems leave sales representatives and sales development representatives (SDRs) flying blind. They can’t see lead engagement history, score intent accurately, or prioritize outreach effectively.\nWhen a customer requests a contract change, the process often involves canceling the original contract, recalculating proration, and manually issuing a new contract. Teams are juggling spreadsheets, chasing approvals through email, and going back and forth across departments. This slows everything down, increases risk, and drains resources.\nIn a high-velocity sales environment, this kind of inefficiency is not acceptable.\nModern CRM expectations\nToday’s revenue teams want more than a digital database. They want CRM that acts as the intelligent control center for their operations. They expect:\nA unified platform connecting the front, middle, and back offices\nReal-time data that drives fast decisions\nA single data model that reduces system complexity\nAI-driven automation that eliminates guesswork\nWhen marketing, sales, contracting, fulfillment, and customer service teams all work on one intelligent platform, organizations can move faster, serve customers better, and help prevent revenue loss.\nMost customers I’ve interacted with are trying to stitch these capabilities together through customizations or bolting on additional applications, but ServiceNow delivers them out of the box.\nMarketing and lead management alignment\nTenon, a marketing automation tool built on ServiceNow’s single data model, works with CRM AI agents to qualify and nurture leads. It handles demo requests, responds to inquiries, and advances lead stages. This gives SDRs time to focus on high-value conversations while warm leads flow into the pipeline efficiently.\nGuided sales experience\nServiceNow Needs Analysis and Playbooks features help sales reps receive visual, step-by-step guidance through the entire sales cycle. They no longer need to memorize workflows or guess what information is required to progress a deal.\nThe system captures key business needs, recommends products relevant to those needs, and helps ensure everything is ready to move from opportunity to quote to order. Reps have clear visibility into what’s been completed, what comes next, and how close they are to closing. This helps save time, reduce errors, and accelerate deal cycles.\nUnified contract lifecycle management\nServiceNow\nContract Management Pro\n, a built-in and not-bolted-on solution, brings sales, revenue operations, legal, and finance into one shared workspace for full visibility and a single source of truth.\nContract AI agents can suggest missing clauses and frequently negotiated language. This helps standardize approvals, speed up negotiations, and close deals faster without having to chase alignment.\nStreamlined customer lifecycle workflows\nServiceNow\nlead-to-cash\ncore fundamentals and move, add, change, delete (MACD) workflows are built on a composable architecture, triggered from sources such as the installed base or service contract lines for scalable, flexible execution.\nServiceNow CPQ\nsupports upsell, cross-sell, and service suspension and recovery within existing contracts.\nWhen forecasting is required, workflows can start with an opportunity, followed by quoting and ordering. And where sales agreements exist (original equipment manufacturer, reseller, and managed service provider use cases, for example), ServiceNow enables direct order creation, meeting compliance with volume and pricing commitments.\nThis unified approach streamlines the customer lifecycle with speed, precision, and adaptability.\nOrder fulfillment\nOrder fulfillment delays are often a result of missing or incomplete information. With ServiceNow, that’s no longer a concern. Our CRM AI agents check billing, purchase orders, start dates, and more before an order moves forward.\nIf something needs attention, AI agents automatically flag the appropriate person to address it. The order keeps moving, even if some items are fulfilled later. This makes the whole process faster, clearer, and easier to manage.\nA connected customer journey\nBolted-on systems and reactive CRM strategies belong to the past. The\nfuture of CRM\nis a unified, AI-powered revenue platform that connects every step of the customer journey, from lead to quote to order to cash.\nNow is the time to explore what’s possible and unlock a new level of speed and efficiency in your revenue operations.\nFind out how ServiceNow expert services can help your organization\nboost customer satisfaction\n.\n© 2025 ServiceNow, Inc. All rights reserved. ServiceNow, the ServiceNow logo, Now, and other ServiceNow marks are trademarks and/or registered trademarks of ServiceNow, Inc. in the United States and/or other countries. Other company names, product names, and logos may be trademarks of the respective companies with which they are associated.\n75\nShares\nTopics\nAI and Automation\nApplication Development\nCareers\nCrisis Management\nCulture\nCustomer Experience\nCustomer Stories\nCybersecurity and Risk\nEducation\nEmployee Experience\nEvents\nFinancial Services\nGovernment\nHealthcare\nIT Management\nManufacturing\nNow on Now\nServiceNow AI Platform\nTelecommunications\nFeatured\nOur shared table: Honoring service through food\nHow culture landed ServiceNow on Fortune World’s Best Workplaces list\nGetting real results from AI: Managing an agentic workforce\nTrends & Research\nServiceNow is again a Gartner-named Leader in CRM Customer Engagement Center\nServiceNow named a Leader by Gartner® in business orchestration and automation\nServiceNow is an IDC MarketScape Leader in AI-enabled aftermarket/service lifecycle and FSM\nYear\n2025\n2024\n2023\n2022"
  },
  {
    "title": "From planned to predictive: Reshaping preventive maintenance",
    "date": "July 30, 2025",
    "link": "https://www.servicenow.com/blogs/2025/reshaping-preventive-maintenance",
    "source": "Servicenow_blog",
    "main_ideas": [
      "Predictive maintenance reduces unplanned downtime and enhances operational efficiency.",
      "Modern technologies like IIoT sensors and cloud analytics enable proactive maintenance strategies.",
      "Organizations are integrating AI to improve maintenance workflows and decision-making."
    ],
    "tags": [
      "predictive-maintenance",
      "iiot",
      "cloud-analytics",
      "artificial-intelligence",
      "operational-efficiency",
      "manufacturing",
      "service-now",
      "data-driven",
      "automation"
    ],
    "original_text": "From planned to predictive: Reshaping preventive maintenance\nNeelima Rustagi\nJuly 30, 2025\nIn today’s industrial landscape, unplanned downtime continues to be one of the most significant threats to operational efficiency. Unexpected outages can erode more than 10% of a company’s annual revenue, according to a Siemens report.\n1\nAt the same time, nearly half of all manufacturers now have dedicated predictive maintenance teams—twice as many as five years ago.\nA combination of low-cost industrial internet of things (IIoT) sensors, scalable cloud analytics, and modern\noperational technology\n(OT) management systems are making\npreventive maintenance\nattainable, helping teams respond to asset conditions before failures occur. Organizations are embracing this shift to increase asset uptime, operational efficiency, and margins.\nThe evolution of maintenance\nTo understand the opportunity, it’s helpful to consider three common maintenance strategies used in manufacturing today:\nPlanned maintenance\nis the most basic level. Maintenance tasks are scheduled at fixed intervals, regardless of whether equipment actually needs attention. It’s widely used but inefficient.\nProactive maintenance\nuses simple, condition-based triggers. When a sensor detects that a parameter has exceeded a set threshold, such as excessive vibration or temperature, maintenance is scheduled.\nPredictive maintenance\ngoes a step further. By analyzing patterns across multiple data points, predictive models can forecast when a failure is likely to happen, giving teams a chance to intervene precisely when it matters most.\nWhile traditional asset management or production management systems are good at planning and record-keeping, they often struggle to keep up with the data demands and responsiveness required for predictive approaches. Even advanced preventive maintenance solutions often fail to deliver real-world results because they lack the capabilities to assign, route, and track the work that needs to be done.\nUnifying shop floor data with AI and automated workflows can make a difference.\nPowering predictive maintenance\nModern condition monitoring systems have made it possible to continuously observe machines using sensors that track vibration, heat, noise, pressure, and other variables. These sensors provide a steady stream of performance data. But raw data alone doesn’t create value. The key is context—being able to connect that data to the right operational workflows.\nThis is where solutions such as\nAWS IoT SiteWise\nand ServiceNow\nOperational Technology Management\nplay a critical role.\nAWS IoT SiteWise handles the heavy lifting when it comes to ingesting and modeling industrial data from sensors, historians, supervisory control and data acquisition (SCADA) systems, and programmable logic controllers (PLCs). It helps teams organize and analyze data in real time or near-real time.\nOnce anomalies are detected, ServiceNow Operational Technology Management, built on the\nServiceNow AI Platform\n, acts as the system of action—creating incidents, triggering work orders, and helping to ensure issues are tracked and resolved before they cause downtime.\nOperator efficiency in action\nLet’s consider a practical use case. An operator on a bottling line notices no visible issues, but the IIoT sensors are telling a different story. An AWS-based monitoring solution detects abnormal vibration from a pump—well above the normal range. That data is run through a predictive model, which estimates a 72% chance the pump will fail within the next 36 hours.\nRather than wait for a failure to happen, the system automatically creates a maintenance event in ServiceNow. That triggers an OT incident, which flows into a planned work order. The task is bundled into a weekend maintenance window, minimizing disruption. Once the repair is done, the operator uses a mobile app to confirm the line is running normally again, and that feedback is sent back into the model to help refine future predictions.\nThis is what predictive maintenance looks like when it works: no downtime, no overtime, and a closed feedback loop that helps the system get smarter over time.\nA foundation for the data-driven factory\nPredictive maintenance is often the first step toward building a truly digital factory. Once your machines are instrumented and your data pipelines are working, you can layer on additional capabilities, such as energy optimization, quality control analytics, and even AI-based digital assistants.\nOrganizations such as\nSiemens\nare already integrating\nconversational AI\ninto their maintenance platforms, allowing operators to interact with the system naturally using voice or chat interfaces.\nIn this context, predictive maintenance isn’t just about fixing machines. It’s about transforming the way your entire operation runs.\nPlanned maintenance got us through the last century. Predictive maintenance will define this one. By combining IIoT data streams with intelligent, automated workflows, manufacturers are turning every asset into a source of insight—and every anomaly into a chance to act before failure strikes.\nThe future belongs to organizations that can anticipate it. With the right tools, that future is already within reach.\nFind out how ServiceNow can help you\nput AI to work in manufacturing\n.\n1\nSiemens, The True Cost of Downtime 2024\n© 2025 ServiceNow, Inc. All rights reserved. ServiceNow, the ServiceNow logo, Now, and other ServiceNow marks are trademarks and/or registered trademarks of ServiceNow, Inc. in the United States and/or other countries. Other company names, product names, and logos may be trademarks of the respective companies with which they are associated.\n79\nShares\nTopics\nAI and Automation\nApplication Development\nCareers\nCrisis Management\nCulture\nCustomer Experience\nCustomer Stories\nCybersecurity and Risk\nEducation\nEmployee Experience\nEvents\nFinancial Services\nGovernment\nHealthcare\nIT Management\nManufacturing\nNow on Now\nServiceNow AI Platform\nTelecommunications\nFeatured\nOur shared table: Honoring service through food\nHow culture landed ServiceNow on Fortune World’s Best Workplaces list\nGetting real results from AI: Managing an agentic workforce\nTrends & Research\nServiceNow is again a Gartner-named Leader in CRM Customer Engagement Center\nServiceNow named a Leader by Gartner® in business orchestration and automation\nServiceNow is an IDC MarketScape Leader in AI-enabled aftermarket/service lifecycle and FSM\nYear\n2025\n2024\n2023\n2022"
  },
  {
    "title": "ServiceNow: Platform first, platform forever",
    "date": "July 17, 2025",
    "link": "https://www.servicenow.com/blogs/2025/servicenow-platform-first-forever",
    "source": "Servicenow_blog",
    "main_ideas": [
      "ServiceNow was founded with the vision of simplifying business application development.",
      "The platform's evolution has been driven by customer needs and technological advancements.",
      "Agentic AI is transforming how ServiceNow addresses business challenges across various functions."
    ],
    "tags": [
      "servicenow",
      "platform",
      "ai",
      "cloud-computing",
      "business-applications",
      "it-service-management",
      "automation",
      "enterprise-software",
      "agentic-ai"
    ],
    "original_text": "ServiceNow: Platform first, platform forever\nPat Casey\nJuly 17, 2025\nMy journey with ServiceNow didn’t start with a grand plan; it started with a near miss— literally. In 2004, I almost ran over Fred Luddy. I was driving through our shared hometown when he stepped into the crosswalk in front of me. Thankfully, I saw him. We recognized each other, as I’d worked for him at a previous company.\nOne thing led to another, and he invited me to check out what he was working on. A few days later, he showed me a very early build of what he called the Glide platform (which is now the\nServiceNow AI Platform\n). It was missing all sorts of features, functions, and capabilities it has now, but the core concepts, from the metadata-driven user interface to the intrinsic relational model built into the data structures, were present even then.\nI didn’t really get it in that first demo. My mind immediately thought of all the things I could not do with Fred’s platform rather than all the things that could be done more simply. Still, I was intrigued by the idea of working on something new with somebody I respected, so I decided to join.\nFred Luddy’s key insights\nWhen Fred founded ServiceNow in 2004, he had a very specific vision. He wanted to build a platform that would allow anyone to create meaningful business applications. We may not have reached the point back then where my mother (who’s a very smart but nontechnical human) could have created an app, but we did succeed in radically reducing the complexity of the process.\nAlthough we ended up going to market with our\nIT Service Management\n(ITSM) applications, the platform vision remained and evolved. And it’s still relevant today as we look at industry developments such as\nagentic AI\n.\nIn hindsight, Fred really had three distinct insights about the market and technology’s ability to solve them. Part of his genius was being able to apply new technology to old problems.\nPlatform:\nFred believed that simplification was a feature. If he simplified the acts of creating, modifying, and updating an application sufficiently, that would more than offset the value lost by restricting what a user could do. By making it dramatically easier to perform frequent activities, people wouldn’t stress about not being able to do some of the more obscure things they could do with other technologies of that era.\nBrowser:\nIn 2004, the idea of delivering software via a browser was novel. The default at that time was to ship desktop application-based “fat” clients, and it wasn’t unusual for a knowledge worker to have dozens of unique client apps on their workstation. By switching to browser-based apps, Fred was ahead of the curve, in that he already saw the browser as the new Universal Client.\nDelivery model:\nFred had experienced all the downsides of traditional software delivery firsthand, since he’d been in the industry for nearly 30 years at that point. He knew the value he could offer with an evergreen software as a service (SaaS) application the customer wouldn’t have to support, manage, or operate.\nOvercoming early challenges\nAlthough we got the big things right, we had some rather significant business challenges to deal with. The simplest of those challenges was selling an enterprise platform. When your company is basically half a dozen people working in the basement of your venture capital firm, it’s kind of an awkward sales discussion.\nWe ended up in a number of pitch meetings where we demonstrated all the power of the platform only to hear the customer ask, “Yes, but what can you do with it?” We tried to turn the question around by asking, “Well, what do you want it to do?”\nWe wrote the original set of ITSM applications that helped drive our initial public offering to show off the power of the platform. Back then, people were much more interested in buying apps than in the platform itself, so that became our default sales motion.\nAnother challenge was that the public cloud infrastructure we take for granted today didn’t exist then. If we wanted to deliver software via a SaaS model, we needed to buy servers, lease data center space and cable racks, lay out networking, and do all the physical infrastructure stuff a cloud requires.\nGetting the cloud right was, in many ways, harder than getting the product and platform right. We’re good cloud operators now, but we weren’t in 2004. We needed lots of on-the-job training because there weren’t many people with that skill set back then.\nThe platform was the goal\nRegardless, we stuck to the original product vision of a platform an average person could use to build business applications. Although we were going to market as an apps company, we kept architecting the technology stack with a platform lens.\nThe apps we sold to our customers were pure play platform apps. Every single one could have been written by a customer who had access to the platform.\nSome customers figured this out and started building their own apps on the platform to do all sorts of interesting stuff. For example,\nCERN\n, a European scientific research center, built an entire site management suite on top of ServiceNow. This enabled a visiting researcher to use our\nService Catalog\nto manage everything from desk lamps to access to the Large Hadron Collider.\nWe’ve stuck with that model through the years, and it’s one of the reasons we’ve been able to expand the breadth of our product area so easily into other areas, such as\nHR\n,\ncustomer relationship management\n,\nsecurity\n, and\nlegal\n.\nIf you want to model a business process—and it has structured data, multiple steps, approvals, notifications, and assignments—the ServiceNow Platform remains one of the most productive ways to do so.\nKey milestones and lessons learned\nWhen I look back at how ServiceNow grew as a company, there were a few pivotal points where we faced unexpected circumstances and made the right decisions.\nFirst was deciding to whom we wanted to sell. The original business concept included the idea that SaaS was going to be a midmarket play and we’d have many small and midsize customers. Early in our journey, though, we started landing big, enterprise customers, such as\nEdmunds.com, TIAA-CREF\n, and\nDeutsche Bank\n.\nWe had to make a call at that point as to whether we wanted to invest in the kind of features major enterprises needed or stay focused on our core, midmarket play. Ultimately, we did both. And by adding a lot of enterprise-grade functionality, we pivoted and moved the platform and applications upmarket.\nA second inflection point occurred during the Great Recession in 2008. It hit the economy like a freight train and disrupted the software industry. People’s budgets and behaviors changed dramatically.\nThe Great Recession was a tail wind for us, because one of our core value propositions was that ServiceNow was better than the competition and, from a total cost of ownership standpoint, cheaper. We were in the right place at the right time, and our newly minted enterprise credibility enabled us to have conversations with buyers about saving money, one of their top priorities.\nWe could scale up to enterprise workloads because we’d designed the platform with a tenancy model and clustering structure that allowed us to run the operations of big customers. Similarly, we could save customers money because of our SaaS and deployment model.\nFrom AI to agentic AI\nWe’ve been offering some form of AI tooling on the platform for at least a decade. We started off using supervised machine learning to solve simple tasks such as assigning and prioritizing cases. Given time and good training data, we could deploy AI that helped save customers time and money.\nThat same platform architecture continues to bear fruit for ServiceNow in the agentic AI era. When new tech comes along, we have to add it only once. Then it’s available to all our customers across all our products.\nAgentic AI systems built on large language models (\nLLM\n) are far more sophisticated than those early machine learning solutions, and far more generalizable in how they can be applied. Today we don’t need to train a model to prioritize cases. We can just have it tell us how to prioritize a list of customer requests. And it’s at least as good as an average human would be if given the same task.\nAdditionally, agentic AI systems can perform more sophisticated reasoning tasks that previous generations of AI couldn’t even conceptualize. For example, an\nAI agent\nrunning on the ServiceNow AI Platform can figure out that Mary’s email account is locked because she hasn’t completed the mandatory security training.\nThat’s an ITSM use case, but AI agents can address similar challenges across every business function. For example, AI agents can walk you through the process of modifying your healthcare enrollment because you just had a baby (an HR use case).\nCalculated risks for continuous improvement\nAs I look back at the history of the company, I’m struck by how much the agentic AI revolution feels like those early days of ServiceNow. AI technology is evolving incredibly rapidly. We don’t yet have clearly defined models, rules, or approaches to help us solve problems—or even to identify which problems are worth solving.\nManaging velocity is a significant challenge when you have 8,400 customers. When we were smaller, with just 84 customers, shipping a bug that affected one customer wasn't a big deal. Now, the stakes are much higher.\nFortunately, our platform has come to the rescue, enabling us to track our development efficiently. We release agentic AI updates frequently and embrace innovation as technology evolves, ensuring we deliver the best features and functionality as quickly as possible.\nHowever, for our core platform services—from the user interface to workflows to business applications—we use a traditional release model. This approach helps us maintain the quality required for these mission-critical systems.\nThe platform's underlying separation of concerns model allows us to achieve this in a way that wouldn't be technically feasible with many other architectures.\nIt’s always a bit reductive to try to summarize something as complex as a company’s history down to one point. But if I had to, it would be this: The best decision we ever made was to build a platform-centric product rather than an application-centric one.\nIt’s a decision that’s helped us at various points throughout the years and continues to help us—and our customers—today.\nFind out more about the\nbenefits of the ServiceNow AI Platform\nfor business transformation.\n© 2025 ServiceNow, Inc. All rights reserved. ServiceNow, the ServiceNow logo, Now, and other ServiceNow marks are trademarks and/or registered trademarks of ServiceNow, Inc. in the United States and/or other countries. Other company names, product names, and logos may be trademarks of the respective companies with which they are associated.\n228\nShares\nTopics\nAI and Automation\nApplication Development\nCareers\nCrisis Management\nCulture\nCustomer Experience\nCustomer Stories\nCybersecurity and Risk\nEducation\nEmployee Experience\nEvents\nFinancial Services\nGovernment\nHealthcare\nIT Management\nManufacturing\nNow on Now\nServiceNow AI Platform\nTelecommunications\nFeatured\nOur shared table: Honoring service through food\nHow culture landed ServiceNow on Fortune World’s Best Workplaces list\nGetting real results from AI: Managing an agentic workforce\nTrends & Research\nServiceNow is again a Gartner-named Leader in CRM Customer Engagement Center\nServiceNow named a Leader by Gartner® in business orchestration and automation\nServiceNow is an IDC MarketScape Leader in AI-enabled aftermarket/service lifecycle and FSM\nYear\n2025\n2024\n2023\n2022"
  },
  {
    "title": "Agentic AI: The future of workforce engagement",
    "date": "July 10, 2025",
    "link": "https://www.servicenow.com/blogs/2025/agentic-ai-future-workforce-engagement",
    "source": "Servicenow_blog",
    "main_ideas": [
      "Agentic AI enhances employee engagement by automating workflows and utilizing data from multiple systems.",
      "Modern platforms like ServiceNow integrate disparate systems to improve employee experiences and productivity.",
      "Companies with engaged employees experience significantly higher profitability and well-being."
    ],
    "tags": [
      "agentic-ai",
      "employee-engagement",
      "servicenow",
      "automation",
      "workflows",
      "data-integration",
      "hr-tech",
      "productivity",
      "business-performance"
    ],
    "original_text": "Agentic AI: The future of workforce engagement\nJosh Kahn\nJuly 10, 2025\nEmployee engagement is no longer a “nice to have.” It’s a business imperative. Instead of asking employees to figure out where to go, what to do, and whom to ask, we should be building systems that do that thinking for them. That’s the key to\nworkforce engagement\n.\nAgentic AI\nis enabling new ways to delight employees and drive greater productivity across the organization—but it takes a combination of AI, data, and workflows.\nThe trifecta: Workflows, data, and AI\nAgentic AI has the ability to reason on its own, work across agents, and take action on the job at hand. It understands regular, natural language and intent, can pull from multiple systems at the same time, and carries out tasks for you. But agentic AI or data from a single system isn't enough to engage workers—it takes workflows too.\nConsider\nemployee onboarding\n. Deterministic workflows handle mission-critical, nonnegotiable steps such as background checks, employee verification, and updating payroll so that new employees can get to work on day 1.\nAgentic AI builds on this, working smarter to turbocharge employees’ efficacy and success and save managers time. The technology can help create personalized new-hire ramp-up plans and schedule high-priority meetings. These activities are perfect for agentic AI because they involve multiple data sources and require reasoning and low-risk, automated actions.\nIf you limit your AI workflows to data that’s available only in your human capital management system, you also limit the scope of what it can accomplish and its ability to reason.\nTo maximize the impact of AI and workflows, you need as much data as you can provide. This data is often sitting in more than 100 systems across the organization, many of which are outside of HR.\nEasier work, better employee engagement\nModern platforms, such as the ServiceNow AI Platform, connect siloed and disparate systems and fragmented data to anticipate needs instead of just responding to them.  Here are a few examples from leaders in employee engagement.\nMondelez International\ncreated an all-encompassing employee portal with self-service as its cornerstone using ServiceNow\nHR Service Delivery\nand\nEmployee Center\n. The solution seamlessly integrates with Workday, Microsoft Teams, and third-party payroll solutions.\nThis has resulted in a 76% jump in self-service, deflection rates of 30% to 60%, and a 78% drop in day 1 laptop delays—earning Mondelez first place in single-departmental employee portals in our\n2025 Best Employee Portal Contest\n.\nIn another instance,\nDanone\nstandardized its employee experience across 96,000 employees with HR Service Delivery and\nApp Engine\n. It provided a single hub where employees can get what they need, when they need it, helping the company secure best overall employee portal in our contest.\nThis is the future of work—streamlined, intuitive, and people-centered.\nThe best experience wins\nOrganizations that get AI right won’t just retain talent—they’ll also improve business. Engaged employees move faster, stay longer, and build stronger cultures. We’re already seeing proof.\nBusinesses with highly engaged workers reap 23% higher profitability, 70% greater well-being, and 22% increased participation in the organization than businesses with disengaged workers, according to Gallup.\n1\nIf your systems are still asking employees to chase answers, there’s a better way. Start with what they need, automate what you can, and empower them to handle the rest. That’s how you turn workflows into impact.\nFind out how ServiceNow can help you\ncreate smarter, more human experiences\nfor every employee.\n1\nGallup, State of the Global Workplace: 2024 Report\n© 2025 ServiceNow, Inc. All rights reserved. ServiceNow, the ServiceNow logo, Now, and other ServiceNow marks are trademarks and/or registered trademarks of ServiceNow, Inc. in the United States and/or other countries. Other company names, product names, and logos may be trademarks of the respective companies with which they are associated.\n85\nShares\nTopics\nAI and Automation\nApplication Development\nCareers\nCrisis Management\nCulture\nCustomer Experience\nCustomer Stories\nCybersecurity and Risk\nEducation\nEmployee Experience\nEvents\nFinancial Services\nGovernment\nHealthcare\nIT Management\nManufacturing\nNow on Now\nServiceNow AI Platform\nTelecommunications\nFeatured\nOur shared table: Honoring service through food\nHow culture landed ServiceNow on Fortune World’s Best Workplaces list\nGetting real results from AI: Managing an agentic workforce\nTrends & Research\nServiceNow is again a Gartner-named Leader in CRM Customer Engagement Center\nServiceNow named a Leader by Gartner® in business orchestration and automation\nServiceNow is an IDC MarketScape Leader in AI-enabled aftermarket/service lifecycle and FSM\nYear\n2025\n2024\n2023\n2022"
  },
  {
    "title": "AI in financial services: Powering the next wave of transformation",
    "date": "July 09, 2025",
    "link": "https://www.servicenow.com/blogs/2025/how-ai-is-transforming-financial-services",
    "source": "Servicenow_blog",
    "main_ideas": [
      "AI is transforming financial services by enhancing customer experiences and operational efficiency.",
      "Banks are increasingly investing in AI to meet regulatory demands and customer expectations.",
      "Agentic AI is emerging as a key technology, enabling autonomous decision-making in financial institutions."
    ],
    "tags": [
      "artificial-intelligence",
      "financial-services",
      "customer-experience",
      "cybersecurity",
      "automation",
      "data-governance",
      "agentic-ai",
      "machine-learning",
      "risk-management"
    ],
    "original_text": "AI in financial services: Powering the next wave of transformation\nServiceNow Blog\nJuly 09, 2025\nExperienced human writers and editors used AI to help research and draft this blog post. These humans then edited and fact-checked the post to ensure it meets our rigorous editorial standards.\nIn today's digital landscape, banks are facing increasing regulatory demands and customer expectations regarding what they should provide. But disconnected data and systems are preventing financial services organizations from meeting those expectations.\nAI offers a way for banks to manage their business end to end, across front, middle, and back offices. In fact, 84% of banks expect to increase their investment in AI throughout the next fiscal year, according to new\nbanking research\nfrom ServiceNow.\nAI is already\ntransforming the financial services industry\n, giving bank workers the tools they need to meet—and exceed—customer expectations.\nTable of contents\nWhat is AI in financial services?\nHow can AI be used in financial services?\nThe rise of agentic AI in financial services\nHow AI is changing jobs in financial services\nHow to use AI in financial services\nThe financial AI maturity imperative\nWhat is AI in financial services?\nAI in financial services\nis the application of artificial intelligence technologies such as\nmachine learning\n,\nnatural language processing\n, and advanced analytics to transform raw financial data into actions that can lead to strategic business value.\nFinancial institutions that harness AI are doing much more than simply automating tasks. They're unlocking capabilities to predict market trends, personalize customer experiences, and make risk-informed decisions with remarkable speed and accuracy—ultimately increasing their bottom line.\nOur research found that 8.4% of banks are already seeing a boost in gross margin from increased AI usage over the previous year.\nHow can AI be used in financial services?\nForward-thinking financial institutions are deploying AI across their entire value chain, creating seamless experiences that were unimaginable just a few years ago. Our research found that 57% of banks have rolled out 100 or more AI use cases across the enterprise, including:\nFront office\nCustomer behavior analysis:\nTransforming vast customer data sets into actionable insights that predict needs before they arise\nHyper-personalization:\nDelivering tailored financial recommendations that resonate with each customer's unique financial journey\nDynamic pricing:\nImplementing demand-based pricing models that maximize value for both customers and institutions\nMiddle office\nEnhanced security:\nDeploying advanced cybersecurity systems that identify threats in real time so that you can stay ahead of sophisticated attacks\nFraud prevention:\nDramatically reducing false positives;\nHSBC\n, for example, cut fraud alert false positives by 60%, saving millions of dollars annually while strengthening customer trust\nRisk management:\nProcessing complex risk factors instantaneously to safeguard assets and optimize portfolios\nBack office\nStreamlined operations\n: Automating routine processes while enhancing accuracy and compliance\nIT infrastructure optimization\n: Automatically predicting and resolving technology issues before they affect customer experience\nFinancial reporting\n: Generating real-time financial insights that drive strategic decision-making\nThe rise of agentic AI in financial services\nThe most significant development transforming financial services is\nagentic AI\n—autonomous systems that can understand, reason, and act on behalf of a financial institution and its customers. Our research reveals that 22% of banks are already using agentic AI solutions and 41% are considering adopting agentic AI within a year.\nCommonwealth Bank of Australia\nis using agentic AI to manage credit card payment disputes. Its solution processes natural language customer queries through a large language model (\nLLM\n). An AI agent then assesses and addresses issues in minutes rather than days—increasing customer satisfaction while reducing operational costs.\nHow AI is changing jobs in financial services\nAI is taking over repetitive work, freeing humans to focus on higher-value activities that drive business outcomes. Examples include:\nStrategic advisors\n: Customer-facing roles are evolving from transaction processors to trusted financial advisors empowered by AI-driven insights.\nRisk innovators\n: Risk management professionals now focus on developing novel approaches to emerging challenges rather than conducting manual compliance checks.\nDigital experience designers\n: New roles center on creating seamless, intuitive digital journeys powered by AI.\nAI ethics specialists\n: These emerging positions are dedicated to helping to ensure\nresponsible AI\ndeployment that maintains customer trust.\nFinancial services organizations leading in AI prioritize training and upskilling. The vast majority have invested in talent development programs that prepare their workforce for an AI-powered future. More than half (56%) believe they have the right mix of talent and skills to carry out their AI strategy.\nHow to use AI in financial services\nOrganizations in our banking study that scored highest in AI maturity are called Pacesetters. Based on the research findings, we developed a Pacesetter roadmap for financial institutions looking to maximize the transformative potential of AI:\nEmbrace an innovation mindset:\nMore than half (52%) of Pacesetters have launched AI innovation centers to stay at the forefront of innovation.\nAdopt a platform approach:\nNearly two-thirds (63%) of Pacesetters prefer comprehensive, AI-powered platforms over point solutions. They understand that AI's true power comes from connecting previously siloed data and processes across the enterprise.\nPrioritize data governance:\nPacesetters recognize that without clean, accessible data, even the most sophisticated AI models will underperform. Almost three-quarters (73%) of Pacesetters have implemented formal data governance and compliance programs.\nBuild cross-functional AI teams:\nAI success requires getting leadership buy-in and cascading that down to staff. Nearly two-thirds (65%) of Pacesetters are operating with a clear, shared AI vision across the wider organization.\nStart with high-impact use cases:\nBegin your AI journey with focused applications that deliver measurable value, then scale systematically across the organization.\nThe financial AI maturity imperative\nIn financial services, the AI race is on. Financial institutions that have embraced AI are seeing margin growth of 10.9% from their AI investments—substantially outperforming the study average of 7.8%, according to our research.\nThese leaders are achieving 2.13 times greater efficiency and productivity from their AI initiatives compared to other organizations. In doing so, they’re creating a competitive gap that widens with each passing quarter.\nThe message is clear: Financial institutions that fail to harness AI risk falling behind. By building on a foundation of clean data, adopting a platform approach, and fostering an innovation culture, you can position your organization at the forefront of the AI-powered future of finance—where unprecedented efficiency meets unparalleled customer experience.\nFind out how ServiceNow can help you\nput AI to work for banking\n.\n© 2025 ServiceNow, Inc. All rights reserved. ServiceNow, the ServiceNow logo, Now, and other ServiceNow marks are trademarks and/or registered trademarks of ServiceNow, Inc. in the United States and/or other countries. Other company names, product names, and logos may be trademarks of the respective companies with which they are associated.\n23\nShares\nTopics\nAI and Automation\nApplication Development\nCareers\nCrisis Management\nCulture\nCustomer Experience\nCustomer Stories\nCybersecurity and Risk\nEducation\nEmployee Experience\nEvents\nFinancial Services\nGovernment\nHealthcare\nIT Management\nManufacturing\nNow on Now\nServiceNow AI Platform\nTelecommunications\nFeatured\nOur shared table: Honoring service through food\nHow culture landed ServiceNow on Fortune World’s Best Workplaces list\nGetting real results from AI: Managing an agentic workforce\nTrends & Research\nServiceNow is again a Gartner-named Leader in CRM Customer Engagement Center\nServiceNow named a Leader by Gartner® in business orchestration and automation\nServiceNow is an IDC MarketScape Leader in AI-enabled aftermarket/service lifecycle and FSM\nYear\n2025\n2024\n2023\n2022"
  },
  {
    "title": "What's Next for AI in Telecom? Insights from MWC 2025",
    "date": "Chief Marketing Officer, Amdocs",
    "link": "https://www.amdocs.com/insights/blog/whats-next-ai-telecom-insights-mwc-2025",
    "source": "Amdocs",
    "main_ideas": [
      "AI is transforming the telecom industry with innovative solutions.",
      "MWC 2025 showcased advancements in AI technologies for telecom.",
      "Telecom companies are leveraging AI for improved customer experiences."
    ],
    "tags": [
      "ai",
      "telecom",
      "mwc-2025",
      "innovation",
      "customer-experience"
    ],
    "original_text": "Request unsuccessful. Incapsula incident ID: 763000390017176554-12250913225509315"
  },
  {
    "title": "How AI powers healthcare innovation",
    "date": "August 28, 2025",
    "link": "https://www.servicenow.com/blogs/2025/how-ai-powers-healthcare-innovation",
    "source": "Servicenow_blog",
    "main_ideas": [
      "AI is transforming healthcare by optimizing operations and enhancing patient experiences.",
      "Healthcare organizations are increasingly investing in AI technologies for better outcomes.",
      "AI tools like machine learning and natural language processing are improving clinical decision-making."
    ],
    "tags": [
      "artificial-intelligence",
      "healthcare",
      "machine-learning",
      "natural-language-processing",
      "predictive-analytics",
      "patient-experience",
      "clinical-decision-support",
      "automation",
      "data-integration"
    ],
    "original_text": "How AI powers healthcare innovation\nServiceNow Blog\nAugust 28, 2025\nExperienced human writers and editors used AI to help research and draft this blog post. These humans then edited and fact-checked the post to ensure it meets our rigorous editorial standards.\nAI is revolutionizing how healthcare is delivered, managed, and experienced. In an industry where decisions affect life and death, AI can help optimize operations, boost worker productivity, and enhance patient experiences.\nAlready, AI is helping organizations reimagine what's possible in medicine and transform medical systems from reactive to proactive. In fact, new\nhealthcare research\nby ServiceNow found that 77% of healthcare organizations plan to increase their AI investments in the next fiscal year.\nLet’s explore how AI powers\nhealthcare innovation\n.\nTable of contents\nWhat is AI in healthcare?\nWhat are AI tools in healthcare?\nWhy AI in healthcare is important\nHow AI in healthcare works\nWhere is AI used in healthcare today?\nWill AI replace healthcare workers?\nWhat is the future of AI in healthcare?\nThe imperative for action\nWhat is AI in healthcare?\nAI in the healthcare industry is the application of AI technologies, including machine learning and natural language processing, to improve patient care and operations. Think of it as the seamless fusion of computational power and clinical and nonclinical expertise.\nHealthcare AI converts vast collections of complex medical data into actionable intelligence that can drive measurable outcomes: saved lives, reduced costs, and better patient experiences.\nAgentic AI\nis the next degree of healthcare intelligence. Whereas traditional AI observes patterns, agentic AI acts on them. Autonomous AI agents analyze data when prompted, identify opportunities, make decisions, and initiate actions to achieve specified goals. They continuously learn, adapt, and evolve—improving with each interaction.\nNearly half (45%) of the healthcare leaders we surveyed are considering adopting agentic AI in the next year.\nWhat are AI tools in healthcare?\nToday's healthcare AI ecosystem offers purpose-built solutions designed to address specific challenges across the care continuum:\nMachine learning platforms\nanalyze complex clinical data to identify disease patterns and predict patient outcomes with remarkable accuracy.\nNatural language processing (NLP)\ntransforms unstructured medical notes into actionable insights, unlocking value from previously inaccessible data.\nComputer vision systems\ninterpret medical imaging with a precision that matches or exceeds what human specialists can do.\nPredictive analytics tools\nforecast patient deterioration before traditional symptoms appear.\nVirtual health assistants\ndeliver personalized care guidance while optimizing resource allocation.\nThe most powerful AI implementations integrate with existing workflows, amplifying human capabilities rather than replacing them. The organizations achieving breakthrough results aren't deploying these tools in isolation. They're implementing them on unified platforms that seamlessly connect AI capabilities across the enterprise.\nWhy AI in healthcare is important\nClinician burnout, rising costs, data overload, and increasing patient expectations are taking their toll on the healthcare industry. AI addresses these challenges head-on to improve the caregiver experience, strengthen risk and compliance, and optimize operations for seamless care.\nIn addition, AI can help streamline research and development, transform compliance from a bottleneck to a competitive advantage, identify and address operational and cybersecurity risks, enhance IT and operational technology connectivity, and increase visibility and control across global operations.\nOur research found that 83% of healthcare providers that have implemented AI have improved experiences. And 55% of healthcare companies have seen gains in their gross margins.\nBesides solving existing problems, AI is helping to uncover new possibilities for care delivery, scientific discovery, and business model innovation that were previously unimaginable.\nHow AI in healthcare works\nHealthcare AI transforms raw, disjointed medical data into coherent, actionable intelligence through a sophisticated process that mirrors and enhances human cognition:\nData integration:\nUnifying information from disparate sources—electronic health records, imaging, genomics, and real-time monitoring\nPattern recognition:\nApplying advanced algorithms that identify subtle correlations and anomalies across vast data sets that could take human analysts years to discover\nPredictive modeling:\nGenerating evidence-based recommendations by comparing current patients, medical device usage, drugs, and other treatments against millions of historical cases\nDecision support\n: Providing a clear rationale for recommendations that helps build trust with clinical and nonclinical users\nContinuous learning:\nRefining accuracy through feedback loops that become more precise with each interaction\nThe true power emerges when these capabilities integrate directly into both clinical and nonclinical workflows, delivering insights precisely when and where decisions are made.\nWhere is AI used in healthcare today?\nAI has transitioned from innovation labs to frontline implementation across the healthcare ecosystem:\nRadiology departments\nuse computer vision to detect subtle abnormalities in imaging studies and improve early cancer detection rates.\nPharmaceutical companies\naccelerate drug discovery timelines\nfrom years to months\nthrough predictive modeling of molecular interactions.\nHealth systems\ndeploy predictive analytics to optimize staffing levels based on anticipated patient volumes, reducing wait times while controlling costs.\nInsurers\nimplement NLP to streamline claims processing, reducing administrative overhead while enhancing member experiences.\nClinicians\nemploy diagnostic support systems to enhance detection accuracy while reducing time to diagnosis.\nResearchers\nuse AI to accelerate hypothesis testing and literature analysis.\nForward-thinking healthcare organizations are implementing comprehensive platforms that unify these capabilities into cohesive, enterprisewide solutions.\nWill AI replace healthcare workers?\nAI isn't replacing healthcare professionals, but it is redefining their capabilities. The future of healthcare is humans and machines working in partnership.\nThe most successful AI implementations augment human expertise by automating routine tasks, surfacing relevant insights, and enabling clinicians and nonclinical employees to practice at the top of their abilities. When administrative burdens decrease, meaningful patient interactions and outcomes increase.\nNearly two-thirds (63%) of the healthcare firms we surveyed are in the process of identifying the skills needed to carry out their AI strategies. That means there are opportunities for workers to move into new roles to help manage AI technologies.\nMany organizations are upskilling and training their workers to fill these skills gaps, particularly in the areas of data science, experience development, and machine learning, our research found.\nWhat is the future of AI in healthcare?\nHealthcare organizations that thrive in the coming decade will be those that move beyond point solutions to establish comprehensive AI strategies that span the entire care continuum. In the future, we can expect:\nAmbient clinical intelligence\nthat documents patient encounters automatically, allowing clinicians to focus entirely on patients rather than screens\nDigital twins\nthat enable treatment simulations on virtual patient models before implementing them in real life\nAutonomous systems\nthat continuously monitor chronic conditions, adjusting treatments in real time based on patient response\nFederated learning\nthat enables AI models to learn across institutions without compromising patient privacy\nThese aren't distant possibilities. They're emerging realities that forward-thinking organizations are already implementing.\nThe imperative for action\nThe organizations that will lead healthcare's next era aren't necessarily those with the most resources. Rather, they’re those with the clearest vision and most effective implementation strategies. They're the ones integrating AI capabilities across their enterprise and creating seamless experiences for clinicians, researchers, administrators, scientists, and patients alike.\nMore than half (51%) of the most advanced healthcare organizations in AI maturity in our study—a group we call Pacesetters—are operating with a clear vision, versus 27% of others.\nIn addition, 74% of Pacesetters take an AI-focused platform approach to connect their data, processes, and workflows. As a result, they’re realizing 1.9 times higher productivity and 1.67 times faster innovation than their counterparts.\nThe future of healthcare belongs to organizations that recognize AI as the defining strategic imperative of our time.\nFind out how ServiceNow can help you\nput AI to work in healthcare\n.\n© 2025 ServiceNow, Inc. All rights reserved. ServiceNow, the ServiceNow logo, Now, and other ServiceNow marks are trademarks and/or registered trademarks of ServiceNow, Inc. in the United States and/or other countries. Other company names, product names, and logos may be trademarks of the respective companies with which they are associated.\n14\nShares\nTopics\nAI and Automation\nApplication Development\nCareers\nCrisis Management\nCulture\nCustomer Experience\nCustomer Stories\nCybersecurity and Risk\nEducation\nEmployee Experience\nEvents\nFinancial Services\nGovernment\nHealthcare\nIT Management\nManufacturing\nNow on Now\nServiceNow AI Platform\nTelecommunications\nFeatured\nOur shared table: Honoring service through food\nHow culture landed ServiceNow on Fortune World’s Best Workplaces list\nGetting real results from AI: Managing an agentic workforce\nTrends & Research\nServiceNow is again a Gartner-named Leader in CRM Customer Engagement Center\nServiceNow named a Leader by Gartner® in business orchestration and automation\nServiceNow is an IDC MarketScape Leader in AI-enabled aftermarket/service lifecycle and FSM\nYear\n2025\n2024\n2023\n2022"
  },
  {
    "title": "How AI in telecom is revolutionizing the industry",
    "date": "August 21, 2025",
    "link": "https://www.servicenow.com/blogs/2025/ai-telecom-revolutionizing-industry",
    "source": "Servicenow_blog",
    "main_ideas": [
      "AI is transforming telecom by creating autonomous networks that enhance operational efficiency.",
      "Agentic AI enables proactive management of networks, improving performance and identifying hidden revenue opportunities.",
      "Telecom companies must overcome challenges like legacy systems and security concerns to implement AI effectively."
    ],
    "tags": [
      "artificial-intelligence",
      "telecommunications",
      "agentic-ai",
      "network-optimization",
      "customer-experience",
      "data-governance",
      "automation",
      "service-delivery",
      "cybersecurity"
    ],
    "original_text": "How AI in telecom is revolutionizing the industry\nServiceNow Blog\nAugust 21, 2025\nExperienced human writers and editors used AI to help research and draft this blog post. These humans then edited and fact-checked the post to ensure it meets our rigorous editorial standards.\nTelecom leaders are facing explosive data consumption growth, modest revenue expansion, intensifying competition, and ever-increasing customer expectations for seamless experiences. The traditional telecom playbook, focused on infrastructure investment and cost optimization, is no longer sufficient to navigate this complex environment.\nAdvances in AI, such as agentic AI, can help telecom organizations address these challenges. Nearly nine out of 10 telecom leaders report higher productivity from their AI investments, according to new\ntelecom research\nfrom ServiceNow. And more than eight in 10 are seeing improvements in gross margins, cost savings, experiences, and competitiveness.\nTable of contents\nWhat is AI in telecom?\nWhat is agentic AI in telecom?\nHow can AI be used in telecom?\nWhat are the challenges of AI in telecom?\nWhy telecom AI can’t wait\nHow is AI changing jobs in telecom?\nHow to implement AI in telecom\nWhat is the future of AI in telecom?\nWhat is AI in telecom?\nAI in telecom\nis, ideally, a unified intelligence layer that transforms fragmented networks and systems into orchestrated ecosystems. It harnesses the massive data flows generated across communications infrastructure to create predictive, self-optimizing systems that continuously evolve.\nAt its core, AI in telecom is the technological foundation that allows telecom companies to deliver autonomous networks that anticipate needs before they arise and make intent-based decisions. It elevates networks from passive conduits to proactive, adaptive ecosystems.\nFor forward-thinking telecom leaders, AI serves as both an accelerator and an amplifier, simultaneously removing operational friction and magnifying the impact of every strategy decision.\nThe most powerful telecom AI implementations seamlessly unify previously disconnected domains—network operations, customer experience, workforce productivity, and service innovation—into a single intelligent fabric that drives outcomes at unprecedented scale and speed.\nWhat is agentic AI in telecom?\nAgentic AI\nin telecom refers to intelligent, autonomous systems that undertake a variety of tasks, such as analyzing and actively optimizing networks and operations and assessing and managing business risks. It’s a fundamental shift from reactive to proactive network and operations management.\nTraditional AI excels at pattern recognition and prediction. Agentic AI in telecom can help deliver far more across the entire service lifecycle, encompassing sales, fulfillment, and service. By observing, deciding, and acting with minimal human intervention, agentic AI can help telecom companies:\nSelf-heal networks and operations before outages affect customers\nAutomatically reconfigure to optimize performance during demand spikes\nIdentify revenue opportunities that may be hidden within service patterns\nOur research found that 18% of telecom companies are already using agentic AI for risk management, fraud identification and mitigation, network optimization, and regulation compliance use cases. And 42% are considering adopting the technology within the next year.\nHow can AI be used in telecom?\nMore than half (54%) of the telecom companies we surveyed rolled out more than 100 AI use cases last year, spanning every aspect of operations. These include:\nBoosted employee enablement\nAI-powered knowledge systems provide telecom employees with instant access to critical information, accelerating resolution times and enabling even junior team members to handle complex issues with confidence.\nNearly half (46%) of the telecom leaders in our survey report significant return on investment (ROI) from using AI search capabilities across their value chain—from customer service to infrastructure management to employee enablement.\nSupercharged customer experiences\nAI-powered self-service helps customers get updates, find answers, and take action. AI-generated case summaries, diagnostic tests, and suggested resolutions empower service workers to resolve issues fast.\nUnified omnichannel engagement\nConnecting your contact center as a service (\nCCaaS\n) solution to an AI-powered customer relationship management (\nCRM\n) platform can unify routing, boost workforce engagement, and simplify communications through cloud telephony.\nService revenue growth\nUsing AI to optimize lead nurture, order exception resolution, and complex service delivery can open new sources of revenue.\nStreamlined issue resolution\nMoving to autonomous networks can provide end-to-end automated service assurance. Connected workflows across the business help enable reliable and proactive service experiences that anticipate, communicate, and resolve issues for increased productivity and expedience.\nModernized network management\nComprehensive visibility into the network and tasks such as inventory modeling and service design enables smarter, faster network planning and deployment. Predicting capacity issues in advance and preventing costly overages and service disruptions can decrease costs.\nWhat are the challenges of AI in telecom?\nDespite compelling returns, implementing AI at scale in telecom environments presents unique challenges. Legacy systems, data silos, and the specialized knowledge required to manage telecom infrastructure and operations create implementation hurdles.\nSecurity concerns are of particular importance in a regulated industry that handles sensitive customer data and critical infrastructure. Only 45% of telecom companies report significant progress creating AI-specific policies to maintain regulatory compliance.\nThis explains why 31% of telecom companies in our study are using agentic AI to support their\ncybersecurity\nstrategies, from detecting anomalies to responding to potential threats in real time.\nStrategic AI implementations require significant investment at a time when many telecom companies are under pressure to reduce expenditures. The solution is to prioritize use cases with clear ROI pathways, allowing initial wins to fund broader transformation.\nWhy telecom AI can't wait\nThe telecom industry stands at an inflection point. Our research reveals that while AI maturity scores for telecom companies dropped 10 points year over year, 79% of these organizations increased AI spending in the same period. This disconnect signals a widening gap between investment and effective implementation—a gap that creates both risk and opportunity.\n\"Many telcos spend too much time trying different AI solutions or building the perfect\nLLM\n[large language model] before launching it,\" says Rohit Batra, general manager of manufacturing, telecom, media, and technology at ServiceNow. \"Meanwhile, less risk-averse competitors are jumping ahead.\"\nThis \"analysis paralysis\" isn't just delaying progress. It's also creating competitive vulnerabilities that more agile players are actively exploiting. As a senior vice president at a Swedish telecom company observed, too many organizations falsely believe they \"know what they are doing with AI,\" when the data clearly indicates otherwise.\nHow is AI changing jobs in telecom?\nAI is redefining the skills that telecom professionals need—not replacing workers. Only 31% of telecom companies strongly agree they have talent with the appropriate skills to execute their AI strategy. As intelligent systems take on routine tasks, telecom workers are transitioning to strategic roles that require uniquely human capabilities: relationship building, creative problem-solving, and innovating.\nWith AI, network engineers can oversee AI systems that handle routine problems automatically, freeing them to focus on architecture rather than troubleshooting. Customer service representatives can become experience designers rather than transaction processors. And data teams can shift from collecting information to extracting actionable intelligence that drives business transformation.\nPerhaps most significantly, AI is creating entirely new roles that didn't previously exist in telecom—from AI ethicists who ensure responsible implementation to data scientists who develop next-generation algorithms tailored to telecom challenges.\nThe telecom companies that posted the highest AI maturity scores in our study, a group we call Pacesetters, are addressing this new reality through comprehensive reskilling programs. More than eight in 10 (81%) Pacesetters have implemented training and support programs, and 67% host AI learning events.\nHow to implement AI in telecom\nSuccessful AI implementation in telecom comes down to strategic, enterprisewide transformation with clear execution pathways. By taking that approach, Pacesetters in our study have increased their revenue 1.84 times in the past year. Based on our research, we recommend these steps to implement AI in telecom:\nLead with an innovation mindset:\nSuccessful AI transformation begins with cultural reinvention. More than eight in 10 telecom Pacesetters encourage employees to experiment with AI.\nTake a single-platform approach:\nFragmented AI initiatives create fragmented results. Nearly two-thirds (64%) of telecom Pacesetters use an AI-powered platform to connect people, data, and processes across their entire ecosystem.\nNurture AI talent and skills:\nTechnology transformation requires human transformation. Leading telecom companies are systematically upskilling their workforces. Pacesetters are 1.6 times more likely than their counterparts to feel they have the right mix of talent and skills to achieve their AI strategy.\nPrioritize data governance and management:\nAI is only as effective as the data feeding it. An enterprisewide data governance framework can help balance innovation and compliance. Nearly two-thirds (62%) of Pacesetters in our study have formalized data governance and compliance.\nEmbrace agentic AI:\nAI agents\noffer new ways to unlock AI value. One-third of telecom Pacesetters are using agentic AI, compared to 15% of other telecom companies.\nSet a long-term shared AI vision:\nSuccessful AI balances ambitious future vision with pragmatic present action. Half of the Pacesetters in our study say they operate with a shared AI vision that’s clearly communicated across the company.\nWhat is the future of AI in telecom?\nThe future of the telecom industry belongs to organizations that view AI as a business transformation imperative. As agentic AI systems evolve from experimental to operational, they will enable entirely new service models imbued with the adaptability and intelligence of advanced AI across the entire service lifecycle.\nThe telecom companies that will thrive in this future aren't waiting for it to arrive—they're actively creating it through decisive implementation, strategic investment, and organizational transformation. While some companies debate theoretical concerns, leaders are systematically capturing value that will fund their continued AI evolution.\nFor telecom executives, the path forward is to act with urgency, implement with purpose, and transform with intention.\nFind out how ServiceNow can help you\nput AI to work for telecom\n.\n© 2025 ServiceNow, Inc. All rights reserved. ServiceNow, the ServiceNow logo, Now, and other ServiceNow marks are trademarks and/or registered trademarks of ServiceNow, Inc. in the United States and/or other countries. Other company names, product names, and logos may be trademarks of the respective companies with which they are associated.\n78\nShares\nTopics\nAI and Automation\nApplication Development\nCareers\nCrisis Management\nCulture\nCustomer Experience\nCustomer Stories\nCybersecurity and Risk\nEducation\nEmployee Experience\nEvents\nFinancial Services\nGovernment\nHealthcare\nIT Management\nManufacturing\nNow on Now\nServiceNow AI Platform\nTelecommunications\nFeatured\nOur shared table: Honoring service through food\nHow culture landed ServiceNow on Fortune World’s Best Workplaces list\nGetting real results from AI: Managing an agentic workforce\nTrends & Research\nServiceNow is again a Gartner-named Leader in CRM Customer Engagement Center\nServiceNow named a Leader by Gartner® in business orchestration and automation\nServiceNow is an IDC MarketScape Leader in AI-enabled aftermarket/service lifecycle and FSM\nYear\n2025\n2024\n2023\n2022"
  },
  {
    "title": "AI security at ServiceNow",
    "date": "August 19, 2025",
    "link": "https://www.servicenow.com/blogs/2025/ai-security-servicenow",
    "source": "Servicenow_blog",
    "main_ideas": [
      "ServiceNow emphasizes the importance of robust security and ethical safeguards in AI deployment.",
      "AI agents must operate within strict parameters to ensure secure autonomy and limit data access.",
      "Real-time monitoring and oversight are essential to detect and respond to anomalies in AI behavior.",
      "Ethical AI deployment requires transparency, accountability, and bias mitigation throughout development."
    ],
    "tags": [
      "ai-security",
      "ethical-ai",
      "service-now",
      "autonomous-agents",
      "real-time-monitoring",
      "data-privacy",
      "cybersecurity",
      "enterprise-operations",
      "ai-governance"
    ],
    "original_text": "AI security at ServiceNow\nVinay Pillai\nAugust 19, 2025\nAgentic AI\nis reshaping how work gets done, unlocking unprecedented speed and scale in enterprise operations.\nAI agents\ncan access sensitive data, interact with core systems, and make choices based on dynamic inputs—with human oversight. But without robust security and ethical safeguards, this technology could unintentionally put work at risk.\nAt ServiceNow, we believe organizations must approach\nAI security\nnot as a technical checklist, but as a strategic foundation for trustworthy innovation. We’re striving to set an example with how we approach AI security.\nDesigning secure autonomy\nThe foundation of secure AI lies in how autonomy is defined and managed. Every AI agent we build at ServiceNow must operate within strict parameters in terms of what it can access, what it can do, and how it’s authenticated.\nWe clearly define agent roles, limit their data access to what’s essential, and authenticate the interactions they initiate. Think of it as role-based access control (RBAC) for our agentic AI workforce. These controls help ensure AI agents interact only with the data and systems they’re designed to handle—nothing more.\nAutonomy isn’t just about giving AI agents freedom to operate; it’s about defining the limits of that freedom. To that end, we design our agents so that their autonomous actions are traceable, communications between systems are encrypted, and only credentialed agents are allowed to interact with sensitive environments. Access and control are prerequisites for scale.\nReal-time oversight, real-time defense\nEven the best-designed AI agents need supervision. They encounter unpredictable and sometimes adversarial environments. One of the growing threats in this space is prompt injection—where bad actors manipulate agent inputs to trigger unintended actions. Risks like this are subtle but dangerous.\nTo defend against this, human teams need real-time\nobservability\n. By continually monitoring AI agent behavior and logging interactions, we’re able to detect anomalies as they occur. This includes tracing anomalous input patterns, unauthorized actions, or unexplained system calls. Isolation techniques such as sandboxing can further reduce risk, helping to ensure that even if an agent is compromised, its impact is contained.\nAI agents differ from traditional software and processes because they’re non-deterministic—they act, learn, and adapt in real time, which makes their behavior inherently unpredictable. To ensure their actions remain secure requires monitoring agents that:\nContinuously observe logs and telemetry\nIdentify signs of problematic behavior\nRespond to problems immediately\nSecuring the stack\nAt ServiceNow, AI agents are part of an intricate ecosystem made up of models, APIs, databases, compute environments, and infrastructure. To truly secure AI, we need to secure the entire ecosystem.\nConfidential compute technologies are a breakthrough enabling this. They isolate and protect data even when it’s being processed. This is essential when AI agents interact with personally identifiable or regulated information.\nAt the same time, large language model (\nLLM\n) routers can distribute tasks across different models based on cost, performance, and trust levels while applying consistent security protocols such as anonymization and encryption.\nProtocols such as A2A (agent-to-agent) and MCP (Model Context Protocol) protocols further extend AI agent functionality—but they also increase attack surfaces. As these protocols and agents evolve, we wrap them in least-privilege access rules, sabotage detection, and authentication layers.\nPrioritizing ethical AI deployment\nAs AI agents gain autonomy, security alone isn’t enough. That’s why ethical deployment is nonnegotiable for us. Transparency is key: AI agents must be able to explain their decisions in ways humans can understand, especially in high-stakes environments. When outcomes are unclear, trust erodes.\nAccountability helps ensure human responsibility remains in the loop at ServiceNow. Even if an AI agent acts independently, someone must govern its impact. Bias mitigation is also critical, as AI agents trained on flawed or imbalanced data can perpetuate harmful patterns. Proactive audits and diverse training inputs help us reduce these risks.\nWe embed ethics into every phase of AI development and deployment as part of our commitment to fairness, clarity, and responsible progress.\nIntegrating AI into the workplace is a must. It offers significant benefits—but only when security and ethics are prioritized. The best way to help ensure that is to design secure autonomy, monitor with precision, secure the full stack, and prioritize ethical integrity. These are the pillars of a resilient AI strategy.\nFind out how ServiceNow can help you\nsecurely put AI to work for people\n.\n© 2025 ServiceNow, Inc. All rights reserved. ServiceNow, the ServiceNow logo, Now, and other ServiceNow marks are trademarks and/or registered trademarks of ServiceNow, Inc. in the United States and/or other countries. Other company names, product names, and logos may be trademarks of the respective companies with which they are associated.\n61\nShares\nTopics\nAI and Automation\nApplication Development\nCareers\nCrisis Management\nCulture\nCustomer Experience\nCustomer Stories\nCybersecurity and Risk\nEducation\nEmployee Experience\nEvents\nFinancial Services\nGovernment\nHealthcare\nIT Management\nManufacturing\nNow on Now\nServiceNow AI Platform\nTelecommunications\nFeatured\nOur shared table: Honoring service through food\nHow culture landed ServiceNow on Fortune World’s Best Workplaces list\nGetting real results from AI: Managing an agentic workforce\nTrends & Research\nServiceNow is again a Gartner-named Leader in CRM Customer Engagement Center\nServiceNow named a Leader by Gartner® in business orchestration and automation\nServiceNow is an IDC MarketScape Leader in AI-enabled aftermarket/service lifecycle and FSM\nYear\n2025\n2024\n2023\n2022"
  },
  {
    "title": "The future is now: Implementing AI in manufacturing",
    "date": "August 13, 2025",
    "link": "https://www.servicenow.com/blogs/2025/implementing-ai-manufacturing",
    "source": "Servicenow_blog",
    "main_ideas": [
      "AI is transforming manufacturing by enhancing efficiency, quality, and innovation.",
      "Manufacturers are increasingly investing in AI, with 82% planning to increase their budgets.",
      "AI will augment human roles rather than replace them, focusing on complex tasks."
    ],
    "tags": [
      "artificial-intelligence",
      "manufacturing",
      "automation",
      "predictive-maintenance",
      "supply-chain",
      "data-governance",
      "operational-efficiency",
      "service-now",
      "machine-learning"
    ],
    "original_text": "The future is now: Implementing AI in manufacturing\nServiceNow Blog\nAugust 13, 2025\nExperienced human writers and editors used AI to help research and draft this blog post. These humans then edited and fact-checked the post to ensure it meets our rigorous editorial standards.\nIn today's hypercompetitive landscape, manufacturers face unprecedented pressure to innovate while optimizing operations and driving new revenue streams. AI can help solve that conundrum.\nNew\nmanufacturing research\nfrom ServiceNow reveals that manufacturers allocated 12.7% of their IT budgets to AI in the last fiscal year and that 82% plan to increase their AI investments in the next fiscal year.\nTable of contents\nWhat is AI in manufacturing?\nHow can AI help in manufacturing?\nWhere is AI used in manufacturing?\nWill manufacturing jobs be replaced by AI?\nWhat are the benefits of AI in manufacturing?\nHow to implement AI in manufacturing\nThe manufacturing AI imperative\nWhat is AI in manufacturing?\nAI in manufacturing\ncombines machine learning, industrial internet of things (IIoT), predictive analytics, and workflow automation into a unified digital ecosystem to transform how products are designed, produced, and delivered. It bridges physical operations and digital intelligence, creating seamless connections between machines, people, and processes.\nManufacturing AI can transform raw production data into actionable intelligence that can help predict maintenance needs, optimize production processes, and make data-driven decisions with speed and accuracy. In so doing, it helps enable real-time decisions that were previously impossible at scale.\nAgentic AI\n—autonomous systems that can reason, plan, and execute complex tasks with minimal human supervision—offers great promise in the industry. Intelligent\nAI agents\ncan independently solve complex manufacturing challenges, orchestrate workflows across disparate systems, and continuously learn from their environment.\nMore than 20% of manufacturers have already deployed agentic AI solutions, according to our research, and another 45% plan to adopt agentic AI within the next 12 months.\nHow can AI help in manufacturing?\nAI empowers manufacturers to break through long-standing barriers of efficiency, quality, and innovation, transforming manufacturing from reactive to proactive.\nAccelerated design and engineering\nAI-empowered product development helps manufacturers streamline the creation process, reducing time to market for new products.\nEnhanced predictive maintenance\nAI algorithms analyze equipment data to predict failures before they occur, transforming maintenance from reactive to predictive. This shift can dramatically reduce downtime while extending machine lifespans.\nIntelligent quality control\nComputer vision systems inspect products with extraordinary accuracy, detecting microscopic defects invisible to the human eye. These systems learn continuously and become more effective with each product examined, expediting the ability to identify, contain, and resolve quality issues even after a product leaves the factory.\nOptimized supply chain\nAI models analyze thousands of variables simultaneously—from weather patterns to geopolitical events—to predict supply chain disruptions before they affect production. This foresight helps improve supplier collaboration and reduce supplier risk.\nStreamlined production\nAdvanced AI hones production parameters in real time, balancing quality, speed, and resource utilization with precision that’s impossible through manual adjustments alone.\nBoosted cost savings\nBy optimizing production processes to reduce energy consumption and waste and by predicting equipment failures to minimize unplanned downtime, AI can help drive costs out of the business.\nImproved operational technology management\nBy providing visibility into and context around manufacturing operational technology environments, AI can help reduce cyber risk and downtime.\nDigitized sales and service\nAI-powered customer relationship management (\nCRM\n) for manufacturing can speed up order to cash, dealer support, and customer service, boosting revenue and improving customer experiences while reducing the cost to serve.\nWhere is AI used in manufacturing?\nThe transformative impact of AI spans the entire manufacturing value chain. In fact, 57% of manufacturers in our study implemented more than 100 use cases in the past year, including:\nCustomer sales and service\nPersonalized customer experiences driven by behavior analysis\nAI-powered recommendation engines for product configurations\nIntelligent chatbots for 24/7 customer support\nProduction and quality control\nProactive security and risk response\nIntelligent workflow orchestration\nAutonomous exception resolution\nSupply chain management\nProactive discrepancy resolutions between purchase orders, goods receipts, and invoices\nPredictive supplier performance\nAutomated onboarding and compliance\nIntelligent payment accuracy\nWill manufacturing jobs be replaced by AI?\nAI will not replace manufacturing jobs, but it will transform the industry. The future of manufacturing is about augmenting human workers’ capabilities and redefining their roles.\nAI excels at handling repetitive, dangerous, and precision-critical tasks. Using AI in these areas can free human workers to focus on innovation, complex problem-solving, and customer relationships. This creates more engaging, higher-value roles while simultaneously improving productivity and safety.\nThe most successful manufacturers approach AI as a collaboration between human expertise and machine intelligence. They focus on reskilling their workforce for this new paradigm, recognizing that their people remain their greatest asset in an AI-powered world.\nPacesetters—organizations in our study that scored highest in AI maturity—are more likely than other businesses to invest in comprehensive AI training programs. In fact, 77% of Pacesetters have implemented training programs to actively develop needed AI skills, compared to 56% of other manufacturers.\nWhat are the benefits of AI in manufacturing?\nThe benefits of AI in manufacturing are substantial and measurable. They include:\nIncreased operational efficiency:\nManufacturing Pacesetters achieve 1.75 times greater efficiency through AI-powered process optimization and intelligent automation.\nEnhanced product quality:\nAI-powered quality control systems detect defects with extraordinary accuracy, reducing waste and warranty claims while enhancing customer satisfaction.\nAccelerated innovation:\nBy analyzing vast amounts of production and market data, AI helps manufacturers identify new product opportunities and optimize designs before physical prototyping begins. Pacesetters report 1.58 times faster innovation.\nSupply chain resilience:\nAI forecasting models help manufacturers anticipate disruptions and adapt quickly, maintaining production continuity despite external challenges.\nSustainability improvements:\nAI optimizes resource utilization and energy consumption, helping manufacturers reduce their environmental footprint while improving profitability.\nMargin enhancement:\nPerhaps most compelling, manufacturers realized an average 7.6% increase in gross margins from their AI investments over the past year, with Pacesetters achieving a 10.3% boost.\nHow to implement AI in manufacturing\nImplementing AI in manufacturing requires a strategic approach focused on value creation rather than technology for its own sake.\nStart with clear business objectives:\nBegin with specific business challenges where AI can deliver measurable value. Avoid the temptation to implement AI without clear performance metrics. Pacesetters are 1.72 times more likely than other organizations to operate with a clear, shared AI vision for business transformation.\nEmbrace a platform approach:\n70% of Pacesetters prefer a comprehensive platform with built-in AI capabilities over point solutions. An enterprise-grade platform provides the integration capabilities necessary for AI to access and analyze data across your entire operation.\nPrioritize data governance:\nAI is only as good as the data that powers it. Our research shows that 53% of Pacesetters have implemented formal data governance programs, compared to 43% of other manufacturers. This focus on data quality translates directly to AI performance.\nBuild cross-functional AI teams:\nSuccessful AI implementation requires both technical expertise and deep domain knowledge. Create teams that blend data scientists with manufacturing experts to ensure AI solutions address real operational challenges.\nDevelop your AI talent pipeline:\nThe AI skills gap is real and growing. Leading manufacturers are investing in both hiring specialized talent and upskilling their existing workforce to thrive in an AI-powered environment.\nBegin small with a focus on agility:\nThe AI revolution waits for no one. Start with small, focused pilots to learn and adapt rapidly, and then scale successful strategies across the business.\nThe manufacturing AI imperative\nAI in manufacturing isn't a distant future—it's today's competitive reality. The path forward requires both technology implementation and a fundamental reimagining of how your manufacturing enterprise operates in an AI-powered world.\nBy unifying AI, data, and workflows on a single platform, you can transform your operations today while building the foundation for tomorrow's innovations. The future belongs to manufacturers who view AI not as a cost center, but as their greatest opportunity for transformation.\nFind out how ServiceNow can help you\nput AI to work in manufacturing\n.\n© 2025 ServiceNow, Inc. All rights reserved. ServiceNow, the ServiceNow logo, Now, and other ServiceNow marks are trademarks and/or registered trademarks of ServiceNow, Inc. in the United States and/or other countries. Other company names, product names, and logos may be trademarks of the respective companies with which they are associated.\n31\nShares\nTopics\nAI and Automation\nApplication Development\nCareers\nCrisis Management\nCulture\nCustomer Experience\nCustomer Stories\nCybersecurity and Risk\nEducation\nEmployee Experience\nEvents\nFinancial Services\nGovernment\nHealthcare\nIT Management\nManufacturing\nNow on Now\nServiceNow AI Platform\nTelecommunications\nFeatured\nOur shared table: Honoring service through food\nHow culture landed ServiceNow on Fortune World’s Best Workplaces list\nGetting real results from AI: Managing an agentic workforce\nTrends & Research\nServiceNow is again a Gartner-named Leader in CRM Customer Engagement Center\nServiceNow named a Leader by Gartner® in business orchestration and automation\nServiceNow is an IDC MarketScape Leader in AI-enabled aftermarket/service lifecycle and FSM\nYear\n2025\n2024\n2023\n2022"
  },
  {
    "title": "Inside S&P Global's Latest Report: How Amdocs Is Transforming Telecom Engagement and Operations Through Agentic BSS and GenAI",
    "date": "28 Oct 2025",
    "link": "https://www.amdocs.com/insights/analyst-report/inside-sp-globals-latest-report-how-amdocs-transforming-telecom-engagement",
    "source": "Amdocs",
    "main_ideas": [
      "Amdocs is revolutionizing telecom engagement with advanced BSS solutions.",
      "The integration of GenAI enhances operational efficiency in telecom.",
      "S&P Global's report highlights the impact of technology on telecom operations."
    ],
    "tags": [
      "amdocs",
      "telecom",
      "bss",
      "genai",
      "s&p-global",
      "technology",
      "operations",
      "engagement"
    ],
    "original_text": "Request unsuccessful. Incapsula incident ID: 895000390129135768-249456871750961612"
  },
  {
    "title": "Reimagine Telecom Billing with AI-Native Innovation",
    "date": "27 Oct 2025",
    "link": "https://www.amdocs.com/insights/whitepaper/reimagine-telecom-billing-with-ai-native-innovation",
    "source": "Amdocs",
    "main_ideas": [
      "AI technology can transform telecom billing processes for increased efficiency.",
      "Innovative solutions are needed to address the complexities of telecom billing.",
      "AI-native approaches can enhance customer experience in telecom services."
    ],
    "tags": [
      "telecom",
      "billing",
      "artificial-intelligence",
      "innovation",
      "customer-experience",
      "technology",
      "automation"
    ],
    "original_text": "Request unsuccessful. Incapsula incident ID: 895000390129135768-321314603780737479"
  },
  {
    "title": "From Build to Value: Amdocs Showcases Fiber Leadership at SCTE TechExpo25",
    "date": "23 Oct 2025",
    "link": "https://www.amdocs.com/insights/video/build-value-amdocs-showcases-fiber-leadership-scte-techexpo25",
    "source": "Amdocs",
    "main_ideas": [
      "Amdocs highlights its leadership in fiber technology at SCTE TechExpo25.",
      "The company emphasizes the transition from building infrastructure to delivering value.",
      "Amdocs showcases innovative solutions for the telecommunications industry."
    ],
    "tags": [
      "amdocs",
      "fiber-technology",
      "scte-techexpo25",
      "telecommunications",
      "infrastructure",
      "innovation",
      "value-delivery"
    ],
    "original_text": "Request unsuccessful. Incapsula incident ID: 895000390129135768-178195946901801409"
  },
  {
    "title": "Financing the Future with Intelligence and Integrity",
    "date": "23 Oct 2025",
    "link": "https://www.amdocs.com/insights/whitepaper/financing-the-future-with-intelligence-and-integrity",
    "source": "Amdocs",
    "main_ideas": [],
    "tags": [],
    "original_text": "Request unsuccessful. Incapsula incident ID: 895000390129135768-321315467069163975"
  },
  {
    "title": "Women in leadership: Sashieka Seneviratne, Director of Cloud RAN Solutions",
    "date": "2025-11-14",
    "link": "https://www.ericsson.com/en/blog/2025/11/women-in-leadership-sashieka-seneviratne-director-of-cloud-ran-solutions",
    "source": "Ericsson_blog",
    "main_ideas": [
      "Sashieka Seneviratne's career exemplifies courage and intentional choices in technology.",
      "She emphasizes the importance of mentorship and advocacy for women in tech.",
      "Sashieka's journey highlights the significance of curiosity and resilience in career growth."
    ],
    "tags": [
      "women-in-tech",
      "leadership",
      "mentorship",
      "cloud-ran",
      "technology",
      "sustainability",
      "ericsson",
      "career-growth",
      "diversity"
    ],
    "original_text": "Like what you’re reading?\nSubscribe now!\nWomen in leadership: Sashieka Seneviratne, Director of Cloud RAN Solutions\nSashieka Seneviratne’s journey at Ericsson shows how curiosity, courage, and intentional choices fuel growth in technology.\nFrom mastering engineering roles to leading innovation, she proves that embracing challenges and new opportunities leads to a fulfilling, impactful career.\nNov 14, 2025\n|\n3 min.\nLara Burt\nLara Burt\nTalent Marketing Activation Specialist\nNov 14, 2025\n|\n3 min.\nLara Burt\nLara Burt\nTalent Marketing Activation Specialist\nLara Burt\nLara Burt\nTalent Marketing Activation Specialist\nSashieka filming at Mobile World Congress in Barcelona\nBreaking barriers in tech: Sashieka Seneviratne’s career journey\nWhen you hear Sashieka speak, one thing stands out immediately: her journey is not just about career progression, it’s about courage, resilience, and redefining what it means to thrive in technology.\nSince Sashieka’s interview, she has taken on a new role as Director of Cloud RAN Solutions, AT&T CU. She also now holds a Board position with Tech Titans, representing Ericsson as the Vice Chair for STEM. As former Director of Sustainable Technologies at Ericsson North America, Sashieka helped lead telecom providers across the U.S. and Canada in transforming their networks to be more energy-efficient and future-ready. But the path to this role was anything but linear.\nFrom Sri Lanka to North America: Following curiosity\nSashieka grew up in Sri Lanka, where at 16 she made a bold decision, she wanted to study abroad. With her parents’ life savings funding just “one shot,” she landed in Canada to study engineering.\nAt first, she didn’t know which field of engineering to pursue. But by following her curiosity, first in civil engineering, and ultimately in electrical engineering specializing in electromagnetics while minoring in business and entrepreneurship, she discovered her passion. That curiosity, she says, became one of her greatest career tools.\n“Every career move I’ve made has been very deliberate. I set goals for where I need to grow next, and what I can contribute.”\nSahshieka talking at the Canadian Telecom Summit\nBuilding\nm\nastery,\nb\nroadening\nh\norizons\nHer early career at Nortel (later acquired by Ericsson) was spent mastering Radio hardware architecture, with focus on Power Amplifier design. For 10 years, she immersed herself in radio hardware engineering, traveling the world to design and test systems. Along the way, she filed patents, earned trade secrets, and built a reputation for technical excellence.\nBut she didn’t stop there. She deliberately chose roles outside her comfort zone, from digital design leadership to customer-facing technical strategy - each time expanding her skill set. Today, she works at the intersection of technology innovation, sustainability, and customer engagement, even representing Ericsson on global stages like Mobile World Congress.\nFour\nl\nessons from 19+\ny\nears in\nt\nech\nReflecting on nearly two decades at Ericsson, Sashieka distilled her career into four guiding lessons:\nDream big, then plan deliberately.\nDreams without goals are just dreams. Every move Sashieka made was intentional, designed to prepare her for the next chapter.\nDon’t let outside voices define you.\nAs a woman in tech, she often faced dismissive comments. She learned to trust her own voice and protect her confidence.\nEmbrace failure as part of growth.\nHer first three patent submissions were rejected, but persistence, feedback, and grit turned setbacks into success.\nCultivate a growth mindset & challenge yourself.\nPreparation is key so that when new opportunities arise, you’ll be ready to take them on.\nOn\nm\nentorship and\ns\nponsorship\nSashieka is passionate about the role mentors and sponsors play in shaping careers, especially for women in tech. She emphasizes that mentorship is not just about guidance, but advocacy:\n“A true mentor is someone who will pound the table on your behalf behind closed doors. To earn that, you need both performance currency and relationship currency.”\nShe encourages employees to take advantage of Ericsson’s open culture, where reaching out to leaders (even by email) is welcomed. Just as importantly, she pays it forward by mentoring others across the company.\nSeneviratne speaking at Mobile World Congress in Barcelona, discussing strategies for decarbonizing the supply chain alongside fellow panelist from Nokia.\nChampioning\nw\nomen in\nt\nech\nAs a woman of color in telecom, Sashieka acknowledges the challenges of perception bias; being underestimated, overlooked, or subjected to stereotypes. Yet she chooses bravery over perfectionism, reminding women to raise their hands for opportunities, make their ambitions known, and build a trusted circle of allies.\n“Make your career goals known. If you want a seat at the table, raise your hand, let it be known, and then ask yourself what you need to do to get there.”\nAdvice for the\nn\next\ng\neneration\nTo interns, new grads, and early-career professionals, Sashieka leaves three pieces of advice:\nDon’t overestimate others\n. Leaders were once beginners too.\nGenius leaves clues\n. Study those you admire and learn from them.\nBe your own cheerleader\n. Your inner voice matters more than outside noise.\nAnd to her younger self? “Learn to speak up sooner. Imposter syndrome can become your superpower because it drives you to overprepare and ultimately excel.”\nWhy Ericsson?\nWhen asked what it’s like to be a woman at Ericsson, her response was immediate:\n“It’s great. You’re surrounded by women who shine in their element, and you’re supported to do the same.”\nAt Ericsson, Sashieka has found not only a place for her, but a platform to grow, lead, and inspire others to follow.\nLooking for your platform to grow?\nCheck out our open roles to find a place for you.\nRELATED CONTENT\nThe Ericsson Blog\nLike what you’re reading? Please sign up for email updates on your favorite topics.\nSubscribe now\nAt the Ericsson Blog, we provide insight to make complex ideas on technology, innovation and business simple."
  },
  {
    "title": "Strengthening 5G security through collaboration: Insights from Deutsche Telekom’s BugBash",
    "date": "2025-11-11",
    "link": "https://www.ericsson.com/en/blog/2025/11/strengthening-5g-security-through-collaboration-insights-from-bugbash",
    "source": "Ericsson_blog",
    "main_ideas": [
      "Deutsche Telekom's BugBash tested 5G security through collaboration with top security researchers.",
      "Real-world testing revealed vulnerabilities and validated the resilience of Ericsson's security controls.",
      "Cybersecurity in telecom requires collaboration to address evolving threats and enhance defenses."
    ],
    "tags": [
      "5g",
      "cybersecurity",
      "deutsche-telekom",
      "ericsson",
      "bugbash",
      "collaboration",
      "network-security",
      "private-5g",
      "security-testing"
    ],
    "original_text": "Like what you’re reading?\nSubscribe now!\nStrengthening 5G security through collaboration: Insights from Deutsche Telekom’s BugBash\nAs 5G reshapes industries and critical services, its growing connectivity increases cybersecurity demands. Ericsson joined Deutsche Telekom’s first BugBash to proactively test and reinforce the security of private 5G networks in real-world conditions.\nBy opening the network to top security researchers with unconventional, creative attack methods, the BugBash delivered insights far beyond traditional lab testing and highlighted how collaborative stress-testing strengthens resilience across the 5G ecosystem.\nNov 11, 2025\n|\n2 min.\nAndreas Blank\nAndreas Blank\nHead of Customer & Solutions Security, CTO office\nCopyright: Deutsche Telekom\nNov 11, 2025\n|\n2 min.\nAndreas Blank\nAndreas Blank\nHead of Customer & Solutions Security, CTO office\nAndreas Blank\nAndreas Blank\nHead of Customer & Solutions Security, CTO office\nThe BugBash initiative: A collaborative security endeavour\nIn October 2025, Deutsche Telekom and Bugcrowd brought together nine professional security researchers from six countries for an extraordinary experiment in cybersecurity. The goal: to exploit a live 5G network set up just for testing, and try to bring it down. The event – held at Deutsche Telekom’s headquarters in Bonn, builds on multiple years of successful BugBash events Bugcrowd designed with T-Mobile US to strengthen defenses against cybercriminals and better protect customers, employees, and data.\nWhy cybersecurity is critical for 5G\n5G technology is the backbone of our hyper-connected society, reaching far beyond mobile communications into critical sectors – from healthcare and manufacturing to logistics, ports and airports, and large-scale processing industries. As the attack surface increases, cybersecurity becomes paramount – not just for operational reliability, but to safeguard the very foundation of digital economies and societies. The complexity of 5G architecture, with features like network slicing, distributed edge deployments, and cloud-native designs, demands proactive resilience.\nAt Ericsson, we see cybersecurity not as an add-on, but as a core design principle. Protecting the integrity, confidentiality, and availability of data across such a complex environment requires continuous testing and a proactive mindset. Through initiatives like the BugBash, Ericsson reinforces its \"secure-by-design\" philosophy.\nReal-world testing – beyond the lab\nTraditional lab-based testing remains essential for validating network security under controlled conditions, but it cannot fully replicate the dynamics of real-world networks. The BugBash provided exactly that: an unpredictable, high-intensity environment where diverse teams of security researchers applied creative, unconventional attack methods. Their task was to probe a dedicated, private 5G standalone (SA) network built on Ericsson’s Private 5G (EP5G) solution – isolated from any commercial network yet replicating realistic enterprise use cases.\nFor five days, the teams tested across three attack vectors – physical, remote, and via antenna – with full freedom to explore potential weaknesses. Ericsson’s Private 5G solution played a central role in the event, complemented by a dedicated team of engineers and security specialists onsite to provide support.\nValidating resilience through open collaboration\nThe results were both reassuring and instructive. Deutsche Telekom’s CISO Dr. Stefan Pütz\nnoted\nthat while some services were disrupted, the built-in security controls “proved surprisingly strong.”\nThe participating researchers showcased advanced techniques attackers could use to target 5G infrastructure – from crafting custom software-defined radio antennas to intercept signals, to identifying encryption vulnerabilities through hardware ports. Despite these challenges, Ericsson’s security controls demonstrated exceptional resilience under diverse simulated attacks from multiple vectors – leaving the team of security researchers unable to gain unauthorized access or extract any sensitive information.\nCore protection mechanisms – such as authentication, encryption, and traffic management – performed exceptionally well under stress, validating our secure-by-design approach, adequate product hardening, and continuous investment in robust, proactive defense – fully aligned with enterprise-grade expectations.\nSecurity is a team effort\nCybersecurity in telecom is inherently collaborative. Events like BugBash highlight the importance of bringing diverse perspectives into cybersecurity testing. Working alongside security researchers revealed new attack patterns and tools, broadening Ericsson’s understanding of security challenges and strengthening its internal security practices.\nThe collaboration extended beyond equipment and testing; the event with Deutsche Telekom, T-Mobile US, and Bugcrowd not only enhanced technical learning but also deepened our shared commitment to safeguarding 5G networks across regions. The findings confirmed the robustness of Ericsson’s security design principles while offering valuable insights for enhancing future 5G products and frameworks –  principles that are continuously adapted to meet the evolving security needs of the enterprise world.\nWhat’s next for 5G security?\nThe BugBash in Bonn was a unique event – and a strong reflection of Ericsson’s ongoing commitment to strengthening cybersecurity practices. By continuously evolving our defenses with real-world insights, we ensure our technology remains resilient against emerging threats. Follow-up tests and innovative initiatives are already on Ericsson’s roadmap: we plan to expand our collaboration with operators and security researchers worldwide.\nEricsson’s participation in the BugBash event reinforced two key principles: security is a shared responsibility across the telecom ecosystem, and innovation thrives on collaboration. As industries and societies increasingly rely on 5G networks, strengthening cybersecurity through continuous testing and cooperation is crucial. The BugBash exemplifies Ericsson’s dedication to protecting tomorrow’s connected world – fostering an open ecosystem that is built on transparency, innovation, and trust.\nRead more\nTelecom security for a safer connected world\nTransforming enterprise security with private 5G\nCybersecurity Testing and Certification\nRELATED CONTENT\nOct 13, 2025\nWhy going digital is still a challenge for factories?\nSep 25, 2025\nConnected workers, competitive advantage: Private 5G transforms manufacturing's talent equation\nAug 14, 2025\nHow Lufthansa Industry Solutions and Ericsson transform logistics operations with private 5G\nThe Ericsson Blog\nLike what you’re reading? Please sign up for email updates on your favorite topics.\nSubscribe now\nAt the Ericsson Blog, we provide insight to make complex ideas on technology, innovation and business simple."
  },
  {
    "title": "How 5G, AI and digitalization are driving the future of energy",
    "date": "2025-11-11",
    "link": "https://www.ericsson.com/en/blog/2025/11/smarter-energy-with-ai-path-to-decarbonization-digitalization",
    "source": "Ericsson_blog",
    "main_ideas": [
      "Digitalization, AI, and 5G are crucial for transitioning to renewable energy systems.",
      "Energy-efficient data centers and smart grids are essential for a low-carbon energy future.",
      "AI's energy demand is significant but improving efficiency can mitigate concerns about consumption.",
      "5G Standalone technology is foundational for the digital transformation of the energy sector.",
      "Stable policies and investments are necessary to support the green transition and decarbonization."
    ],
    "tags": [
      "digital-transformation",
      "energy-efficiency",
      "artificial-intelligence",
      "5g",
      "renewable-energy",
      "decarbonization",
      "smart-grids",
      "data-centers",
      "ict",
      "sustainability"
    ],
    "original_text": "Like what you’re reading?\nSubscribe now!\nHow 5G, AI and digitalization are driving the future of energy\nThe COP U.N. climate talks will highlight how digitalization, AI, and smart grids are driving the transition to renewable energy and electrified industries.\nEnergy-efficient data centers and 5G Standalone networks are essential to achieving a low-carbon energy system.\nNov 11, 2025\n|\n5 min.\nDaniel Paska\nDaniel Paska\nDirector Sustainability Policy\nHashtags\nHashtags\n#DigitalTransformation\n#EnergyEfficiency\n#AI\nNov 11, 2025\n|\n5 min.\nDaniel Paska\nDaniel Paska\nDirector Sustainability Policy\nDaniel Paska\nDaniel Paska\nDirector Sustainability Policy\nHashtags\n#DigitalTransformation\n#EnergyEfficiency\n#AI\nDigitalization is one of the most powerful enablers of the global shift toward cleaner, smarter, and more resilient energy systems. Yet today’s electricity grids were not built for renewable energy. They were built for fewer, centralized sources such as coal-fired plants. Renewable energy is also often distributed across regions, and the power output fluctuates over time, making predictability a challenge.\nTo decarbonize and phase out fossil fuels, we must electrify heavy industries and the transport sector. We also need more electricity generated from clean sources such as renewables and to eliminate power produced from fossil fuels.\nThis is why digitalizing electrical grids and the whole electricity sector is vital to create control mechanisms and to optimize grid management that will support these greener energy goals. If we also digitalize all end users and increase data sharing between users, distributors  and electricity producers, we can create a true digital energy ecosystem.\nIn many ways, this is what we already do within the telecommunications sector when we predict network traffic to optimize network management. The same digitalization principles are needed for electrical grids, for which data is key. And collecting the right and necessary amount of data from electrical grids will require advanced connectivity and artificial intelligence (AI).\nIn recent years, however, many have feared that the information and communications technology (ICT) sector will require large amounts of electricity from the total consumption due to the rapid adoption of AI and the related expansion of data centers. It is important to show fact-based numbers on energy consumption, which is why Ericsson has done extensive research on the electricity consumption of the ICT sector, AI, and data centers.\nAs global leaders meet in Brazil for the latest COP U.N. climate talks, the transition and decarbonization of energy, manufacturing and transport sectors – as well as the role of renewable energy deployment – will be key priorities. Countries will present their Nationally Determined Contributions (NDC), which are climate action plans reaching from 2025 until 2035 to achieve the Paris agenda. These will set the pace for the climate transition for the coming years.\nWill digitalization further increase energy consumption?\nUnderstanding the true energy impact of digitalization is essential for informed policymaking and investment. As digitalization accelerates exponentially, the ICT sector, particularly telecommunication networks and data centers, is expected to consume even more electricity. Yet this rise will likely be far smaller than many reports suggest. What remains uncertain is how fast AI services and technologies will evolve.\nLooking back, most ICT studies have greatly overestimated future electricity usage because they assumed that larger data volumes would proportionally require more electricity to transmit and process the data. However, Ericsson’s own research reveals that while total data traffic has increased by about 80 times between 2007 and 2023, the ICT sector used only 1.4 times more electricity. This means that data transmission and electricity usage are clearly not directly proportionate.\nEricsson has also calculated the estimated electricity usage and potential carbon footprint for the ICT sector, up until 2030. It is expected that overall electricity consumption will continue to increase to approximately 1,245 terawatt-hours (TWh), from about 1,070 TWh in 2024. In recent years, data centers have been identified as the major contributors to the ICT sector’s growing energy consumption, whereas networks have contributed to this growth less.\nHow much electricity does AI consume?\nAI’s overall energy demand is a frequent concern. Current systems use substantial electricity for training purposes and require increasingly powerful hardware. It remains difficult to predict how AI services and technologies will evolve or how energy efficient they will become.\nHowever, while the energy demand from AI is significant, concerns surrounding exponential increases in usage are mitigated by AI’s advancements toward energy efficiency. Ericsson estimates that up to 12 million AI graphics processing units (GPUs) have been in operation at the end of 2023, consuming approximately 21 TWh. This corresponded to approximately 8 percent of the total energy needed for all data centers, and less than 1 percent of the whole ICT sector. By 2028, it is estimated that AI alone will account for approximately 25 percent of the total data center electricity usage. This highlights the urgent need to prioritize energy efficiency in data centers.\nDespite the ongoing and predicted rise, AI hardware supply limitations will prevent an exponential increase in energy usage. Additionally, AI chips and other energy-related equipment are becoming more efficient, while new-generation network system standards are gradually incorporating measures related to AI and energy efficiency. Furthermore, deploying new generations of more energy-efficient networks and server systems will allow companies to phase out older and wasteful technologies.\nFinally, we need to assess how reliable AI electricity forecasts are. According to the International Energy Agency (IEA), AI-related chips have doubled their efficiency every three years, and recent models use 99 percent less power to perform the same calculations as a similar chip from 2008. In addition, the IEA predicts that both servers and AI GPUs will advance with more efficient processors entering the market before 2030.\nRegarding energy consumption, there is a considerable difference between generative AI—large language models (LLMs) such as ChatGPT and Google Gemini—and dedicated AI services. Generative AI is trained on large data sets, requiring huge amounts of energy, while more dedicated models with a specific purpose only need smaller data sets for training, meaning a smaller energy footprint and, consequently, a more energy-efficient version of AI.\nLet’s look at the European energy sector as an example. Utilities need dedicated and energy-lean AI solutions for grid management and control that could run either through edge computing or in local data centers without relying on the large computing power required for generative AI. Similar solutions and machine learning algorithms are used for network control in telecommunication systems, consuming much less electricity than LLMs.\nWhy 5G Standalone matters\nDecisions on digitalization-related investments and future regulatory policies depend on accurate information and assumptions. The ICT sector’s electricity consumption is an aspect that needs to be considered by utility companies and governments alike, which is why reliable predictions are an important basis for decision-making. These choices are crucial to the successful digital transformation of the energy sector.\nAs mentioned above, data is key to obtaining the information needed to optimize energy systems and provide functionalities such as AI for grid control and management. Energy-related data needs to flow between end users, distributors, and producers to provide, for example, forecasting, grid management, and flexibility solutions.\nConnectivity is critical to obtain this data—and this is where 5G Standalone (SA) becomes so important. In non-standalone 5G, the radio components, such as the base stations, use 5G, while the core relies on legacy 4G technologies. Although this leads to higher speeds and larger bandwidth than 4G, the main advantages of 5G cannot be fully realized\nIn contrast, 5G SA utilizes 5G base stations and a full 5G core to increase speed and bandwidth. This way, it can support advanced services crucial for the energy sector’s digital transformation and the creation of a future-proof digital ecosystem, including but not limited to network slicing, edge computing, 5G voice, RedCap devices, time-critical communication (TCC), network exposure, and enhanced fixed wireless access (FWA).\nIn this sense, 5G SA is not just a connectivity upgrade but a foundational technology for the global energy transition.\nConclusion\nWith COP30, many people now realize that energy and AI should be top of mind. In fact, the host country of COP30, Brazil, decided to present its largely renewable-based energy sector as an opportunity for tech giants looking to establish data centers in the country. This underscores the critical role of connectivity and digital solutions in supporting the green transition of utilities, power grids, transport systems, buildings, and industries. Digital infrastructure needs to be prioritized to help phase out fossil-fuel-based energy sources and decarbonize our societies.\nStable and long-term policy frameworks are crucial for enabling these technologies to reach their full potential, providing the certainty necessary for large-scale investment and innovation. Additionally, the technology sector must continue to develop increasingly energy-efficient data centers, AI solutions, and network architectures, as well as uphold their Net Zero commitments across the entire value chain to keep emissions down.\nDigital and connectivity solutions must be seen as equal pillars alongside clean technologies, grids, and renewables. Only through connectivity and digitalization can we achieve a decarbonized energy system powered by efficient data centers, responsible electricity consumption of AI, and large-scale renewable deployment. In short, digitalization is not a byproduct of the energy transition but its backbone.\nFurther reading\nExplore the challenges of and solutions for industrial decarbonization\nLearn how telecom, data centers, and AI revolutionize ICT energy usage\nSee the opportunities 5G Fixed Wireless Access presents\nDiscover Ericsson's vision for a greener 6G future\nRELATED CONTENT\nNov 03, 2025\nRedefining 5G network deployment with Ericsson Site Digital Twin\nApr 03, 2025\nFrom custom kicks to a personalized world\nMar 25, 2025\nSustainability: A key to business success today\nThe Ericsson Blog\nLike what you’re reading? Please sign up for email updates on your favorite topics.\nSubscribe now\nAt the Ericsson Blog, we provide insight to make complex ideas on technology, innovation and business simple."
  },
  {
    "title": "Redefining 5G network deployment with Ericsson Site Digital Twin",
    "date": "2025-11-03",
    "link": "https://www.ericsson.com/en/blog/2025/11/redefining-5g-network-deployment-with-ericsson-site-digital-twin",
    "source": "Ericsson_blog",
    "main_ideas": [
      "Ericsson Site Digital Twin enhances 5G deployment speed, precision, and sustainability.",
      "The solution integrates advanced technologies like BIM, LiDAR, and AI for efficient network management.",
      "It reduces costs and environmental impact by minimizing site visits and optimizing resource usage."
    ],
    "tags": [
      "5g",
      "ericsson",
      "digital-twin",
      "telecom",
      "sustainability",
      "network-deployment",
      "automation",
      "bim",
      "lidar",
      "ai"
    ],
    "original_text": "Like what you’re reading?\nSubscribe now!\nRedefining 5G network deployment with Ericsson Site Digital Twin\nEricsson Site Digital Twin brings speed, precision, and sustainability to 5G network deployment.\nSolution takes advantage of efficiency and standardization, as well as sustainability and scale.\nNov 03, 2025\n|\n4 min.\nVaishnavi Bichu\nVaishnavi Bichu\nCustomer Project Manager\nNov 03, 2025\n|\n4 min.\nVaishnavi Bichu\nVaishnavi Bichu\nCustomer Project Manager\nVaishnavi Bichu\nVaishnavi Bichu\nCustomer Project Manager\nDriving efficiency, compliance, and sustainability across the telecom lifecycle\nThe telecom industry is entering a new era where networks must be deployed faster, smarter, and more sustainably. At Ericsson, we are proud to lead this transformation with the Ericsson Site Digital Twin — a solution that redefines how operators plan, design, build, and optimize their networks.\nBy combining advanced Building Information Modeling (BIM) with LiDAR, drone-based data capture, and AI-driven automation, the Ericsson Site Digital Twin creates a geospatially accurate, dynamic 3D model of every site. This model becomes the single source of truth throughout the network lifecycle — consolidating structural, electrical, and RF data into one authoritative reference.\nUnlike legacy workflows dependent on static documents, fragmented systems, and multiple site visits, the Ericsson Site Digital Twin provides a digital-first, collaborative foundation that reduces rework, lowers costs, and minimizes environmental impact — all while accelerating 5G rollout timelines.\nScoping and planning: Clarity today, speed tomorrow\nThe scoping and planning phase is one of the most technically demanding and resource-intensive stages of telecom deployment. Teams must assess site feasibility, RF coverage and interference patterns, free space availability, selection of the optimal RAD (Radio Access Device) center, structural integrity of towers and supporting infrastructure, power capacity, backhaul availability, grounding and lightning protection, and compliance with zoning, permitting, and safety regulations.\nTraditionally, this process is slowed by disaggregated data, limited site visibility, and siloed collaboration. Engineers, vendors, and project managers often rely on static PDFs, spreadsheets, and CAD files that rapidly fall out of sync, while multiple field visits are required to verify measurements, confirm tower and equipment conditions, and validate environmental and structural constraints. Civil, RF, and regulatory teams frequently operate independently, causing delays, rework, and inconsistent documentation, and text-heavy municipal submissions often fail to clearly convey complex technical requirements, slowing approvals.\nEricsson Site Digital Twin overcomes these challenges by providing a geospatially precise, parametric 3D representation of each site. These models embed critical metadata including structural load limits, antenna orientation and height, free space availability, RAD center location, equipment weight, power requirements, and component compatibility — consolidating structural, electrical, and RF considerations into a single, continuously updated reference. Stakeholders can remotely assess site conditions, simulate RF coverage and interference, evaluate free space for additional equipment, test deployment scenarios, and produce detailed, visual documentation for regulatory submissions. The result is fewer site visits, reduced rework, optimized material usage, and faster compliance, enabling operators to gain clarity today and speed tomorrow while minimizing engineering and regulatory risk.\nNetwork deployment: Precision in action\nThe deployment phase is where design plans are executed in the field, and precision is critical. Traditional workflows often face challenges such as inconsistent designs, unclear instructions, material shortages, and inefficient crew utilization, which can lead to delays, rework, and increased costs.\nWith Ericsson Site Digital Twin, each site is represented by a standardized, parametric 3D model that serves as a single source of truth for all stakeholders. These models ensure that every deployment follows consistent templates while embedding key metadata — including RAD center locations, free space, structural load limits, equipment weight, and power requirements.\nThis integrated approach enables:\nStandardized designs\n: Templates and design parameters can be applied consistently across multiple sites, regardless of geography or vendor.\nClarity for crews\n: Construction teams receive precise, unambiguous instructions, reducing errors and misinterpretations.\nSkilled labor efficiency\n: With workforce shortages a growing challenge, Ericsson Site Digital Twin workflows maximize productivity by minimizing wasted time.\nAutomated BoM creation\n: Site models automatically generate accurate Bills of Materials (BoM) aligned with design specifications, ensuring the right parts are ordered in the right quantities the first time.\nMaterial readiness\n: Integration with inventory and forecasting systems ensures the correct equipment is available on site, reducing delays and idle crew time.\nOperational oversight\n: Real-time monitoring of work orders, site verifications, acceptance checks, and OHS compliance keeps the project on track and maintains quality standards.\nBy combining the engineering accuracy of BIM with the dynamic capabilities of the Ericsson Site Digital Twin, operators achieve faster builds, fewer outages, optimized resource utilization, and deployment schedules that remain on track — all while maintaining safety, quality, and regulatory compliance.\nPost-build optimization: Living networks, continuous improvement\nEven after construction, networks require validation, documentation, and fine-tuning to ensure long-term performance. Traditional approaches are manual and fragmented, often leading to:\nDelayed detection of construction or integration issues.\nInconsistent records of redlines and as-built conditions.\nLonger tuning cycles with limited pre-analysis capabilities.\nHigher compliance risks from incomplete documentation.\nEricsson Site Digital Twin streamlines this phase by serving as a continuously updated “as-built” record. With fresh LiDAR scans, drone imagery, and engineering inputs, operators can:\nAutomatically compare as-built conditions against original designs.\nSeamlessly capture and integrate redline updates.\nRun remote simulations to prepare tuning strategies before on-site adjustments.\nMaintain centralized documentation, making audits faster and less disruptive.\nThis reduces unnecessary site visits, accelerates quality assurance, and ensures ongoing compliance—keeping networks optimized, reliable, and sustainable.\nEnvironmental and economic impact\nEricsson Site Digital Twin not only enhances operational efficiency but also aligns with global sustainability goals. By reducing the need for multiple site visits, optimizing material usage, and minimizing rework, the solution significantly lowers the carbon footprint of network deployments.\nEconomically, the solution delivers additional savings through automated BOM creation, which eliminates over-ordering, avoids shortages, and improves capital expenditure accuracy. Operators also reduce labor costs by minimizing field visits and maximizing crew efficiency. Standardized designs and real-time inventory integration prevent errors, while faster deployment timelines and streamlined regulatory approvals reduce project costs — enabling operators to bring 5G services to market more quickly and competitively.\nScalability and adaptability for future networks\nAs telecom networks evolve toward 6G and beyond, the complexity of deployments will only increase. Ericsson Site Digital Twin is inherently scalable, capable of integrating new data sources such as IoT sensors, AI-driven analytics, and real-time network performance metrics. This adaptability ensures that the solution remains relevant for future technologies, supporting operators in managing increasingly dense and heterogeneous networks.\nMoreover, Ericsson Site Digital Twin facilitates collaboration across global teams and vendors. Cloud-based platforms allow stakeholders to access and update models in real time, ensuring alignment across geographies and reducing the risk of miscommunication. This collaborative framework is particularly valuable for multinational operators managing large-scale deployments across diverse regulatory environments.\nLooking ahead: The future of network deployment\nEricsson Site Digital Twin is ushering in a new era where telecom deployments are driven by data, collaboration, and environmental awareness. By continuously updating the model with the latest site data, operators maintain an accurate reference that supports maintenance and future upgrades.\nThose who embrace this digital-first approach gain a real advantage. They can roll out networks faster, lower costs, meet compliance standards more easily and reduce environmental impact. It’s a smarter, more responsible way to build the resilient networks that tomorrow’s world demands.\nRead more\nReady to transform your network deployments?\nAt Ericsson, we are dedicated to helping operators unlock the full potential of their 5G networks through innovative Site Digital Twin solutions. Discover how our technology can accelerate rollout, reduce costs, ensure compliance, and build sustainable, future-ready networks.\nDigital twins: what are they and how are they enabling future networks?\nEricsson Site Digital Twin to take control of your evolution\nAT&T’s wireless site digitization advancements\nRELATED CONTENT\nOct 27, 2025\nEricsson Site Digital Twin to take control of your evolution\nSep 09, 2025\nAT&T’s wireless site digitization advancements\nMar 02, 2020\nFast, accurate and sustainable 5G rollouts\nThe Ericsson Blog\nLike what you’re reading? Please sign up for email updates on your favorite topics.\nSubscribe now\nAt the Ericsson Blog, we provide insight to make complex ideas on technology, innovation and business simple."
  },
  {
    "title": "Building networks, breaking barriers: My journey at Ericsson",
    "date": "2025-10-31",
    "link": "https://www.ericsson.com/en/blog/asia/2025/building-networks-breaking-barriers-my-journey-at-ericsson",
    "source": "Ericsson_blog",
    "main_ideas": [
      "Ericsson promotes a culture of inclusion and diversity to drive innovation.",
      "The author's role as an RF Engineer emphasizes collaboration and connectivity.",
      "Continuous learning and support are key aspects of the work environment at Ericsson.",
      "Belonging at Ericsson is about being valued and heard in a diverse workplace.",
      "The author encourages authenticity and curiosity for potential new employees."
    ],
    "tags": [
      "ericsson",
      "inclusion",
      "diversity",
      "rf-engineering",
      "5g",
      "collaboration",
      "continuous-learning",
      "telecommunications",
      "workplace-culture"
    ],
    "original_text": "Like what you’re reading?\nSubscribe now!\nBuilding networks, breaking barriers: My journey at Ericsson\nAt Ericsson, inclusion isn’t just a policy, it’s part of who we are. We believe that diverse perspectives drive innovation, and that fairness and respect should guide every decision we make.\nIn my journey as an RF Engineer, I have seen firsthand how a culture of belonging and purpose can unlock both personal growth and real-world impact.\nI would like to share a few reflections that have shaped my experience here, moments that have helped me find purpose, build connections, and keep learning along the way.\nOct 31, 2025\n|\n2 min.\nVishal Kumar\nVishal Kumar\nRF Engineer, Ericsson India\nOct 31, 2025\n|\n2 min.\nVishal Kumar\nVishal Kumar\nRF Engineer, Ericsson India\nVishal Kumar\nVishal Kumar\nRF Engineer, Ericsson India\nFinding my purpose\nWhen I joined Ericsson about an year ago, I was drawn by its global reputation for innovation and the real-world impact of its technology. What I didn’t realize then was how deeply that sense of purpose would shape my own experience here.\nEvery day, I see the difference our work makes — connecting people, powering communication, and helping societies move forward. It’s a reminder that even the smallest task contributes to something bigger. That feeling of impact is what keeps me motivated.\nCreating connections that matter\nAs an RF Engineer in the Radio Access Network (RAN) department, I work on optimizing wireless network performance and ensuring seamless connectivity for users. My role involves analyzing, designing, and maintaining radio frequency systems to enhance mobile coverage, capacity, and quality.\nI collaborate with teams across functions and geographies to solve challenges and build reliable telecom solutions that meet the evolving needs of customers and operators.\nIt’s challenging and dynamic work, but what makes it fulfilling is the sense of collaboration, knowing that behind every connected call or streaming moment, there’s a team of people working together to make it seamless.\nLearning everyday\nL\nearning for me, has never stopped here. I’ve explored courses on 5G RAN & Non-Standalone NR, Cloud SDN, Ericsson Cloud SDN 7, and BCSS SW R&D 5G Fundamentals through Degreed, our digital learning platform. It has helped me grow and advance in my current role.\nA culture that cares\nSupport and empathy are core to how we work. From my very first day, my teammates and managers made sure I felt included and confident in my role. When I’ve needed flexibility\nor personal reasons, their understanding made it easy to balance responsibilities without worry. That culture of well-being where people genuinely care for each other allows you to perform at your best. You’re trusted to deliver, but you’re also supported as a person. It’s something I truly value.\nWhere inclusion feels real\nFor me, belonging means being seen, heard, and valued for who you are and that’s exactly what I’ve experienced here. At Ericsson, inclusion isn’t a policy; it’s an everyday behavior. People listen, collaborate, and celebrate diverse perspectives.\nWorking with colleagues from different cultures has made me more open-minded and creative. It’s taught me that innovation happens when everyone feels safe to share their voice and ideas.\nAdvice for those considering Ericsson\nIf you're considering joining Ericsson, my advice is simple:\ncome as you are and stay curious\n. This is a place that values authenticity, encourages continuous learning, and makes inclusion part of everyday life, not just a statement.\nWhat makes me proud is knowing that my work helps keep people connected around the world. Even on the most demanding days, that shared purpose is what keeps me grounded.\nAt Ericsson, I’ve found a community where impact, growth, well-being, and belonging come together and that’s what makes this journey truly meaningful.\nReady to take the next step in your career?\nDiscover how you can be part of a truly inclusive team at Ericsson by exploring our current opportunities.\nRead more stories\nCareer transitions: Insights from Swati Kamat\nSix reasons why Ericsson is the best place to start your career\nRELATED CONTENT\nThe Ericsson Blog\nLike what you’re reading? Please sign up for email updates on your favorite topics.\nSubscribe now\nAt the Ericsson Blog, we provide insight to make complex ideas on technology, innovation and business simple."
  },
  {
    "title": "New 3GPP requirement ensures protection for fixed satellite systems",
    "date": "2025-10-29",
    "link": "https://www.ericsson.com/en/blog/2025/10/ota-spatial-emission",
    "source": "Ericsson_blog",
    "main_ideas": [
      "3GPP introduces new requirements to protect fixed satellite systems from mobile interference.",
      "A performance metric called EEIRP measures over-the-air emissions towards satellites.",
      "The new regulations allow flexible beamforming configurations for base stations."
    ],
    "tags": [
      "3gpp",
      "satellite",
      "spectrum",
      "standardization",
      "5g",
      "interference",
      "telecommunications",
      "regulations",
      "mobile-networks"
    ],
    "original_text": "Like what you’re reading?\nSubscribe now!\nNew 3GPP requirement ensures protection for fixed satellite systems\nTo ensure the protection of fixed satellite systems from mobile systems in the upper 6 GHz band, 3GPP has developed a new performance metric and innovative test procedures to measure over-the-air (OTA) spatial emissions, in line with International Radio Regulations.\nA new requirement for base stations limits the amount of power radiated upward to prevent interference with fixed satellite uplink receivers at frequencies in the upper 6 GHz range.\nOct 29, 2025\n|\n4 min.\nTorbjörn Elfström\nTorbjörn Elfström\nPrincipal Researcher, Microwave systems\nAurelian Bria\nAurelian Bria\nStandardization manager, Radio\nLorenza Giupponi\nLorenza Giupponi\nResearcher standardization, Radio and spectrum\nHashtags\nHashtags\n#standardization\n#satellite\n#spectrum\nOct 29, 2025\n|\n4 min.\nTorbjörn Elfström\nTorbjörn Elfström\nPrincipal Researcher, Microwave systems\nAurelian Bria\nAurelian Bria\nStandardization manager, Radio\nLorenza Giupponi\nLorenza Giupponi\nResearcher standardization, Radio and spectrum\nTorbjörn Elfström\nTorbjörn Elfström\nPrincipal Researcher, Microwave systems\nContributor (+2)\nAurelian Bria\nAurelian Bria\nStandardization manager, Radio\nLorenza Giupponi\nLorenza Giupponi\nResearcher standardization, Radio and spectrum\nHashtags\n#standardization\n#satellite\n#spectrum\nThe “upper 6 GHz” range between 6425 and 7125 MHz is one of the widest New Radio (NR) operating bands available for mobile communications, making it one of the most interesting frequency bands for 5G NR, leading to 6G. However, Fixed Satellite Service (FSS) systems already utilize a large part of this spectrum (from 6425 to 7075 MHz) for backhaul, broadcast and other uplink purposes. As a result, the mobile industry’s access to this spectrum range requires proactive measures to prevent interference with satellite systems.\nEnsuring interference-free co-existence with satellites\n5G NR base stations are primarily intended to connect mobile terminals on the ground but they frequently transmit some RF power toward the sky as well. While it is often unintentional, this is considered normal behavior because even the most advanced antennas today generate side lobes that point toward the sky.\nThe issue that arises is that if the aggregated power coming from a large number of base stations were to exceed certain limits, it could degrade the sensitivity of a satellite’s uplink receiver and the satellite could experience loss of service. For this reason, the International Telecommunication Union’s World Radio Conference 2023 (WRC-23) established regulations that limit the amount of power base stations can radiate above the horizon in the frequency band 6425-7075 MHz (see Resolution 220 (WRC-23). However, unlike a traditional requirement that sets a cap on the transmitter power, this new metric developed by the ITU-R, with the active participation of Ericsson, allows for a high degree of flexibility in beamforming configuration and power settings.\n3GPP Release 19: OTA spatial emission\nThe implication of the new regulation agreed at WRC-23 was that spatial characteristics of base station antenna radiation would need to be included in 3GPP standards for the first time. A new performance metric called “expected EIRP (equivalent isotropically radiated power)” – EEIRP – has been standardized for this purpose in line with the Annex to Resolution 220 (WRC-23). EEIRP is calculated by averaging the emissions above the horizon while considering specific limits at different elevation angles. 3GPP has also developed a base station RF requirement and corresponding test methodology for Massive-MIMO-capable base stations that is designed to support different types of base stations tailored to fit specific coverage scenarios.\nThe 3GPP group responsible for radio performance and protocol aspects implemented the new requirement and developed an appropriate over-the-air (OTA) test methodology in the relevant technical specifications (\nTS 38.104\nand\nTS 38.141-2\n). The new requirement was released in specification version 19.0.0, which became available in March 2025. The technical background information, including description, simulation results and measurement uncertainty evaluation, is available in a technical report (\nTR 38.908\n).\nThe new 3GPP requirement is called OTA spatial emission. Since this is a completely new type of requirement that includes spatial characteristics, it does not fit into the original structure. As a result, the specifications were extended with a new clause dedicated to OTA spatial emission.\nThe OTA spatial emission requirement specifies the maximum allowed radiated power toward the satellite systems expressed in dBm/MHz, while providing communication to user equipment in the terrestrial network. The requirement is presented as a set of seven limits for seven different elevation angular ranges. It is important to note that the limit applicable for emissions close to the horizon is higher than the emission level for an elevation angle pointing straight up.\nEEIRP limit\nSelect all\n(dBm/MHz)\n0\n5\n10\n15\n20\n25\n0 ≤ θ < 5\n27\n5 ≤ θ < 10\n23\n10 ≤ θ < 15\n19\n15 ≤ θ < 20\n18\n20 ≤ θ < 30\n16\n30 ≤ θ < 60\n15\n60 ≤ θ < 90\n15\nNo data to display.\nThe EEIRP test approach\nCompliance with the OTA spatial emission requirement is assured using a completely new and innovative test concept that determines a base station’s ability to suppress emission generated upward toward satellites, while transmitting a set of test beams within the supported steering range. The test beam constellation consists of 21 beams, all of them configured for the highest supported directivity, uniformly distributed within the intended steering range (the coverage area) supported by the base station. A base station can support several steering ranges tailored to different coverage situations utilizing different power capabilities.\nTesting is performed in an anechoic chamber where the EIRP radiation pattern is evaluated for each test beam. The EIRP measurement can be set up in such a way that the 21 test beams are looped through in sequence for each OTA chamber positioner location. This method reduces the total test time significantly because it takes much more time to move the positioner than it does to change the beam direction.\nIn the first averaging stage the average radiation pattern over the 21 test beams is calculated. If a configuration considering mechanical tilt is considered, the average radiation pattern is rotated with respect to the mechanical tilt setting.\nIn the second averaging stage, the EEIRP is calculated for seven elevation angular ranges. Then the measured EEIRP is compared to the requirement levels. If all measured levels for a given configuration are below the requirement limits, the base station meets the protection requirement.\nThe test specification includes instructions on how to configure the base station for testing , along with guidelines for calculating EEIRP based on the measured EIRP patterns for each beam in the test beam set. All the technical details related to the measurement of OTA spatial emission, measurement of radiation pattern for each test beam, data post processing and test object configuration can be found in\nTS 38.141-2\n.\nThe base station test procedure was designed to model the antenna’s ability to suppress unintended spatial emission toward satellites in the sky. With this update, 3GPP WG4 base station RF specifications provide the industry with a harmonized and standardized test methodology, including test object configuration and a complete description of criteria for compliance to the limits.\nFlowchart with four steps: EIRP measurement, average EIRP pattern calculation, EEIRP per bin calculation, and Compare measured EEIRP profile with requirements mask.\nDeployment aspects\nThe new requirement provides a reliable method for measuring a base station’s ability to suppress emissions toward a satellite for a defined set of test beams for a declared steering range. When a base station is installed at a site in a live network, it is essential that the configuration of the steering range complies with the limits that were evaluated during testing.\nControl over a number of other parameters is necessary to guarantee a base station’s compliance with all EEIRP limits. The base-band processing unit needs to monitor how much power is being transmitted above the horizon, in every beamforming instance, as well as on average over many instances. In the event EEIRP limits may be exceeded due to beamforming operation, mitigation techniques would be activated to ensure compliance.\nA significant step forward\nThe introduction of OTA spatial emission requirements in 3GPP Release 19 marks a significant step forward in ensuring the safe and efficient coexistence of terrestrial 5G networks and fixed satellite services in the frequency bands in the upper 6 GHz range. By standardizing the new metric, EEIRP, and defining a comprehensive test methodology, the industry now has a standardized framework to measure, verify and control emissions directed toward the sky. This development not only safeguards the performance of critical fixed satellite systems but also gives mobile operators the flexibility they need to deploy advanced 5G networks in one of the most promising frequency ranges.\nUltimately, the new requirement is an example of how collaboration between various Ericsson teams, and across international bodies, regulation and standardization groups enables innovation while protecting existing services – paving the way for a more reliable and sustainable use of spectrum resources.\nRead more\nHow we reached a common vision on the architecture for 5g non-terrestrial networks in 3GPP rel-1\nRedCap and eRedCap – standardizing simplified 5G devices for the Internet of Things\nITU World Radiocommunication Conference 2023 (WRC-23) Final Acts, Resolution 220\nUsing 3GPP technology for satellite communication\nRELATED CONTENT\nThe Ericsson Blog\nLike what you’re reading? Please sign up for email updates on your favorite topics.\nSubscribe now\nAt the Ericsson Blog, we provide insight to make complex ideas on technology, innovation and business simple."
  },
  {
    "title": "Women in leadership: Emily Selvera, Head of Performance and Transformation",
    "date": "2025-10-28",
    "link": "https://www.ericsson.com/en/blog/2025/10/women-in-leadership-emily-selvera-head-of-performance-and-transformation",
    "source": "Ericsson_blog",
    "main_ideas": [
      "Emily Selvera's 16-year career at Ericsson highlights the importance of curiosity and authenticity.",
      "A supportive company culture fosters growth and leadership opportunities for employees.",
      "Flexibility and respect for diversity are key components of effective leadership."
    ],
    "tags": [
      "women-in-leadership",
      "career-growth",
      "company-culture",
      "authenticity",
      "flexibility",
      "ericsson",
      "leadership",
      "professional-development",
      "diversity"
    ],
    "original_text": "Like what you’re reading?\nSubscribe now!\nWomen in leadership: Emily Selvera, Head of Performance and Transformation\nEmily Selvera’s 16-year journey at Ericsson demonstrates how curiosity, authenticity, and openness to opportunity can lead to a fulfilling career.\nHer story underscores the power of a supportive culture and leadership grounded in flexibility, empathy, and trust.\nOct 28, 2025\n|\n3 min.\nLara Burt\nLara Burt\nTalent Marketing Activation Specialist\nOct 28, 2025\n|\n3 min.\nLara Burt\nLara Burt\nTalent Marketing Activation Specialist\nLara Burt\nLara Burt\nTalent Marketing Activation Specialist\nOver 16 years at Ericsson, Emily Selvera has built a global career spanning finance, analytics, and transformation. From Dallas to Madrid to Johannesburg, she’s led teams across continents and now heads Performance & Transformation for Market Area Americas.\nToday, she drives business excellence and continuous improvement initiatives that enable smarter decision-making and sustainable growth. Her journey reflects the value of curiosity, courage, and staying true to yourself in a culture that empowers growth.\nFrom intern to leader: Emily Selvera’s 16-year journey at Ericsson\nWhen Emily Selvera first walked into Ericsson as a summer intern, she thought she’d only be there for three months. At the time, she was finishing her accounting degree at the University of Texas at Dallas, preparing for her CPA license, and already had a full-time offer from a Big Four accounting firm, a dream for most accounting students.\nBut sometimes, life takes an unexpected turn. In those three short months, Emily found something rare: a company culture that inspired her to stay. “The first three months of Ericsson left such a strong impression on me that I knew I didn’t want to leave. I took a risk, but in my heart, I knew it was the right thing to do.” What began as a three-month internship has turned into 16 years of growth, transformation, and leadership.\nTaking risks and finding belonging\nEmily started her career in business operations, later transitioning into business finance as Ericsson centralized its finance teams. From there, she explored different finance roles, eventually moving into performance and transformation, where she now leads initiatives within Business Control and Sourcing.\nHer career has been defined by saying “yes” to opportunities, even when the timing wasn’t perfect. “Every time I asked for something, whether it was a new project, a chance to travel, or to work with a new team, it didn’t always come immediately. But people remembered. And eventually, those opportunities came.” That willingness to ask, paired with Ericsson’s culture of support, has shaped Emily’s career in unexpected and rewarding ways, including assignments in South Africa,\nSenegal, Sweden, India and Madrid.\nA culture of trust and opportunity\nLooking back, one moment from her internship stands out: “Three weeks into the job, my manager asked me to present results to senior leaders. I had no experience, just what I had learned in school. But they trusted me. That experience set the tone for my career.”\nIt’s that trust, combined with Ericsson’s openness to employee ambitions, that convinced Emily she could build a career here. “At every stage of my life, whether I wanted to go back to school, travel the world, or now start a family, Ericsson has supported me.”\nLeading with flexibility, empathy, and authenticity\nAs a people leader, Emily has shaped her leadership style around flexibility and respect for diversity. Having worked across market areas and global functions, she’s learned that no two people are the same. “There is no one-size-fits-all leadership model. Some people want close involvement; others prefer independence. The most important thing is flexibility, and remembering that everyone deserves respect, care, and appreciation.”\nFor Emily, authenticity is non-negotiable. Early in her career, she worried that her fun, lighthearted personality might not be taken seriously in a corporate environment. Over time, she realized that being herself (silly jokes and all) was her biggest strength.\n“It took me time to realize that being authentic would get me further than trying to fit in. I’ve gotten further by being myself than I ever did trying to mirror someone else’s energy.”\nLessons from 16 years at Ericsson\nEmily’s career journey has given her insights not just into leadership, but into navigating change and staying true to yourself. Some of her biggest takeaways include:\nSpeak up about your goals\n. Even if opportunities don’t come immediately, they will be remembered.\nFind your unique strengths\n. Whether it’s a technical skill or a personality trait, bring it forward from day one.\nEmbrace job shadowing\n. Some of Emily’s biggest career shifts, including going back to school for a systems engineering degree, came from shadowing colleagues in different roles.\nNever stop learning\n. Emily has earned five degrees, four sponsored by Ericsson, because each new project or interest sparked a desire to deepen her knowledge.\nBe yourself\n. Authenticity not only builds trust, it also sustains a career.\nAdvice to early career professionals\nIf she could give advice to her 20-year-old self, Emily would say: “Don’t dull your personality or try to be someone else at work. Be yourself. Authenticity is more powerful than fitting in.” She also encourages new hires to identify and share their unique skills from day one: “Every new hire I’ve worked with brought something special to the table, even if they didn’t recognize it. Don’t underestimate what you bring. Speak up, and you can make an impact right away.”\nOne Ericsson, many paths\nLooking back on Ericsson’s evolution, Emily reflects on the company’s shift from many regional units to five global market areas as one of the biggest and best changes she’s witnessed.\n“It created more collaboration, more tolerance for differences, and helped us learn from each other. It truly feels like One Ericsson.”\nAnd for Emily, that’s what keeps her inspired: the chance to grow, adapt, and contribute to something larger than herself. Emily’s journey shows that careers aren’t just about roles or titles, they’re about finding a place that values your ambitions, supports your growth, and lets you be your authentic self. For her, that place has been Ericsson, for 16 years and counting.\nDoes Ericsson sound like a place for you?\nCheck out our open roles to find your next career move\n.\nRELATED CONTENT\nNov 14, 2025\nWomen in leadership: Sashieka Seneviratne, Director of Cloud RAN Solutions\nOct 02, 2025\nZero trust\nJun 03, 2025\nRecruitment process\nThe Ericsson Blog\nLike what you’re reading? Please sign up for email updates on your favorite topics.\nSubscribe now\nAt the Ericsson Blog, we provide insight to make complex ideas on technology, innovation and business simple."
  },
  {
    "title": "The US can win the global tech race with trusted networks and global collaboration",
    "date": "2025-10-21",
    "link": "https://www.ericsson.com/en/blog/2025/10/us-global-tech",
    "source": "Ericsson_blog",
    "main_ideas": [
      "The US must lead in 6G and AI for technological competitiveness and national security.",
      "Collaboration between nations is essential for building a trusted digital ecosystem.",
      "Industry partnerships and adherence to security standards are crucial for safeguarding infrastructure."
    ],
    "tags": [
      "6g",
      "ai",
      "national-security",
      "collaboration",
      "digital-ecosystem",
      "telecom",
      "infrastructure",
      "innovation",
      "trusted-networks"
    ],
    "original_text": "Like what you’re reading?\nSubscribe now!\nThe US can win the global tech race with trusted networks and global collaboration\nThe US must lead in 6G and AI to ensure technological competitiveness and ensure national security\nSuccess depends on strong alliances, open ecosystems, and fair market rules\nOct 21, 2025\n|\n3 min.\nYossi Cohen\nYossi Cohen\nPresident and Head of Market Area Americas\nHashtags\nHashtags\n#6G\n#security\nOct 21, 2025\n|\n3 min.\nYossi Cohen\nYossi Cohen\nPresident and Head of Market Area Americas\nYossi Cohen\nYossi Cohen\nPresident and Head of Market Area Americas\nHashtags\n#6G\n#security\nFor the past two decades, digital technology has not only driven US economic leadership but served as an increasingly important cornerstone of national security. At the same time, communications networks are critical national infrastructure and are as important as roads, railways and utilities. Recent attempts by state actors to infiltrate or disrupt telecom networks underscore why ‘trusted’ must be a security standard, not a slogan.\nToday the US has the opportunity and the responsibility to maintain and extend its leadership in key areas like 6G and AI.\nThe US is Ericsson’s largest and most important market, and we take pride in being an integral part of the US tech ecosystem. We’ve been here for 120 years as a telecom provider and more recently as the largest manufacturer of 5G equipment in the U.S., with our manufacturing plant in Texas. Our presence includes more than 7,000 employees, multiple R&D hubs, and manufacturing operations.\nYou can take a deep dive into our American commitment in my blog post from last year on\nhow 5G leadership demands game-changing moves\n.\nWe can only succeed through collaboration\nThe digital tech stack is comprised of 5G/6G, cloud, semiconductors and AI. Global technology leadership in the digital stack is at the center of present and future security concerns, and it is not surprising that digital technology is at the center of debates about national resilience and geopolitics.\nHowever, it will be a struggle even for the US to achieve the scale needed to develop an ecosystem capable of innovating and sustaining scalable digital stacks.\nWe can only build a trusted digital ecosystem through collaboration between nations and other organizations aligned in their commitment to security, openness, innovation and consistent technology standards. US-led partnerships across regions will be vital to creating supply chains that are secure, independent, and scalable with partners. As part of this effort, adherence to security and supply-chain standards such as SCS 9001 provides verifiable trust across the ecosystem.\nThis way, we can achieve a secure and trusted digital stack without risking fragmented markets, duplicated investments, insecure technology and inconsistent standards.\nIndustry collaboration with governments is equally critical. Interoperable systems create a collaborative environment for entities across diverse geopolitical settings Efforts to align technology standards internationally – in areas such as spectrum allocation and Open RAN – are crucial for reducing costs, fostering competition, and facilitating rapid innovation.\nLongstanding bipartisan efforts in the US, and more recent developments such as the “rip and replace” program for untrusted telecom equipment, show a promising commitment to safeguarding critical infrastructure. Ericsson remains strongly committed to working alongside industry representatives, policymakers, and allied nations to ensure that trusted technology providers drive the evolution of global networks.\nWe at Ericsson are working to foster ecosystem partnerships to pool expertise, share resources, and drive innovation while maintaining strategic economic security.  This ranges from our Aduna joint venture to Silicon Valley partners in the cloud and major tech space.\nThe US needs to lead in AI and 6G\nThe acceleration of digitalization, complemented by automation and electrification, will gain wide momentum in the next five to ten years. This cross-sectoral interplay will be underpinned by rapid technological advances across three cornerstone technologies: AI, cloud and mobile.\nWireless connectivity is already an essential part of the AI stack, and AI services will only scale with access to reliable, low latency connectivity with guaranteed uplink performance, especially as AI applications move to the edge. Trusted connectivity is also essential to safeguard the American AI stack as it is promoted and expands globally.\nCommercial 6G is expected around 2030, assuming the first standards are available in 2029. 6G will build on and evolve from previous generations and introduce new concepts. The first wave of 6G will advance technologies and use cases already introduced in the 5G era.\nAs 6G develops, new network technologies will begin to redefine service possibilities, moving networks into new paradigms of ultra lean design, limitless connectivity, integrated sensing and communication, and seamless ground, air and satellite coverage. Through AI-native capabilities, 6G will take the telecom industry significantly closer to fully autonomous network operations with zero human touch, and we see new monetization opportunities through AI-as-a-Service models. Because integrated sensing and communications (ISAC) will greatly expand what networks can ‘sense,’ governance and supplier trust become even more critical to prevent misuse by bad actors.\nEricsson is already preparing for commercial 6G with early portfolio planning and system testbeds and trials. We have already started collaborations with key American partners, suppliers and customers.\nLooking ahead: Ericsson is a natural partner for the US\nAs competitive and security challenges continue to evolve, Ericsson believes that steadfast collaboration is the only path forward. We welcome deeper partnerships with the US government on domestic infrastructure.\nLooking ahead, our role is to contribute open interfaces, verifiable security, and US-based manufacturing within a multi-vendor, standards-aligned trusted stack. We will work with government, operators, and partners to strengthen domestic infrastructure while preserving an open, competitive global ecosystem.\nRead more\nFind out more about our presence in United States\nRELATED CONTENT\nThe Ericsson Blog\nLike what you’re reading? Please sign up for email updates on your favorite topics.\nSubscribe now\nAt the Ericsson Blog, we provide insight to make complex ideas on technology, innovation and business simple."
  },
  {
    "title": "Autonomous Operations: The path to resilient IT",
    "date": "2025-10-15",
    "link": "https://www.ericsson.com/en/blog/2025/10/autonomous-operations-the-path-to-resilient-it",
    "source": "Ericsson_blog",
    "main_ideas": [
      "Autonomous operations enable proactive issue prevention in complex IT environments.",
      "The autonomy loop consists of observing, orienting, deciding, and acting for continuous improvement.",
      "A holistic strategy is essential for transitioning from basic automation to full operational autonomy."
    ],
    "tags": [
      "autonomous-operations",
      "ai",
      "cloud-computing",
      "it-operations",
      "telecom",
      "automation",
      "agentic-ai",
      "business-resilience",
      "oss-bss",
      "continuous-improvement"
    ],
    "original_text": "Like what you’re reading?\nSubscribe now!\nAutonomous Operations: The path to resilient IT\nOSS/BSS, cloud, and IT environments are becoming more complex, and manual fixes or basic automation can’t keep up. Autonomous operations, powered by agentic AI and closed-loop automation, enable self-learning systems that proactively prevent issues. This blog explains why the shift to autonomous operations is vital, how the autonomy loop works, and how to plan your next steps.\nOct 15, 2025\n|\n4 min.\nEmad Damra\nEmad Damra\nProduct Marketing Manager\nRohit Agarwal\nRohit Agarwal\nStrategic Product Manager\nGurpreet Kaur Bedi\nGurpreet Kaur Bedi\nStrategic Product Manager\nOct 15, 2025\n|\n4 min.\nEmad Damra\nEmad Damra\nProduct Marketing Manager\nRohit Agarwal\nRohit Agarwal\nStrategic Product Manager\nGurpreet Kaur Bedi\nGurpreet Kaur Bedi\nStrategic Product Manager\nEmad Damra\nEmad Damra\nProduct Marketing Manager\nContributor (+2)\nRohit Agarwal\nRohit Agarwal\nStrategic Product Manager\nGurpreet Kaur Bedi\nGurpreet Kaur Bedi\nStrategic Product Manager\nThe imperative: Shifting to autonomy in IT operations\nFor years, operations have relied on people fixing problems as they arise, then on scripts automating parts of the work. But nowadays complexity has outpaced this approach.\nOSS/BSS, cloud, and IT environments are growing more complex, with new services, new partners, and multi-vendor systems, while your customers expect everything to “just work”. Running things manually is no longer an option – it’s too slow, costly, and, moreover, risky.\nFigure 1: Shift to autonomy for true resilience\nAutomation has helped, but only to a point. Task-based scripts and siloed fixes deliver efficiency gains but don’t solve the real problem.\nTM Forum\ndefines five levels of autonomy, from simple assisted automation (Level 1) to fully autonomous, intent-driven networks (Level 5). Most communication service providers (CSPs) are still climbing this ladder. The goal is Level 5 – the real leap for autonomous operations. At this stage, operations become intent-driven, self-learning, and proactive, aiming to prevent issues before they affect your business, while unlocking resilience, reducing costs, and providing consistent performance.\nFrom observability to autonomous operations\nPicture this: your telecom IT running like a well-oiled machine, fixing issues before they even become problems, and delivering top-notch service with minimal hassle. That’s the magic of autonomous operations in IT for CSPs! It’s like giving your operations a super-smart assistant who’s always learning and improving. Let’s break down how it works and why it’s important for efficient operations.\nAt the core, four key pillars hold everything together:\nSmart data management:\nCollect and make sense of the flood of data from your different systems.\nIntent-driven operations:\nTranslate big-picture business goals into clear, actionable steps.\nAgentic AI-powered automation:\nLet AI handle tasks automatically while avoiding conflicts.\nContinuous learning from human actions:\nObserve how humans solve problems and learn to do it better next time.\nTogether, these pillars create what we call the autonomy loop: Observe → Orient → Decide → Act, capturing the journey from awareness to intelligent actions. It starts with observing system telemetry, then orienting that data into context to understand its meaning. Next, AI-driven decisions are made to determine the best course of action, followed by automated execution. As the loop repeats, the system not only resolves issues faster but also learns and adapts, driving continuous improvement.\nNow, here’s how it plays out:\nWith intent management and agentic AI, you can turn big business goals into clear operational steps. The system assesses real-time conditions, applies the right instructions, and even handles conflicts automatically.\nSometimes, things get tricky, and that’s when the “adaptive knowledge engine” function kicks in. The platform observes how humans resolve the issue, learns from it, and stores that know-how for the future. Over time, the system becomes smarter, faster, and more reliable.\nThe result? Not just efficiency for you, but also a better experience for your customers.\nTake order failure handling as an example.\nTraditionally, this is a headache — back-office teams jump between multiple screens, chase data across systems, and repeat rule-based steps over and over again. The result: inefficiency, delays, and a poor customer experience.\nWith an autonomous operations framework, it’s different. An agent can simply express the intent to handle different types of order failures. AI agents then step in – they monitor, detect failures, and apply the right resolution actions automatically. What used to be manual and error-prone now becomes seamless, directly improving the customer experience.\nLet’s look at how the order failure case is handled through the autonomy loop: Observe → Orient → Decide → Act.\nObserve:\nCollect telemetry from IT systems, hardware, and cloud infrastructure across the end-to-end order management process.\nOrient:\nThis is where raw observations are translated into context. Based on the captured telemetry, a situational picture is built and then analyzed by the Decide layer..\nDecide:\nHere’s where the magic happens. This layer is the brain, using AI to spot anomalies in order flow, pinpoint root cause analysis (RCA), and assess service impacts. Agentic AI steps in to analyze the cause of the failure, align it with the business intent for handling order failures, and determine the best next steps.\nAct:\nExecute corrective actions, such as adjusting order parameters and retrying orders. If something can’t be fixed automatically, the system doesn’t just stop — it observes how humans handle it and learns to address it next time.\nFigure 2: The autonomy loop: Observe -> Orient -> Decide -> Act\nIn short, autonomous operations aren’t just about cutting costs or automating tasks. They’re about creating IT systems that are constantly watching, deciding, acting, and evolving — serving as a true partner in delivering reliable services at scale.\nEnabling autonomy with an end-to-end approach\nThe journey to autonomous operations demands a holistic, end-to-end strategy to ensure you don’t just automate isolated tasks, but also build a robust, self-improving ecosystem that can adapt and deliver value continuously.\nEricsson Intelligent IT Suite is strategically designed to empower you on the journey toward autonomous operations. It is built on the key pillars of multi-agentic AI, closed-loop automation, intent-based operations, and extensive telco knowledge planes to achieve operational autonomy. Our solution is backed by proven experience in multi-vendor environments, supported by seamless integration across cloud and IT layers.\nA successful end-to-end autonomous operations journey transforms business resilience, agility, and performance. It should be feedback-driven, self-improving, and built on systems that balance machine autonomy with meaningful human oversight, ensuring enterprise-wide success.\nHow should you plan your next steps?\nYour journey toward autonomous operations needs a clear, step-by-step approach. It begins with identifying your business intents, followed by assessing current maturity levels and conducting a gap analysis. Then we design a roadmap that takes you from basic automation to full autonomy, enabling “Zero wait, Zero touch, Zero trouble” experiences.\nFigure 3: Advancing toward AIOps and autonomy\nThis approach turns business intents into actionable autonomy. To make this possible, we leverage advanced IT managed services tools,including:\nA centralized data repository for full observability across IT and infrastructure layers\nNetwork topology-based alarm correlation for smarter operations\nAgentic AI to localize faults, generate and evaluate solutions, and record human actions\nAutomated Method of Procedure (MOP) generation, enhancing the knowledge base continuously\nWith this end-to-end framework, you can confidently move toward a future of intelligent, autonomous operations.\nYour path to autonomy starts here\nThe shift to autonomy is no longer a question of if, but how fast. You can’t afford to stay locked into operations-centric KPIs that only measure efficiency. The future is about outcomes that reflect customer experience, agility, and resilience.\nAutonomous operations, powered by AIOps and agentic AI, unlock this future. They enable zero-touch, closed-loop operations in which problems are predicted, prevented, and resolved before they impact the business.\nBut autonomy isn’t built on technology alone. It demands expertise, the right tools, and people ready to lead this change. Together, these create the foundation for operations that scale with confidence and deliver lasting business impact.\nRead more:\nRead the brief:\nEricsson Intelligent IT Suite\nLearn more about:\nOSS/BSS Services for better business outcomes\nOther related content:\nEricsson OSS/BSS - Sell. Deliver. Get paid\nIntelligent IT Suite\nRELATED CONTENT\nSep 24, 2020\neSIM: Driving global connectivity in the automotive industry\nOct 18, 2019\nWhat is NB-IoT? Practical tips to unlock its business potential\nSep 02, 2020\nHow to improve customer experience with intelligent operations\nThe Ericsson Blog\nLike what you’re reading? Please sign up for email updates on your favorite topics.\nSubscribe now\nAt the Ericsson Blog, we provide insight to make complex ideas on technology, innovation and business simple."
  },
  {
    "title": "Oracle Expands AI Agent Studio for Fusion Applications with New Marketplace, LLMs, and Vast Partner Network",
    "date": "2025-10-15",
    "link": "https://www.oracle.com/news/announcement/ai-world-oracle-expands-ai-agent-studio-for-fusion-applications-with-new-marketplace-llms-and-vast-partner-network-2025-10-15/",
    "source": "Oracle",
    "main_ideas": [
      "Oracle expands AI Agent Studio with a new marketplace for partner-built AI agents.",
      "Support for multiple LLMs enhances flexibility and AI adoption in Oracle Fusion Applications.",
      "Over 32,000 certified experts are available to optimize AI implementations for customers."
    ],
    "tags": [
      "oracle",
      "ai-agent-studio",
      "fusion-applications",
      "llm",
      "artificial-intelligence",
      "cloud-computing",
      "automation",
      "enterprise-software",
      "partner-network"
    ],
    "original_text": "Skip to content\nAccessibility Policy\nClose Search\nSearch Oracle.com\nQUICK LINKS\nOracle Cloud Infrastructure\nOracle Fusion Cloud Applications\nOracle Database\nDownload Java\nCareers at Oracle\nSearch\nCountry\nView Accounts\nBack\nCloud Account\nSign in to Cloud\nSign Up for Free Cloud Tier\nOracle Account\nSign-In\nCreate an Account\nHelp\nSign Out\nContact Sales\nMenu\nMenu\nPress Release\nOracle Expands AI Agent Studio for Fusion Applications with New Marketplace, LLMs, and Vast Partner Network\nNew AI Agent Marketplace delivers partner-built AI agents directly within Oracle Fusion Cloud Applications to streamline operations and unlock new levels of efficiency\nSupport for OpenAI, Anthropic, Cohere, Google, Meta, and xAI in Oracle AI Agent Studio for Fusion Applications will enhance flexibility and improve AI adoption\nMore than 32,000 certified experts trained in Oracle AI Agent Studio will help customers optimize AI\nOracle AI World, Las Vegas—Oct 15, 2025\nOracle today announced the latest updates to Oracle AI Agent Studio for Fusion Applications, a comprehensive platform for building, testing, and deploying AI agents and agent teams across the enterprise. The latest updates expand the Oracle Fusion Cloud Applications AI ecosystem and include a new AI Agent Marketplace, extended LLM support and agent-building resources, and a vast network of Oracle-certified AI agent experts.\n“Organizations are grappling with rising business complexity and the urgent need to accelerate AI adoption,” said Chris Leone, executive vice president of Applications Development, Oracle. “By building a comprehensive AI ecosystem centered around Oracle Fusion Applications, we’re giving customers the flexibility to address complex challenges swiftly, securely, and confidently. The AI Agent Marketplace and other enhancements to the AI Agent Studio enable our customers to supplement the embedded AI agents in Fusion Applications with validated, industry-specific capabilities from our growing AI ecosystem of systems integrators and independent software vendors.”\nNew AI Agent Marketplace Taps Partner Expertise to Accelerate Enterprise AI Adoption\nThe new\nOracle Fusion Applications AI Agent Marketplace\nenables customers to easily deploy Oracle-validated, partner-built AI agents within Oracle Fusion Applications. Marketplace seeded partner templates are embedded in\nOracle AI Agent Studio\nto help customers accelerate automation, boost productivity, and address complex, industry-specific business challenges.\nUnlike other AI agent marketplaces, Oracle AI Agent Marketplace is embedded natively within Oracle Fusion Applications, allowing customers to access, test, and deploy third-party AI agents directly within existing workflows. Customers can install and manage validated agent templates, created by certified Oracle PartnerNetwork members, alongside Oracle pre-built agents in a unified experience. To learn more, please visit\nOracle AI Agent Marketplace\n.\nNew LLMs and Enhancements Support Multi-Step Agentic Workflows in AI Agent Studio\nOracle AI Agent Studio enables customers and partners to select the best-performing LLM for their business needs, with support for OpenAI, Anthropic, Cohere, Google, Meta, and xAI. Additional updates to Oracle AI Agent Studio include new:\nIntegration & Extensibility Capabilities\nMCP support:\nEnables users to extend agent capabilities with third-party data and tools through seamless integration with external systems via the Model Context Protocol (MCP), an AI industry standard.\nA2A agent cards:\nEnables cross-agent collaboration with third-party agents by allowing agents to communicate and pass context between each other via standardized connectors.\nCredential store:\nControls to help ensure that AI agents can safely access external services, such as APIs, without exposing sensitive data by enabling users to securely manage API keys and authentication tokens within the Oracle AI Agent Studio.\nObservability and Evaluation Capabilities\nMonitoring dashboard:\nHelps users detect and address AI agent issues quickly by providing real-time visibility into agent performance, such as data around sessions, latency, error rates, and token usage.\nAgent performance evaluation:\nImproves AI agent effectiveness by providing systematic testing and measurement of how well agents perform in quality, correctness, and safety metrics compared to set goals.\nAgent tracing:\nHelps users debug AI agents and optimize performance by capturing detailed execution data around agent workflows.\nPerformance metrics:\nHelp users improve agent effectiveness and track efficiency over time by monitoring key indicators like correctness, latency, API errors, and token consumption.\nToken usage:\nMakes costs more predictable for customers by measuring token consumption for premium LLMs.\nPrompt Management Capabilities\nPrompt libraries and lifecycle management:\nHelp users manage agents across different parts of the lifecycle—from authoring and testing to version maintenance—by storing all prompts and agentic use cases in a central store.\nTopics management:\nHelps improve agent consistency by storing all topics being used across AI agents in a central store, increasing visibility into which capabilities are available to specific agents and providing the same prompt boundaries for agents operating in similar domains.\nAI Agents Capabilities\nExpanded Agent templates:\nHelp users quickly configure and deploy AI agents by delivering predefined blueprints for common agent use cases within the Oracle AI Agent Studio.\nAgent builder assistant:\nEnables AI agents in the Oracle AI Agent Studio to create an agent from scratch, defining topics, prompts, and tools based on high level direction from a user.\nAI Agent Studio FAQ agent:\nProvides additional support for agent builders with a Q&A assistant agent that answers questions using natural language about tasks or projects they are working on within Oracle AI Agent Studio, such as configuring agent templates, building agents from scratch, publishing agents into production, or evaluating agent performance.\nMultimodal and Retrieval-Augmented Generation (RAG) Capabilities\nMultimodal RAG:\nImproves agent Q&A performance by using RAG to incorporate more than just text – documents, images, tables, etc. – in the agent’s analysis.\nRAG over external sources:\nEnhances agent performance by using RAG over documents stored in external content repositories such as SharePoint.\nWorkflow Agents and Nodes Capabilities\nDeterministic execution:\nEnables consistent and predictable results for business-critical processes by allowing users to set prescriptive agentic workflows with pre-defined outcomes for specific types of AI agents.\nChaining workflows:\nHelp improve the outcome of deterministic agent execution for multi-steps tasks by connecting multiple workflows together.\nAgent node:\nEnables users to complete more complex processes with their agent by adding additional agents to a workflow when a more dynamic action is required, such as making decisions or interpreting context.\nHuman-in-the-loop:\nHelps users balance automation with oversight and control by incorporating human review and approvals into workflows.\nTrusted Network of Certified Experts\nOver 32,000 certified experts have completed rigorous training on how to build the most effective agents within Oracle AI Agent Studio, enabling customers to leverage the highest performing agents and optimize AI across their workflows.\nThis network of experts will further expand the breadth of Oracle AI Agent Marketplace by adding new expert-built agents and agent templates to help customers maximize their AI potential. This growing AI ecosystem of experts ensures customers have access to validated, secure, and trusted AI agents ready to transform business processes.\nAnalyst Support\n“In the current enterprise AI-arms race, Oracle has proven itself to be a steadfast competitor. With the launch of AI Agent Marketplace, Oracle is raising the bar once again,” said Mickey North Rizza, Group Vice-President Enterprise Software, IDC. “With the new marketplace offering an ever-expanding range of partner-built AI agents natively supported in Fusion Applications, Oracle customers will be uniquely able to accelerate AI adoption. This continued innovation underscores Oracle’s commitment to delivering tangible value and productivity gains to its customers in today’s fiercely competitive AI landscape.”\n“Enterprise application suites that embed AI capabilities and offer flexible agent development environments are taking a clear lead in the market,” said Holger Mueller, vice president and principal analyst at Constellation Research. “Expanding these ecosystems with accessible marketplaces for partner-built AI agents represents a natural evolution, making it easier for enterprises to adopt and scale AI-driven automation.”\nContact Info\nCelina Bertallee\nOracle PR\ncelina.bertallee@oracle.com\n+1.559.283.2425\nAbout Oracle Fusion Cloud Applications\nOracle Fusion Cloud Applications provide an integrated suite of AI-powered cloud applications that enable organizations to execute faster, make smarter decisions, and lower costs. Oracle Fusion Applications include:\nOracle Fusion Cloud Enterprise Resource Planning (ERP):\nProvides a comprehensive suite of AI-powered finance and operations applications that help organizations increase productivity, reduce costs, expand insights, improve decision-making, and enhance controls.\nOracle Fusion Cloud Human Capital Management (HCM):\nProvides a unified AI-powered HR platform that connects all people-related processes and data to help organizations automate tasks throughout the employee lifecycle, improve the employee experience, and give HR leaders actionable workforce insights.\nOracle Fusion Cloud Supply Chain & Manufacturing (SCM):\nProvides a unified AI-powered platform that integrates supply chain and operations processes and helps organizations enhance resilience and quickly adapt to market changes.\nOracle Fusion Cloud Customer Experience (CX):\nProvides a suite of AI-powered applications that helps organizations manage marketing, sales, and service processes to win business, build stronger customer relationships, and improve customer experiences.\nAbout Oracle\nOracle offers integrated suites of applications plus secure, autonomous infrastructure in the Oracle Cloud. For more information about Oracle (NYSE: ORCL), please visit us at\nwww.oracle.com\n.\nAbout Oracle AI World\nOracle AI World is where customers and partners discover the latest product and technology innovations, see how AI is being applied across industries, and connect with experts and peers. Attendees will gain practical tips and insights to drive immediate impact within their organizations and explore how Oracle is helping unlock the full potential of cloud and AI. Join the event to see new capabilities in action and hear from thought leaders and industry movers. Register now at\noracle.com/ai-world\nor follow the news and conversation at\noracle.com/news\nand\nlinkedin.com/company/oracle\n.\nFuture Product Disclaimer\nThe preceding is intended to outline our general product direction. It is for informational purposes only and may not be incorporated into any contract. The development, release, timing, and pricing of any features or functionality described for Oracle's products may change at Oracle Corporation’s sole discretion.\nTrademarks\nOracle, Java, MySQL, and NetSuite are registered trademarks of Oracle Corporation. NetSuite was the first cloud company—ushering in the new era of cloud computing."
  },
  {
    "title": "Oracle Launches Fusion Applications AI Agent Marketplace to Accelerate Enterprise AI Adoption",
    "date": "2025-10-15",
    "link": "https://www.oracle.com/news/announcement/ai-world-oracle-launches-fusion-applications-ai-agent-marketplace-to-accelerate-enterprise-ai-adoption-2025-10-15/",
    "source": "Oracle",
    "main_ideas": [
      "Oracle launched an AI Agent Marketplace to enhance enterprise AI adoption.",
      "The marketplace allows seamless deployment of partner-built AI agents within Oracle Fusion Applications.",
      "Customers can access validated AI agents to improve workflows in various business areas."
    ],
    "tags": [
      "oracle",
      "ai-agent-marketplace",
      "enterprise-ai",
      "cloud-applications",
      "productivity",
      "automation",
      "business-solutions",
      "partner-network",
      "workflow-optimization"
    ],
    "original_text": "Skip to content\nAccessibility Policy\nClose Search\nSearch Oracle.com\nQUICK LINKS\nOracle Cloud Infrastructure\nOracle Fusion Cloud Applications\nOracle Database\nDownload Java\nCareers at Oracle\nSearch\nCountry\nView Accounts\nBack\nCloud Account\nSign in to Cloud\nSign Up for Free Cloud Tier\nOracle Account\nSign-In\nCreate an Account\nHelp\nSign Out\nContact Sales\nMenu\nMenu\nPress Release\nOracle Launches Fusion Applications AI Agent Marketplace to Accelerate Enterprise AI Adoption\nNew AI Agent Marketplace empowers customers to seamlessly deploy partner-built AI agents within Oracle Fusion Cloud Applications to simplify workflows and maximize productivity\nOracle AI World, Las Vegas—Oct 15, 2025\nOracle today announced the\nOracle Fusion Applications AI Agent Marketplace\n, a new solution that enables Oracle Fusion Cloud Applications customers to easily find and deploy validated, partner-built AI agents directly within their enterprise environment. Part of\nOracle AI Agent Studio for Fusion Applications\n, the new marketplace helps customers boost productivity and address complex business challenges by enabling them to accelerate AI adoption at scale through secure AI agents built and ready for enterprise use.\n“The age of intelligent automation has arrived, and in order to stay competitive, organizations need AI solutions that are powerful, scalable, and easy to adopt,” said Chris Leone, executive vice president of Applications Development, Oracle. “With Oracle AI Agent Marketplace, we’re helping our customers fast-track enterprise AI adoption, address their unique business needs, and streamline operations by bringing our growing network of partner expertise directly into our AI ecosystem. These enterprise-grade AI agents will help organizations enhance workflow efficiency and create meaningful impact with speed and security, but without complexity.”\nOracle AI Agent Marketplace offers partner-built agent templates to transform finance, HR, supply chain, and customer experience processes across multiple industries. System integrators (SIs) from across the Oracle PartnerNetwork are contributing to the Oracle AI Agent Marketplace and distributing their agents within Oracle Fusion Applications, including Alithya, Apex IT, Apps Associates, Argano, Automus, CLOUDSUFI, GoSaaS, Grant Thornton, Huron, IBM Consulting, Infosys, KNEX, Mastek, Trinamix, and Wipro. Other global SIs, including Accenture, Deloitte, KPMG, and PwC have additional agent templates listed on\nOracle.com\nfor joint customers. Examples of SI-built agents include:\nApex IT:\nThe Address Alignment agent can enable sales orders to be processed and shipped faster and more efficiently by automatically adding the appropriate shipment address and verifying its accuracy across both sales data in\nOracle Fusion Cloud Customer Experience (CX)\nand Accounts Receivables (AR) data in\nOracle Fusion Cloud Enterprise Resource Planning (ERP)\n.\nIBM:\nThe Smart Sales Order Entry Assistant agent can help reduce order entry errors, accelerate order capture, and enhance customer satisfaction by using natural language prompts to streamline sales processes and automate manual steps to create, validate, and manage sales orders.\nInfosys:\nThe Hire to Retire agent helps HR managers easily access and update employee data by retrieving information such as contract details, role assignments, or reporting lines and automatically updating employee profiles as needed. The AI agent also strictly enforces Oracle Fusion Applications role-based access control to ensure users can only access and modify data that they are authorized for. This automation reduces manual effort, accelerates onboarding, improves data accuracy, and enables HR teams to focus on strategic, value-driven initiatives.\nKPMG:\nThe Purchase Order Item Price History agent can help streamline procurement decision-making. It can reduce manual research time and deliver deeper insights to optimize negotiation strategies by providing rapid access to historical purchase order data such as previous suppliers, purchase dates, average price over past orders, and actionable pricing insights for current orders.\nThe Oracle AI Agent Marketplace also includes agents featuring industry-leading independent software vendors (ISVs) including Box, Intellinum, Loqate, RChilli, Stripe, and Syniverse. Examples of ISV agents include:\nBox:\nThe Box Data Extraction agent delivers more comprehensive and relevant interactions with Oracle Digital Assistant by extracting specific metadata or structured content from documents stored in Box and integrating it as business objects within Oracle workflows for finance, procurement, HR, and customer experience.\nStripe:\nThe Infosys Invoice Collection AI agent powered by Stripe reduces manual effort for Finance and AR collection teams by enhancing Oracle Fusion for invoice collections, invoice payment processing, and reminders. The Agent offers personalized discounts or incentives to support complex billing arrangements and reduce day sales outstanding on invoices. It also relies on Stripe’s Smart Retries, which utilizes an AI model that evaluates time-dependent, dynamic signals to optimize payment collections on invoices.\nRChilli:\nThe Talent Data Refresh agent streamlines the job application process by enriching outdated candidate profiles with structured information from public professional sources and updating resume fields into standardized formats.\nLoqate:\nThe Contact Verification agent verifies customer contact information such as addresses, phone numbers, and/or email addresses, and makes suggestions for updating contact data within customer engagement workflows.\nUnlike other standalone agent marketplaces, Oracle’s AI Agent Marketplace is embedded natively within Oracle Fusion Applications, allowing customers to discover and deploy AI agents directly within their flow of work. With AI Agent Marketplace, customers can install and manage validated agent templates, created by Oracle PartnerNetwork members, alongside Oracle pre-built agents in a unified experience. Key features include:\nBuilt-in domain and industry expertise:\nCustomers can drive faster results, solve industry challenges, and accelerate innovation with ready-to-use agents developed by leading SIs and ISVs.\nSeamless, no-code deployment:\nCustomers can deploy AI Agent Marketplace agents with just one click and use natural language-driven processes to launch agents quickly without the need for complex coding or integrations.\nCustomizable agent templates:\nCustomers can address specific industry or business use cases by modifying pre-built templates with documents, tools, prompts, or APIs.\nValidated trust and security:\nCustomers can deploy AI Agent Marketplace agents with confidence, as every AI Agent Marketplace agent is validated through a comprehensive checklist, applying the same security standards which are applied to Oracle-built agents.\nOracle support:\nCustomers will receive consistent support with every AI Agent Marketplace agent, whether partner- or Oracle-built, benefiting from Oracle's enterprise-grade support services, which cover tool usage, debugging, integration, and runtime issues.\nOracle PartnerNetwork Support\n“Box and Oracle are dedicated to helping customers fast-track the adoption of secure AI agents,” said Ben Kus, CTO at Box. “The Box AI agents available on Oracle’s new AI Agent Marketplace enable our joint customers to get the most out of their enterprise content stored in Box and take action with that data. This open ecosystem will foster sustainable growth by enabling intelligent decision-making across industries.”\n“The launch of Oracle AI Agent Marketplace creates an unmatched opportunity for us to differentiate our expertise, accelerate innovation, and engage with Oracle’s expansive customer base,” said Dinesh Rao, EVP & Chief Delivery Officer, Infosys. “This unified, built-in solution empowers us to co-innovate and deliver tailored AI solutions for our Fusion customers by harnessing\nInfosys Topaz\n. It sets the stage for driving mutual growth and value within a single, trusted environment.”\n“The Oracle Fusion Applications AI Agent Marketplace is an ideal platform to deploy KPMG's deep industry and domain-specific AI agents directly into business workflows. Our Purchase Order Item Price History agent is a great example of this—it autonomously assembles and evaluates historical data to deliver immediate, actionable procurement insights and next-step recommendations at the moment of decision,” said Swami Chandrasekaran, KPMG Global AI & Data Labs Leader. “This marketplace is a key enabler for us at KPMG, as it helps us deploy and distribute this next-generation AI securely, responsibly, and at scale, allowing our clients to make critical business decisions with greater speed and confidence.”\nContact Info\nCelina Bertallee\nOracle PR\ncelina.bertallee@oracle.com\n+1.559.283.2425\nAbout Oracle Fusion Cloud Applications\nOracle Fusion Cloud Applications provide an integrated suite of AI-powered cloud applications that enable organizations to execute faster, make smarter decisions, and lower costs. Oracle Fusion Applications include:\nOracle Fusion Cloud Enterprise Resource Planning (ERP):\nProvides a comprehensive suite of AI-powered finance and operations applications that help organizations increase productivity, reduce costs, expand insights, improve decision-making, and enhance controls.\nOracle Fusion Cloud Human Capital Management (HCM):\nProvides a unified AI-powered HR platform that connects all people-related processes and data to help organizations automate tasks throughout the employee lifecycle, improve the employee experience, and give HR leaders actionable workforce insights.\nOracle Fusion Cloud Supply Chain & Manufacturing (SCM):\nProvides a unified AI-powered platform that integrates supply chain and operations processes and helps organizations enhance resilience and quickly adapt to market changes.\nOracle Fusion Cloud Customer Experience (CX):\nProvides a suite of AI-powered applications that helps organizations manage marketing, sales, and service processes to win business, build stronger customer relationships, and improve customer experiences.\nAbout Oracle\nOracle offers integrated suites of applications plus secure, autonomous infrastructure in the Oracle Cloud. For more information about Oracle (NYSE: ORCL), please visit us at\nwww.oracle.com\n.\nAbout Oracle AI World\nOracle AI World is where customers and partners discover the latest product and technology innovations, see how AI is being applied across industries, and connect with experts and peers. Attendees will gain practical tips and insights to drive immediate impact within their organizations and explore how Oracle is helping unlock the full potential of cloud and AI. Join the event to see new capabilities in action and hear from thought leaders and industry movers. Register now at\noracle.com/ai-world\nor follow the news and conversation at\noracle.com/news\nand\nlinkedin.com/company/oracle\n.\nFuture Product Disclaimer\nThe preceding is intended to outline our general product direction. It is for informational purposes only and may not be incorporated into any contract. The development, release, timing, and pricing of any features or functionality described for Oracle's products may change at Oracle Corporation’s sole discretion.\nTrademarks\nOracle, Java, MySQL, and NetSuite are registered trademarks of Oracle Corporation. NetSuite was the first cloud company—ushering in the new era of cloud computing."
  },
  {
    "title": "Oracle Advances Enterprise AI with New Agents Across Fusion Applications",
    "date": "2025-10-15",
    "link": "https://www.oracle.com/news/announcement/ai-world-oracle-advances-enterprise-ai-with-new-agents-across-fusion-applications-2025-10-15/",
    "source": "Oracle",
    "main_ideas": [
      "Oracle introduces new AI agents in Fusion Cloud Applications to enhance decision-making.",
      "The AI agents aim to streamline operations across finance, HR, supply chain, and customer experience.",
      "Organizations can create custom AI agents using Oracle's AI Agent Studio for Fusion Applications."
    ],
    "tags": [
      "oracle",
      "ai-agents",
      "fusion-applications",
      "cloud-computing",
      "enterprise-ai",
      "finance",
      "hr",
      "supply-chain",
      "customer-experience"
    ],
    "original_text": "Skip to content\nAccessibility Policy\nClose Search\nSearch Oracle.com\nQUICK LINKS\nOracle Cloud Infrastructure\nOracle Fusion Cloud Applications\nOracle Database\nDownload Java\nCareers at Oracle\nSearch\nCountry\nView Accounts\nBack\nCloud Account\nSign in to Cloud\nSign Up for Free Cloud Tier\nOracle Account\nSign-In\nCreate an Account\nHelp\nSign Out\nContact Sales\nMenu\nMenu\nPress Release\nOracle Advances Enterprise AI with New Agents Across Fusion Applications\nNew AI agents embedded in Oracle Fusion Cloud Applications drive smarter decision-making across finance, HR, supply chain, sales, marketing, and service\nOracle AI World, Las Vegas—Oct 15, 2025\nOracle today announced new AI agents within\nOracle Fusion Cloud Applications\nto help organizations drive faster execution, make smarter decisions, and lower costs. Built using\nOracle AI Agent Studio for Fusion Applications\n, embedded into the world’s most complete suite of cloud applications, and powered by industry-leading LLMs, the new AI agents help business leaders transform core finance functions, optimize HR processes, enhance end-to-end supply chain performance, and unlock new revenue opportunities.\n“AI is changing everything across every industry, redefining how work gets done, transforming business processes, and unlocking new value from enterprise data,” said Steve Miranda, executive vice president of Applications Development, Oracle. “With the expanded AI capabilities embedded in Oracle Fusion Applications, our customers can re-architect their finance, HR, supply chain, and customer experience operations. Whether it’s detecting anomalies with ERP, closing skills gaps with HR, streamlining fulfillment in supply chain, or surfacing opportunities for sales teams, the AI agents within Fusion Applications empower our customers to work smarter, drive efficiency, and grow with confidence.”\nRunning on Oracle Cloud Infrastructure, Oracle AI agents are prebuilt with advanced security and natively integrated within Oracle Fusion Applications at no additional cost. Embedded within the existing workflows of a business, they help users operate faster and make better decisions. The new agents are planned to streamline operations and unlock new levels of productivity across finance, HR, supply chain, and customer experience processes.\nOracle Fusion Cloud Enterprise Resource Planning (ERP)\nand\nOracle Fusion Cloud Enterprise Performance Management (EPM)\nAI agents include:\nPayables Agent:\nHelps accounts payable (AP) teams automate multi‑channel invoice processing. The agent can ingest invoices from email, portals, EDI/e‑invoicing, and PDFs; extract and normalize data; match to POs and receipts; create distributions and accounting; apply tax, policy, and fraud checks; and route for approval and payment. This boosts straight‑through processing, reduces manual effort and errors, and helps strengthen compliance.\nLedger Agent:\nHelps accountants shift from report chasing to continuous insight and action. The agent can set natural‑language monitoring prompts, deliver context‑aware inquiry and explanations with supporting details, and auto‑create adjustment journals. This accelerates issue resolution, reduces handoffs, improves accuracy, and enables continuous financial visibility.\nPlanning Agent:\nHelps financial planning and analysis (FP&A) teams move to continuous, connected planning. The agent can provide real‑time trend and variance analysis via natural‑language interactions, run event‑driven predictions on Fusion financial/operational data, and guide what‑if simulations. This shortens cycles, improves forecast accuracy, and enables better cross‑functional decisions.\nPayments Agent:\nHelps finance teams optimize cash outflows and expand payment choices. The agent can evaluate and manage early pay, virtual cards, and financing options; enable bank system interactions for faster supplier onboarding and execution; and monitor acknowledgements/exceptions. This speeds payment outcomes, increases program adoption, and boosts working capital.\nOracle Fusion Cloud Human Capital Management (HCM)\nAI agents include:\nTeam Sync Advisor Agent:\nHelps employees and managers execute more effective meetings. The agent can submit weekly updates on employee performance progress, challenges, or requests and deliver an actionable summary of these updates with follow-up questions to the manager to guide 1:1 check-ins.\nTalent Advisor Agent:\nHelps managers plan for employee promotions and career development. The agent can answer a manager’s questions about their team members, leveraging data from goals, performance evaluations, check-ins, feedback, and recognitions to get an accurate view of employee performance and appropriate next steps for their career, such as promotions or pay raises.\nManager Concierge Agent:\nHelps managers more effectively lead their teams. The agent can support inquiries around compensation, leave, talent management, and employment details and help ensure every question is efficiently routed to the appropriate agent, delivering timely, accurate, and relevant assistance for team management needs.\nOracle Fusion Cloud Supply Chain & Manufacturing (SCM)\nAI agents include:\nQuote to Purchase Requisition Agent:\nHelps procurement teams reduce manual effort, save time, and minimize errors by automating the supplier quote intake to requisition process. The agent can capture supplier quotes received via email and generate requisitions with quote details.\nFulfillment Processing Assistant Agent:\nHelps fulfillment managers streamline urgent shipping requests and simplify the pick, pack, and ship process. The agent can quickly retrieve order status, initiate picking, recommend optimal packing, and execute shipping to expedite high-priority orders.\nSales Order Assistant Agent:\nHelps customer service representatives create sales orders and improve perfect order performance. The agent can add customers, items, pricing, and promotion details to sales orders, check availability, schedule deliveries, and provide real-time recommendations.\nOracle Fusion Cloud Customer Experience (CX)\nAI agents include:\nAccount Product Fit Agent:\nHelps marketers prioritize customers that are most likely to make a purchase. The agent can identify customers most interested in buying by using Ideal Customer Profile (ICP) and predictive scoring, account data, and engagement signal data.\nDeal Advisor Agent:\nHelps sellers source subject matter expertise to close deals faster. The agent can automatically surface expert guidance from product and pricing overviews, solution guides, customer references, and use cases for sellers to share with a potential customer.\nEscalation Prediction Agent:\nHelps service representatives proactively identify service requests that are at risk of being escalated. The agent can analyze customer sentiment based on attributes of the request and predict which service requests will likely be escalated.\nIn addition to the new AI agents embedded in Oracle Fusion Applications, customers and partners can also create and manage their own unique AI agents using\nAI Agent Studio for Fusion Applications\n, a comprehensive platform for building, testing, and deploying AI agents and agent teams across the enterprise. With AI Agent Studio for Fusion Applications, Oracle Fusion Applications customers can also take advantage of the\nAI Agent Marketplace\n, a new solution that enables them to easily find and deploy validated, partner-built AI agents directly within their enterprise environment.\nTo learn more about Oracle Fusion Applications, visit\nwww.oracle.com/applications\n.\nContact Info\nCelina Bertallee\nOracle PR\ncelina.bertallee@oracle.com\n+1.559.283.2425\nAbout Oracle Fusion Cloud Applications\nOracle Fusion Cloud Applications provide an integrated suite of AI-powered cloud applications that enable organizations to execute faster, make smarter decisions, and lower costs. Oracle Fusion Applications include:\nOracle Fusion Cloud Enterprise Resource Planning (ERP):\nProvides a comprehensive suite of AI-powered finance and operations applications that help organizations increase productivity, reduce costs, expand insights, improve decision-making, and enhance controls.\nOracle Fusion Cloud Human Capital Management (HCM):\nProvides a unified AI-powered HR platform that connects all people-related processes and data to help organizations automate tasks throughout the employee lifecycle, improve the employee experience, and give HR leaders actionable workforce insights.\nOracle Fusion Cloud Supply Chain & Manufacturing (SCM):\nProvides a unified AI-powered platform that integrates supply chain and operations processes and helps organizations enhance resilience and quickly adapt to market changes.\nOracle Fusion Cloud Customer Experience (CX):\nProvides a suite of AI-powered applications that helps organizations manage marketing, sales, and service processes to win business, build stronger customer relationships, and improve customer experiences.\nAbout Oracle\nOracle offers integrated suites of applications plus secure, autonomous infrastructure in the Oracle Cloud. For more information about Oracle (NYSE: ORCL), please visit us at\nwww.oracle.com\n.\nAbout Oracle AI World\nOracle AI World is where customers and partners discover the latest product and technology innovations, see how AI is being applied across industries, and connect with experts and peers. Attendees will gain practical tips and insights to drive immediate impact within their organizations and explore how Oracle is helping unlock the full potential of cloud and AI. Join the event to see new capabilities in action and hear from thought leaders and industry movers. Register now at\noracle.com/ai-world\nor follow the news and conversation at\noracle.com/news\nand\nlinkedin.com/company/oracle\n.\nFuture Product Disclaimer\nThe preceding is intended to outline our general product direction. It is for informational purposes only and may not be incorporated into any contract. The development, release, timing, and pricing of any features or functionality described for Oracle's products may change at Oracle Corporation’s sole discretion.\nTrademarks\nOracle, Java, MySQL, and NetSuite are registered trademarks of Oracle Corporation. NetSuite was the first cloud company—ushering in the new era of cloud computing."
  },
  {
    "title": "The Choctaw Nation of Oklahoma Unlocks the Value of Enterprise AI with Oracle Fusion Cloud Applications",
    "date": "2025-10-15",
    "link": "https://www.oracle.com/news/announcement/ai-world-choctaw-nation-unlocks-the-value-of-enterprise-ai-with-oracle-fusion-cloud-applications-2025-10-15/",
    "source": "Oracle",
    "main_ideas": [
      "The Choctaw Nation uses Oracle Fusion Cloud Applications to enhance efficiency and insights.",
      "Embedded AI capabilities automate HR and financial processes for the Choctaw Nation.",
      "Oracle's generative AI service aids in preserving the Choctaw language through translation."
    ],
    "tags": [
      "choctaw-nation",
      "oracle",
      "enterprise-ai",
      "cloud-applications",
      "hr-automation",
      "financial-management",
      "language-preservation",
      "generative-ai",
      "tribal-leadership"
    ],
    "original_text": "Skip to content\nAccessibility Policy\nClose Search\nSearch Oracle.com\nQUICK LINKS\nOracle Cloud Infrastructure\nOracle Fusion Cloud Applications\nOracle Database\nDownload Java\nCareers at Oracle\nSearch\nCountry\nView Accounts\nBack\nCloud Account\nSign in to Cloud\nSign Up for Free Cloud Tier\nOracle Account\nSign-In\nCreate an Account\nHelp\nSign Out\nContact Sales\nMenu\nMenu\nPress Release\nThe Choctaw Nation of Oklahoma Unlocks the Value of Enterprise AI with Oracle Fusion Cloud Applications\nThird largest federally recognized tribe in the US leverages embedded AI capabilities to increase efficiency, improve insights, and empower the next generation of tribal leaders\nOracle AI World, Las Vegas—Oct 15, 2025\nThe Choctaw Nation of Oklahoma\n, the third-largest Indian Nation in the US, is leveraging\nOracle Fusion Cloud Applications\nto support its mission to foster growth and prosperity for its members. With Oracle Fusion Applications, the Choctaw Nation has been able to leverage embedded AI to automate HR and financial processes, reduce costs, and enhance the employee experience. Additionally, the Choctaw Nation is using\nOracle Cloud Infrastructure (OCI) Generative AI service\nto support language translation from English to Choctaw to help preserve the language.\nThe Choctaw Nation has more than 250,000 tribal members and operates dozens of casinos, four resort hotels, dozens of restaurants, 32 medical facilities, and over 60,000 acres of ranching and agriculture. In addition, its team of over 13,000 full-time associates provides nearly 150 programs offering education, healthcare, housing, and other essential services to members. To continue its expansion and support the evolving needs of its tribal members, the Choctaw Nation needed to streamline key business processes. With Oracle Fusion Applications, the Choctaw Nation has been able to leverage embedded AI capabilities to improve efficiency, automate key HR and finance processes, and enhance the employee experience.\n“For sovereign nations, leadership means planning for future generations. Embracing AI is key to building a strong foundation that supports our values, drives economic growth, and secures our long-term success,” said Emily Crow, IT director of enterprise services, Choctaw Nation of Oklahoma. “With Oracle Fusion Applications, we’ve been able to automate key business processes, improve insights, and help grow the next generation of leaders. We’ve already adopted over 40 generative AI capabilities and look forward to leveraging more of Oracle’s AI agents and the AI Agent Studio to better support our people and improve operational efficiency as we continue to expand.”\nWith the embedded AI capabilities in\nOracle Fusion Cloud Human Capital Management (HCM)\n, the Choctaw Nation has been able to improve the employee experience, generate better workforce insights, and reduce manual HR processes. AI-powered features and solutions like the Learning and Training Advisor Agent, Oracle Grow, and Oracle Dynamic Skills support the Choctaw Nation employees by recommending skills and learning opportunities connected to their current role and future aspirations, helping them to set and achieve goals, and empowering them to execute more comprehensive and impactful performance reviews. This has resulted in significant time savings and the ability to scale career growth conversations more broadly across the Choctaw Nation.\nWith\nOracle Fusion Cloud Enterprise Resource Planning (ERP)\n, the Choctaw Nation has been able to increase productivity, reduce costs, and improve financial controls. The tribe uses the embedded AI capabilities in Oracle Cloud ERP to streamline invoice processing and plans to implement AI-powered capabilities, including predictive cash forecasting and narrative reporting, as well as Oracle's virtual credit card with J.P. Morgan Chase to maximize business-to-business invoice payments to further automate core finance functions. Also,\nOracle Fusion Cloud Supply Chain & Manufacturing (SCM)\nenables the Choctaw Nation to improve inventory management.\nIn addition to the embedded AI capabilities in Oracle Fusion Applications, the Choctaw Nation is using\nOCI Generative AI service\nto power a Choctaw language translation model. With fewer than 300 first-language speakers within its tribal community, this will play a vital role in preserving the language.\n“With broad and complex operations, it’s often challenging for tribal nations to oversee business and workforce data across multiple industries while also meeting unique regulatory requirements,\" said Steve Miranda, executive vice president of Applications Development, Oracle. “With Oracle Fusion Applications, the Choctaw Nation has been able to take advantage of advanced AI capabilities to increase productivity, streamline critical business processes, cultivate the next generation of leaders, and set the stage for a future of innovation and growth.”\nLearn more about the Choctaw Nation’s success with Oracle Fusion Applications\nhere\nand\nhere\n.\nContact Info\nKerry Coughlin\nOracle\nkerry.coughlin@oracle.com\n+1.914.450.9485\nAbout Oracle Fusion Cloud Applications\nOracle Fusion Cloud Applications provide an integrated suite of AI-powered cloud applications that enable organizations to execute faster, make smarter decisions, and lower costs. Oracle Fusion Applications include:\nOracle Fusion Cloud Enterprise Resource Planning (ERP):\nProvides a comprehensive suite of AI-powered finance and operations applications that help organizations increase productivity, reduce costs, expand insights, improve decision-making, and enhance controls.\nOracle Fusion Cloud Human Capital Management (HCM):\nProvides a unified AI-powered HR platform that connects all people-related processes and data to help organizations automate tasks throughout the employee lifecycle, improve the employee experience, and give HR leaders actionable workforce insights.\nOracle Fusion Cloud Supply Chain & Manufacturing (SCM):\nProvides a unified AI-powered platform that integrates supply chain and operations processes and helps organizations enhance resilience and quickly adapt to market changes.\nOracle Fusion Cloud Customer Experience (CX):\nProvides a suite of AI-powered applications that helps organizations manage marketing, sales, and service processes to win business, build stronger customer relationships, and improve customer experiences.\nAbout Oracle\nOracle offers integrated suites of applications plus secure, autonomous infrastructure in the Oracle Cloud. For more information about Oracle (NYSE: ORCL), please visit us at\nwww.oracle.com\n.\nAbout Oracle AI World\nOracle AI World is where customers and partners discover the latest product and technology innovations, see how AI is being applied across industries, and connect with experts and peers. Attendees will gain practical tips and insights to drive immediate impact within their organizations and explore how Oracle is helping unlock the full potential of cloud and AI. Join the event to see new capabilities in action and hear from thought leaders and industry movers. Register now at\noracle.com/ai-world\nor follow the news and conversation at\noracle.com/news\nand\nlinkedin.com/company/oracle\n.\nTrademarks\nOracle, Java, MySQL, and NetSuite are registered trademarks of Oracle Corporation. NetSuite was the first cloud company—ushering in the new era of cloud computing."
  },
  {
    "title": "Why going digital is still a challenge for factories?",
    "date": "2025-10-13",
    "link": "https://www.ericsson.com/en/blog/2025/10/whats-the-hidden-challenge-factories-face-when-going-digital",
    "source": "Ericsson_blog",
    "main_ideas": [
      "Legacy network infrastructures hinder digital transformation in manufacturing.",
      "A robust, purpose-built network is essential for leveraging advanced manufacturing technologies.",
      "Private 5G networks can enhance scalability, performance, and security for manufacturers."
    ],
    "tags": [
      "digital-transformation",
      "legacy-networks",
      "private-5g",
      "smart-manufacturing",
      "industrial-iot",
      "automation",
      "network-infrastructure",
      "ai",
      "manufacturing"
    ],
    "original_text": "Like what you’re reading?\nSubscribe now!\nWhy going digital is still a challenge for factories?\nAs manufacturers move toward smarter, more connected operations, key technologies are driving transformation:\nIndustrial IoT (IIoT): real-time visibility and connected operations\nAI and automation: smarter decisions, greater efficiency\nBut one critical enabler is often overlooked — the network infrastructure.\nWithout a robust, purpose-built network, even the smartest tools can’t deliver their full potential.\nOct 13, 2025\n|\n2 min.\nJan Diekmann\nJan Diekmann\nTechnical Account Manager – Ericsson Enterprise Wireless Solutions\nViswanath Kolur\nViswanath Kolur\nBusiness Initiator, PCN Strategy Alliances, Ericsson Enterprise Wireless Solutions\nHashtags\nHashtags\n#privatenetworks\n#smartmanufacturing\n#digitaltransformation\nOct 13, 2025\n|\n2 min.\nJan Diekmann\nJan Diekmann\nTechnical Account Manager – Ericsson Enterprise Wireless Solutions\nViswanath Kolur\nViswanath Kolur\nBusiness Initiator, PCN Strategy Alliances, Ericsson Enterprise Wireless Solutions\nJan Diekmann\nJan Diekmann\nTechnical Account Manager – Ericsson Enterprise Wireless Solutions\nContributor (+1)\nViswanath Kolur\nViswanath Kolur\nBusiness Initiator, PCN Strategy Alliances, Ericsson Enterprise Wireless Solutions\nHashtags\n#privatenetworks\n#smartmanufacturing\n#digitaltransformation\nThe hidden bottleneck: Legacy networks\nManufacturers are investing heavily in digital tools to optimize production, reduce costs, and navigate workforce challenges. According to industry reports, the manufacturing global IoT market is projected to grow from USD 116.5 billion in 2024 to over USD 674 billion by 2032\n1\n, and 95% of manufacturers are investing or planning to invest in AI and machine learning within the next five years\n2\n.\nDespite this commitment, many organizations are not seeing the expected results.\nWhy? The network.\nMany manufacturers still rely on legacy infrastructures—Wi-Fi networks, wired connections, and outdated systems—that were not designed for modern, interconnected operations. These legacy networks often become “hidden bottlenecks,” slowing data flow, limiting device connectivity, and restricting scalability.\nThis situation leads to a sobering realization: \"We’re further behind than we thought\" when it comes to preparedness for true digital scale. Without a robust, purpose-built network foundation, the full benefits of advanced manufacturing technologies cannot be realized.\nWhen organizational silos meet technical reality\nDigital transformation requires IT and operational technology (OT) teams to collaborate in ways that legacy networks and organizational structures rarely allow. Real-time control systems demand ultra-low latency, industrial environments generate interference patterns, and security requirements become more complex as production systems connect beyond traditional boundaries.\nThis misalignment often leads to a sobering realization: even with AI, robotics, and IoT in place, digital transformation goals remain elusive without the proper network foundation.\nThe impact of legacy networks\nThe limitations of legacy networks manifest in multiple ways:\nLimited scalability: Traditional networks require costly upgrades to add devices or expand coverage.\nBandwidth and performance constraints: Real-time analytics, remote diagnostics, and autonomous operations suffer delays.\nReliability and security concerns: Outdated infrastructure increases the risk of downtime and cyber threats.\nOperational inflexibility: Rigid systems hinder the rapid deployment of new technology and process improvements.\nIndustrial layouts—filled with heavy machinery, electromagnetic interference, or hygienic constraints—exacerbate these challenges, making cabling upgrades costly, complex, and disruptive.\nThe key to unlocking digital transformation success\nRead the paper\nThe case for a purpose-built network: Private 5G and beyond\nTo overcome these challenges, manufacturers need to rethink their network strategy. A modern, purpose-built network—such as private 5G—can serve as a foundational enabler of digital transformation. Here’s why:\nEnhanced scalability: Seamless expansion to connect new IoT devices, machinery, and multiple sites without extensive cabling.\nSuperior performance and reliability: High throughput, ultra-low latency, and consistent connectivity support autonomous robots, AI analytics, and safety-critical systems.\nSecurity and control: Enterprises maintain control over operational data, reducing vulnerability to cyber threats.\nOperational flexibility: Rapid deployment of new technologies, remote diagnostics, and faster recovery from disruptions.\nCost-effectiveness: Reduced cabling and infrastructure modifications lower total cost of ownership and accelerate ROI.\nRealizing the competitive advantage\nManufacturers that strategically address their network infrastructure unlock multiple benefits:\nFully leverage their digital investments\nAchieve greater operational agility\nReduce downtime and increase reliability\nScale initiatives effortlessly across multiple facilities\nAddress workforce and supply chain challenges more effectively\nFor manufacturing leaders, it’s vital to assess your current network capabilities and consider deploying purpose-built solutions like private 5G. Doing so will not only eliminate hidden bottlenecks but also unlock new levels of efficiency, flexibility, and resilience—ensuring your manufacturing operation is truly future-ready.\nBuilding a\nf\nuture-\nr\neady\nn\network\nThe most successful organizations approach network infrastructure as a strategic asset rather than a technical afterthought. By prioritizing modern, purpose-built solutions, manufacturers can:\nScale digital initiatives seamlessly as business needs evolve.\nAvoid costly network overhauls that disrupt operations.\nFuture-proof their facilities for emerging technologies like private 5G, real-time AI, and autonomous systems.\nThe choice isn’t whether to upgrade—it’s how quickly manufacturers can deploy networks capable of supporting today’s digital transformation while preparing for tomorrow’s demands.\nDon't\nlet network infrastructure derail your digital transformation. Get the complete analysis in our white paper:\nPrivate 5G: The secret behind your digital transformation success.\n1\nFortune Business Insights, \"IoT in Manufacturing Market Size, Share\" | Industry\nReport 2032\n2\nRockwell Automation, \"Ninety-Five Percent of Manufacturers Are Investing in AI to Navigate Uncertainty and Accelerate Smart Manufacturing\"\nRELATED CONTENT\nThe Ericsson Blog\nLike what you’re reading? Please sign up for email updates on your favorite topics.\nSubscribe now\nAt the Ericsson Blog, we provide insight to make complex ideas on technology, innovation and business simple."
  },
  {
    "title": "What makes neutral host 5G essential for indoor efficiency?",
    "date": "2025-10-08",
    "link": "https://www.ericsson.com/en/blog/2025/10/what-makes-neutral-host-essential-for-indoor-5g-efficiency",
    "source": "Ericsson_blog",
    "main_ideas": [
      "Indoor 5G coverage is now essential for productivity and customer experience.",
      "Legacy distributed antenna systems are inadequate for modern data demands.",
      "Neutral host small cell solutions simplify infrastructure and enhance connectivity.",
      "Enterprises benefit from reduced costs and improved operational efficiency with modern 5G solutions.",
      "Transitioning to neutral host systems enables innovation and competitive advantages."
    ],
    "tags": [
      "neutral-host",
      "indoor5g",
      "digital-transformation",
      "5g-technology",
      "enterprise-connectivity",
      "small-cell",
      "legacy-systems",
      "network-slicing",
      "ericsson"
    ],
    "original_text": "Like what you’re reading?\nSubscribe now!\nWhat makes neutral host 5G essential for indoor efficiency?\nReliable indoor 5G cellular coverage has shifted from a nice-to-have to a business-critical utility\n. Employees expect seamless connectivity, customers demand it, and safety teams rely on it. Yet many buildings still depend on outdated systems that can’t keep up.\nJust like electricity or water, indoor 5G is fundamental to productivity and customer experience. But as mobile carriers are stepping back from indoor system funding, the responsibility now lies with building owners—and yesterday’s solutions weren’t built for today’s needs.\nOct 08, 2025\n|\n2 min.\nRay Sabourin\nRay Sabourin\nGlobal Vertical Partnership Lead, Emerging Verticals\nHashtags\nHashtags\n#neutralhost\n#indoor5G\n#digitaltransformation\nOct 08, 2025\n|\n2 min.\nRay Sabourin\nRay Sabourin\nGlobal Vertical Partnership Lead, Emerging Verticals\nRay Sabourin\nRay Sabourin\nGlobal Vertical Partnership Lead, Emerging Verticals\nHashtags\n#neutralhost\n#indoor5G\n#digitaltransformation\nWhy legacy systems fall short\nFor years, enterprises used distributed antenna systems (DAS) to extend cellular service indoors. Once effective for voice and text, these systems now struggle with today’s data-heavy demands. Legacy DAS is costly, complex, and space-consuming, requiring separate equipment for each mobile operator. It drains energy, takes up valuable real estate, and can’t support modern 5G applications.\nHybrid work, video conferencing, real-time collaboration platforms, and cloud-based enterprise applications all rely on robust mobile connectivity. Even a few seconds of lag or a dropped call can translate into lost revenue, frustrated employees, or weakened customer trust.\nIn short, legacy DAS is no longer aligned with how enterprises operate. It locks organizations into expensive complexity and holds back digital transformation.\nA smarter way forward: Neutral host\n5G\ns\nmall cell\nNeutral host\n5G\ns\nmall cell\nsolutions\nfundamentally change the equation\nand represent a clean break from the\nabove challenges\n.\nRather than building separate infrastructure for each operator, neutral host systems allow multiple carrie\nrs to share a single, simplified platform—while still maintaining control of their own spectrum and services.\nInnovations like Ericsson’s Radio Dot System compress what once filled entire rooms into compact, scalable units that deliver high-speed coverage throughout every corner of a building.\nPowering performance and efficiency\nPerformance isn’t just about speed.\nIt’s about enabling new possibilities for enterprises. Small cell neutral host systems extend far beyond the capacity and coverage benefits of traditional DAS:\nNetwork slicing:\nEnterprises can dedicate network resources to specific applications, like prioritizing emergency communications or mission-critical collaboration tools.\nIndoor positioning:\nThe infrastructure supports advanced location-based services and asset tracking, helping organizations manage workflows more efficiently.\nPrivate 5G evolution:\nSmall cell infrastructure provides a natural bridge to private 5G networks. Enterprises can deploy today with confidence, knowing the same system can support advanced 5G use cases tomorrow.\nThey’re also leaner to run—requiring up to 90% less space and 1.5–5x less energy than traditional DAS, using simple Ethernet cabling instead of bulky coaxial cables.\nSimplified operations, seamless experiences\nBeyond the technology, the operational model of neutral host small cell systems creates real business value. Instead of juggling multiple vendors, contracts, and carrier relationships, building owners partner with a single provider who manages coordination end to end.\nThis consolidation reduces risk, simplifies operations, and allows enterprises to focus on delivering exceptional experiences rather than troubleshooting connectivity. Employees gain seamless mobility across buildings, customers enjoy consistent service, and critical communications remain reliable when they matter most.\nIndoor cellular coverage becomes invisible—the way all great infrastructure should be. It just works, enabling businesses to innovate, adapt, and thrive.\nFrom connectivity burden to business enabler\nThe shift from legacy DAS to modern neutral host small cell solutions is more than just a technology upgrade—it’s a mindset shift. Forward-thinking enterprises are no longer asking, \"How do we patch what’s broken?\" Instead, they’re asking, \"How do we build connectivity that drives our business forward for the next decade?\"\nThose that take the leap gain more than coverage. They unlock flexibility, lower costs, and a platform for future innovation. Indoor cellular infrastructure moves from being a burden to being a business enabler—fueling productivity, safety, and competitive advantage.\nThe future of e\nnterprise indoor connectivity\nMoving from legacy DAS to neutral host small cell systems isn’t just an upgrade—it’s a strategic leap forward. Forward-thinking enterprises are transforming connectivity into a business enabler that drives innovation, flexibility, and growth.\nReady to explore how modern indoor\n5G\nsolutions can transform your enterprise connectivity?\nLearn more about host networks and small cell solutions that help enterprises worldwide move from connectivity neutral challenges to competitive advantages.\nRead the Ericsson/Fierce Wireless report\nRELATED CONTENT\nThe Ericsson Blog\nLike what you’re reading? Please sign up for email updates on your favorite topics.\nSubscribe now\nAt the Ericsson Blog, we provide insight to make complex ideas on technology, innovation and business simple."
  },
  {
    "title": "How to bring private 5G to life in mining: A five-step path to safer, smarter operations",
    "date": "2025-10-06",
    "link": "https://www.ericsson.com/en/blog/2025/10/how-to-operationalize-private-5g-in-mining--a-pathway-to-safer-smarter-sites",
    "source": "Ericsson_blog",
    "main_ideas": [
      "Private 5G technology is essential for safer and smarter mining operations.",
      "Mining companies must collaborate with various partners for successful 5G deployment.",
      "A structured pilot program is crucial to demonstrate the value of private 5G.",
      "Change management and clear communication are vital for adopting new technologies in mining."
    ],
    "tags": [
      "mining",
      "privatenetworks",
      "digitaltransformation",
      "5g",
      "automation",
      "safety",
      "connectivity",
      "ericsson",
      "industry-4-0",
      "sustainability"
    ],
    "original_text": "Like what you’re reading?\nSubscribe now!\nHow to bring private 5G to life in mining: A five-step path to safer, smarter operations\nThe mining industry is at a crossroads. Global demand for critical minerals, like lithium, copper, nickel, and rare earth elements, is set to nearly triple by 2030 and quadruple by 2040. Meeting this demand isn’t just about extracting more—it’s about mining smarter, safer, and more sustainably.\nPrivate 5G is emerging as a foundational technology to achieve this transformation. It delivers the industrial-grade connectivity required to power automation, real-time analytics, remote operations, and advanced safety systems. But for mine operators, two practical questions remain:\nHow do you begin a private 5G trial?\nOnce proven, how do you scale it across your site?\nOct 06, 2025\n|\n2 min.\nKirstin Sym-Smith\nKirstin Sym-Smith\nGlobal Vertical Partner Lead, Mining, Ericsson Enterprise Wireless Solutions\nBrajesh Sinha\nBrajesh Sinha\nConsulting Manager\nHemanth Kumar\nHemanth Kumar\nSenior Business Consultant\nHashtags\nHashtags\n#mining\n#privatenetworks\n#digitaltransformation\nOct 06, 2025\n|\n2 min.\nKirstin Sym-Smith\nKirstin Sym-Smith\nGlobal Vertical Partner Lead, Mining, Ericsson Enterprise Wireless Solutions\nBrajesh Sinha\nBrajesh Sinha\nConsulting Manager\nHemanth Kumar\nHemanth Kumar\nSenior Business Consultant\nKirstin Sym-Smith\nKirstin Sym-Smith\nGlobal Vertical Partner Lead, Mining, Ericsson Enterprise Wireless Solutions\nContributor (+2)\nBrajesh Sinha\nBrajesh Sinha\nConsulting Manager\nHemanth Kumar\nHemanth Kumar\nSenior Business Consultant\nHashtags\n#mining\n#privatenetworks\n#digitaltransformation\nWhy connectivity is mining’s critical enabler\nMining operations face mounting pressure to reduce costs, improve ESG performance, protect workers, and guard against cyber and physical threats. In environments where downtime can cost millions, connectivity isn’t optional—it’s mission-critical.\nLegacy networks such as Wi-Fi or leaky feeders can’t keep pace with the demands of smart mining. Private 5G changes that equation. It brings:\nRobust, wide-area coverage (surface and underground)\nUltra-low latency and reliability for open-pit connectivity for fleets, drones, and worker systems.\nSeamless mobility for autonomous fleets and connected workers in harsh environments of dust, vibration, and extreme temperatures.\nStrong security for mission-critical data\nIt’s not just about connectivity today—it’s about building the digital foundation for tomorrow.\nOur latest white paper\naddresses how to begin a private 5G trial and how to scale it across the site in five distinct steps, offering a clear roadmap for mining companies ready to embrace the next generation of connectivity.\nFive steps for a successful private 5G deployment\nStart with ecosystem collaboration\nPrivate 5G deployment isn’t a one-company effort. It requires alignment across:\nConnectivity providers (Ericsson for the core network technology)\nEquipment manufacturers (Caterpillar, Komatsu, Epiroc, Sandvik)\nSystem integrators (Becker, Ambra, and others who tailor integration)\nSpectrum access is also critical. Countries like the U.S., Germany, Australia, Chile, and Brazil have already allocated industrial spectrum, setting the stage for reliable deployments.\nPilot with purpose\nMining pilots are less about proving that 5G works—and more about proving its value. A typical pilot follows four stages:\nUse case selection – Focus on high-impact scenarios (autonomous trucks, real-time video, safety systems).\nEcosystem coordination – Engage partners to design fit-for-purpose solutions.\nDry testing – Validate off-site before deployment.\nEvaluation – Measure against operational and business KPIs.\nScale intelligently\nAfter a successful pilot, scaling can take different forms:\nFull-site deployment for rapid transformation.\nPhased rollout, often one production face at a time, aligned to milestones.\nPlanning with scalability in mind ensures new use cases can be added quickly as they emerge.\nManage change and adoption\nSuccessful deployment isn’t just technical—it’s cultural. Clear communication from leadership that private 5G enhances safety, job quality, and innovation (not workforce reduction) is essential. Collaboration between IT, operations, and network teams smooths the transition.\nMaintain for the long haul\nOnce live, networks require monitoring, updates, and cybersecurity vigilance. Many mines adopt a hybrid model—keeping critical data on-site while enabling secure remote access for diagnostics and support.\nBuilding a roadmap for mining’s future\nAs mining moves rapidly toward autonomy and intelligence, private 5G is emerging as a foundation for the industry’s future. The question is no longer if it will be adopted, but when.\nOperators who act now are already realizing the benefits—greater safety, less downtime, and higher productivity. The journey to smarter, safer, and more sustainable mining starts with one decision: to connect with the power of private 5G.\nReady to get started?\nRead the full paper\nfor a practical guide to operationalize mining in both greenfield and brownfield sites.\nRELATED CONTENT\nThe Ericsson Blog\nLike what you’re reading? Please sign up for email updates on your favorite topics.\nSubscribe now\nAt the Ericsson Blog, we provide insight to make complex ideas on technology, innovation and business simple."
  },
  {
    "title": "AIOps Network Operator Survey: From Ambition to Action",
    "date": "17 Oct 2025",
    "link": "https://www.amdocs.com/insights/whitepaper/aiops-network-operator-survey-from-ambition-to-action",
    "source": "Amdocs",
    "main_ideas": [],
    "tags": [],
    "original_text": "Request unsuccessful. Incapsula incident ID: 895000390129135768-391440055240952270"
  },
  {
    "title": "Cognitive bank/telco partnerships: How GenAI and AI supercharge success",
    "date": "17 Nov 2025",
    "link": "https://www.amdocs.com/insights/article/cognitive-banktelco-partnerships-how-genai-and-ai-supercharge-success",
    "source": "Amdocs",
    "main_ideas": [],
    "tags": [],
    "original_text": "Request unsuccessful. Incapsula incident ID: 895000390129135768-321359542023555527"
  },
  {
    "title": "Singapore FinTech Festival 2025 - Day 3: Autonomous Quality and AI-Driven Developer Velocity",
    "date": "15 Oct 2025",
    "link": "https://www.amdocs.com/insights/event/meet-amdocs-studios-singapore-fintech-festival-2025-day-3",
    "source": "Amdocs",
    "main_ideas": [
      "The Singapore FinTech Festival 2025 focuses on advancements in autonomous quality.",
      "AI-driven developer velocity is a key theme discussed at the festival.",
      "Innovations in fintech are showcased through various presentations and discussions."
    ],
    "tags": [
      "fintech",
      "autonomous-quality",
      "ai-driven",
      "developer-velocity",
      "innovation",
      "technology",
      "singapore-festival"
    ],
    "original_text": "Request unsuccessful. Incapsula incident ID: 895000390129135768-295643597137447366"
  },
  {
    "title": "Webinar: Powering Fiber Deployments with Automation",
    "date": "14 Nov 2025",
    "link": "https://www.amdocs.com/insights/video/powering-fiber-deployments-with-automation",
    "source": "Amdocs",
    "main_ideas": [
      "The webinar focuses on automating fiber deployment processes.",
      "Participants will learn about the benefits of automation in telecommunications.",
      "Expert speakers will share insights on current trends in fiber technology."
    ],
    "tags": [
      "fiber-optics",
      "automation",
      "telecommunications",
      "webinar",
      "technology",
      "networking",
      "deployment",
      "industry-trends"
    ],
    "original_text": "Request unsuccessful. Incapsula incident ID: 895000390129135768-249484600059824588"
  },
  {
    "title": "Accelerating the path to fiber networks",
    "date": "12 Nov 2025",
    "link": "https://www.amdocs.com/insights/whitepaper/accelerating-path-fiber-networks",
    "source": "Amdocs",
    "main_ideas": [],
    "tags": [],
    "original_text": "Request unsuccessful. Incapsula incident ID: 895000390129135768-249485072506227148"
  },
  {
    "title": "The Platform Powering TFB’s Enterprise Shift",
    "date": "05 Nov 2025",
    "link": "https://www.amdocs.com/insights/case-study/platform-powering-tfbs-enterprise-shift",
    "source": "Amdocs",
    "main_ideas": [],
    "tags": [],
    "original_text": "Request unsuccessful. Incapsula incident ID: 895000390129135768-321367376043903431"
  },
  {
    "title": "Modernizing Production Workflows at DreamWorks Animation",
    "date": "03 Nov 2025",
    "link": "https://www.amdocs.com/insights/case-study/modernizing-production-workflows-dreamworks-animation",
    "source": "Amdocs",
    "main_ideas": [],
    "tags": [],
    "original_text": "Request unsuccessful. Incapsula incident ID: 895000390129135768-295653973778434502"
  },
  {
    "title": "A new era of financial service: The convergence of banking and telecom",
    "date": "03 Nov 2025",
    "link": "https://www.amdocs.com/insights/article/new-era-financial-service-convergence-banking-and-telecom",
    "source": "Amdocs",
    "main_ideas": [
      "The integration of banking and telecom is reshaping financial services.",
      "Telecommunications companies are entering the banking sector to offer new financial products.",
      "This convergence enhances customer experience through seamless digital transactions.",
      "Regulatory challenges may arise as industries merge and innovate.",
      "Consumer demand for convenience drives the growth of fintech solutions."
    ],
    "tags": [
      "banking",
      "telecom",
      "fintech",
      "digital-transactions",
      "financial-services",
      "innovation",
      "regulation",
      "customer-experience"
    ],
    "original_text": "Request unsuccessful. Incapsula incident ID: 895000390129135768-391470626818165198"
  },
  {
    "title": "Together, We’re Defining the Next Era of Partner Success",
    "link": "https://blogs.cisco.com/partner/together-were-defining-the-next-era-of-partner-success",
    "description": "Discover how the Cisco 360 Partner Program is redefining partnership—driving growth, profitability, and innovation with partners at the center. Explore the latest updates, new incentives, and what’s next for 2026.",
    "source": "Cisco_blog",
    "main_ideas": [
      "The Cisco 360 Partner Program aims to redefine partnership for growth and innovation.",
      "New commitments focus on profitability, predictability, and growth for partners.",
      "AI-driven support and new specializations enhance partner capabilities in the evolving market."
    ],
    "tags": [
      "cisco",
      "partner-program",
      "profitability",
      "artificial-intelligence",
      "innovation",
      "ecosystem",
      "collaboration",
      "marketing",
      "growth"
    ],
    "original_text": "Partner\nTogether, We’re Defining the Next Era of Partner Success\n4 min read\nElisabeth De Dobbeleer\nOne year after announcing the Cisco 360 Partner Program, it’s incredible to see how far we’ve come.\nWhat began as a bold vision to redefine how Cisco partners engage, grow, and win together has become a reality — shaped by your trust, your feedback, and your commitment to helping customers succeed.\nThat collective energy was on full display at Cisco Partner Summit 2025, which exceeded every expectation. The energy was electric, the conversations were meaningful, and the sense of shared purpose was undeniable.\nBefore we look ahead, I want to pause and say thank you.\nOur ecosystem — resellers, distributors, service providers, advisors, developers, and consultants — represents the full strength of Cisco partnership. Every one of you plays a part in delivering customer outcomes and creating value that lasts.\nRedefining What Partnership Means\nWhen we set out to build this program, we didn’t just want to modernize incentives or rename tiers. We wanted to redefine what engagement means.\nIt’s no longer about transactions — it’s about building businesses, evolving practices, and delivering meaningful outcomes.\nAnd what makes this journey truly unique is that we’ve done it together.\nFrom Partner Executive Exchanges to advisory boards, surveys, and more than 1,000 partner 1-to-1 meetings — your input has guided every decision. Every discussion, every piece of feedback helped make this program stronger, simpler, and more aligned to how you do business in a fast-moving, AI-driven market.\nOur Next Chapter: Profitability, Predictability, and Growth\nAt last year’s summit, we made three promises: time, protection, and partnership — and we’ve delivered on each one.\nTime:\n15 months. 12 months in with 3 more to go.\nProtection:\nWe promised to protect your investments, and we did.\nPartnership:\nThe co-design has been unprecedented!\nThis year, we’re building on that foundation with three new commitments:\nProfitability you can plan for. Predictability you can trust. Growth you can count on.\nProfitability remains our shared priority — and it’s stronger than ever.\nWith VIP 46, we’ve delivered the richest product rebate cycle in the program’s history across Campus Refresh, AI, Security, and Collaboration. And this momentum doesn’t stop here. The same profitability logic continues in the Cisco Partner Incentive, launching January 2026, where 87% of VIP 46 SKUs will earn the same or more under the new model.\nThis next chapter brings VIP, CSPP, and Lifecycle together into one simple, predictable framework that rewards growth across the full customer lifecycle — Land, Adopt, Expand, and Renew — ensuring partners can plan confidently and profit even more as the AI era accelerates. You can explore your potential using the\nCisco Partner Incentive Estimator\n.\nWe’re also unlocking new profitability through Premium Services in collaboration with Cisco CX — giving partners new ways to deliver proactive, predictive, and personalized AI-driven support that strengthens customer relationships and expands recurring revenue.\nIf profitability is what you earn, predictability is how you plan.\nYour Partner Value Indexes are now live and tracking, and everything you’ve achieved since August counts through July 2027 — giving you full visibility into how your actions today shape your rewards tomorrow. You can track progress and insights in the enhanced\nPartner Experience Platform (PXP)\n.\nPredictability also means having a complete view across Cisco’s expanding portfolio. That’s why we’re integrating Splunk into the Cisco 360 Partner Program, creating a unified experience that connects observability, security, and AI-powered infrastructure under one model.\nAnd then there’s growth — the natural outcome of confidence and capability.\nThe Cisco 360 Partner Program rewards partners who invest in enablement and innovation. It also helps you differentiate in the market with new designations, highlighting your expertise and customer impact.\nWe’re backing that differentiation with significant marketing investments — new branding toolkits, campaign assets, and demand-generation programs designed to help you stand out, reach new customers, and grow faster.\nBuilt on Trust. Ready for the AI Era.\nAI is transforming everything, and agility is what sets great ecosystems apart. That’s why I’m so proud of our new next generation of Specializations — Secure Networking and Secure AI Infrastructure — which recognize partners who are leading with innovation and delivering measurable outcomes in the AI era.\nWe also introduced new bonus opportunities, coming later in the year, within the Cisco Partner Incentive — rewarding both Next Gen Specializations and Cross-Sell expansion — because your growth is our growth.\nTo explore all Partner Summit announcements,\nclick here\n.\nWhat Comes Next\nThe Cisco 360 Partner Program has always been about one thing — creating a complete, agile ecosystem where all partners, from resellers to MSPs — distributors to developers, play a vital role in driving innovation and delivering outcomes that matter.\nAnd as we count down to launch, there’s even more to look forward to.\nWe’re expanding the program with new Partner Value Indexes that recognize every facet of Cisco’s partner community. Soon, we’ll introduce a Mass-Scale Infrastructure Value Index, giving partners the scale and architectural alignment to lead in AI-ready outcomes.\nWe’re also adding Value Indexes for Distributors, Advisors, and Developers — highlighting the unique contributions of every partner type and reinforcing that every role in this ecosystem counts.\nHere are three simple ways to keep your momentum going:\nUse the\nCisco Partner Incentive Estimator\nto explore your earnings potential and connect with your Partner Account Executive to explore ways to increase your profitability.\nLog into\nPXP\nto track your progress, boost your Value Index, and access marketing and enablement tools.\nTake advantage of new marketing and branding resources to showcase your expertise and grow faster.\nCisco 360 Marketing Launchpad\nPartner Branding\nThe Cisco 360 Partner Program carries your signature. It reflects your feedback, your collaboration, and our shared belief that when we move together as one agile partner ecosystem — power meets purpose.\nThank you for helping us build something extraordinary.\nWith just three months to go before the Cisco 360 Partner Program officially launches, the momentum is undeniable. Every insight, every collaboration, every shared win has brought us to this moment — and the best is still ahead.\nWe’d love to hear what you think. Ask a Question, Comment Below, and Stay Connected with #CiscoPartners on social!\nCisco Partners Facebook\n|\n@CiscoPartners X\n|\nCisco Partners LinkedIn\nAuthors\nElisabeth De Dobbeleer\nSenior Vice President, Cisco Partner Program"
  },
  {
    "title": "Forrester Total Economic Impact™ Study Identifies the Strategic Value of Cisco Intersight",
    "link": "https://blogs.cisco.com/datacenter/forrester-total-economic-impact-study-identifies-the-strategic-value-of-cisco-intersight",
    "description": "Cisco Intersight transforms IT operations from a complex challenge into a strategic advantage, simplifying the deployment and management of server fleets across data centers and distributed edge environments. An independent 2025 Forrester TEI study quantifies this value, revealing a 192% ROI over three years and significant financial benefits through improved uptime, increased productivity, and faster time to value.",
    "source": "Cisco_blog",
    "main_ideas": [
      "Cisco Intersight offers a 192% ROI over three years for organizations managing server fleets.",
      "The Forrester TEI study highlights significant benefits in uptime, productivity, and compliance.",
      "Intersight simplifies IT operations, reducing deployment times and enhancing security measures."
    ],
    "tags": [
      "cisco",
      "intersight",
      "forrester-tei",
      "it-operations",
      "cloud-computing",
      "data-centers",
      "automation",
      "security",
      "roi"
    ],
    "original_text": "Data Center\nForrester Total Economic Impact™ Study Identifies the Strategic Value of Cisco Intersight\n3 min read\nGautham Ravi\nI often get asked what the “strategic” value of Cisco Intersight is to our customers besides, of course, the simplicity and ease of use it offers. I agree, when you’re managing complex, distributed environments while facing pressure to optimize costs and enhance security, having quantifiable data about potential returns becomes essential for decision making. We strongly felt that rather than running the math ourselves, we would commission Forrester Consulting to interview our customers directly and conduct a comprehensive Total Economic Impact™ (TEI) study.\nDrawing from interviews with seven decision makers at six organizations across various industries, the study found that a composite enterprise based on interviewed customers achieved a 192% ROI with a net present value of $3.3 million over three years.\n1\nThese numbers represent real outcomes from organizations managing between 100 and 10,000 servers.\nKey findings from the 2025 Forrester TEI study\nThe research identified four primary areas where Cisco Intersight delivered quantifiable business benefits:\nImproved uptime and resilience ($2.7M benefit):\nOrganizations experienced a 50% reduction in mean time to resolution (MTTR) through proactive fault detection and centralized visibility. One healthcare organization’s IT team reported waking up to find replacement parts already being delivered before they even knew a problem existed.\nIncreased IT productivity ($1.7M benefit):\nTeams achieved an 80% reduction in infrastructure build and deployment times while avoiding the need to double their infrastructure staff size. One interviewed customer, a financial services company, maintained flat headcount while growing from $20 billion to $75 billion in revenue.\nReduced time to value ($289K benefit):\nUsing Intersight, infrastructure deployment accelerated dramatically, with an interviewed healthcare organization completing 27 domains across multiple data centers in just three hours. This speed enabled faster project execution and earlier returns on infrastructure investments.\nReduced security and compliance risk ($267K benefit):\nIntersight helped reduce both the frequency and length of security breaches through proactive monitoring, automated compliance, and centralized visibility.\nA deeper look at market realities\nThe study occurs against a backdrop of significant infrastructure challenges. With new AI workloads requiring specialized compute capabilities, multicloud strategies creating management complexity, and security threats escalating across distributed environments, traditional management approaches struggle to keep pace.\nInfrastructure teams face mounting pressure to deliver more with existing resources. The research shows organizations before Intersight deployment struggled with:\nScaling limitations:\nManual processes created bottlenecks when rapid infrastructure expansion was needed.\nVisibility gaps:\nManaging five to six different interfaces made comprehensive oversight nearly impossible.\nResource inefficiency:\nValuable IT staff time was consumed by repetitive manual tasks instead of focused on strategic initiatives.\nThese challenges particularly impact compliance and security posture. As one healthcare organization noted, trying to track contracts, warranties, and security advisories across an expanding hardware base became increasingly problematic without centralized visibility.\nFive critical areas of business impact\nEnhanced operational resilience\nThe study found organizations cut downtime frequency and duration by over 70%. A senior infrastructure engineer in the travel and hospitality industry emphasized the value of single-pane-of-glass visibility: “The idea that we have a single pane of glass and I can manage our global fleet of hardware this easily was a huge selling point.”\nWorkforce optimization and satisfaction\nEvery organization interviewed estimated they would have needed to double their team size without Intersight. A financial services manager noted: “Every hour that I have my [team] work on something that could be automated or made easier through Intersight is an hour I get back that they can be doing the transformational work I need them to do.”\nAccelerated deployment capabilities\nTeams reported reducing domain deployment from over an hour to just 10 minutes. This speed enables prestaging infrastructure before hardware arrival and supports rapid response to business needs.\nStrengthened security and compliance\nIntersight reduced the risk of security breaches and lowered remediation costs through proactive monitoring, automated compliance, and centralized visibility. Its role in standardizing configurations and reducing manual errors also led to improved compliance with corporate policies and industry regulations, as automation allowed teams to meet audit requirements with confidence.\nCost-effective hardware management and future readiness\nOrganizations reported more cost-effective management of hardware investments. Intersight’s policy-driven automation and visibility allowed teams to optimize workloads, avoid over-provisioning, and make smarter decisions about hardware needs according to actual usage patterns. Furthermore, Intersight provides the flexibility to meet future demands, with interviewees noting its role in facilitating AI infrastructure expansion and edge computing requirements.\nInfrastructure complexity is only growing\nThe research makes clear that infrastructure management will become more challenging, not less. AI workloads, edge computing expansion, and increasingly sophisticated security requirements demand management platforms capable of handling complexity at scale.\nOrganizations that establish robust infrastructure management capabilities now position themselves advantageously for future challenges. The alternative, attempting to manage growing complexity with legacy tools, creates operational risk and limits strategic agility.\nCisco Intersight helps your team not just keep up with these evolving demands but get ahead by simplifying operations while providing the visibility and automation needed for modern infrastructure management.\nReady to explore the complete analysis?\nRead the full Forrester TEI study on Cisco Intersight\nfor a detailed methodology, comprehensive findings, and frameworks to evaluate the potential impact for your organization.\n1\nThe Total Economic Impact™️ of Cisco Intersight: Cost Savings and Business Benefits Enabled by Intersight\n, Forrester, November 2025\nGet the Forrester TEI\nstudy\non\nCisco\nIntersight\nAuthors\nGautham Ravi\nDirector, Product Managment\nCisco Cloud and Compute Group"
  },
  {
    "title": "Revolutionizing Network Troubleshooting with Deep Research AI Agents",
    "link": "https://blogs.cisco.com/sp/revolutionizing-network-troubleshooting-with-deep-research-ai-agents",
    "description": "The first blog in this three-part series explores how deep research can be applied to network operations using a Deep Network Troubleshooting Agentic AI solution. It introduces a multi-agent approach that accelerates root cause analysis, enhances reliability and empowers engineers—especially those in complex, multivendor environments—by automating and augmenting troubleshooting processes while ensuring human oversight.",
    "source": "Cisco_blog",
    "main_ideas": [
      "Deep Network Troubleshooting uses agentic AI to enhance network diagnostics and troubleshooting.",
      "A multi-agent approach automates root cause analysis while ensuring human oversight.",
      "AI agents improve efficiency and consistency in troubleshooting across multivendor environments."
    ],
    "tags": [
      "network-troubleshooting",
      "agentic-ai",
      "root-cause-analysis",
      "multivendor",
      "automation",
      "deep-research",
      "cisco",
      "network-operations",
      "artificial-intelligence"
    ],
    "original_text": "SP360: Service Provider\nRevolutionizing Network Troubleshooting with Deep Research AI Agents\n5 min read\nJavier Antich\nTroubleshooting networks is hard. Fragmented tools, institutional knowledge, and escalating complexity make it a time-consuming, high-stakes challenge. But what if we could rethink the process entirely—using AI agents that reason, verify, and collaborate like a team of expert engineers?\nThis post kicks off a three-part series on Deep Network Troubleshooting, a new approach that applies agentic AI and deep research principles to network diagnostics. In today’s post, we introduce the concept and architecture. Next, we’ll explore how we ensure reliability and minimize hallucinations. The final post in the series will focus on transparency and observability—critical for building trust in AI-driven operations.\nLet’s begin with the big idea: what happens when deep research meets deep troubleshooting?\nHow agentic AI is transforming network troubleshooting\nAgentic AI is already reshaping how work gets done across industries—and network automation and operations are no exception. Among all the places it can help, troubleshooting and diagnostics stand out: they are high-value, time-sensitive, and notoriously fragmented across tools, teams, and institutional knowledge.\nIn this post, I’d like to introduce Deep Network Troubleshooting—an agentic AI solution inspired by the deep research agents popularized by OpenAI, Anthropic, and others, and purpose-built for multivendor network diagnostics. It blends large language model (LLM)-powered autonomy with knowledge-graph reasoning, domain-specific tools, and error-mitigation techniques to accelerate root cause analysis (RCA) while keeping humans in control.\nWhat is deep research AI and why it matters for networking\nFor the past few months, several leading AI labs and AI frameworks have introduced deep research agentic solutions. While there is no single definition of what deep research is, we could define it as a disciplined, multistep approach to solving complex questions: plan the investigation, search broadly, verify facts, and refine until the evidence aligns. Think of it like a team of AI agents working together—gathering, validating, and synthesizing information—to deliver fast, trustworthy answers.\nFigure 1: Deep research option on popular AI platform\nIf you haven’t explored deep research features from platforms like OpenAI, they’re worth checking out.\nThese features demonstrate multiple agents collaborating, iterating, and refining their understanding until they reach a well-supported answer.\nIt’s a powerful approach to solving complex problems. And when you see it in action, it naturally raises the question: why not apply this same methodology to network troubleshooting?\nWhy troubleshooting suits agentic AI\nTroubleshooting is, at its core, a structured research task:\nYou start with symptoms (alerts, SLO breaches, user tickets).\nForm hypotheses and collect evidence (telemetry, logs, configs, topology).\nIterate: test → refute → refine—until you land on a root cause and a safe fix.\nThat loop maps perfectly to multi-agent systems that plan, gather, validate, and summarize—fast and repeatedly—without getting tired or distracted.\nCan LLM-powered agents really diagnose network issues?\nLLM-powered agents invite fair skepticism: hallucinations, shallow reasoning, weak reliability. The key is to constrain and augment them:\nTool-centric design\n: Agents never “guess” device state; they fetch it through authenticated tools (CLI/NETCONF/REST, NMS/APIs, log search, packet captures).\nGrounding in a knowledge graph\n: The network’s entities and relationships (devices, interfaces, Virtual Routing and Forwarding, Border Gateway Protocol sessions, services) provide context and constraints, guiding reasoning and reducing false leads.\nVerification loops\n: Agents cross-check claims against telemetry and rules; suspect conclusions must be re-proven from independent signals.\nDeterministic guardrails\n: Policies, playbooks, and safety checks minimize risks with changes unless a human approves.\nMemory and provenance\n: Every step is logged with evidence and lineage so engineers can audit, reproduce, or challenge a conclusion.\nWhen you put the philosophy debates aside and implement the technology using a careful approach, the results are compelling.\nAdapting deep research AI for network operations\nDeep research agents excel by orchestrating multiple specialists that:\nPlan a line of inquiry\nGather and synthesize evidence\nIterate until confidence is achieved\nDeep Network Troubleshooting adapts this pattern to networks.\nMeet the agents: Roles in AI-powered network diagnostics\nTo keep things running smoothly and quickly, modern networks can lean on a mix of smart AI agents—each one handling a specific part of troubleshooting or fixing issues.\nThese are some of the key agents that power this new approach:\nDeep Troubleshooting agent:\nInterprets problem and identifies hypothesis.\nHypothesis tester:\nEvaluates validity of hypothesis.\nQuery agents:\nReason about a request and draft a plan on how to address it, breaking it down into smaller steps which are then executed autonomously.\nRCA synthesizer:\nAssembles a clear root cause with evidence, side effects, and confidence.\nRemediation draftsman:\nProposes safe actions and rollback plans; routes to approval.\nEach agent is LLM-powered\n,\nknowledge graph-driven, and runs with embedded safety and reliability mechanisms.\nCore architecture pillars of Deep Network Troubleshooting\nLet’s take a closer look at the key building blocks that make Deep Network Troubleshooting both intelligent and safe. These range from knowledge graphs and LLMs to the tools, safeguards, and human oversight that keep everything grounded.\n•\nKnowledge graph\n: A continuously updated KG models devices, links, protocols, services, policies, and their temporal changes. It provides:\nPath and blast-radius reasoning (who’s affected and why)\nPolicy constraints (what “good” looks like)\nEntity disambiguation (for example, eth1/1 versus Gi0/1) and multivendor normalization.\n•\nLarge language models\n:\nLLMs\nare the brains of\nan\nagent\nand\ndetermine\nthe agent’\ns\nability to reason, plan\n,\nand interact with the knowledge graph and tools, to\naccomplish\nthe\ngoals.\n•\nDomain tools and adapters\n:\nDeep Network Troubleshooting relies on a wide range of domain tools and adapters—like connectors for CLI, NETCONF, RESTCONF, streaming telemetry, SNMP, syslog, NMS/ITSM, CMDB, packet brokers, and cloud APIs—to ensure agents only act on facts they can verify directly through trusted sources.\n•\nError-mitigation techniques\n:\nMultiple techniques are used in parallel to minimize the probability of an error.\n(Stay tuned for more\ndetail\ns\non this\nin\nthe\nnext installment of this\nseries.)\n•\nHuman-in-the-loop safety\n:\nAgents are\nr\nead\n-only by default\n; proposed changes are structured as remediation drafts with diffs, impact analysis, and rollback.\nHow AI agents improve network operations and MTTR\nThis is disruptive, transformational—perhaps even scary. But it augments network operations teams beyond what any other technology has enabled so far.\nNetworks are heterogeneous, multivendor, dynamic, and—whether we like it or not—a significant portion of the data necessary to troubleshoot problems is unstructured.\nIn a setup like this, AI agents can really step up and help network engineers do more—faster, smarter, and with less manual grind.\nWhen something breaks, you might wish you had ten engineers to chase down the root cause. And sure, maybe you do, if you’re at a massive organization. But with AI agents, you don’t need ten people; you can spin up ten agents, or even a hundred, all working in parallel under the guidance of a single engineer. That’s the beauty of software—it lets us rethink how we approach problems, like evaluating dozens of hypotheses at once to zero in on where the issue really started.\nThe consequences of this are tangible:\nFaster MTTR:\nAgents compress the search space and automate the grind.\nBetter signal-to-noise:\nFindings are anchored in verifiable evidence and graph context.\nEngineer leverage:\nFocus humans on novel, high-judgment cases; delegate the routine tasks.\nFleet-wide consistency:\nUse the same methodical investigation, every time, across vendors.\nThe vision at Cisco for AI-driven network troubleshooting\nDeep Network Troubleshooting exemplifies our investment in practical, safe agentic AI for real networks. It’s designed for multivendor environments and built to meet network teams where they are: existing tooling, established change control, and clear audit needs. It represents industry-leading innovation in network diagnostics and, to our knowledge, the industry’s first agentic solution with this breadth of applicability in multivendor settings, and it’s coming as part of our\nCrosswork Network Automation\nsolution.\nConnect with Cisco to explore AI-powered network diagnostics\nIf you’re exploring how to delegate more diagnostics to software—safely and credibly—we’d love to connect. Deep Network Troubleshooting helps teams move faster, reduce toil, and make every incident a little less…incident-y.\nWant to dive deeper? Let’s connect, have some fun exploring this technology, and make amazing things happen together.\nPlease join us.\nJoin the conversation\nat the Community.\nAdditional resources\nAutonomous Networks for Service Providers white paper\nCisco Crosswork Network Automation\nAuthors\nJavier Antich\nPrincipal Product Management Engineer\nCTO Office - Provider Connectivity Group"
  },
  {
    "title": "Connected, Protected, Ready: Securing Partner Growth in the AI Era",
    "link": "https://blogs.cisco.com/partner/connected-protected-ready-securing-partner-growth-in-the-ai-era",
    "description": "Cisco Partner Summit emphasized the crucial role of partners in securing the AI era. With 86% of businesses facing AI-related security incidents, Cisco is enabling partners to build AI-ready infrastructures and help customers confidently adopt new capabilities through innovations like Multi-customer management in Cisco Security Cloud Control and enhancements to the Cisco 360 Partner Program.",
    "source": "Cisco_blog",
    "main_ideas": [
      "Cisco emphasizes the importance of partners in securing the AI era.",
      "86% of businesses faced AI-related security incidents in the past year.",
      "Cisco is enabling partners to build AI-ready infrastructures for customers."
    ],
    "tags": [
      "cisco",
      "ai",
      "security",
      "partners",
      "cloud-computing",
      "managed-service-providers",
      "cybersecurity",
      "infrastructure",
      "innovation"
    ],
    "original_text": "Partner\nConnected, Protected, Ready: Securing Partner Growth in the AI Era\n1 min read\nBrian Feeney\nThere’s nothing quite like the energy of Cisco Partner Summit week! Looking back on our time in San Diego, I’m reminded that partnership at Cisco isn’t just a strategy, it’s our speciality. Every innovation, milestone, and customer success story is powered by the strength and resilience of our partner ecosystem. Together, we truly secure what’s next.\nThe highlight for me this year was seeing how our collective efforts are redefining what ‘secure’ means in the AI era. According to the Cisco AI Readiness Index 2025, just 14% of organizations feel fully prepared to realize the value of AI. At the same time, the 2025 Cisco Cybersecurity Readiness Index reveals that 86% of business leaders experienced at least one AI-related security incident in the past year. It’s clear: we can no longer simply react to threats, we must anticipate them, and the partner community makes all this possible.\nOur announcements and innovation shared last week and this week at Cisco Live Melbourne are more than just technology. We’re enabling our partners to build AI-ready infrastructures and help customers confidently adopt new capabilities while staying secure. A few examples:\nMulti-customer management in Cisco Security Cloud Control\n, designed specifically for Managed Service Providers (MSPs) to scale operations efficiently, reduce friction, and accelerate time-to-value.\nA new wave of opportunity to help partners and customers\nmodernize campus, branch, and industrial networks\nfor the AI era with security built in. Cisco Access Manager\nfuses identity into the network\n, delivering full identity-based access control natively through the Meraki Dashboard.\nNew elements in the\nCisco 360 Partner Program\nto empower partners to drive profitability with AI\nand security\n, including\nthe\nnew\nSpecializations and\nCisco Partner Incentive bonuses,\nannounced at Partner Summit.\nAs we look ahead, I’m inspired by the opportunities we’re creating together. We’ll keep investing in your profitability, incentivizing on hunting and expanding behaviors, and supporting you with the right security expertise to turn our shared vision into real impact. The future of security isn’t something we build alone, it’s something we create, and secure, together.\nRead more about our recent announcements on the\nCisco Newsroom\nWe’d love to hear what you think. Ask a Question, Comment Below, and Stay Connected with #CiscoPartners on social!\nCisco Partners Facebook\n|\n@CiscoPartners X\n|\nCisco Partners LinkedIn\nAuthors\nBrian Feeney\nVice President\nGlobal Security Partner Sales"
  },
  {
    "title": "New Cisco Secure Access Python SDK",
    "link": "https://blogs.cisco.com/developer/new-cisco-secure-access-python-sdk",
    "description": "Security developers and network engineers usually find it easier to use SDKs. The SDK implements authentication and usage best practices, handles errors, and provides information about missing parameters. Here is the new Secure Access Software Development Kit, which is built using the Secure Access API. The SDK can help you orchestrate security and policy changes, […]",
    "source": "Cisco_blog",
    "main_ideas": [
      "The new Cisco Secure Access Python SDK simplifies security development for engineers.",
      "It implements best practices for authentication and error handling.",
      "The SDK aids in managing security policies and resource deployment."
    ],
    "tags": [
      "cisco",
      "secure-access",
      "python-sdk",
      "software-development",
      "security",
      "network-engineering",
      "api",
      "devnet",
      "coding-assistant"
    ],
    "original_text": "Developer\nNew Cisco Secure Access Python SDK\n1 min read\nOleksii Borysenko\nSecurity developers and network engineers usually find it easier to use SDKs. The SDK implements authentication and usage best practices, handles errors, and provides information about missing parameters.\nHere is the new\nSecure Access Software Development Kit\n, which is built using the Secure Access API.\nThe SDK can help you orchestrate security and policy changes, manage the deployment of resources, and more.\nIn the\nExamples folder\nyou can find examples for:\nManaging API credentials\nManaging Destination Lists\nExport/Import Access Policy Rules\nExporting Roaming Computers\nDevelopers can now use and work with the SDK through their favorite coding assistant (VS Code, GitHub Copilot, Cursor, Codex, Gemini CLI, etc.). In the repository, you can find\nAGENTS.md\nthat helps your coding assistant navigate and work with the Secure Access SDK, and contains security instructions that can protect your commits and pull requests.\nHelpful Links:\nCisco Secure Access playlist\nSecure Access Announcements\nAuthors\nOleksii Borysenko\nSoftware Engineering Technical Leader\nDevNet"
  },
  {
    "title": "Cisco Recognized as a Major Player in the 2025 IDC XDR MarketScape",
    "link": "https://blogs.cisco.com/security/cisco-recognized-as-a-major-player-in-the-2025-idc-xdr-marketscape",
    "description": "Cisco has been recognized as a Major Player in the IDC MarketScape: Worldwide Extended Detection and Response (XDR) Software 2025 Vendor Assessment.",
    "source": "Cisco_blog",
    "main_ideas": [
      "Cisco has been recognized as a Major Player in the IDC MarketScape for XDR software.",
      "Cisco's XDR solution features an open architecture for seamless integration with third-party tools.",
      "The solution emphasizes network and cloud detections, enhancing visibility and response capabilities."
    ],
    "tags": [
      "cisco",
      "xdr",
      "security",
      "network-detection",
      "cloud-security",
      "threat-detection",
      "it-industry",
      "vendor-assessment"
    ],
    "original_text": "Security\nCisco Recognized as a Major Player in the 2025 IDC XDR MarketScape\n2 min read\nNirav Shah\nWe’re excited to share that Cisco has been recognized as a\nMajor Player\nin the IDC MarketScape: Worldwide Extended Detection and Response (XDR) Software 2025 Vendor Assessment (doc #US52997325, September 2025).\nWe believe this recognition validates our commitment to an open, network-led approach to XDR and reinforces our vision for empowering security teams with comprehensive threat detection and response capabilities.\nKey Highlights of the IDC MarketScape\nThe IDC MarketScape emphasizes showcases the distinct advantages that set our solution apart:\nTruly Open XDR Architecture\n— The IDC MarketScape notes, “Cisco XDR has a truly open XDR architecture.” Our open, hybrid approach to XDR allows customers to seamlessly integrate telemetry from both Cisco security solutions and third-party tools. This enables customers to maximize their existing security investments while unlocking the full potential of XDR by delivering visibility, detection, and response across their entire security environment.\nPowerful Network and Cloud Detections\n— The IDC MarketScape notes, “Cisco places special emphasis on NDR and network-based detections in Cisco XDR.” Our network-led approach to XDR means that Cisco XDR natively includes built-in network detection and response capabilities such as entity modeling to quickly identify network anomalies across both on-premises and cloud environments. This gives customers critical context and visibility into their security environment, including unmanaged and IoT/OT devices that cannot run traditional agents from endpoint-centric tools.\nBeyond the IDC MarketScape\nWe believe this recognition from the IDC MarketScape is a strong affirmation of our innovative and forward-thinking approach to XDR. To us, it validates our strategy to deliver a comprehensive XDR solution that seamlessly integrates with diverse customer environments, providing unparalleled visibility, automation, and response capabilities.\nWe believe our positioning in the IDC MarketScape is part of a broader trend of consistent recognition of Cisco across the industry. For example, GigaOm has recognized Cisco as a Leader in their XDR Radar report for two consecutive years (2024-present). Furthermore, a recent IDC survey (“IDC, The Top 6 XDR Vendors: Adoption Trends, September 2025” doc# US53805525, September 2025) noted that according to survey respondents, Cisco XDR accounts for 9.1% of overall adoption, with its highest share at 13.2% in enterprises with 1,000 to 2,499 employees. This is a notable achievement for a solution that has been available for only two years!\nExperience the Power of Cisco XDR\nWe invite you to explore how Cisco XDR can simplify your security operations and help you stay ahead of the evolving threat landscape. To learn more about Cisco XDR, please visit\nour website\n.\nWe’d love to hear what you think! Ask a question and stay connected with Cisco Security on social media.\nCisco Security Social Media\nLinkedIn\nFacebook\nInstagram\nX\nAuthors\nNirav Shah\nSecurity Product Marketing\nThreat, Detection & Response"
  },
  {
    "title": "Cisco at AutoCon 4: AI, Automation, and the Human Side of ‘Ops’",
    "link": "https://blogs.cisco.com/learning/ai-automation-and-the-human-side-of-ops-cisco-at-autocon-4",
    "description": "Discover how AI and automation are transforming network operations at AutoCon 4, November 17–21, 2025, in Austin, TX.",
    "source": "Cisco_blog",
    "main_ideas": [
      "Automation is essential for network engineers to stay competitive in their roles.",
      "AutoCon 4 will showcase hands-on demos for operational automation and observability.",
      "Cisco U offers resources to help engineers learn automation skills and best practices."
    ],
    "tags": [
      "automation",
      "network-engineering",
      "cisco",
      "autocon",
      "ai",
      "observability",
      "devops",
      "programming",
      "telemetry"
    ],
    "original_text": "Learn with Cisco\nCisco at AutoCon 4: AI, Automation, and the Human Side of ‘Ops’\n2 min read\nJulio Fernandez\nLet’s be honest: automation isn’t optional anymore.\nIf you’re a network engineer wondering how AI and automation will change your job, here’s the reality. Engineers who automate will outpace those who don’t.\nSee what’s possible with Cisco at AutoCon 4\nAutoCon 4, November 17–21, 2025, in Austin, TX, is where the community compares notes on what actually works—code, playbooks, telemetry, and the people/process shifts that make it all stick. Come see what’s possible at the Cisco booth, or\nstart free today at Cisco U.\nand turn a boring repetitive task into your first automated win.\n“My main takeaway from AutoCon was seeing how our customers organize themselves to actually do NetDevOps—\nwhat network engineers learn, how they partner with developers, and how mutual understanding shapes success at scale.”\n—François Caen, Product Manager, Learn with Cisco\nWhy teams stall on automation (and how to move forward)\nMany organizations have a few scripts or pilots but struggle to scale their automation practice.\nThe usual blockers:\nRework & inconsistency:\nevery site is a snowflake.\nLimited visibility:\nno useful telemetry or dashboards.\nSkills gap:\nengineers aren’t sure where to start, or how deep to go.\nWhat gets momentum back:\nAPI-first workflows\nwith clear intent and guardrails.\nModel-driven telemetry\nthat turns data into action.\nShared patterns\n(Git, reviews, tests) across network + software teams.\nAutomation you’ll find at the Cisco booth at AutoCon 4\nHands-on demos\nthat show how to get from manual tasks to repeatable pipelines:\nOperational Automation:\nintent-based, API-first workflows that cut tickets and toil.\nScalable Observability:\nTurn telemetry into insights for capacity, security, and SLOs.\nProgrammability:\nPython, SDKs, and open APIs—use what fits your stack.\nSkill-Building with Cisco U:\ntutorials, labs, and learning paths mapping the technologies above to CCNA → CCNP → CCIE.\nBring us a task that wastes your time.\nWe’ll show a path to automate it, or where to start learning.\nCan’t make it to Austin? Start in 30 minutes\nYou don’t need a plane ticket to Austin to make progress. Follow François’ advice: “Find one repetitive task, automate it, and come to Cisco U. to learn how. Start with a free tutorial or Python for Network Engineers, then grow and test your skills along the Automation CCNA, CCNP, and CCIE path.”\nJoin our vibrant and free community of learners\nand get help and advice there.\nStart right now at\nCisco U\n.\n—get a free account in minutes.\nFAQs\nWhat is NetDevOps?\nApplying software practices (version control, CI/CD, testing) to network deployment and operations.\nDo I have to be a developer?\nNo. Start small with Ansible, Python, or low-code tools and build depth over time.\nWhat does Cisco show at AutoCon?\nOperational automation, observability, and programmability—plus hands-on demos, learning,  and certifications prep via Cisco U.\nWhere do I start today?\nAt\nu.cisco.com\n—free tutorials, guided labs, and structured learning paths.\nAutomation doesn’t scale alone—it takes a community\nThe technology is ready. What’s needed now is shared experience, clear paths, and collaboration across roles and vendors. AutoCon is where that happens.\nWe look forward to seeing you in Austin for AutoCon 4! Let’s accelerate automation—together.\nSign up for\nCisco U.\n| Join the\nCisco Learning Network\ntoday for free.\nLearn with Cisco\nX\n|\nThreads\n|\nFacebook\n|\nLinkedIn\n|\nInstagram\n|\nYouTube\nUse\n#CiscoU\nand\n#CiscoCert\nto join the conversation.\nAuthors\nJulio Fernandez\nSr Content & Growth Marketing Consultant\nCisco Marketplace and Developer APIs"
  },
  {
    "title": "Beyond the Cloud: Partners’ Secure AI Edge Opportunity with Cisco",
    "link": "https://blogs.cisco.com/partner/beyond-the-cloud-partners-secure-ai-edge-opportunity-with-cisco",
    "description": "Discover how Cisco Unified Edge empowers partners to deliver secure, real-time AI inferencing at the edge. Explore the tremendous market opportunity to help customers maximize AI investments and win at the edge with a unified, simplified platform.",
    "source": "Cisco_blog",
    "main_ideas": [
      "Cisco Unified Edge enables secure, real-time AI inferencing at the edge.",
      "The edge computing market presents a $143 billion opportunity by 2034.",
      "Cisco simplifies AI deployment with a unified platform for partners.",
      "Partners can enhance customer engagements with managed services at the edge.",
      "Cisco offers training and resources to support partners in AI edge solutions."
    ],
    "tags": [
      "cisco",
      "ai",
      "edge-computing",
      "cloud-infrastructure",
      "security",
      "partners",
      "real-time",
      "managed-services",
      "training",
      "market-opportunity"
    ],
    "original_text": "Partner\nBeyond the Cloud: Partners’ Secure AI Edge Opportunity with Cisco\n2 min read\nCassie Roach\nForget the hum of distant data centers for a second. Imagine a world where intelligence doesn’t come from afar but is right where the action happens. This isn’t science fiction—it’s the reality of AI computing at the edge, where algorithms dive headfirst into the physical world. Picture a smart traffic camera, not just recording and sending data back, but instantly analyzing patterns and optimizing traffic flow autonomously.\nCisco has always delivered optimized architectures to the edge and now, with\nCisco Unified Edge\n, we are driving the new frontier of agentic AI innovation.\nAccording to\nGartner\nby 2025, 75% of all data will be processed at the edge rather than in data centers. By 2030,\nStatista\nestimates there will be 77 billion edge devices in operation—everything from cameras to smart sensors to robotic machines. These devices process data closer to where it’s generated, presenting a tremendous $143 billion market opportunity by 2034 for Cisco and our partners to help customers maximize their AI investments.\nThat’s why Cisco is redefining what’s possible—building AI platforms, to make AI accessible for everyone. Cisco Unified Edge, which we announced on November 3 and is orderable NOW, unifies security, compute, networking, and storage into one modular platform. With zero-touch deployment, ISV mapping, agentic workflows, pre-validated designs and simplified delivery, now it’s even easier for our channel partners to help customers roll out AI faster than ever before.\nCisco’s edge advantage\nWith Cisco Unified Edge, partners now can seamlessly extend secure, high-performance cloud and AI infrastructure wherever data is generated—empowering customers to deploy real-time AI inferencing at the edge for optimized decision-making.\nCisco Unified Edge is transformational for partners trying to help customers deploy AI agents across thousands of edge locations—including retail stores, factories, and hospitals. Today, it’s challenging to integrate different vendors, different management platforms, and different security models. Cisco Unified Edge simplifies all of that. One system. One platform. Built-in security with zero-trust architecture. Centralized management with Cisco Intersight for global visibility and control. No need for specialized skills on-site.\nWhat’s in it for you\nFor partners, this is a tremendous land-and-expand opportunity. You’re not just selling edge infrastructure—you’re selling the secure foundation for AI at scale, with managed services wrapped around it, positioning you to win at the edge.\nThe edge is where you can maximize your unique IP, customer relationships and profitability by offering vertical market use cases and value-added consulting as well as managed services. This means multi-year customer engagements as you help them deliver their outcomes at the edge.\nInvesting in you\nTo give you a fast start, we are hosting virtual training webinars and in-person technical roadshows in multiple cities globally starting this month. We’re offering co-marketing and demand-gen planning with partners as well.\nWant to host an AI edge customer workshop focused on retail, healthcare and manufacturing use cases? Let’s do it. Visit Cisco’s\nCloud + AI Infrastructure Partner Sales Center\non SalesConnect for Unified Edge sales resources, training information and incentives.\nCisco Unified Edge is\nyour gateway to delivering AI at the edge\n—with performance, simplicity, and security.\nThe future is here. Let’s conquer the AI edge frontier together.\nWe’d love to hear what you think. Ask a Question, Comment Below, and Stay Connected with #CiscoPartners on social!\nCisco Partners Facebook\n|\n@CiscoPartners X\n|\nCisco Partners LinkedIn\nAuthors\nCassie Roach\nGlobal Vice President, Cloud and AI Infrastructure Partner Sales\nGlobal Partner Sales"
  },
  {
    "title": "Parenting Through Chronic Illness: My Journey with Cisco by My Side",
    "link": "https://blogs.cisco.com/wearecisco/parenting-through-chronic-illness-my-journey-with-cisco-by-my-side",
    "description": "Angee B., Cisco Digital Impact Office Strategic Marketing Manager, shares how Cisco’s flexibility helps her support her daughter’s unique needs and thrive in her career.",
    "source": "Cisco_blog",
    "main_ideas": [
      "Angee Barnett shares her journey as a mother to a child with chronic kidney disease.",
      "Cisco's flexible work culture allows her to balance parenting and career effectively.",
      "The support from Cisco and colleagues has been crucial during challenging times."
    ],
    "tags": [
      "chronic-illness",
      "parenting",
      "flexible-work",
      "cisco",
      "support-system",
      "resilience",
      "community",
      "well-being",
      "healthcare"
    ],
    "original_text": "We Are Cisco\nParenting Through Chronic Illness: My Journey with Cisco by My Side\n3 min read\nAngee Barnett\nFinding Strength in the Unexpected\nThey say you can’t pour from an empty cup, but what if your “cup” is filled by chasing soccer balls, art supplies, and hope, all while working for a company that has your back? My journey as a mom to a teenager with chronic kidney disease is anything but typical, and the support I’ve found at Cisco is just as extraordinary.\nWhen Life Changes Overnight\nIn 2019, everything changed for my family. What we thought was just a stubborn case of the flu quickly led to an ER visit for pneumonia and the unexpected diagnosis of Stage 3 Chronic Kidney Disease for my daughter. Suddenly we were navigating surgeries, endless appointments, and the stark reality that her kidneys would never fully recover.\nToday, her kidneys function at less than 15%, and despite corrective surgery slowing the damage, she is now actively seeking a kidney donor for transplant. This critical step offers her the chance to stay on the field as a competitive goalkeeper, skate, continue school, and keep chasing her dreams of becoming a lawyer without the shadow of kidney failure or dialysis slowing her down.\nMeet Avery: More Than a Diagnosis\nAvery is the heartbeat of our family — a kid who faces every challenge with grit and a smile. When I say she’s “cooler than I could ever hope to be,” I mean it. She’s determined not to let her illness define her, despite the constant doctor’s appointments, missed school days, and more than a few detours from the usual teenage life. Her resilience inspires me every single day.\nA Team That Truly Shows Up\nWhen I learned Avery was approved for her Make-a-Wish trip to Hawaii, I reached out to my Cisco team to share the news and request time off with barely any notice. Not only did they rally to cover my work, but they also made it clear: “Be with Avery. We’ve got you.” For ten days, I was able to be fully present with no emails, no meetings, just making memories with my daughter.\nThat kind of support isn’t a one-off at Cisco, but when you experience it firsthand, it’s unforgettable.  It also reinforced just how many resources I’ve leaned on throughout my time here:\nFlexible work means I’m able to handle doctor’s appointments or school calls when Avery isn’t feeling well, without sacrificing my career or my value to the team.\nThe RethinkCare program has given me expert guidance on parenting through medical challenges.\nI’ve found community and tools for self-care through Cisco’s well-being resources, including virtual therapy, mindfulness and resilience courses, and health coaching.\nColleagues have gone above and beyond, even donating to the National Kidney Foundation in Avery’s honor.\nBuilding Community, Even Without an Office\nLiving in Kansas City, where there isn’t a physical Cisco office, hasn’t stopped me from finding connection. In fact, I’ve found a local tribe of KC Cisconians.\nDuring Cisco’s Global Week of Giving, several of us gathered for a day supporting Children’s Mercy (Avery’s care team), assembling “Happy Kits” for patients like Avery. Knowing my colleagues care about a cause so precious to me means everything. That feeling of community and purpose is real.\nThe Power of Flexibility and Empathy\nBeing a parent to a child with a chronic illness is a lesson in resilience, vulnerability, and gratitude. The flexibility and understanding I’ve received at Cisco have allowed me to be the mom Avery needs while still growing my career. I never feel like I’m choosing between my family and my work; the two are in harmony because of Cisco’s culture and benefits.\nI’ve gained confidence, knowing that my company genuinely cares about my well-being, not just my productivity. On the days when the school calls or Avery’s health dips, I don’t panic. I know I can be there for her, and that sense of security is priceless.\nWhy I love where I work\nAs a strategic marketing manager in Cisco’s Digital Impact Office, I get to tell stories about how technology changes lives. But the story closest to my heart is my own. My daily work is richer because I understand firsthand what it means to need support, flexibility, and empathy.\nCisco isn’t just a tech company; it’s a family. It’s a support system that values people, not just productivity. Here, I get to be a marketer, a mom, and a caregiver, and I never have to choose between them.\nWorking for Cisco means I have the freedom to take care of my daughter and myself without fear or guilt. Every time I open my laptop, I know my leaders and teammates truly care — not just about the work, but about the people behind it.\nIf you’re wondering what makes Cisco different, it’s this: You’re empowered to bring your whole self to work and to bring your best self home. For anyone facing the unknown or supporting a loved one through chronic illness, know that you don’t have to do it alone. At Cisco, you’re surrounded by colleagues who care, leaders who listen, and resources that make a real difference.\nIf you’re looking for a company that supports you through life’s toughest moments — and celebrates the best ones — you’ll find it at Cisco.\nExplore careers now.\nSubscribe to the WeAreCisco Blog.\nAuthors\nAngee Barnett\nGlobal Marketing & Brand Manager\nDigital Impact Office, Women of Cisco Board of Directors"
  },
  {
    "name": "The progression of AIOps in today’s network environment",
    "link": "https://www.nokia.com/blog/the-progression-of-aiops-in-todays-network-environment/",
    "source": "Nokia_blog",
    "main_ideas": [
      "AIOps enhances network management by utilizing AI for improved efficiency and accuracy.",
      "Natural language interfaces simplify interactions with network management tools for users.",
      "Nokia's EDA platform integrates AI to streamline data center network operations."
    ],
    "tags": [
      "aiops",
      "autonomous-networking",
      "network-management",
      "nokia",
      "data-centers",
      "machine-learning",
      "natural-language-processing",
      "kubernetes",
      "cloud-computing"
    ],
    "original_text": "The progression of AIOps in today’s network environment\nby\nClayton Wagar\n14 Nov 2025\nThe path to network autonomy\nAt Nokia, we’ve helped design and build many of the largest networks on the planet. Alongside that, we’ve built operations tools that help optimize the design, deployment, and operation of those networks. Network management tools have always played a critical role in unlocking the most capability and value from networks of all types, around the world.\nIn recent years, the growing demands of scale and complexity have driven interest in Autonomous Networking, where the tools used to manage network infrastructure take on a more sophisticated role, promises to offload much of the mundane while increasing accuracy. The goal, of course, is for systems to perform the work of network management on behalf of the people who define the outcomes. Several autonomous network frameworks exist, with perhaps the most well know from the TM Forum.\nMuch like the levels of a self-driving vehicle, the\nTM Forum Autonomous Networks framework\ndefines a number of levels, correlating to the amount of work performed by humans versus systems. From a completely manual starting point, each level indicates an increasing amount of overall work in the domain of a system – first with humans in the loop, and ultimately a completely system-driven management.\nMost of the original thinking about autonomous networks didn’t consider artificial intelligence – at least not in today’s form. Certainly machine learning has long been a core feature of network management tools, but today’s large language model (LLM) capabilities add a significant new enabler on the path to network autonomy. “AIOps” appears frequently now, making a promise that AI somehow changes our fundamental capabilities in operating networks.\nWhat enables AIOps?\nThe first, and perhaps biggest impact of AI is the ability to interact with our networks with natural language. Today’s network practitioners are expected to be linguists – deploying knowledge of a variety of interface languages from command line to database querying. The arrival of a universal natural language interface for network operations has changed the way we think about tooling. Inputs and outputs can now be more fluent, precise, and customized. Workforce impacts are also clear, allowing a greater pool of applicants by lowering the burden of knowledge to get started and become productive.\nSecondly, the advent of agentic tool calling allows AI-enabled systems to interact with other systems in a programmatic fashion. We can quickly process logs, check configurations, and interact with ticket systems simply by enabling tools via MCP or API. Each of these tools is specialized, ensuring the accuracy of information as it’s processed. Much like assembling a great sports team, each position player has a job to do, brought together by the coach calling the plays.\nThe third enabler is the AI models themselves. True autonomy in network operations means that the systems operating on our behalf are\nat least\nas good as a human. Output from a model should be accurate, provable, and explainable. A model that excels at natural language understanding may not give the most accurate results for diagnosis, or configuration. Using multiple models in a workflow is common today, this can mean using small trained models for high quality, reproducible results – and leveraging large language models to interact with humans and their intent.\nAIOps in Nokia's EDA for data center networks\nNokia’s EDA is a Kubernetes-based, model-driven platform for managing large scale, complex data center networks. From deployment to ongoing maintenance, EDA simplifies management of both traditional data center workloads as well as the most advanced AI fabrics. As we looked to bring AI capabilities to EDA, we focused on high-impact use cases that leveraged the best of AI’s capabilities today.\nWe first took the lowest hanging fruit – the EDA Query Language (EQL). This powerful capability allows users to quickly find and filter information about the network with a simple query box. And while EQL has tremendous power, it’s still another language to learn. Our team leveraged AI to allow EDA users to form their question as natural language – “show me all down interfaces which are not disabled”, reducing the clock cycle of troubleshooting greatly.\nIn an upcoming release of EDA, we’ve added AskEDA – a chatbot companion inside the EDA user interface. AskEDA is a powerful tool which allows you to ask questions about what you’re seeing on the screen, quickly sort through complex information like alarms, and more. See something unusual you want to monitor on a regular basis? Search, sort, and filter information using AskEDA, and then have a customized dashboard widget created automatically. Need to triage the root cause of an issue? AskEDA will sort through logs and alarms and give you an evidence-based explanation of what’s wrong, and how to fix it.\nWe recently showed this capability at Network Field Day 39 in November of 2025. A video is worth 1,000,000 words –\ngo check it out\n!\nThe path forward\nAI’s impact on network operations is real, and at each level of the Autonomous Networks framework we will see it’s impact. Today, AIOps is a tool that can be leveraged as needed and appropriate to assist humans in the operation of large, complex networks. For an advance look at some of how we explore the design space with AIOps,\nc\nheck out this recent Packet Pushers VideoByte for more\n. We are excited to bring these new capabilities to market soon, and look for expanded capabilities powered by AIOps during 2026!"
  },
  {
    "name": "AI is driving the evolution of autonomous networks",
    "link": "https://www.nokia.com/blog/ai-is-driving-the-evolution-of-autonomous-networks/",
    "source": "Nokia_blog",
    "main_ideas": [
      "AI is essential for the evolution of autonomous networks to support AI-driven applications.",
      "Network operations will increasingly rely on AI agents for self-management and predictive maintenance.",
      "Spatial awareness and semantic communications are crucial for fully autonomous network operations."
    ],
    "tags": [
      "artificial-intelligence",
      "autonomous-networks",
      "network-operations",
      "predictive-maintenance",
      "semantic-communications",
      "bell-labs",
      "data-security",
      "automation",
      "digital-twins"
    ],
    "original_text": "AI is driving the evolution of autonomous networks\nby\nAnne Lee\n14 Nov 2025\nI can’t help but notice that amid the hype surrounding AI, chips and data centers, the network rarely seems to get a mention. As a Bell Labs researcher, it seems to me that this is a critical gap. Intelligent, agile and reliable connectivity that dynamically meets the needs of AI-driven applications will be essential. I would go even further and say that without autonomous or mostly autonomous networks, it’s difficult to see how AI will fully realize its potential.\nThe key to achieving networks that can support AI, ironically, will also depend on AI; specifically, the development of specialized AI agents that are able to work in concert to operate the network in all its aspects. Let’s see what that might look like.\nAI demands network evolution\nImagine, for instance, that an enterprise AI application using a hybrid private-public cloud makes an API request for an on-demand network slice to connect a customer, employee or IoT device back to the enterprise’s private cloud for data security reasons. The slice might only be needed for the time period of the transaction or event. Now imagine this request for a slice being repeated by thousands of different AI applications across the same network in this same period.\nThis represents a new paradigm for network operations, which traditionally relied on predictable traffic patterns to plan for and manually manage network resource deployment. Automation, though it’s being used today, will have to evolve massively. Just as AI forced this evolution, unsurprisingly, network operators will turn to AI, especially AI agents, to create networks that self-operate.\nNetwork operations\nThe building blocks of networks that self-operate (NSOs) will be network module agents (NMAs), which are AI agents that intelligently operate a network node, for instance, in the RAN, core or optical domains. These agents address a specific function to perform a task like predictive maintenance, root cause analysis, or resource management. They receive inputs such as KPIs and alarms or analyze local log or sensor data and do things like tune parameters and self-heal the node.\nNMAs can interact directly with each other, but are also orchestrated by other agents, called large network agents (LNAs) that are assigned to a network domain or service layer in the network. LNAs aggregate the outputs of multiple NMAs and orchestrate their activities. They have their own AI internal components that do such things as reason, filter-out hallucinations, and remember the chain of interactions. They also manage communications between agents, including API calls to foundational AI models, local non-language models, applications, tools, and digital twins, as well as interactions with human engineers and customers.\nIn order, for instance, to provide fully autonomous predictive maintenance, an NMA may monitor KPIs and sensors for specific network equipment. The NMA would convey information back to an LNA of the network that a particular card under its watch is starting to fail. The LNA has a system-wide view of many NMAs allowing it to draw conclusions through reasoning as to whether this was just one card failing or a more serious potential node failure.  Depending on its prediction, the LNA may interact with a supply chain AI agent to order a new card and assign a human technician to replace the card or take more holistic actions possibly involving human technicians to prevent a service impacting failure.\nSpatial awareness\nThere are many things that happen to networks in the physical world that won’t be properly captured by network equipment data, especially if the physical fault involves a complete loss of a connection. Thus, to be completely self-operating, network AI agents will also be needed to understand the physical layer of the network, that is, how things happen in the world.\nThese large world agents (LWAs) are a kind of embodied AI, which have physics models that enable them to analyze visual, temporal and spatial data from cameras, text, video/audio and sensor data, and they undertake real-world actions using, for instance, robots, cars, drones, or human personnel. They rely heavily on digital twins to model the world, especially those aspects of it that directly affect the network infrastructure.\nSemantic communications\nIn the complex chain of AI agent interactions needed to self-operate the network, it is not simply a matter of machine-to-machine communications, since humans will many times be in the decision-making loop. For the sake of transparency, among other things, it’s best that communications between agents are carried out in natural language. For this to be efficient, only the key information, with context where required, should be used.\nLet’s say a field engineer encounters an issue with the DSL cross-connect box in a customer’s backyard that requires specialized knowledge to resolve. The field engineer may use a smart tablet device powered by an AI agent with semantic communication capabilities to initiate a video call with a remote expert. The AI agent on the tablet analyzes the video feed from its camera and extracts relevant information, such as the type of box, wiring, etc. Meanwhile temperature, vibration and moisture sensor data from the cabinet provide the environmental conditions. All these inputs are analyzed by a remote expert human or AI agent, who/which provides precise, step-by-step guidance to the field engineer.\nTrustworthy autonomy\nAs with every discussion around AI today, it’s important to acknowledge the elephant in the room. How do we ensure that handing over the operation of such critical infrastructure is safe? There are five principles that we at Bell Labs see as critical:\nMultimodal integration and contextual awareness-seamless integration and reasoning across multiple modalities to provide context-aware insights and actions\nExplainability, safety and compliance-prioritization of safety and adherence to industry standards ensuring explainable decision-making and incorporating human-in-the-loop validation for critical actions\nRobustness and reliability-high reliability for edge cases and implementation of fail-safe mechanisms\nScalability and real-time performance-support for high-data throughput with real-time inferencing available on devices or the edge cloud as well as the ability to scale to multiple facilities and tasks\nData privacy and security-protection of sensitive network data and network AI models.\nThere can be enormous benefits in automating networks. The intelligent fusion of network operation agents (NMAs and LNAs), spatial intelligence agents (LWAs), and semantic communications will take us there. This integration promises to enhance operational efficiency and reduce downtime significantly. Most importantly, it will be essential for building the dynamic, resilient platform needed to realize the promises of an AI world.\nIf you are interested in a more in-depth discussion of AI and networks that self-operate, we have recently made available a white paper exploring our findings and recommendations:\nAdvancing AI: networks that self-operate\n."
  },
  {
    "name": "Nokia recognized as leader in AI-powered RAN automation by TÉRAL Research for tenth year in a row",
    "link": "https://www.nokia.com/blog/nokia-recognized-as-leader-in-ai-powered-ran-automation-by-teral-research-for-tenth-year-in-a-row/",
    "source": "Nokia_blog",
    "main_ideas": [
      "Nokia has been recognized as a leader in RAN automation for ten consecutive years.",
      "The MantaRay portfolio enables operators to achieve zero-touch, intent-based autonomous network operations.",
      "Nokia's solutions address challenges in integrating legacy systems with advanced RAN architectures."
    ],
    "tags": [
      "nokia",
      "ran-automation",
      "mantaray",
      "ai",
      "telecom",
      "self-organizing-networks",
      "o-ran",
      "network-optimization",
      "autonomous-networks"
    ],
    "original_text": "Nokia recognized as leader in AI-powered RAN automation by TÉRAL Research for tenth year in a row\nby\nAji Ed\n13 Nov 2025\nFor the tenth consecutive year, Nokia has been recognized as the leader in RAN automation by TÉRAL Research. This acknowledgment highlights Nokia’s consistent innovation and leadership in Self-Organizing Networks (SON) and its ability to drive the telecom industry’s transition from traditional SON to advanced O-RAN-aligned architectures. With its comprehensive MantaRay portfolio, Nokia continues to empower operators to achieve zero-touch, intent-based autonomous network operations while seamlessly evolving to Non-RT RIC and Service Management & Orchestration (SMO).\nMoving toward autonomous networks\nThe telecom industry is experiencing a paradigm shift, moving from legacy systems to next-gen automation and advanced architectures. Operators face challenges integrating legacy systems and solutions with emerging architecture. These transitions require solutions that optimize network operations while ensuring compatibility with existing deployments. Operators encounter several constraints in this transition, including technological complexity in integrating new architectures with legacy systems without disrupting services, operational challenges in achieving autonomous network operations in increasingly complex environments, and scalability needs to ensure solutions can scale across diverse RAN architectures, including purpose-built RAN, Cloud RAN, and Enterprise networks.\nField-proven MantaRay portfolio for AI-driven RAN operations\nTo address these challenges, Nokia leveraged its field-proven MantaRay portfolio. By integrating mature MantaRay SON assets with O-RAN Non-RT RIC capabilities, Nokia developed solutions that support the coexistence of rApps with pre-standard applications. This approach ensures operators can evolve seamlessly towards Non-RT capabilities while maintaining operational efficiency. Nokia’s MantaRay portfolio offers a comprehensive suite of solutions for RAN automation, including MantaRay SON, which has been proven in over 120 large-scale customer networks globally and evolves into Non-RT RIC capabilities to support autonomous operations; MantaRay AutoPilot, an intent-based orchestration solution that enables Level 4 autonomous RAN operations; MantaRay Energy, which uses AI-driven optimization of RAN energy consumption to reduce operational costs without compromising network KPIs; Nokia RAN slice controller that provides dynamic orchestration and resource management capabilities to ensure each network slice is provisioned to meet specific service level agreements; and last but not least, it includes the MantaRay Network Management, a unified system for managing RAN, Cloud RAN, Core, and Enterprise networks.\nNokia confirmed as a leader in AI-powered RAN automation\nBefore implementing Nokia’s solutions, operators relied on manual processes and legacy SON systems, leading to inefficiencies and limited scalability. After adopting Nokia’s MantaRay portfolio, operators achieved zero-touch, intent-based autonomous network operations, enhanced energy efficiency through AI-driven optimization, seamless journey towards integration of rApps with existing systems, and accelerated operational and business outcomes. Nokia’s solutions enable operators to transition smoothly towards advanced RAN architectures, achieving significant improvements in network automation and efficiency. The recognition by TÉRAL Research underscores Nokia’s leadership in driving innovation and delivering tangible results for its customers.\nLooking ahead, Nokia continues to drive advancements in RAN automation by expanding the capabilities of its MantaRay portfolio to support future O-RAN standards, continuously enhancing AI-driven solutions for energy optimization and network management, and collaborating with operators and industry partners to accelerate the adoption of autonomous networks globally.\nNokia’s recognition as a leader in TÉRAL Research’s RAN Automation report is a testament to its commitment to innovation and excellence. By addressing industry challenges and delivering transformative solutions, Nokia continues to shape the future of autonomous networks and empower operators worldwide.\nDownload the TĖRAL Research report here\n.\nMultimedia, technical information, and related news\nMantaRay SMO\nMantaRay SON\nMantaRay Autopilot\nMantaRay NM"
  },
  {
    "name": "Taking industries further with the enhanced Nokia Drone Networks platform",
    "link": "https://www.nokia.com/blog/taking-industries-further-with-the-enhanced-nokia-drone-networks-platform/",
    "source": "Nokia_blog",
    "main_ideas": [
      "Nokia Drone Networks has expanded its platform for public safety and industrial operations across multiple countries.",
      "The new 5.2 XLR version enhances drone capabilities with extended flight range and advanced temperature control.",
      "Nokia is focusing on sustainability and regulatory compliance in drone operations with innovative technologies."
    ],
    "tags": [
      "nokia",
      "drone-networks",
      "5g",
      "sustainability",
      "public-safety",
      "industrial-operations",
      "drone-technology",
      "regulatory-compliance",
      "motorola",
      "bvlos"
    ],
    "original_text": "Taking industries further with the enhanced Nokia Drone Networks platform\nby\nThomas Eder\n12 Nov 2025\nWe have come a long way since launching the first CE-certified 5G automated drone-in-a-box in May 2023. We have gone nationwide in\nBelgium\n,\nSwitzerland\nis planning similar deployment, and\nSpain\nis enhancing its emergency services using our platform.\nIn 2024, we integrated\nMotorola’s CAPE drone software\nto help transform public safety and industrial operations in the US. Since then, we have deployed drones in California and continuing with rollouts along the East Coast. Our success and the expansion into the region are largely due to our open architecture, which enables integration with other third-party solutions and the creation of new services. With further software integrations underway, we are heading towards a true, use-case oriented Nokia Drone Networks application ecosystem, which is becoming a reality.\nIn addition to gaining market share, we have also expanded our customer base beyond public safety. We are currently preparing for deployments on major highway, power line, and substation inspection projects across Europe. And in the UAE,\nEtisalat (e& UAE) is collaborating with us\nto build out its drone network for the launch of a drone-as-a-service platform to support the diverse mission-critical needs of public safety teams and industrial enterprises, including surveillance, inspection and disaster response.\nBased on this field experience and our collaboration with current partners and customers, we are excited to share news of the next version of Nokia Drone Networks - a smarter, more powerful solution designed to make deployment and scaling easier than ever. With its new capabilities, this release empowers customers to take on the most demanding operations with more confidence and precision\nEmpowering BVLOS Operations with 5G\nIn addition to our open architecture, customers are choosing Nokia Drone Networks because the solution leverages\n5G connectivity\nfor long-range, secure, and reliable\nbeyond-visual-line-of-sight (BVLOS) operations\n. Both elements are essential parts of the future drone industry. Nokia drones can be remotely flown from anywhere, taking off and returning to the ruggedized docking station that both protects and recharges them in preparation for their next flights.\nThis reduces the need for truck rolls and on-site personnel, as drones can inspect harsh and hard-to-reach infrastructure in the most extreme temperatures. Whether used for one-off trips or scheduled maintenance flights, organizations can achieve sustainability benefits and better protect workers.\nIntroducing the new Nokia Drone Networks 5.2 XLR\nWith the new release we are pushing boundaries with extended flight range (XLR stands\nfor Extra Long Range), advanced temperature control, and smarter motor technology, redefining 5G automated drone missions. Discover how these innovations will empower critical operations worldwide.\nExtended flight range\n: We want to make drone flight time reporting more transparent. Nokia drones can fly in a 10 kilometer (6.2 miles) radius, equipped with the Nokia dual gimbal camera and parachute and hover on site for an additional 10 minutes before returning to the docking station. This means teams can access images even further across forest fires, conduct longer pipeline inspections in remote deserts and gain greater situational and mission-critical awareness. We aren’t hearing this level of detail from competitors, where flight times are reported without any indication of whether payloads are used, or hover times included.\nNext-level temperature control:\nWhen continuously operating drones from a docking station, the heat generated during flying and charging builds up in the battery. That’s why we’ve sourced a new component with silicon anode technology from our partner Amprius, and we are now among the first ones on the market to introduce active cooling at the battery itself. We’ve added new cooling capability at the docking station, too. This feature is critical, for example, when operating in high heat environment, for example remote pipeline inspections across deserts.\nActive cooling at the battery\nDriving sustainability with smarter motor technology\n: Because the new batteries can operate at a lower voltage, we needed the motors to do the same, so we have transitioned to US-manufactured motors, with a more integrated and capable technology stack. We’d already reached the point where our drones can remain in operation for three years, and the new components we are extending the lifetime to six years, making them a more sustainable alternative to other industrial drones on the market. We want all our customers to benefit from the most sustainable solution, so these upgrades are being offered to our existing customers too.\nSmarter motor technology\nEvolving towards regulatory compliance:\nWe continue to navigate the complexities of drone operations for our customers in many ways with Nokia Drone Networks 5.2 XLR:\nThe transition towards new components sourced from US innovators, including the batteries and motors, brings us a step closer to a solution required by mission-critical industries in North America.\nA new add-on module for Automatic Dependent Surveillance-Broadcast (ADS-B) and Flight-Related Automatic Numbering and Reporting (FLARM) communications advances compliance with aviation agencies when operating in increasingly busy airspaces around the world.\nThere is significantly less paperwork for industries and public safety agencies to operate drones over populated areas, such as industrial campuses and urban locations, as our parachute is now the first in Europe in its weight class, over 10 kg, to achieve the M2 high certification level.\nBuilding the future of drone operations - together\nWe want to make it easier for other industrial verticals, such as utilities, to adopt drone solutions and achieve their unique goals through automated infrastructure inspection, mapping and improved data collection. We are committed to extending the limits of our solution and helping customers achieve sustainability goals by reducing their reliance on vehicles and helicopters.\nAs the market is moving fast, we can’t do this alone, and thanks to Nokia Drone Network’s open architecture, we continue to work with ecosystem partners to deliver best-in-class solutions. Another example of this is an already announced partnerships with Gremsy and Yellowscan to develop an advanced payload portfolio, including more sophisticated cameras. Working with our partners, we will maintain the pace of evolution happening in the drone industry as we redefine the phrase ‘the sky is the limit’ for our customers."
  },
  {
    "name": "Five security threats to hunt in Radio Access Networks",
    "link": "https://www.nokia.com/blog/five-security-threats-to-hunt-in-radio-access-networks/",
    "source": "Nokia_blog",
    "main_ideas": [
      "Modern Radio Access Networks face increased security threats due to their complexity and interconnectivity.",
      "Attackers exploit weak credentials and lateral movement tactics to compromise network management systems.",
      "AI-powered threat hunting is essential for identifying anomalies that traditional monitoring may miss."
    ],
    "tags": [
      "radio-access-networks",
      "cybersecurity",
      "ai",
      "threat-hunting",
      "nokia",
      "telecom",
      "network-security",
      "lateral-movement",
      "privilege-escalation"
    ],
    "original_text": "Five security threats to hunt in Radio Access Networks\nby\nNils Ahrlich\n12 Nov 2025\nModern Radio Access Networks (RAN) are no longer hardware islands; they’re software-defined, virtualized, and deeply interconnected. That agility comes at a cost: a bigger, more complex attack surface that perimeter defenses alone can’t protect. Recent attacks by groups like Salt Typhoon and Weaver Ant show how adversaries exploit “living off the land” tactics and stealthy webshells to slip past defenses and pivot deep into the network.\nHow confident are you that your radio network hasn’t already been breached?\nIn this blog, you’ll discover five critical anomalies every telecom operator should hunt for, and why AI-powered threat hunting reveals what routine monitoring misses. These insights come from Nokia’s\nAdvanced Cybersecurity Consulting Services\n, based on real-world engagements with leading telecom operators, where telco-specific security assessments and proactive threat hunting are now recognized as industry best practices.\nFigure 1: Observed cyber kill chain in RAN\n1. Brute-force attacks on radio nodes\nWhat it is\n:\nAttackers often start by brute-forcing weak or default credentials on radio nodes such as gNBs. If they succeed, they gain a foothold for deeper attacks.\nWhy it matters\n:\nThis is a common entry point for campaigns targeting exposed network elements, and it often precedes privilege escalation or lateral movement.\nHow to hunt\n:\nLook for spikes in failed login attempts from single or distributed IPs targeting management interfaces. Use Security Information and Event Management (SIEM) queries to track authentication failures over short time windows and correlate with geolocation anomalies. Example: filter logs for repeated failures on gNB-DU/CU interfaces within a 10-minute window.\n2. Lateral movement across the network\nWhat it is\n:\nOnce inside, attackers aim to move sideways, often through the Network Management System (NMS), to reach more valuable targets.\nWhy it matters\n:\nCompromise of the NMS gives attackers control over multiple network elements, enabling large-scale disruption. Groups like Salt Typhoon and Volt Typhoon have used this tactic.\nHow to hunt\n:\nWatch for accounts behaving oddly, such as an NMS account accessing radio nodes in distant regions or making large-scale configuration changes outside normal hours. Correlation rules in SIEM or Extended Detection and Response (XDR) solutions can highlight unusual authentication paths or privilege use across network segments.\n3. Privilege escalation on critical elements\nWhat it is\n:\nAttackers rarely settle for basic access; they escalate privileges to gain control over critical systems.\nWhy it matters\n:\nElevated privileges allow attackers to modify configurations, create new accounts, and execute disruptive commands.\nHow to hunt\n:\nHunt for accounts suddenly gaining admin rights or performing actions outside their normal role, such as creating new users or modifying system configurations. Compare activity against change-control windows and baseline behaviors. Investigate orphaned or unknown processes running on jump hosts or terminal servers.\n4. Unauthorized remote access\nWhat it is\n:\nRemote Desktop Protocol (RDP) servers in management environments are prime targets for attackers, often exploited through weak passwords or phishing.\nWhy it matters\n:\nUnauthorized RDP access can lead to ransomware or full network compromise.\nHow to hunt\n:\nQuery Windows Event Logs for failed RDP logons (Event ID 4625) and filter for patterns like repeated failures from one IP or multiple accounts. SIEM dashboards can visualize these spikes. Example: create a query for high-frequency failed logins from a single source IP targeting multiple accounts.\n5. Rootkits and suspicious binaries\nWhat it is\n:\nAdvanced attackers hide in plain sight using rootkits that modify system files and kernel modules to stay invisible.\nWhy it matters\n:\nNokia’s\n2025 Threat Intelligence Report\nhighlights that 45% of surveyed telecom security professionals faced threats using custom-built toolkits designed for telecom infrastructure, enabling attackers to maintain stealth for months. These persistence mechanisms often target lawful interception paths and signaling systems, making detection extremely difficult.\nHow to hunt\n:\nGo beyond basic log analysis. Monitor for unexpected changes to system binaries, unknown kernel modules, or unusual API calls. Integrity checks and anomaly detection tools can reveal hooking techniques used by rootkits to intercept system functions. For example, hunt for modifications in kernel-level drivers or unexplained processes tied to critical network components.\nFigure 2: Attack behaviors observed by surveyed telecom security professionals\n(source: Nokia Threat Intelligence Report 2025)\nWhy XDR and AI are critical for RAN threat hunting\nEffective threat hunting starts with a clear hypothesis, such as an adversary has gained a foothold in the management network and is now probing for ways to infiltrate the RAN via base stations. From there, the hunt focuses on network traffic and logs originating in the management layer and targeting RAN infrastructure, guided by the latest attack patterns and tactics observed in telecom-specific campaigns.\nHowever, turning a hypothesis into actionable detection requires a multi-layered approach. SIEM platforms remain foundational for aggregating and correlating logs, while SOAR (Security Orchestration, Automation, and Response) accelerates incident response through automation and playbooks. As attacks grow more sophisticated, telecom operators need XDR to unify telemetry across endpoints, networks, and cloud environments, providing the context that SIEM alone cannot.\nAI amplifies this stack by detecting subtle patterns, predicting attacker behavior, and reducing false positives at scale. At Nokia, we combine SIEM correlation, SOAR-driven automation, and XDR’s unified detection and response capabilities with AI-powered analytics into a single framework designed for telecom operators. This layered strategy moves beyond reactive monitoring to proactive defense, essential for securing RAN against advanced threats."
  },
  {
    "name": "What is a pluggable? The future of optical networking.",
    "link": "https://www.nokia.com/blog/what-is-a-pluggable-the-future-of-optical-networking/",
    "source": "Nokia_blog",
    "main_ideas": [
      "Pluggable optics modules enhance optical networking by converting electrical signals to light pulses.",
      "The evolution of pluggable transceivers supports higher bit rates and longer transmission distances.",
      "Coherent optical communication improves data transmission efficiency and reduces power consumption significantly."
    ],
    "tags": [
      "pluggable-optics",
      "optical-networking",
      "coherent-transceivers",
      "data-centers",
      "network-architecture",
      "nokia",
      "800g",
      "ai-supercycle",
      "fiber-optics"
    ],
    "original_text": "What is a pluggable? The future of optical networking.\nby\nKurt Raaflaub\n11 Nov 2025\nThe network impact of the AI supercycle is top of mind for our partners and end-customers. When discussing Nokia data center fabric and interconnect solutions, pluggable optics modules are a key topic. For those of us in the optical transport and IP routing space, the term ‘pluggables’ refers to\n800G coherent multi-haul optical transceivers\n. However, when engaging our system integrator partners or their enterprise customers’ IT managers, what the term ‘pluggables’ means can be less clear. In fact, on several occasions, as I waxed poetic about the value offered by Nokia coherent optical pluggable transceivers to those audiences — highlighting their reduced space and power requirements, I have been met with “What is a pluggable?”\nWhat is a pluggable?\nA pluggable, or small form-factor pluggable (SFP) optical transceiver is a compact, removable module standardized to convert high-speed electrical signals into pulses of light before transmission, and conversely, upon receiving the pulses of light, it converts them back to electric signals. Well, at least the simpler versions do it that way. More on that later. From around 2 in. (50 mm) to over 5 in. (125 mm) in length, the pluggable is inserted into a networking device, such as a switch, router, or server, and allows that device to be connected to a fiber optic network.\nIntroduced in the early 2000s, SFPs quickly replaced the larger Gigabit Interface Converter (GBIC) standard for Ethernet switches and IP routers. This allowed manufacturers to design switches and routers with a much higher port density, enabling more connections in the same space. SFP transceivers were widely adopted beyond Ethernet switches and IP routers for other high-bandwidth applications, such as data centers. The \"pluggable\" nature of these modules made it easy to add, remove or change them without replacing the entire networking device. This enables network operators to start with a basic, lower-cost network setup and then upgrade individual transceiver modules to faster speeds or longer-reach technologies as their business needs evolve.\nAlthough SFPs were a new standard, their port design allowed backward compatibility with existing networks, while also providing a path to upgrade to higher-speed modules. This was accomplished through industry standards that defined the physical dimensions, electrical interface and operational specifications for SFPs and their future versions.\nSFP pluggable form factors have evolved over the last two decades to support higher bit rates, higher input power and longer reach. As Table 1 demonstrates, multiple pluggable options have been deployed using different data rates and supporting various ‘lane’ quantities and speeds. Today’s communications service provider and hyperscale market demands 400G and 800G capable QSFP-DD and OSFP pluggable form factors aligned with new router and switch availability.\nTable 1:\nPerformance summary of different pluggable optical transceivers\nPluggable evolution: copper to fiber, grey to colored\nOptical pluggable transceivers support higher bit rates, longer transmission distances and less power per bit delivered than copper variants. Copper interfaces and cabling typically tap out at 10Gb/s and 100m. An optical pluggable offers network operators a range of cost and performance options. There are ‘grey’ options that operate on a single wavelength within a fiber to transmit data — for example 1310 nm or 1550 nm. They are very cost-effective and offer network reach in the tens of kilometers. Multiple wavelength (colored) optical transceiver variants offer even higher bit rates and reach. This is known as dense wavelength division multiplexing (DWDM).\nGrey optics offer simple, cost-sensitive, short-range connections where fiber is plentiful. Colored optics (DWDM) are for high-capacity, long-distance links where it is critical to maximize limited fiber pairs.\nWhy are next-gen coherent optics important?\nA decade ago, optical communication systems primarily relied on intensity modulation with direct detection (IM-DD) to transmit information by modulating the light's intensity on and off. Next, 4-level pulse-amplitude modulation (PAM4) provided four levels of intensity, increasing the bit rate. As transmission speeds increased, IM-DD/PAM4 faced limitations due to optical fiber dispersion and nonlinear effects of travelling over long distances of fiber, in addition to the optical signal attenuation experienced over the link, making it difficult to meet the growing demand for bandwidth.\nThe introduction of coherent optical communication, which leverages the phase, amplitude, and polarization of light waves using higher-performance digital signal processing (DSP) enables more efficient data transmission. This breakthrough allowed optical systems to achieve longer-distance transmission at higher speeds, significantly improving capacity and performance.\nWhat problems do pluggable optics solve?\nThe rise of coherent pluggable transceivers addressed the critical network transport problems of cost, complexity, and scalability posed by rapidly increasing data traffic. Before these small pluggable modules, high-speed, long-distance transmission was only possible using much larger, more expensive chassis-based optical systems. When we compare these legacy platforms to today’s\n800G coherent multi-haul optical transceivers\n, network operators can reduce the power per bit delivered by 99%, down to 0.04W/Gbit. Inserting pluggable optics directly into host devices to provide optical networking capabilities, known as IP over DWDM (IPoDWDM), saves space.\nNote these larger chassis-based systems have also evolved. Modern compact modular platforms support capacity over 10 terabits per second in only two rack units of space (3.5in. or 89mm high), versus decade-old chassis-based systems that filled a seven-foot telecom rack. The\nNokia 1830 GX\nand\n1830 PSI-M\ncompact modular optical systems are modern examples, supporting 100 times the capacity in a fraction of the space.\nWhat are the challenges of using IPoDWDM?\nBy employing IPoDWDM architectures, network operators benefit from the lowest power per bit delivered and lowest footprint. However, blending the IP and Optical domain comes with challenges and compromise. Coherent optical pluggables are constrained by the router port speed, and longer links can cause port capacity loss. The biggest challenge may be the loss of a clear demarcation between IP and Optical domains and the associated management complexity. Nokia offers the\nthin transponder\ndeployment model as an alternative to IPoDWDM: This\nrecent blog\noutlines the solution and its benefits.\nReducing cost and complexity while increasing density and flexibility\nBy integrating a sophisticated DSP and other components into a standardized, pluggable module, coherent transceivers reduce the overall system cost and complexity. Network operators can buy routers or switches with open, standardized ports and add the coherent (long- or short-reach) functionality only when and where it is needed, enabling a \"pay-as-you-grow\" financial model. The miniaturization and vertical integration of components within coherent pluggables provides better power efficiency per bit transmitted. This is a crucial factor for large data centers and network operators looking to control rising energy costs and reduce their environmental footprint.\nPluggable coherent optical transceivers, especially the latest 400G, 800G, and 1.6T generation promise a critical networking advantage. As enterprises navigate through the AI supercycle, they need to reduce networking cost and complexity while increasing networking density and flexibility. Simple pluggable optics are used to network 800 and 1.6Tb/s speeds between datacom racks on different floors, whereas the latest multi-haul coherent pluggable transceivers can also network across the city, country or the continent.\nRegardless of the enterprise vertical, whether it’s research and education, fintech, health and life sciences, federal government, mission-critical utilities or oil and gas — or the networking use-case — be it building, campus or long-haul, pluggable-based architectures are top of mind. So now you know: the answer to What is a pluggable? It’s the future of optical networking."
  },
  {
    "name": "MPEG Systems wins Technology & Engineering Emmy® Award – Nokia delegates recognized",
    "link": "https://www.nokia.com/blog/mpeg-systems-wins-technology-engineering-emmyr-award-nokia-delegates-recognized/",
    "source": "Nokia_blog",
    "main_ideas": [
      "MPEG Systems wins an Emmy Award for its work on the Common Media Application Format.",
      "CMAF streamlines multimedia content delivery across various platforms and devices.",
      "The collaborative effort of industry experts is crucial for developing global technology standards."
    ],
    "tags": [
      "mpeg",
      "emmy-award",
      "cmaf",
      "video-streaming",
      "technology-standards",
      "nokia",
      "media-delivery",
      "broadcasting",
      "streaming-services"
    ],
    "original_text": "MPEG Systems wins Technology & Engineering Emmy® Award – Nokia delegates recognized\nby\nVille-Veikko Mattila\n11 Nov 2025\nHigh-quality video streaming is a behind-the-scenes engineering marvel, with every seamless viewing experience made possible by significant R&D investments and years of technical innovation by some of the industry’s brightest minds. Open global standards – which are crucial for ensuring interoperability between countless devices and systems – are key to all of this, and standards groups like the\nMoving Picture Experts Group (MPEG)\nplay a pivotal role.\nThe work in MPEG brings together the leading experts in the industry to collaboratively solve technical problems and develop essential specifications that underpin modern video delivery, from efficient compression to robust transport protocols. Developing global technology standards is a testament to how companies can work together towards a mutual goal.\nThis year, the MPEG Systems Working Group has been honored with a prestigious\nTechnology & Engineering Emmy® Award\nfor its pioneering work on the Common Media Application Format (CMAF), which has truly transformed how video is delivered across digital platforms.\nWhat is CMAF and why is it important?\nCMAF is a standardized container format developed by MPEG to streamline multimedia content delivery across diverse platforms and devices. By harmonizing fragmented MP4 files for both HTTP Live Streaming (HLS) and Dynamic Adaptive Streaming over HTTP (DASH) protocol suites, CMAF enables efficient, low-latency streaming while significantly reducing storage and bandwidth requirements. This makes it highly relevant for several industries, such as broadcasting, streaming services, telecommunications, and consumer electronics, where consistent and scalable media delivery is critical.\nCMAF completes the streaming technology puzzle by building on the ISO Base Media File Format (ISOBMFF) and working seamlessly with DASH streaming technology. The MPEG Systems Working Group, with Nokia as one of the key contributors, has previously earned Technology & Engineering Emmy® Awards for both standards, as highlighted in our earlier blogs on\nISOBMFF\nand\nDASH\n.\nKudos to Nokia delegates\nThis achievement is not just a recognition of a standard; it is a celebration of the collaborative effort and dedication of all those involved in its development. The award primarily honors the MPEG Systems Working Group, with special acknowledgment for the chairs, editors, and a list of contributors as recognized in the\nMPEG press release\n.\nAmong these contributors are two Nokia video technology experts:\nMiska Hannuksela\nand\nKashyap Kammachi Sreedhar\n, who participated in defining the video codec profile specifications for CMAF\n.\nThese specifications are vital for ensuring consistent playback and efficient streaming across devices as they establish standardized configurations that enable interoperability between encoders, packagers, and players. By streamlining content workflows, supporting adaptive bitrate switching, and accommodating future codec advancements, these profiles serve as a fundamental component of reliable and scalable media delivery.\nInnovating together to inspire tomorrow\nI want to express my heartfelt congratulations to the entire MPEG Systems Working Group for this outstanding achievement. And a special thanks to Miska and Kashyap for their years of dedication and profound contributions to video innovation.\nThe work of all the recognized individuals continues to shape the future of video technology and exemplifies the unwavering commitment to excellence in global standards development."
  },
  {
    "name": "Protecting tacit knowledge in the age of agentic AI, through a technology and legal lens",
    "link": "https://www.nokia.com/blog/protecting-tacit-knowledge-in-the-age-of-agentic-ai-through-a-technology-and-legal-lens/",
    "source": "Nokia_blog",
    "main_ideas": [
      "Tacit knowledge is becoming a critical asset in the age of agentic AI.",
      "Enterprises must protect tacit knowledge to maintain competitive advantage.",
      "Legal frameworks are essential for safeguarding tacit knowledge in AI operations."
    ],
    "tags": [
      "tacit-knowledge",
      "agentic-ai",
      "ai-ops",
      "intellectual-property",
      "automation",
      "data-governance",
      "enterprise-software",
      "knowledge-management",
      "legal-frameworks"
    ],
    "original_text": "Protecting tacit knowledge in the age of agentic AI, through a technology and legal lens\nby\nJitin Bhandari\n10 Nov 2025\nAs enterprises accelerate adoption of agentic AI, frontier models and the full AI engineering / AI Ops stack, a new challenge is emerging — one that sits at the intersection of technology, data and law. That challenge is the protection of tacit knowledge.\nFor decades, organizations recognized people, processes and their data sets as their greatest assets. In today’s AI-driven landscape, that truth is evolving. This tacit knowledge — the invisible know-how, intuition and skill embedded in daily operations — is increasingly being captured, modeled and automated by AI systems. The implications are profound for both productivity and intellectual property (IP) governance.\nTacit knowledge represents the experience-based intelligence that’s difficult to write down but essential to how an organization runs — the way engineers solve a recurring issue, how a support team prioritizes tickets or how operations teams handle complex deployments.\nPost-agentic and GenAI era, we must recognize and protect the strategic value of this tacit knowledge. One used to think rightfully that “humans are the most important resources of the company,” but considering the powerful AI engineering tech stack capabilities we have witnessed, we must now recognize that “embedded tacit knowledge in such AI Ops technology” is an equally critical asset.\nThis blog will explore some communications industry vertical-specific parallels, showing how tacit knowledge protection applies to all enterprises on their journey to agentic AI and AI Ops adoption, especially when the AI Ops is highly closed.\nUnlocking tacit knowledge as a critical asset\nIn the ever-evolving enterprises — industry-specific verticals and our communications sectors are no different — the ability to stay competitive increasingly hinges not only on network infrastructure and market reach, but also on how effectively communications providers can harness tacit knowledge — the often unstructured, experience-based know-how residing in knowledge bases leveraging AI Ops technology.\nIn industries such as telecommunications, financial services and manufacturing, competitiveness increasingly depends on how effectively organizations can\nunlock and operationalize tacit knowledge\nthrough AI. This knowledge — derived from field experience, network troubleshooting, customer interactions and process optimization — is often unstructured and difficult to codify.\nA solution that can best help unlock and harness such knowledge will have the definitive competitive advantage in the agentic AI / AI Ops era.\nWith AI Ops technologies, tacit knowledge becomes the foundation for automation across:\nNetwork and system design\n– Learning from historical best practices to guide new deployments.\nDeployment automation\n– Using AI Ops and GitOps for end-to-end delivery with minimal human intervention.\nContinuous optimization\n– Applying AI-assisted analytics to improve cost, latency and performance dynamically.\nCustomer experience automation\n– Leveraging prior fault and resolution data to accelerate issue recovery and retention.\nAI Ops-based tacit knowledge mining: technology perspective\nIn recent years, and now more so weekly, we have witnessed an unprecedent pace of innovation in GenAI, agentic AI technology and, correspondingly, its increasing abilities toward automation. Agentic AI and GenAI innovations are accelerating rapidly, but even the most capable models cannot reason over proprietary or vertical-specific knowledge unless it is deliberately infused. True enterprise differentiation will depend on how well companies can extract, structure and embed their tacit knowledge into AI systems.\nThis is where tacit knowledge infusion comes in. Unlocking tacit knowledge, along with the expertise to pair it with advanced AI engineering techniques, is essential in securing any enterprise structural advantages and our long-term differentiating values. Several key technology areas are called out below:\nKnowledge curation, synthesization, federation and vectorization:\nTacit knowledge is often scattered across documents, logs and communications. Curating and cleansing this corpus, then embedding it into vector databases, enables models to access deep organizational context.\nLLM/SLM/RLM-fine tuning:\nTacit knowledge infusion into large, small and (more recently) reasoning-centric language models using advanced continuous pre-training (CPT), curriculum training and parameter efficient fine tuning (PEFT) techniques; this enables powerful, open parameter models to acquire deep telco knowledge (with or without RAG assistance).\nAlignment and Reinforcement Learning:\nPost deployment of agentic AI application, reward-guided fine tuning using various reinforcement learning methods for human objectives is essential to achieve high response quality. This is often referred to as “alignment” and is a form of continuous (self-) learning. Advanced techniques pair human feedback with synthesized data to achieve even better tuning results.\nAgentic workflow\n: Aiming to act as a “virtual telco specialist,” an AI powered agentic application with tacit telco knowledge can execute complex tasks with a hierarchy of sub-agents and deep agents delivering complex tasks as network traffic optimization, customer care specialist and driving 360-degree customer experiences for networks.\nMultimodal analysis of telco content:\nIn telco and similar sectors, models must interpret network diagrams, call-flow charts and technical schematics. This multimodal comprehension becomes a form of encoded tacit expertise.\nWith the techniques above, one must recognize that tacit knowledge will be trained into domain-/vertical-specific multi-model farms (the trained model is a carrier of tacit knowledge). To be clear, the models (or similarly vector databases) have now “learned” the tacit knowledge, like how a human employee accumulates skills and expertise over time. In effect, once fine-tuned, models and vector-stores themselves become carriers of tacit knowledge, a form of institutional memory that persists even when employees leave. Protecting these assets becomes as critical as protecting source code or trade secrets.\nAI sovereignty and ownership of such AI Ops technology remains a critical control point. Understanding ownership of each sub-component of this complex Industry-specific verticalized AI Ops stack is critical to protecting value leakage.\nProtecting tacit knowledge: a legal perspective\nWith the increasing use of AI Ops for knowledge automation, there are critical intellectual property considerations related to tacit knowledge that must be addressed. First some basic definitions:\nCopyright\nrecognizes the value of the way in which an idea, information or knowledge is expressed or displayed, rather than the value of the idea itself. This is one of the most critical forms of IP for enterprise because copyright serves as the legal basis for software licensing, as well as for licensing of proprietary documentation such as user manuals for our equipment.\nA\ntrade secret\nis any business or technical information that is valuable because it is unknown to other parties. The information does not need to cross a certain threshold of inventiveness (like for patents) or originality (like for copyrights) to be eligible for protection. The key is that it must be kept confidential to be entitled to protection.\nRisks and control points\nPersona-based AI agents (e.g., NetOps Engineer, Security Specialist) fine-tuned on proprietary enterprise data can represent valuable trade secrets or derivative copyrighted works. When customers or vendors use such AI Ops tools, agreements must explicitly define controls points and understand risks around:\nUnauthorized model training or retraining using enterprise data.\nUse of proprietary documentation for embedding or vectorization.\nRedistribution or commercial use of derivative fine-tuned models.\nThe closed-model dilemma\nEnterprises face heightened risk when engaging closed (think open weights, training data sets) AI model vendors that do not guarantee data isolation or non-training clauses. Even if documentation is shared under confidentiality, once that data is used to train a model, control over its internalized knowledge is effectively lost.\nLegal recourse — such as breach of contract or IP infringement — is often impractical, as enterprises prioritize customer relationships over litigation. The pragmatic solution is therefore\npreventive governance\n, including:\nMetadata tagging of confidential content during knowledge curation.\nRestrictive license terms for AI-related data use.\nInternal AI Ops governance frameworks defining what can or cannot be used for model training.\nProtecting tacit knowledge requires both contractual discipline and technical design choices that ensure enterprise data sovereignty.\nStrategic implications for enterprises\nTacit knowledge, once invisible and human-bound, is now a digital asset codified in models, embeddings and process data. As enterprises scale agentic AI adoption, they must view their tacit knowledge repositories as both a:\nStrategic differentiator\nenabling automation and value creation.\nSensitive intellectual property asset\nvulnerable to leakage through AI integrations.\nEnterprises should therefore:\nMap tacit knowledge flows\nwithin AI Ops pipelines.\nDefine governance and data ownership policies\nfor AI training and deployment.\nEngage legal, technical and compliance teams\nto jointly design protective clauses and safeguards.\nPrioritize open or sovereign AI architectures,\nwhere feasible, to retain control of embedded enterprise intelligence.\nConcluding thoughts\nIn the era of agentic AI and AI Operations,\ntacit knowledge is no longer confined to people — it lives in data, processes and models.\nHarnessing it unlocks automation and innovation. Failing to protect it risks irreversible knowledge leakage and competitive erosion.\nEnterprises that combine\nAI engineering excellence\nwith\nrobust legal governance\nwill define the next generation of intelligent, sovereign organizations — where tacit knowledge is not only leveraged but secured as a core strategic asset."
  },
  {
    "name": "The 12th Brooklyn Summit marks a tipping point toward the 6G era",
    "link": "https://www.nokia.com/blog/the-12th-brooklyn-summit-marks-a-tipping-point-toward-the-6g-era/",
    "source": "Nokia_blog",
    "main_ideas": [
      "The 12th Brooklyn Summit focuses on the transition from 5G to 6G technologies.",
      "Key themes include artificial intelligence and value creation in the 6G era.",
      "Collaboration between industry and academia is essential for shaping future 6G advancements."
    ],
    "tags": [
      "6g",
      "5g",
      "artificial-intelligence",
      "nokia",
      "telecommunications",
      "value-creation",
      "nyu",
      "networking",
      "innovation"
    ],
    "original_text": "The 12th Brooklyn Summit marks a tipping point toward the 6G era\nby\nAron Heller\n10 Nov 2025\nThe year 2025 marks the halfway point between the 5G and 6G eras of wireless communications. It’s a milestone symbolizing the bridge between the groundbreaking 5G technologies that were unleashed at the start of this decade and the promise of the next generation of immersive 6G networks that await us at the end of it.\nTherefore, it is no surprise that one of the premier events of the communications industry would focus on this significant transition that will propel theoretical concepts into standardized technologies and, eventually, innovative products that shape our world.\nThe theme of this year’s\nBrooklyn 6G Summit\n, hosted by Nokia and the\nNYU Wireless\nresearch center, was aptly coined “Building what’s next” and it primarily explored two critical pillars of 6G development: artificial intelligence and value creation.\nFor the 12th time, leading voices from technology, business, academia and regulation came together to shape the future of wireless in a three-day event on the campus of the\nNYU Tandon School of Engineering\n.\nA series of keynote addresses, lively panels and physical demonstrations showcased a wide range of 6G topics surrounding AI and value creation, such as energy efficiency, security, network digital twins, the integration of Non-Terrestrial Networks and more.\nNokia President and CEO Justin Hotard kicked it all off in\na recorded fireside chat\nwith his new chief technology and AI officer Pallavi Mahajan, in which he described how Nokia will be at the heart of a new hyper-digital 6G world and the AI Supercycle and AI-Native networks that will accompany it.\n“What’s going to change as we look ahead is the opportunity for AI to be a bridge between the physical and the digital world,” he said. “We realize that for networks to be valuable in this world they need to actually be different. They need to be designed from the start for AI.”\nIn 6G, it’s all about AI\nLike other upgrades of\ngenerations of communications\n, the evolution from 5G to 6G is expected to generate faster speeds, lower latency and better performance. But 6G looks to offer much more value in creating a fusion of the digital, physical and human worlds.\nFresh off the announcement of\nthe groundbreaking strategic partnership with Nokia\n, in which it is investing $1 billion to accelerate AI-RAN innovation and lead transition from 5G to 6G, NVIDIA Senior Vice President Ronnie Vasishta highlighted the centrality of AI to the 6G future.\n“6G really distributes AI to the entire population and enterprises. It's the connectivity fabric for AI, and it cannot be underestimated how important that is,” he said. “When you look at a dynamic world and you also start to use the network as a sensor, AI becomes essential. It’s very different from the 5G world.”\nMore than 300 participants, including more than 60 speakers and panelists, attended this year’s gathering at the New York University (NYU) Brooklyn campus, and many more tuned in for the livestream, to provide an eclectic gathering of academia, industry analysts, service providers, equipment vendors and startups from various corners of the telecom industry.\nThese included a wide swath of customers, partners, engineers and innovators, as well as representatives from Verizon Wireless, KDDI Research, Intel, NTT DOCOMO, Qualcomm, Axiom Space and more.\nFor instance, Arpit Mehta, the Head of Americas Carrier Product Management at Meta, discussed the future of immersive experience with AI glasses, while wearing a pair of futuristic spectacles on his face as he described what they could do.\nKeynotes were delivered by major operators from the United States, India, South Korea and Japan, each outlining their vision of 6G implementation and predicting how it could affect industry and society.\n“6G, so far, in my view needs to solve two priorities: the uplink problem and the device problem,” said Yago Tenorio, SVP Strategy at Verizon Wireless, explaining what needed to be done to unlock the vast 6G potential. “What matters to the customer is: give him a native, cellular, connected sensor network that he can deploy around him in any way he wants.”\nLively panel discussions included those on AI Data, the role of verticals in 6G value creation and the impact of large Telco models and network digital twins.\nThere was also a special segment devoted to the\nNokia Bell Labs centennial celebration\n, in which Nokia Bell Labs President for Core Research Peter Vetter outlined how the 6G advancements of today stand on the shoulders of giants from the past 100 years of Bell Labs technology.\n“The big innovations that happened at Bell Labs in our 100-year history shaped our wireless industry,” Vetter said. “But we are not only reflecting on what happened in the past, we reflect and highlight what we are doing to shape the next 100 years. And that starts for the 6G era in the next decade.”\nWatch our three roving reporter roundups from the summit:\nIndustry and academia working together\nThe summit included nearly 40 demonstrations from Nokia and participating companies, showcasing the vast potential of future 6G networks. It also featured an Open House, where NYU Wireless students showcased a wide range of cutting-edge technologies on campus, such as nanotech labs, various robotic arms, robots and even robotic dogs.\nLater, some of these same students took on their professors in the first 6G Brooklyn Summit Game Show. The Jeopardy-style game included categories such as history, fundamentals, spectrum, 6G, AI/ML and Non-Terrestrial Networks.\nIn a crowd-pleasing upset, which bode well for the future of technology, the students emerged victorious by a decisive margin.\nIn was an outcome that did not trouble in the least one of the professors who participated.\n“We always want our students to do better than we did, so I’m delighted they beat us,” said NYU Wireless founder Ted Rappaport.\nIndeed, one of the main characteristics of the Brooklyn 6G Summit is the focus on strong collaboration between industry and academia to shape the future 6G-era together. Appropriately, the opening panel was devoted to the U.S. academic view of 6G.\n“When you bring people together when there is a new technology, you can make great strides,” Rappaport added. “It’s how you build a comfort level and a consensus on what’s most important. We are doing that for 6G.”\nBut before diving into the future, there was also room to celebrate the past as the summit honored several trailblazers in telecommunication technology. The annual Pioneer Award was presented to Dave Forney, namesake of the influential Forney algorithm in coding theory and the inventor of the modern modem. The Lifetime Academic Achievement Award was bestowed upon Prof. Andrea Goldsmith, the president of Stony Brook University and the former Dean of Engineering and Applied Science at Princeton, who shared her captivating life story and trailblazing path as a female technologist in a celebratory dinner in her honor.\nIt all added up to what Head of Nokia Standards Peter Merz said was a hopeful message for the future.\n“We had candid discussions with excellent people that are moving the ecosystem forward,” he concluded. “There is still a lot of work to be done but I am confident that we as a community will make it happen.”"
  },
  {
    "name": "Innovation for D-Band microwave transport: dual polar capacity boost",
    "link": "https://www.nokia.com/blog/innovation-for-d-band-microwave-transport-dual-polar-capacity-boost/",
    "source": "Nokia_blog",
    "main_ideas": [
      "Nokia introduces dual polar full-duplex technology for D-Band microwave transport.",
      "The new solution significantly increases capacity and efficiency for wireless networks.",
      "Commercial D-Band deployments are expected to begin between 2028 and 2030."
    ],
    "tags": [
      "nokia",
      "d-band",
      "wireless-transport",
      "5g",
      "6g",
      "full-duplex",
      "dual-polarization",
      "microwave-transport",
      "network-innovation"
    ],
    "original_text": "Innovation for D-Band microwave transport: dual polar capacity boost\nby\nGiuseppe Targia\n10 Nov 2025\nIt was great to meet so many customers and partners at our annual user group event, WaveExperts 2025. I have been reflecting on how far we have come in redefining the future of wireless transport and how much potential still lies ahead.\nAcross the world, mobile network traffic continues to surge. It’s no longer just traditional broadband usage, but increasingly data generated by AI-enhanced applications and immersive content experiences. This exponential rise in data traffic is driving operators to deploy higher capacity everywhere, while also keeping cost efficiency and sustainability in focus. Wireless transport solutions provide a flexible and cost-efficient alternative to fiber.\nIntroducing dual polar, full-duplex wireless transport\nAt Nokia, we invest significantly in research and innovation to help our customers stay at the forefront of technological developments. Last year, we completed the\nworld’s first full-duplex wireless transport trial using D-Band spectrum\n(130–175 GHz), paving the way for next-generation backhaul and fronthaul in dense urban environments.\nD-Band microwave transport can provide high spectral efficiency in a compact form factor, ensuring robust 5G backhaul capacity and performance where it’s needed most.\nNow, we have taken another major step forward: integrating dual polar operations into our D-Band full-duplex prototype, built on Nokia’s commercial Wavence Ultra-Broadband Transceiver platform.\nFor operators, the benefits of this industry-first solution are clear:\nUnlock massive new capacity without laying fiber\nLower cost per bit through higher spectral efficiency\nSimplify rollouts with compact, energy-efficient equipment ready for 6G evolution.\nHow does dual polarization work with full duplex?\nDual polarization enables the antenna to simultaneously send and receive signals in horizontal and vertical polarization planes within the same frequency channel. This effectively doubles the capacity without requiring additional spectrum.\nOur breakthrough combines the dual-polar operations with the full-duplex system, enabling a fourfold capacity increase compared to earlier solutions.\nIn practice, our compact D-Band radio solution paves the path to the next level, toward 25 Gbps in each direction over a single 2 GHz channel. This means scaling up to 50 Gbps with a traditional FDD license (2 + 2 GHz channel).\nShaping the future of wireless transport\nWith dual polarization now part of the equation, our D-Band microwave transport solution sets a new benchmark for what’s possible in wireless transport. We expect the first commercial D-Band deployments to start between 2028 and 2030, delivering higher capacity, lower costs and outstanding user experiences.\nTo learn more about our D-Band innovations and how they can transform your network, connect with our experts and visit our\nmicrowave transport webpage\n.\nLet’s continue shaping the future of wireless transport together!"
  },
  {
    "name": "Syncing up at ITSF 2025",
    "link": "https://www.nokia.com/blog/syncing-up-at-itsf-2025/",
    "source": "Nokia_blog",
    "main_ideas": [
      "Nokia showcased its optical transport solutions at ITSF 2025 in Prague.",
      "Sync over DWDM networks presents significant challenges due to asymmetry.",
      "Sync-as-a-service (SyncaaS) could enable network operators to monetize their infrastructure.",
      "Coherent network Primary Reference Timing Clock (cnPRTC) aims to enhance timing performance across networks."
    ],
    "tags": [
      "network-synchronization",
      "optical-transport",
      "dwmd",
      "syncaas",
      "nokia",
      "timing-standards",
      "ha-tt",
      "itsf",
      "telecom"
    ],
    "original_text": "Syncing up at ITSF 2025\nby\nJon Baldry\n7 Nov 2025\nThe International Timing and Sync Forum, aka ITSF, is always one of the event highlights of the year for me and my colleagues who focus on\nnetwork synchronization\n. It’s a well-organized event with a great community, a very focused agenda with deep technical discussions, and it’s always held in premier destinations. This year’s conference took place last week in Prague.\nThe Nokia team had a significant presence at ITSF this year, with multiple speaking/poster slots and a booth with live demos of both our 1830 PSS and 1830 GX optical transport solutions. Both use optical timing channel (OTC)-based approaches to deliver leading performance and functionality. The 1830 PSS OTC implementation is focused on robust large-scale core-to-edge sync networks, where cost-effective clock integration, sync manageability and operations and quick integration of new timing standards are key. The 1830 GX OTC implementation focuses on a core network timing-cloud architecture, where high-performance boundary clocks, coupled with a long-haul focused OTC, preserve critical timing budget for metro and edge networks.\nWith three days of detailed discussions covering nearly every aspect of sync and timing, the breadth of sync-related content covered at the conference was vast. In this blog I’ll focus on four topics that we as a Nokia team were focused on.\nA long way to go with understanding of sync over DWDM challenges\nThis is a topic we’ve discussed numerous times at ITSF in the past. But with increasing numbers of network operators looking at sync over DWDM as an option to reduce reliance on highly-vulnerable global network satellite systems (GNSS) such as GPS or Galileo, and with an increased number of new attendees at ITSF, it isn’t surprising that as an industry there’s still work to do to get this message across to those who need to hear it. Simply put, almost everything we do in DWDM networks to increase service speeds, spectral efficiency or network reach adds asymmetry, which creates a real challenge for sync and timing.\nThomas Hiestand, Systems Architect at Nokia, gave a presentation outlining testing results of running PTP timing over various DWDM transponders and discussed the issues these present when sync transport is required over a DWDM network. The results showed that end-to-end sync in-band, directly over DWDM traffic, gives considerable timing error and is very unlikely to work in real-world deployments. To combat this, many DWDM vendors implement OTC-based solutions that use an OTC dedicated to out-of-band sync traffic, bypassing those troublesome OTN and DWDM components that are sources of asymmetry. But as with many things in life, not all OTC implementations are equal. Thomas’ final conclusion to the question of sync over these transponders was “it depends”. If the right OTC implementation is used in core and regional networks, then there could be enough timing margin left to support sync directly over these transponders at the edge of a network, perhaps in older legacy access networks. But you need the right end-to-end sync strategy and the right OTC-based implementation in the rest of the network for this to be possible.\nAll things in life aren’t equal – you need to test, test and test again\nI just mentioned that OTC implementations aren’t equal in many ways, and these small differences can have a big impact on overall OTC performance and capabilities. Likewise, conformance to critical timing standards isn’t always equal, which can also impact sync performance across a network. A good example of this, is the specification the industry uses for telecom boundary clocks (T-BC) and telecom time synchronous clocks (T-TSC) deployed in networks with full timing support – ITU-T G.8273.2.\nThis specification defines class A, B, C and D clocks with increasingly tight specifications. Class D clocks have generally been such high precision that the only parameter generally considered in G.8273.2 compliance statements and testing is time error noise generation. François Maurice, Synchronization Systems Engineer at Nokia and Editor of the ITU-T G.8275.1 recommendation, and Billy Marshall, Senior Applications Engineer at Calnex, gave a joint presentation discussing the importance of testing the broader range of ITU-T G.8273.2 parameters. They concluded that poorly designed and validated T-BC clocks can exhibit noise transfer within a network, even though they are compliant to the time error noise generation specification. Testing all parameters is vital at all stages of T-BC development and compliance testing. Network operators looking to validate vendor compliance should also consider specifically asking for compliance to all parameters, rather than a simple yes/no to ITU-T G.8273.2 support.\nYou can learn more about this topic here\nOnce you’ve got sync distribution right, can you further monetize the network?\nGetting sync distribution over DWDM transport networks right can be a challenge, but it’s totally possible with the right solution. Nokia has deployed tens of thousands of sync cards in DWDM networks across the globe, supporting network operators with sync and timing distribution to support mobile networks and other mission-critical, sync-dependent applications. Building large sync networks that span from the core of the network right to the cell sites at the edge of the network requires high-performance, resiliency, and excellent operations, administration and maintenance (OAM) capabilities. Once these are in place with sync being delivered across a national network, what else could this investment be used for?\nStéphan Roullot, Product Line Management Director at Nokia, presented Nokia’s strategy for enabling network operators to further monetize their network infrastructure through the addition of sync-as-a-service (SyncaaS) capabilities. SyncaaS is a concept that has been discussed for many years, but without the right standardization of the service definitions and the ability to manage and operate large sync transport networks, these discussions were largely hypothetical. Stéphan outlined the work Nokia is undertaking within the standards world, alongside multiple major network operators, to bring this reality to life. SyncaaS could very soon be the next logical step for many network operators once they have built their own robust sync distribution networks.\nNew applications for sync transport\nITSF is an excellent forum for the discussion of sync challenges and applications, the industry should work towards to resolve these challenges. A good example is the concept of cnPRTC, or coherent network Primary Reference Timing Clock (PRTC). Initially, this term can be slightly confusing for those of us from the optical networking industry, as the term “coherent” in this context is totally different to coherent used in coherent modulation adopted in transmission optics. Here cnPRTC refers to the concept of connecting, or federating, multiple independent timing domains into a single larger resilient timing domain with very high performance. A key element of this architecture is high-accuracy timing transfer (HA-TT), which requires sub-nanosecond sync performance over hundreds of kilometres. To achieve this, we need to focus entirely on sync and build sync only transport, without additional DWDM traffic on the fiber. I presented a poster outlining the latest advances Nokia is making in HA-TT development using standard DWDM components to deliver the required nanosecond level performance.\nAll in all, ITSF was another great event. Record-breaking numbers for attendees and sponsoring companies show the growing level of interest in this very specialised area within our industry, and it was great to see the high level of interaction from across Nokia at the event. Next year we move on to Geneva, hope to see you there!"
  },
  {
    "name": "Nokia's social impact journey in 2025",
    "link": "https://www.nokia.com/blog/nokias-social-impact-journey-in-2025/",
    "source": "Nokia_blog",
    "main_ideas": [
      "Nokia focuses on bridging the digital divide through enhanced connectivity and digital literacy.",
      "Partnerships with organizations like UN Women and Save the Children amplify Nokia's social impact efforts.",
      "The company is shifting from disaster relief to building long-term resilience in communities."
    ],
    "tags": [
      "nokia",
      "digital-divide",
      "social-impact",
      "digital-literacy",
      "partnerships",
      "community-development",
      "5g",
      "employee-volunteering",
      "resilience"
    ],
    "original_text": "Nokia's social impact journey in 2025\nby\nNicole Arian Markazi\n6 Nov 2025\nWith\nCOP 30\ndue to begin next week it is an ideal time to reflect on  an extraordinary  2025. This past year marked a pivotal moment in our social impact approach, demonstrating our unwavering dedication to making a tangible difference in communities worldwide.\nThrough Nokia’s corporate social Impact theme of ‘bridging the digital divide’, we seek to establish a robust and sustainable connection to the digital world for education and workforce development, in communities who otherwise might not have access to such a connection. There are two major sub-themes, and at least one needs to be addressed through a corporate social impact initiative.\nConnecting the unconnected:\nReduce Coverage Gap:\nBusiness as usual but focus on additional mobile broadband subscriptions serviced or connected Fiber to the home customers for underserved areas.\nReduce Usage Gap:\nProvide internet-enabled digital devices and provide affordable access points\nEnable the connected\nProvide digital literacy skills according to relevance for communities\nEnd User safety and security awareness\nAdvanced digital skills to underserved university / colleges\nIt is this second aspect of enabling the connected to which I want to turn here. In Ethiopia, an\ninnovation hub\nin collaboration with Digital Opportunity Trust has been opened which aims to enhance the skills of young people for careers in the telecommunications sector.  The\nDigital Skills Center project in Ghana\nequally aims to advance digital skills and foster innovation, leveraging 5G deployment. Collaborators include NGIC, Plan International Finland, Plan International Ghana, three universities, and CENDLOS. With both initiatives we aim to empower the next generation, promote social inclusion, and encourage digital literacy, especially among girls and young people.\nBuilding long-term resilience\nOne significant strategic shift in 2025 was to move our focus from immediate disaster relief to building long-term resilience especially when it comes to connectivity in communities. This strategic evolution will allow us to address root causes and empower communities to better withstand future challenges.\nWe remain deeply committed to bridging the digital divide through enhanced connectivity, equitable digital access, and robust digital enablement. To strengthen our efforts we introduced new and aligned processes for both central and country management, fostering consistency and clarity across our global operations. A key improvement was the introduction of a decentralized donation distribution process, empowering local teams to nominate social initiatives more effectively to regional needs. The response from our regional teams was fantastic and enabled us to for a truly global reach, extending our impact across 5 markets and 17 countries.\nPartnerships amplify our reach and effectiveness\nOur partnership focus was also paramount, continuing our\nUN Women collaboration\n, starting new programs with\nSave the Children\nand many others and our engagements with our customers. These collaborations amplified our reach and effectiveness, allowing us to tackle complex challenges together.\nI am especially proud of how our contributions went beyond monetary funding, embracing a truly multi-layered approach. We established a robust volunteering engagement model that encourages meaningful contributions, fostering deeper, more sustained involvement from our employees.\nThree enablers for impact\nAs we move into 2026, we've identified three enablers for impact that will build upon our 2025 successes. We aim to Empower Employee Contribution by positioning our people as essential contributors and creating a strategic, impact-driven Volunteerism approach. We will Amplify Impact Through Collaboration by actively partnering with customers and government entities for greater collective good. And finally, we will Strengthen Initiatives with Expertise, not just through donating Nokia equipment and in-kind services, but also by providing our invaluable human networks.\n2025 has been a testament to Nokia's dedication to social responsibility. Every initiative, every partnership, and every hour of volunteering has contributed to a more connected and resilient world. I am incredibly proud of our collective efforts and excited for the continued impact we will make together."
  },
  {
    "name": "Why proven and secure industrial IP/MPLS is the best choice for mission-critical grid modernization",
    "link": "https://www.nokia.com/blog/why-proven-and-secure-industrial-ipmpls-is-the-best-choice-for-mission-critical-grid-modernization/",
    "source": "Nokia_blog",
    "main_ideas": [
      "IP/MPLS networks enhance reliability and security in modernizing energy grids.",
      "Utilities like Ameren and Fingrid are adopting IP/MPLS for digital transformation.",
      "IP/MPLS provides robust security features against cyber threats for critical networks."
    ],
    "tags": [
      "ip-mpls",
      "grid-modernization",
      "cybersecurity",
      "digital-transformation",
      "utilities",
      "ameren",
      "fingrid",
      "smart-grid",
      "energy"
    ],
    "original_text": "Why proven and secure industrial IP/MPLS is the best choice for mission-critical grid modernization\nby\nDominique Verhulst\n5 Nov 2025\nPower utilities everywhere are pursuing modernization initiatives aimed at bringing greater reliability, visibility and sustainability to their energy grids. Many are making IP/MPLS networks a central part of these projects, including\nAmeren\nin the US,\nFingrid\nin Finland, Stedin in the Netherlands, Red Electrica in Spain and Transpower in New Zealand.\nWhat’s driving these utilities to adopt IP/MPLS, especially when some utilities still think IP networks aren’t proven or secure like traditional technologies such as leased lines based on copper cables? They’ve realized the concerns about IP/MPLS are unfounded and that they can realize major business benefits by\nmaking IP/MPLS a key part of their grid modernization efforts\n.\nA proven foundation for critical networks\nIP/MPLS isn’t a new, untested technology. It was established by the Internet Engineering Task Force (IETF) in 1997, when Titanic dominated the box office, the Palm Pilot 1000 helped us organize our lives and we used Netscape Navigator to surf the web on our Windows 95 PCs.\nIn the 28 years since then, IP/MPLS has been continuously hardened and improved. It has also earned the trust of the world’s top communications service providers (CSPs) as the foundation for mission-critical government and industrial networks.\nSecuring the world’s largest and most important networks\nSecurity is one of the main reasons CSPs trust IP/MPLS. Deployed in some of the world’s largest and most important networks, IP/MPLS has proven that it can keep data and systems secure. It’s also constantly evolved to keep pace with cyber threats.\nAs more CSPs have adopted IP/MPLS technology, they have developed new and more robust ways to secure packet networks. Today’s IP/MPLS networks have extensive integrated security features that help utilities defend against cyberthreats, ensure data privacy and comply with regulations and standards such as North American Electric Reliability Corporation – Critical Infrastructure Protection (NERC CIP) and NIS2 in Europe.\nWhy does this matter? Because if a hacker, saboteur or massive fault causes the grid to go dark, the outage will also knock out the internet, e-commerce, global markets and much more. The power utility industry is already one of the most hardened in terms of its careful analysis of change impact and the actions it takes to ensure safe and reliable power delivery. For utilities that want to monitor their substations with high-definition video cameras or encrypt data generated by the grid, choosing a legacy technology such as TDM SDH/SONET over the more advanced, always-evolving IP/MPLS would be like securing a safe with a manual bike lock instead of the latest biometric, blockchain-based security controls.\nA driver of digital transformation for leading utilities\nThe other advantage of\nIP/MPLS\nis that it can support the smart grid applications power utilities want to deploy to modernize their communications, improve grid control and monitoring, and digitally transform transmission and distribution. It provides the flexibility they need to seize opportunities arising from distributed energy resources (DERs), along with the agility needed for enhanced grid automation, augmented reality maintenance and digital twins. With these capabilities, utilities can embrace new grid innovations at speed and scale to optimize asset performance and efficiency while exploring new business models.\nOne utility that’s reaping the benefits of IP/MPLS is Ameren, which powers 2.5 million electric customers and more than 900,000 natural gas customers in the US states of Missouri and Illinois.\nAmeren began to roll out a private fiber IP/MPLS network along its transmission lines in 2017\n, connecting substations, operations centers and other critical locations as part of its digital transformation strategy.\nWith IP/MPLS, Ameren has improved the quality of its teleprotection application—and boosted overall service quality and reliability—by ensuring substations respond quickly if there is a fault on the line. The IP/MPLS fiber network also extends Ameren’s service, security and management environments into the distribution grid, with the company planning for a private LTE (P-LTE) network to enable advanced automation, Internet of Things and workforce mobility applications. Ameren\nwon the 2020 Utility Technology Council APEX award\nfor its groundbreaking Nokia-powered P-LTE trial.\nMany other utilities have embraced IP/MPLS, too. Finland’s\nFingrid is using the technology as the backbone of a smart grid\nto manage the growing adoption of variable DERs such as wind, solar and bio-energy. In the Netherlands, Stedin Groep is working with Nokia to implement an IP/MPLS network that will overcome the bottlenecks it faces when interconnecting DERs with the main grid while also enabling new capabilities such as substation automation.\nSpain’s Red Electrica is building out an\nIP/MPLS network and a new optical transport network\nto support next-gen IP-based applications, including IoT asset management and distributed energy management. IPTO, the national grid operator of Greece and Transpower, the national grid operator of New Zealand, are making a similar moves, with each rolling out a nationwide IP/MPLS network for substation control, protection and automation.\nThese companies have seen the future. They’re building modernized energy grids that are intelligent, adaptive and highly secure, with reliable, scalable IP/MPLS technology at the core. With the clear benefits IP/MPLS can offer over TDM SDH/SONET and other legacy technologies, we at Nokia believe it is the best technology to take any power utility into the future. It’s only a matter of time until utilities’ last lingering doubts about it are wiped away completely.\nLearn more about IP/MPLS for grid modernization\nWebsite:\nIP/MPLS or MPLS-TP?\nArticle:\nThe future grid wavelength: Migrating SDH to Internet Protocol\nE-book:\nHarness the power of IP/MPLS for power grid communications\nWebsite:\nPower utility modernization"
  },
  {
    "name": "Upgrading H.26x video coding features for the AI era",
    "link": "https://www.nokia.com/blog/upgrading-h26x-video-coding-features-for-the-ai-era/",
    "source": "Nokia_blog",
    "main_ideas": [
      "Nokia's VSEI standard enhances video coding for AI-generated content.",
      "Version 4 of VSEI introduces features for authenticity and creative control.",
      "The standard supports digital signing and AI usage restrictions for video content.",
      "Generative AI is integrated for video enhancement and compression.",
      "VSEI version 4 improves machine-to-machine video optimization and metadata handling."
    ],
    "tags": [
      "nokia",
      "vsei",
      "video-coding",
      "artificial-intelligence",
      "machine-vision",
      "digital-signing",
      "content-creation",
      "video-authenticity",
      "generative-ai"
    ],
    "original_text": "Upgrading H.26x video coding features for the AI era\nby\nMiska Hannuksela\n,\nJill Boyce\n3 Nov 2025\nWhen every pixel can be faked,\nit’s getting harder to trust what we see on screen. Videos generated and manipulated using artificial intelligence (AI) are raising new questions about authenticity and creative control.\nThat’s why standards matter. Nokia is leading the way with the Versatile Supplemental Enhancement Information (VSEI) standard, designed to help everyone—from content creators to viewers—verify, protect, and enhance video in the AI era. The VSEI standard complements video coding standards like H.264 (Advanced Video Coding, AVC), H.265 (High Efficiency Video Coding, HEVC), and H.266 (Versatile Video Coding, VVC). Version 4 of the VSEI standard was recently completed, addressing emerging use cases in AI, machine vision, and the preservation of creative intent. In this blog, we summarize the new features and enhancements provided by the new VSEI version.\nVersatile Supplemental Enhancement Information (VSEI)\nThe VSEI standard plays a crucial role in enhancing video coding standards such as H.264, H.265, and H.266; collectively referred to as H.26x in this blog. While the core decoding algorithms of the H.26x standards have remained unchanged for years, the continuously developed VSEI standard ensures that H.26x codec implementations can continue to evolve to address particular use cases better.\nVSEI version 4 is a major update, providing a range of new features, as well as enhancements to features specified in earlier versions of the standard. The standardization of VSEI version 4 was a collaborative effort over a period of 2 years by more than 10 companies, with Nokia being among the most active contributors.\nThe VSEI standard specifies supplemental enhancement information (SEI) messages that can be included in coded video bitstreams. This extra information helps devices understand and process videos better. The metadata contained in SEI messages is synchronized with the coded video and can help improve picture quality or give details about the video itself. Thanks to the VSEI standard, decoders in different devices and applications can read and use this information in the same way, making video experiences more reliable and consistent.\nShepherding AI manipulations of video content\nAI-based video generation and manipulation have become increasingly accessible and sophisticated, which makes detecting AI-generated or manipulated content more difficult. Therefore, verifying the authenticity of video content has become essential.\nVSEI version 4 lets video creators use\ndigital signing\nof coded video to prove that their content is authentic and hasn’t been altered since its creation. For instance, a news agency can use digital signing to add a special mark to its videos, which allows viewers to verify that the video really comes from the agency and hasn’t been changed.\nNew regulations require showing clear labels, called\nAI markings\n, if content was created or modified by AI. This is particularly important, for example, when generative AI is used to alter the appearance of a public figure, like a politician during an election campaign. VSEI version 4 makes it possible to add these AI marking labels to videos, so viewers know when AI was involved.\nAdditionally, VSEI version 4 lets content owners set\nAI usage restrictions,\nwhich are rules about how their videos can be used by AI. For example, they can choose to prevent their videos from being used to train AI models, helping to protect their privacy and uphold content owner rights.\nGenerative AI for video enhancement and compression\nThe previous version of the VSEI standard introduced support for\nneural-network post-filtering\n(NNPF), arguably marking the first time AI was integrated in a video standard. Since then, Nokia has explored various aspects of NNPF technology, most lately\nfor concealing common problems in videos, called artefacts\n, such as contouring (uneven color areas) and blockiness (visible squares), resulting from video coding at limited bitrates. NNPF also allows content creators to control the post-processing of their videos, ensuring that their creative intent remains uncompromised.\nNow, VSEI version 4 makes\nNNPF even smarter by adding generative AI features\n. For example, text prompts can be added to videos to guide generative filtering. In addition to conventional filtering purposes, such as making videos look sharper, generative NNPF can be used to extend pictures spatially or create future pictures.\nGenerative face video coding\nis another new feature. It lets videos of human faces to be coded at bit rates as low as a few kilobits per second. This technology works by coding one main or base picture and some additional details, and then AI creates the rest of the video using those inputs. The VSEI standard includes signaling to tell decoders which neural network models and face parameters to use for the video to play correctly.\nCreator-driven post-processing\nVSEI version 4 allows video creators to specify the\npreferred order of post-processing operations\n, including color transformation, adding film grain, and rotating pictures for display. They can also set up different processing chains for different display resolutions. What's more, the film grain support, which has existed in the H.26x codecs for decades, has now been enhanced to enable the signaling of different\nfilm grain models depending on the display resolution\n. This means that videos look their best whether they’re shown on a phone or on a big screen.\nWith these additions to VSEI version 4, content creators now have better control over how their videos look in receiver devices and help preserve their creative intent.\nVideo for computer vision\nVideo is increasingly consumed by machine analysis tasks rather than watched by humans. It has been reported that\nmachine-to-machine video constitutes tens of zettabytes annually\n. Thus, optimizing video compression without compromising machine task accuracy is becoming more important. VSEI version 4 adds several new features for enhanced machine-to-machine video.\nAs videos optimized for computer vision may not provide an optimal viewing experience for humans,\nsafeguards against displaying machine-targeted video\nhave been incorporated within the signaling that describes encoder operation, post-processing chains, and neural-network post-filtering. More broadly,\nthe types of encoder optimizations\ncan be detailed in the encoder optimization information (EOI) SEI message, which allows receiving systems to make suitable adjustments to post-processing and analysis tasks.\nMany machine tasks, such as person identification, work best when the important parts, called regions of interest (ROIs), are shown in the highest possible picture quality, while the background doesn’t matter as much. Video encoding systems can use ROI detection and optimization of the pre-processing or encoding to make sure these important areas look their best, even if it means lowering the quality and bitrate of the remaining regions. For example, an encoder may use a finer quantization step size for ROIs, which can be described in an EOI SEI message. Alternatively, an encoder may\npack foreground regions at a higher spatial resolution and background regions at a lower resolution\ninto source pictures used in encoding. This can be described in a\npacked regions information (PRI) SEI message\nso the receiving system knows how to restore the original positions of the regions.\nWhen a video is split into different objects using semantic or instance segmentation, each object can be shown with its own solid color in an object mask picture. VSEI version 4 makes\ndescribing object masks\npossible,\nso these masks can be included in the same coded video clip as the original source video. This feature makes H.26x a great output format for segmented video.\nPicture metadata extensions\nSometimes video is recorded at a different speed than it is shown. For example, a video may be captured at a high picture rate, such as 240 Hz, and played back in slow motion, or vice versa. The\nsource picture timing\ninformation SEI message carries metadata about the capture timing of the pictures, helping keep track of when each picture was taken.\nSome image sensors can capture wavelengths beyond visible light. The modality information SEI message indicates whether the images in the video show\nvisible light, infrared, or ultraviolet\n,\nand can even include details about the exact wavelength.\nJust like digital photos can store extra details (metadata), VSEI version 4 lets videos include\nimage format metadata\n, so important information about how and when the video was made can travel with the file.\nNokia advances emerging use cases for coded video\nAs AI continues to reshape how we create and experience video, the need for trust and authenticity has never been greater. VSEI version 4 sets new benchmarks for transparency, creative control and intelligent machine vision. These latest enhancements empower content creators, device makers and viewers to verify, protect and enhance video, ensuring that innovation and trust go hand in hand in the digital world.\nThe new and enhanced SEI messages specified in VSEI version 4 make the H.26x coding standards even more capable of addressing the most important emerging use cases for coded video, including AI and machine vision, while safeguarding creative intent.\nAt Nokia, we are proud to have led the way in the development of the VSEI standard. Our team has contributed key technologies to the standard and held pivotal editorial roles in shaping its direction. Today, we continue to pioneer secure, intelligent and inspiring video experiences for the digital world."
  },
  {
    "name": "Designing for reliability: How Nokia SR Linux and Event-Driven Automation transform data center network design",
    "link": "https://www.nokia.com/blog/designing-for-reliability-how-nokia-sr-linux-and-event-driven-automation-transform-data-center-network-design/",
    "source": "Nokia_blog",
    "main_ideas": [
      "Nokia SR Linux and EDA enhance data center network reliability through automation and dynamic validation.",
      "Transitioning to a proactive design process reduces downtime and improves operational efficiency.",
      "The digital twin environment allows for accurate testing and validation before production deployment."
    ],
    "tags": [
      "nokia",
      "sr-linux",
      "event-driven-automation",
      "data-centers",
      "network-reliability",
      "automation",
      "digital-twin",
      "configuration-management",
      "downtime-reduction",
      "it-operations"
    ],
    "original_text": "Designing for reliability: How Nokia SR Linux and Event-Driven Automation transform data center network design\nby\nScott Robohn\n31 Oct 2025\nIn today’s data center environment, the margin for error in network design has all but disappeared. As workloads grow more distributed and real-time applications push latency limits, every design decision, from topology planning to configuration modeling, must be both accurate and validated before deployment.\nAccording to a recent\ndata center fabric reliability study\nby Nokia Bell Labs Consulting, a Bell Labs model of data center design and operations shows how the combination of\nNokia SR Linux\nand\nNokia Event-Driven Automation\n(EDA) can deliver measurable reliability improvements throughout the network lifecycle, with particularly significant gains during the design phase.\nBy replacing static, manual and error-prone design workflows with dynamic validation and automation, SR Linux and EDA help organizations transition from reactive operations to proactive, reliability-first operations.\nThe challenge\nDesign complexity and configuration drift\nIn legacy data center network architectures, referred to in the study as the Present Mode of Operation (PMO), network design remains largely a manual, static process. Engineers create configuration templates, diagrams and provisioning playbooks that often diverge from reality as soon as changes are made to production.\nKnown to network engineers as\nconfiguration drift\n, this is a major reliability risk. When production networks differ from their intended design, the result is often unexpected behavior, service-impacting outages and inconsistent operational practices.\nThese design challenges directly affect reliability. In fact, the study identified configuration and provisioning errors as major contributors to downtime and mean time to restore. When these errors are reduced, overall availability and resilience increases.\nThe solution\nSR Linux and EDA and the integrated digital twin capability\nIn the best-practice case, Future Mode of Operation (FMO), powered by SR Linux and EDA, the design process becomes dynamic, automated and inherently more reliable.\nAt the center of this transformation is the idea of the EDA digital twin, or in other words, a like-for-like virtual environment that allows engineers to design, test and validate network configurations with real production intent inputs before they’re applied in production.\nThe digital twin bridges the gap between design and deployment. Every configuration created and tested within the digital twin directly mirrors the production environment including the same device models, the same topologies and the same intent parameters.\nFor example, a network design team might use the digital twin to prototype a new data center leaf-spine deployment. They can model routing policies, VLAN segmentation and EVPN configurations in a virtualized environment identical to the intended production fabric.\nOnce that full fabric design and configuration is sufficiently tested in the twin (mirroring the full production environment), it can be deployed into production with confidence.\nReliability is also reinforced through EDA’s built-in dry-run validation, performed prior to every configuration or provisioning action. This automated check confirms consistency between the intended configuration and the live network state.\nIn practice, that means every design iteration is automatically tested for syntax, policy conflicts and operational feasibility, all of which reduce the probability of human-induced failures, resulting in up to 95% reduction in downtime for configuration and provisioning tasks.\nDesigning with intent\nEDA’s automation framework introduces a fundamental change to how design intent is expressed and maintained. What this means in practice is that instead of static templates or per-device scripts, EDA uses intent-based inputs which are abstract representations of the desired network state that are automatically translated into validated configurations.\nIn the design phase, this allows engineers to model network intent, validate network dependencies, and simulate failure and recovery behavior.\nFor example, a network architect could model how an active-active spine layer behaves during link failure events, measure expected failover delay and verify that redundancy protocols such as BGP ECMP or EVPN-VXLAN converge as intended.\nEDA’s validation engine then ensures that when the design moves from the digital twin to production, all tested intents and configurations are preserved. This approach drastically reduces common cause configuration failures and protection errors, both of which were modeled as key contributors to downtime in the Bell Labs analysis.\nImpact on reliability and business outcomes\nAccording to the study, organizations transitioning from a legacy PMO architecture to SR Linux and EDA (FMO2) achieved up to 23.9X less or a 96% reduction in downtime.\nWhen the design process itself becomes reliable, meaning validated, automated and executable, the benefits carry forward into deployment, operations and ongoing maintenance. The model predicts that downtime due to design and deployment issues can be reduced by 81% compared to the legacy PMO scenario.\nFor example, incorrect configurations no longer find their way into production. Upgrades and expansions inherit validated design logic, and intent consistency ensures that what engineers designed is what’s actually running in the network.\nFrom a business perspective, this reliability translates directly into measurable value.\nThe study quantifies the financial impact of reduced downtime in three areas:\nPenalty Cost Reduction\n(up to 60%) by preventing SLA violations during rollout.\nRevenue Loss Reduction\n(up to 53%) by maintaining availability of digital services.\nReputation Loss Reduction\n(up to 44%) through improved customer experience and operational trust.\nIn practical terms, for a mid-sized enterprise or service provider, these design-driven reliability gains can equate to millions of dollars annually in avoided losses and operational savings.\nSummary\nAs networks become more complex and mission-critical, the ability to design with confidence is emerging as a key competitive advantage.\nThe SR Linux and EDA solution empowers data center architects to bridge the legacy gap between design and deployment, ensuring that every configuration, topology and policy is tested and validated in advance.\nThrough its digital twin environment and pre-deployment validation, Nokia’s solution makes reliable design a reality, eliminating guesswork, minimizing risk and enabling continuous innovation.\nThe foundation of operational reliability is a well-validated design, and with SR Linux and EDA, that foundation has never been stronger.\nThis is the first blog post in a series. To see the other posts, visit:\nhttps://www.nokia.com/data-center-networks/blogs/\nYou can also find out more about the study\nhere\nand read the executive summary\nhere\n."
  },
  {
    "name": "Building a more resilient, sustainable and equitable digital future",
    "link": "https://www.nokia.com/blog/building-a-more-resilient-sustainable-and-equitable-digital-future/",
    "source": "Nokia_blog",
    "main_ideas": [
      "Nokia emphasizes the role of digital technology in achieving climate goals at COP30.",
      "The company showcases its sustainability efforts and innovations at the Finland Pavilion.",
      "Digitalization is critical for decarbonizing industries and enhancing climate resilience."
    ],
    "tags": [
      "nokia",
      "cop30",
      "sustainability",
      "digitalization",
      "climate-change",
      "renewable-energy",
      "smart-grids",
      "ai",
      "telecommunications",
      "decarbonization"
    ],
    "original_text": "Building a more resilient, sustainable and equitable digital future\nby\nTony D’Arcy\n30 Oct 2025\nIn a little over a week’s time, a small group of Nokians will be in Belem, Brazil for the 2025 United Nations Climate Change Conference, or Conference of the Parties of the UNFCCC, more commonly known as\nCOP30\n. This COP takes place ten years after the famous Paris Agreement of 2015, and is the halfway point to 2030, when countries are expected to meet their climate pledges under the Paris Agreement.\nWhy go?\nNokia’s networks support approximately 271 million fixed connections and 5.6 billion mobile subscriptions across 120 countries. We are the only truly global supplier of mobile and fixed networks and sustainability is a driver of long-term value creation for Nokia.\nWe have been to previous COPs, and as I’ve said\nbefore\n, the COP process is critical. Collaboration is also critical, and digital technologies are increasingly seen as a key lever in the decarbonization of the most energy intense industries. The transition to renewables and smart grids, the globally recognized future of energy, is impossible without digital technology and connectivity networks. This year in COP30, countries are expected to provide their new climate transition plans known as Nationally Determined Contributions (NDCs). It is already clear many of these plans will include increasing reference to the critical role of digitalization in achieving these plans\nThe Finnish Pavilion at COP will highlight themes such as decarbonizing industry, digitalization, circular and bioeconomy, and climate resilience, showcasing Finland as a technology and climate innovation hub.  We will join Finnish business and industry climate leaders under Finland's delegation at the Finland Pavilion where we are hosting panels with customers and global experts on key topics including AI and sustainability, digital resilience, digital equity, and sustainable finance. We will also meet customers, partners and other key stakeholders and participate in other partner programs as well as supporting the International Telecommunication Union’s Green Digital Action track.\nDigitalization’s critical enabling role\nDigitalization and enhanced connectivity are a critical part of the solution to decarbonizing and dematerializing physical industries that significantly contribute to global carbon emissions. This is our handprint – it represents the enablement effect of the technology solutions we provide. We aim to maximize this handprint, as it provides our greatest potential impact on climate change.\nOur recent\nPeople and Planet impact report\nshows this handprint in action, working with customers across different industries to help them achieve their goals. A great example here includes the ESB Smart Grid in Chattanooga, using our fiber optic network. The Smart Grid allows many processes that once required site visits to now be handled automatically or remotely, reducing EPB’s carbon footprint in 2023 by 250,000 truck miles, with a reduction of 3.6 million lbs of CO2 emissions and 915,889 lbs of waste diverted from landfill. Perhaps the biggest impact of the Smart Grid has been the reduction of power outages by 50% during severe weather events, saving customers $55 million per year.\nAnother example is our work with\nCoreWeave\n, the AI Hyperscaler™, to build a high-performance wide area network across the US and Europe. Nokia continues to work to enable solutions that support\nmore traffic within the same energy envelope\n, contributing to more efficient scaling of AI infrastructure.\nMinimizing our footprint\nWe are doing this while also continually striving to minimize any potential negative impacts of technology.  This is our “footprint”. We have both an environmental and a social footprint. We collaborate throughout our value chain to continually minimize our footprint.\nAs part of this process, we are working with our suppliers on reducing the embodied emissions in our products. As many customers begin to move toward renewable and sustainable energy sources in their operations, the footprint of our supply chain becomes their focus. In 2024, for example, we worked with over 9,300 suppliers globally, with 80% of our supplier spend concentrated among approximately 400 partners, all engaged through our responsible sourcing program.\nOver the past five years, we have reduced our total greenhouse gas emissions by 36%\n, including a 56% reduction among final assembly suppliers and an 85% reduction in our own facilities. Our chipsets have made significant generation-over-generation advances in power consumption, such as FP5 consuming up to 75% less power than the previous generation, and our AirScale 5G massive MIMO base stations using up to 50% less energy compared to 2019.\nSustainable value\nHandprint and footprint, digitalization and decarbonization, climate resilience and adaptation are all issues that our customers and partners are grappling with.\nEighty one telco operators\nfor example, have set or committed to near-term science-based targets under the Science Based Targets Initiative (SBTi), representing nearly half of the industry by connections and two-thirds by revenue. Seventy one of these targets have been validated by the SBTi. The benefit of being at COP is to emphasize the criticality of digitalization and advanced connectivity to climate, government and industrial stakeholders   – through the meetings,  and the panels that we are hosting on AI and sustainability, disaster-resilient infrastructure, digital equity, and sustainable finance. To find out more, check out our\nCOP 30 webpage\nand follow our social media channels in the coming weeks to discover the key takeaways. And for those in Belem, come visit the Finland Pavilion and join in the discussions. Collaboration and co-innovation is a necessity to reach our common goals."
  },
  {
    "name": "Beyond the horizon: How network APIs optimize drone flights",
    "link": "https://www.nokia.com/blog/beyond-the-horizon-how-network-apis-optimize-drone-flights/",
    "source": "Nokia_blog",
    "main_ideas": [
      "Network APIs enhance drone operations by enabling reliable BVLOS connectivity.",
      "Mobile networks like 4G LTE and 5G provide extended range and reduced interference.",
      "Network as Code allows for real-time network data access and programmable connectivity.",
      "Dynamic adaptation during flights improves safety and operational efficiency.",
      "Mobile network-connected drones represent a significant advancement in drone technology."
    ],
    "tags": [
      "drones",
      "network-apis",
      "bvlos",
      "5g",
      "network-as-code",
      "real-time-data",
      "drone-operations",
      "mobile-networks",
      "infrastructure-inspection",
      "package-delivery"
    ],
    "original_text": "Beyond the horizon: How network APIs optimize drone flights\nby\nMikko Jarva\n29 Oct 2025\nDrones are rapidly transforming industries, from infrastructure inspection to package delivery and emergency response. But many applications require operation Beyond Visual Line of Sight (BVLOS), presenting unique challenges. Reliable network connectivity is paramount for safe and efficient BVLOS drone operations, and that's where Network APIs come in\nTraditional radio frequency (RF) communication and WiFi have long been the standard for drone control and data transmission. However, their limitations in range, interference susceptibility, and spectrum availability hinder the growth of Beyond Visual Line of Sight (BVLOS) operations. This is where mobile network-connected drones, empowered by Network as Code, offer a transformative solution.\nMobile Networks: Expanding the Horizons of Drone Operations:\nCellular networks, particularly 4G LTE and the emerging 5G technology, provide a compelling alternative including:\nExtended Range:\nTheoretically unlimited operational distance, limited only by cell tower coverage.\nEnhanced Reliability:\nReduced interference compared to crowded RF spectrums.\nIncreased Flexibility\n: Global accessibility, minimizing the need for costly redesigns.\nHigh-Speed Data:\n5G's high throughput enables real-time video streaming, AI processing, and large-scale drone operations.\nLow Latency:\nFaster response times improve safety and efficiency, enabling compute-intensive functions to be offloaded to the cloud.\nSupport for Many Devices:\n5G's capacity allows for the management of numerous drones simultaneously, crucial for swarm operations and Unmanned Traffic Management (UTM) systems.\nNetwork as Code: Enriching Intelligent Drone Control:\nNetwork as Code takes mobile network connectivity a step further. Working together with Nokia Drone Networks and other leading drone platforms, Network as Code provides direct access to real-time network data and programmable connectivity through APIs. This helps in a few distinct ways:\nBefore Takeoff:\nNetwork-Aware Route Optimization: Drone management systems can plan routes that avoid congested areas, low-signal zones, and restricted airspace, ensuring mission success.\nOptimal Network Selection: The system can choose the best mobile network provider for the planned route, guaranteeing bandwidth and latency.\nDuring Flight:\nDynamic Adaptation: The drone operating system can monitor network signal strength and congestion in real-time, adapting to changing conditions mid-flight.\nQuality on Demand (QoD): Bandwidth and latency can be dynamically adjusted to meet the demands of specific tasks, such as high-quality video streaming.\nPost-Flight:\nData-Driven Insights: Network data provides valuable information for optimizing future flights and improving operational efficiency.\nRegulatory and compliance:\nNetwork-assisted positioning and network status verification ensure compliance with airspace regulations.\nConclusion:\nMobile network-connected drones, especially when enhanced by Network as Code, represent a significant advancement in drone technology. They overcome the limitations of RF and WiFi, enabling safer, more reliable, and efficient BVLOS operations across a wider range of applications. The ability to dynamically adapt to changing network conditions and optimize routes in real-time makes Network as Code an essential component for the future of drone operations. This technology is not just about extending range; it's about creating a smarter, more responsive, and ultimately safer drone ecosystem."
  },
  {
    "name": "How thin transponders help you get more from coherent pluggables",
    "link": "https://www.nokia.com/blog/how-thin-transponders-help-you-get-more-from-coherent-pluggables/",
    "source": "Nokia_blog",
    "main_ideas": [
      "Thin transponders provide a third option between embedded transponders and Coherent Routing.",
      "They offer lower CAPEX, power consumption, and smaller footprint compared to traditional solutions.",
      "Thin transponders enable technology lifecycle separation, enhancing operational flexibility for network operators."
    ],
    "tags": [
      "thin-transponders",
      "coherent-routing",
      "network-operators",
      "capex",
      "power-consumption",
      "fiber-capacity",
      "pluggable-technology",
      "nokia",
      "optical-transport"
    ],
    "original_text": "How thin transponders help you get more from coherent pluggables\nby\nFady Masoud\n28 Oct 2025\nIn life, we sometimes face choices where neither option is perfect and both require trade-offs. Imagine you're choosing between two cars: one is a fuel-efficient compact car with excellent mileage but low horsepower, and the other is a powerful sports car that delivers thrilling performance but consumes far more fuel. The dilemma lies in balancing practicality with passion. But what if you had a third choice, a car that combines good horsepower and decent fuel consumption?\nNetwork operators no longer have to choose between embedded transponders and Coherent Routing, also known as IP over DWDM (IPoDWDM), when it comes to deployment models for coherent pluggables. There’s now a compelling third option:\nthin transponders\n.\nWhy consider thin transponders?\nIn a\nprior blog\n, we discussed how thin transponders provide a new deployment model by leveraging the latest generation of pluggable coherent technology. They combine some of the strengths of embedded transponders and Coherent Routing without the related disadvantages.\nJust like embedded transponders, thin transponders offer multiple client ports (100G, 200G, 400G or 800G) for gray optics to carry traffic from other platforms such as routers, along with multiple line ports for high-capacity coherent pluggables such as 400G ZR, 400G ZR+, 800G ZR or 800G ZR+.\nSimilar to IPoDWDM solutions, thin transponders offer lower CAPEX, lower power consumption and a smaller footprint, but without operational challenges. They also combine some of the advantages of embedded transponders, such as multiple client-side aggregation, operational domain separation and some of the optical capabilities of full-fledged embedded transponders.\nThin transponders also enable “technology lifecycle separation” between the photonic and the IP layer, which allows network operators to benefit from the latest generation of coherent pluggables, such as ICE-X 800G ZR/ZR+, in existing 400G routers. This helps them maximize return on investment (ROI) and operational flexibility by avoiding a network-wide upgrade to the latest 800G-capable generation of all routers.\nWhile thin transponders enable compelling reductions in power consumption and footprint, embedded transponders remain the best choice for improving spectral efficiency and maximizing fiber capacity. For example, embedded transponders deliver on average 20% more fiber capacity than pluggable-based thin transponders for the same optical link.\nComparing DSP use by embedded and thin transponders\nThe primary difference between embedded and pluggable solutions lies in the digital signal processor (DSP). With more space and power to work with, the DSP for embedded solutions can be physically larger, support more gates and enable more functionality. This includes a full suite of advanced features, such as support for a wide range of modulation formats and very high chromatic dispersion compensation, which enables networks to extract maximum capacity per fiber.\nIn contrast, when packaged inside a compact coherent pluggable, such as 800G QSFP-DD or OSFP, the same DSPs must operate within stringent space and thermal constraints, which limits the set of capabilities that can be supported. Even so, coherent pluggables still deliver significant advantages by reducing space and power consumption compared to traditional systems. And while they cannot match the full performance and feature set of full-fledged embedded optical engines, the latest generation based on 3 nm technology can still comfortably reach long-haul distances, as highlighted in Table 1.\n3 nm DSP in coherent pluggables - Thin transponders\n3 nm DSP in embedded transponders\nNumber of gates\n400 million\n1 billion\nMax Baud rate\n135G baud\n200G baud\nModulation\n16-QAM, 16-QAM PCS, QPSK\n16-QAM PCS, 64-QAM PCS\nCompensation for chromatic dispersion (terrestrial)\n~20-30 ns/nm\n164 ns/nm\nMax reach at 800 Gb/s (terrestrial)\n1,700 km\n5,000+ km\nTable 1: Comparison of 3nm DSPs in embedded transponders and in 800G coherent pluggables\nUse cases for thin transponders\nAs noted, thin transponders combine key attributes of embedded transponders and Coherent Routing, providing cost-effective, flexible and highly reliable optical transport that leverages the latest generation of coherent pluggables. Thin transponders are the solution of choice when space and power are limited, and a low variety of client services is required. They also reduce sparing costs because the same 800G coherent pluggables can be used in Coherent Routing/IPoDWDM applications and thin transponder modules. Figure 1 depicts a typical thin transponder application: connecting data centers.\nFigure 1: Using a thin transponder to connect data centers\nAnother key application of thin transponders is backhauling data center traffic at submarine landing terminal equipment (SLTE) sites. Embedded transponders are used to maximize fiber capacity from the wet plant. Thin transponders are used to reduce power consumption and footprint for traffic in the dry plant, connecting inland data centers as depicted in Figure 2.\nFigure 2: Data center backhaul using thin transponders\nCase study: Quantifying the benefits of thin transponders\nTo quantify the benefits of thin transponders, we performed a network analysis on a fully filled 1,000 km optical link using average sellable price (ASP) and publicly available technical specifications (power consumption, footprint, density, capacity–reach, etc.). Figure 3 shows the area of focus for the analysis, which compared an embedded transponder, a thin transponder and Coherent Routing/IPoDWDM, covering all hardware units inside the dash-lined rectangles.\nFigure 3: A detailed view of all three deployment models used in the analysis\nAs highlighted in Figure 4, thin transponders offer compelling benefits as a third option in addition to embedded transponders and Coherent Routing/IPoDWDM. They offer savings of up to 41% in CAPEX ($/G), up to 36% in power consumption (W/G) and up to 50% in footprint (RU). If we were analyzing vehicles, we could say a thin transponder is a car that gets good gas milage and delivers solid performance.\nFigure 4: Benefits of thin transponders over a fully filled 1,000 km optical link\nFind out more\nNokia offers a full suite of thin transponders, supported on a wide set of platforms, to address the requirements of any application.\nWatch our webinar on the pluggable transceiver revolution\nto learn more about how thin transponders combine key strengths from embedded transponders and Coherent Routing/IPoDWDM to enhance deployment flexibility while providing very compelling economics of reducing CAPEX, power consumption and footprint."
  },
  {
    "name": "5G for defense: How Nokia is driving innovation for the U.S. military",
    "link": "https://www.nokia.com/blog/5g-for-defense-how-nokia-is-driving-innovation-for-the-us-military/",
    "source": "Nokia_blog",
    "main_ideas": [
      "Nokia Federal Solutions provides 5G technology tailored for U.S. military operations.",
      "Private 5G networks enhance secure communication in mission-critical environments.",
      "Tactical 5G solutions enable real-time data sharing in austere conditions.",
      "Nokia's technology supports the DoD's Combined Joint All-Domain Command and Control vision.",
      "Nokia is shaping the future of military communications with next-generation standards."
    ],
    "tags": [
      "nokia",
      "5g",
      "military",
      "tactical-networks",
      "secure-communication",
      "cjadc2",
      "federal-agencies",
      "mission-critical",
      "innovation",
      "technology"
    ],
    "original_text": "5G for defense: How Nokia is driving innovation for the U.S. military\nby\nJacqueline Lampert\n28 Oct 2025\nAt a sprawling military base in the American Southwest, aircrews prepare for flight operations while support teams stream maintenance data in real time from the flightline. A few thousand miles away, a forward unit activates a secure private 5G network from an MRZR, linking unmanned assets and ISR sensors across the battlespace. These are not isolated moments; they’re part of a growing transformation fueled by Nokia Federal Solutions’ 5G solutions.\nMission-driven innovation for the U.S. military\nIn today’s complex and contested operating environments, the ability to communicate securely, reliably, and at speed is mission critical. Whether on a remote airfield, on a training range, or at the tactical edge, U.S. military forces need infrastructure that moves with the mission, not behind it. Nokia Federal Solutions is delivering exactly that\nAs a dedicated U.S.-focused entity within Nokia, we bridge commercial innovation with mission assurance—bringing carrier-grade 5G adapted for military and federal operations. From private base-wide deployments to rapidly deployable tactical networks, Nokia’s platforms power the communications backbone for the modern warfighter.\nPrivate 5G: Secure connectivity for federal missions\nOur 5G private wireless solutions give federal agencies and the U.S. Department of War the best of both worlds: commercial-scale innovation and mission-specific customization.\nWhether you’re running a large installation, managing a logistics hub, or supporting operations in the field, our technology delivers high-performance, secure connectivity where it’s needed most.\nBuilt for mission-critical environments, our solutions offer:\nCarrier-grade RAN and core, adapted for private network environments\nBroadband coverage across bases, hangars, airfields, and ranges\nSecure, resilient performance in rugged or RF-challenged locations\nSupport for dynamic spectrum sharing, microwave transport, and backhaul\nFrom inside aircraft fuselages to a -30-degree training range, our technology ensures always-on, high-performance connectivity that keeps your mission moving.\nTactical 5G: Built for the edge\nWhen the mission goes beyond the wire, Nokia goes with it.\nOur Tactical Private Wireless solutions, led by the Nokia Banshee family, deliver self-contained, portable 4G/5G networks that enable real-time voice, video, and data in austere and disconnected environments. With capabilities like:\nRapid deployment in minutes\nSelf-forming, self-healing mesh networking\nLow-latency, high-bandwidth communications\nSeamless interoperability with legacy comms, SATCOM, and ISR systems\nThese systems are field proven by federal users in operations ranging from disaster response to tactical missions. Whether mounted in vehicles, worn in a backpack, or deployed in fixed command posts, the Nokia Banshee product family delivers operational advantage at the tactical edge.\nAligned with the CJADC2 vision\nAs the DoD drives toward Combined Joint All-Domain Command and Control (CJADC2), the network becomes the foundation of every mission. Nokia Federal’s 5G architecture is designed for seamless, secure, and scalable operations across domains that enable faster decision cycles and real-time data fusion across the battlespace.\nAI/ML-capable infrastructure for edge analytics\nOpen, standards-based architecture for interoperability\nMission-configurable networks for joint and coalition use\nWe’re not just enabling communication—we’re accelerating decision advantage.\nUse Cases: Where innovation meets mission\nNokia 5G private and tactical solutions are already supporting real-world federal use cases:\nFlightlines\n: Enable high-speed data offload for efficient aircraft operations and maintenance\nContested logistics\n: Maintain comms integrity across supply chains\nTraining ranges\n: Deliver realistic, immersive training with real-time feedback\nEmergency services\n: Support first responders with secure, deployable broadband\nMicrowave transport\n: Ensure robust backhaul and redundancy\nDynamic spectrum sharing\n: Optimize frequency use in congested environments\nReady for what’s next\nAt Nokia Federal Solutions, we’re not just keeping up with technology, we’re helping define its future. As 5G matures and 6G emerges, we’re working hand-in-hand with U.S. government stakeholders to shape next-generation standards and deliver systems that serve mission needs now and into the future.\nMission readiness starts with the right network. Let’s build it together.\nVisit our 5G private wireless solutions page or reach out to our team to explore how Nokia Federal can help transform your communications landscape."
  },
  {
    "name": "Making video streaming possible",
    "link": "https://www.nokia.com/blog/making-video-streaming-possible/",
    "source": "Nokia_blog",
    "main_ideas": [
      "Nokia leads in video compression technology, enabling seamless streaming of high-definition content.",
      "The company has developed multiple generations of video codecs, improving efficiency and quality.",
      "Nokia engages in licensing agreements to foster innovation and protect its intellectual property."
    ],
    "tags": [
      "video-compression",
      "streaming",
      "nokia",
      "video-codecs",
      "intellectual-property",
      "licensing",
      "multimedia",
      "3d-video",
      "innovation"
    ],
    "original_text": "Making video streaming possible\nby\nVipul Mehrotra\n27 Oct 2025\nImagine if I told you that before watching a three-hour 4K movie at home, you had to choose what you were going to watch two weeks in advance. Sounds crazy, right? But without video compression technology, it would take that long to download the movie. There would be no turning on your TV or tablet and hitting play straight away.\nA leader in video technologies\nNokia is a leader in the development of video technologies, including video compression technology that makes streaming of High-Definition video possible. Our inventors have been heavily involved in the development of all market-adopted video codecs, from the H.264/Advanced Video Coding (AVC) standard in the early 2000s to the H.266/Versatile Video Coding (VVC) standard completed in 2020. Each of these generations of codecs have halved the bitrate required compared to their predecessor without compromising picture quality, and make streaming possible for billions of viewers every day.\nWith over 30 years of research and innovation, our multimedia assets include key technologies related to video processing, coding, storage, display, user interface, and much more. So far, our leadership in this area has been recognized by five Technology & Engineering Emmy® Awards.\nThis work continues today. For example, over the last year our researchers have made significant contributions to a new edition of the versatile supplemental enhancement information (VSEI) standard, which is intended to be used with H.265/HEVC and H.266/VVC video codecs, and to the explorations by the Joint Video Experts Team towards the next video coding standard, which is likely to be known as H.267.\nWe are also leading the way with volumetric video, a technique that captures 3D representations of people or objects from multiple camera angles so that viewers can move around or change their viewpoint in real time rather than being fixed to a flat 2D perspective.\nWe have developed a standards-based real-time\nvolumetric video system\n(using V3C / MPEG Immersive Video standards) that aims for low-latency streaming over existing networks, enabling richer 3D video communication without needing entirely new infrastructure.\nVirtuous circle of innovation\nPatent license agreements enable companies to build on our proven technologies. Earlier this year, we reached a patent agreement with Amazon covering the use of our video technologies in Amazon’s streaming devices and Prime services. And, we have successfully concluded license agreements with five other streaming companies, including a new agreement signed with Starz last week.\nDeals like this fuel the virtuous circle of innovation: we license Nokia’s innovations and contributions to industry standards to other companies so they can build on our work. In return, they pay royalty fees for the use of our technology, which we re-invest, along with additional investment, in developing the next generation of inventions.\nLitigation always a last resort\nWhile we always prefer amicable agreements, we stand ready to defend our intellectual property when needed. For example, we recently initiated litigation against Paramount in the US, Brazil, Germany and the UPC concerning the unauthorized use of our video technologies in their streaming services. Our preference is to avoid litigation, but Paramount left us with no choice. We hope that Paramount engages with us to conclude an agreement under which they will pay for the use of our technologies in their streaming services. And we remain prepared to pursue legal action against others who choose not to timely conclude licenses on fair terms.\nFast forward to the future\nLooking ahead, our ongoing multimedia research and standardization work, as well as the licensing of these innovations will continue to power the next wave of multimedia experiences. Stay tuned for more exciting updates on our research milestones, licensing programs, and the technologies set to enable tomorrow's video experiences!"
  },
  {
    "name": "6G: Your passport to the immersive experience revolution",
    "link": "https://www.nokia.com/blog/6g-your-passport-to-the-immersive-experience-revolution/",
    "source": "Nokia_blog",
    "main_ideas": [
      "6G will enhance immersive experiences through improved network capabilities for XR applications.",
      "Smart glasses and headsets are evolving, enabling more advanced mixed reality experiences.",
      "Nokia's RXRM system enables low-latency immersive experiences for various industries."
    ],
    "tags": [
      "6g",
      "extended-reality",
      "smart-glasses",
      "nokia",
      "augmented-reality",
      "virtual-reality",
      "ai",
      "mixed-reality",
      "telecommunication",
      "immersive-experience"
    ],
    "original_text": "6G: Your passport to the immersive experience revolution\nby\nKlaus Pedersen\n,\nStefano Paris\n27 Oct 2025\nWhat if, as you stood among the ruins of ancient Rome, the stones beneath your feet began to glow and the city rebuilt itself around you? eXtended Reality (XR) encompasses technologies that merge the digital and physical worlds, enabling immersive experiences that blur the line between reality and the virtual realm. While 5G-Advanced has been designed to support XR applications, the growing ecosystem of smart glasses and headsets will demand even greater network capabilities, especially as more people take these immersive experiences outdoors. To fully realize this potential, 6G must deliver enhanced performance, supporting high download and upload data rates for real-time applications with stringent latency requirements, anytime, anywhere.\nSmart glasses pivot\nXR headsets such as the Microsoft HoloLens and Magic Leap achieve immersive mixed reality experiences for enterprise and creative use by combining onboard computing with advanced spatial mapping. These types of headsets require efficient rendering of complex 3D multimedia objects, either locally on the device or through edge cloud processing, to ensure smooth and realistic interactions.\nIn recent years, a new class of lightweight, stylish smart glasses has emerged. This evolution began with audio and camera glasses like Amazon Alexa Echo Frames and Meta Ray-Ban Stories Gen 1, offering basic functionalities such as video capture and voice assistance. By 2023, display-less AI glasses, exemplified by Meta Ray-Ban Stories Gen 2, introduced contextual large language model (LLM) capabilities, selling\ntwo million units\n. These glasses enable users to capture photos and videos, listen to audio, take calls, and interact hands-free with an AI assistant using voice commands. This year we also saw the debut of head-up display (HUD) smart glasses, including Meta Ray-Ban Display, Google Android XR Glasses, and Brilliant Labs’ Halo, which overlay text, images, and simple videos. Looking ahead, fully immersive 6DoF (six degrees of freedom) AR glasses, such as the Meta Orion prototype, promise wide-field-of-view color displays with spatially anchored 3D interactions, despite ongoing optical challenges. ABI Research forecasts 15 million shipments of no-display AI glasses alone by 2030 with a CAGR of nearly 68%.\nExtended reality experiences\nThere is also a broad set of XR experiences that don’t require smart glasses. These services instead run on devices like smartphones, tablets or PCs. Consumer use cases comprise of garden furniture try-out, navigation, social media filters or location-based augmented reality mobile games such as Pokémon Go.\nNokia\nRXRM\n(Real-time eXtended Reality Multimedia) is a system for streaming low-latency 360° video with spatial 3D audio, enabling immersive real-time experiences such as remote supervision, situational awareness and teleoperation. When paired with Nokia’s\n5G 360° camera\n, RXRM becomes a full end-to-end solution for immersive media in industrial, entertainment, defense and remote operations contexts.\nNokia also works with partners on\nnetwork digital twins\n. This XR applications enable operators to utilize virtual replicas of real-world infrastructure to simulate, monitor, and optimize network performance in real time.\nAt Nokia, we’re pushing the boundaries of immersion with groundbreaking research into\nthermal haptics technology\nfor XR that lets users feel temperature changes through touch. By tracking how heat moves through different materials, Nokia is pioneering conductivity-based thermal haptics that make digital experiences more lifelike than ever.\nThe new XR enablers in 6G\nFrom a 3GPP standards perspective, the evolution of XR enablers accelerated with 5G-Advanced and is anticipated to advance further with 6G. Recent 5G-Advanced XR enablers include enhanced support for adaptive low-latency traffic, building on the Nokia-developed and award-winning Low Latency, Low Loss, Scalable throughput (\nL4S\n) scheme, which boosts Quality of Experience (QoE) of variable rate services. Additionally, increased XR application awareness in the radio access network (RAN) along with other capacity-enhancing features boost overall XR capacity and QoE, e.g. by means of exploring the\nnew PDU-set information\n. Terminal power-saving features for XR services have also been introduced to extend device battery life and make XR suitable for everyday use, a key factor for driving mass-market adoption.\nWith today’s typical 5G deployments, XR capacity is on the order of 6-10 simultaneous users per 100MHz carrier macro cell at 3.5GHz, when considering demanding users with 4K high-quality real-time video and 10-15ms bounded one-way latency for the RAN part.\nThese\n5G-Advanced XR features\nare projected to largely be included also in 6G. At the same time 6G is poised to offer significant better XR performance and pave the way for the next generation of XR services and devices, as expressed in Nokia’s\n6G Day One white paper\n. 6G will provide superior support for high data rate, real-time applications with bound latency constraints, wherever needed. This will be achieved through a novel design of the\n6G RAN protocols\n, featuring more efficient parallel processing and enhanced support for step-wise introduction of new device types so as to support emerging XR use cases. Specifically, the development of innovative XR devices featuring various form factors and powered by AI-driven capabilities for seamless interaction between users and cyberspace necessitates a more adaptable approach to designing the RAN protocol stack, rather than relying on a rigid, monolithic framework. Moreover, an\nadaptive QoS\nscheme is anticipated, enabling the RAN to autonomously upgrade and downgrade QoS metrics within a given range, working in collaboration with applications to achieve a higher QoE.\n6G’s AI-native capabilities\nwill further enhance XR performance by learning XR traffic characteristics to autonomously adapt the network and serve it more efficiently on the radio interface. The modernized, lean, and AI-native 6G physical layer will also contribute to substantially increase performance for XR services.\nAdvancements through compute-network coordination will also be pursued for 6G. This involves a seamless integration between 6G systems, service exposure platforms, and cloud platforms to optimize server selection and dynamically offload compute services. By leveraging autonomous real-time network coordination and system status exposure, 6G will enable the deployment of distributed applications that require real-time interaction, such as XR and AI. As an example, 6G will natively support\noffloading computationally complex tasks\nsuch as XR split rendering to network edge servers without compromising device performance. Additionally, the proposed technology framework envisions the 6G core providing QoS, traffic steering, and network metrics, facilitating a more efficient and responsive network environment. This will be achieved through a collaborative ecosystem where application clients, servers, and DNS servers act as application functions, supported by a cloud operations manager and a service exposure and monetization platform. This coordination promises to unlock new compute services, enhancing user experiences and paving the way for innovative applications in the 6G era. The figure below depicts the key enablers to have the next generation of XR come true in 6G.\nUsing Nokia’s state-of-the-art dynamic system-level simulator, we have assessed 6G’s potential to support higher XR cell capacity. The simulator includes detailed modeling of the air interface, RAN protocols, and realistic representation of XR traffic in the form of real-time 4K video at 45Mbps with one-way latency bounds of 10-15ms, in line with 3GPP simulation guidelines. We studied a dense urban macro scenario, assuming MU-MIMO (Type-II precoding) with up to 64 CSI-RS ports for 3.5GHz deployments with 100MHz, and 256 CSI-RS for 7GHz with 200MHz. Additionally, we considered optimized Radio Resource Management (RRM), such as smart Code Block Group-based Hybrid ARQ and AI-powered dynamic scheduling. These studies revealed that 6G has the potential to support approximately 20 XR users per cell at 3.5GHz with 100MHz bandwidth, increasing to more than 50 XR users per cell for a deployment at 7GHz with 200MHz carrier bandwidth. These are very encouraging numbers to sustain the increase of XR traffic in 6G, indicating significant gains over what is possible with today’s 5G deployments. These are initial XR capacity estimates, which will, of course, be further refined as 6G standardization progresses, ensuring that all features included in 6G Radio are accurately reflected in our system-level simulator to produce highly relevant and realistic results.\nThe bright future of mobile XR\nThe future for new cutting-edge XR features looks bright for mobile users as 6G takes such technologies to the next level, enabling exciting new use cases that are not yet on our radar as of today. Collaborative efforts in standards along with strong ecosystems of network vendors, device manufacturers, service platforms, and creative application developers will unlock the full potential of XR. This will make immersive reality and experiences scalable, desirable, affordable and accessible to everyone from everywhere.\nWith 6G, AI and XR can become the user experience for the realities of tomorrow."
  },
  {
    "name": "Notes from GITEX 2025 - Networks that power, protect and scale",
    "link": "https://www.nokia.com/blog/notes-from-gitex-2025-networks-that-power-protect-and-scale/",
    "source": "Nokia_blog",
    "main_ideas": [
      "GITEX 2025 showcased advancements in AI, cloud, cybersecurity, and data centers.",
      "Nokia demonstrated AI holographic technology for oil and gas applications.",
      "The event highlighted the importance of secure, high-performance networks for industrial automation."
    ],
    "tags": [
      "gitex",
      "ai",
      "cloud-computing",
      "cybersecurity",
      "data-centers",
      "nokia",
      "oil-and-gas",
      "quantum-security",
      "industrial-automation"
    ],
    "original_text": "Notes from GITEX 2025 - Networks that power, protect and scale\nby\nAli Emam\n24 Oct 2025\nGITEX 2025 (October 13-17, 2025) once again turned Dubai into a global tech stage—and it also marked the last edition at Dubai World Trade Centre before the show moves to the Dubai Exhibition Centre, Expo City in 2026. This year’s footprint spanned both DWTC and Dubai Harbour, with a week of conversations across AI, cloud, cybersecurity, quantum,\ndata centers\nand\nmission-critical\napplications.\nTen years ago, when I was based here, we demoed a live 10 Gbps 5G experience with du at GITEX 2015. Coming back in 2025, the emphasis feels more grounded: building the digital foundations—\nnetworks + data centers + security\n—that make AI and industrial automation real at scale.\nWhat we showed at Nokia\nOur story was consistent: networks do more than connect—they transform industries. At our stand, we focused on high-performance IP/optical transport, private wireless,\nAI-native networking\n, quantum-safe security and resilient\ndata-center fabrics\nbuilt for AI/High-Performance Computing (HPC)—capabilities that underpin mission-critical operations.\nOil & gas — the “future-ready oil plant” hologram\nA highlight for me was our\nAI holographic demo\nfor oil and gas. This compelling demo illustrates how edge AI, computer vision and sensor fusion enable use cases like flare monitoring or corrosion detection when combined with industrial-grade connectivity and compute. We ran it on the Nokia stand and with partners on the show floor (including du).\nPower utilities — mission-critical by design\nFor utilities, the focus remains on\ndigital substations\nand automation at scale—grounded in IEC-based architectures and deterministic, carrier-grade IP/optical transport—with\nquantum-safe\npaths to protect critical energy networks over the long term.\nData centers for AI/HPC\nMany of the week’s “wow moments” hinged on compute: training, inference, model serving and time-series analytics. The practical takeaways:\nKeep compute\nclose to where data is created\n(on-prem/edge or primary data center) for latency, cost and compliance\nUse high-capacity\nData Center Interconnect (DCI)\nand coherent optics to synchronize clusters\nMove\nresults\n, not raw firehose—supporting\ndata locality/residency/sovereignty\nwhile scaling reliably\nPeople behind the tech\nI’ve included a few photos—moments from both stands (including the AI hologram), a couple of group photos of our Energy team and the colleagues who presented the demo, plus a quick selfie catching up with old friends.\nIf you’d like a deeper dive on oil & gas architectures for AI/HPC, quantum-safe options for energy networks or utility automation patterns, drop me a message on\nLinkedIn\n. I’d be happy to compare notes after the show.\nFor more information:\nMove to Expo City in 2026\n(official): GITEX GLOBAL news\nhttps://www.gitex.com/News/worlds-largest-tech-and-food-events-set-for-landmark-move-to-dubai-exhibition-centre-at-expo-city-dubai-in-2026\n2025 dual-venue footprint\n(DWTC + Dubai Harbour)\nhttps://www.gitex.com/about\nNokia at GITEX 2025\nhttps://www.nokia.com/events\nNokia at GITEX\nfocus areas/demos\nhttps://www.nokia.com/events/gitex-global\nAI Hologram demo for oil & gas\n(public post)\nhttps://www.linkedin.com/posts/nokia-industries_gitexglobal-futurereadyoil-aiinenergy-activity-7336613654584320000-Vyd2\nAli Emam’s GITEX LinkedIn post:\nhttps://www.linkedin.com/posts/ali-emam_gitex2025-nokia-missioncritical-activity-7385260714321600512-9BUk"
  },
  {
    "name": "The internet commons under siege: Why 33 Tbps DDoS attacks are everyone's problem",
    "link": "https://www.nokia.com/blog/the-internet-commons-under-siege-why-33-tbps-ddos-attacks-are-everyones-problem/",
    "source": "Nokia_blog",
    "main_ideas": [
      "33 Tbps DDoS attacks are overwhelming internet infrastructure and affecting legitimate users.",
      "The costs of DDoS attacks are externalized across the entire internet ecosystem.",
      "A distributed defense approach is necessary to effectively combat large-scale DDoS attacks."
    ],
    "tags": [
      "ddos",
      "internet-security",
      "network-infrastructure",
      "cybersecurity",
      "nokia",
      "aisuru-botnet",
      "distributed-defense",
      "internet-exchange",
      "collateral-damage",
      "service-providers"
    ],
    "original_text": "The internet commons under siege: Why 33 Tbps DDoS attacks are everyone's problem\nby\nJérôme Meyer\n23 Oct 2025\nOn October 9, Nokia Deepfield observed a 33 terabits-per-second distributed denial-of-service (DDoS) attack against a gaming provider. For context, the\ntotal\ncapacity of many\nnational\ninternet backbones is measured in similar terabit ranges. An attack of this magnitude isn't just targeting a server or even a network — it's consuming infrastructure at internet scale.\nThis wasn't an isolated incident.\nAs Brian Krebs reported\n, the Aisuru botnet has been systematically breaking DDoS records, with a 29.6 Tbps attack recorded just days before, on October 6. The trajectory is clear: what was unthinkable two years ago is now routine. What was routine six months ago is now inadequate for defense. We're in a new regime, and most of our defensive thinking hasn't caught up.\nThe hidden costs of internet-scale attacks\nWhat makes these attacks fundamentally different from what we have seen before is the collateral damage. When someone launches a 33 Tbps attack at a single IP address, they're not just attacking that target. They're attacking the internet infrastructure itself.\nThe attack traffic has to travel through the internet's shared infrastructure: peering links, internet exchange points (IXPs), backbone networks. At these volumes, all that infrastructure becomes congested. Peering links saturate. Internet exchange (IX) ports max out. And suddenly, traffic that has nothing to do with the attack starts getting dropped. Legitimate users can't access legitimate services because the internet pipes are full of “garbage” traffic.\nThis is a classic\ntragedy of the commons\n. The attacker bears almost none of the expense. The target bears some. But most of the burden falls on everyone else who shares the infrastructure: other networks, other users, other services. The costs are externalized across the entire internet.\nThe problem inside your network\nThere's another cost that's getting less attention: the impact on the networks hosting the attacking devices. According to\nKrebs's investigation\n, a significant portion of Aisuru's 300,000 compromised devices is hosted\nwithin\ncommunications service provider (CSP) networks in the U.S. One security researcher observed 500 gigabits per second of attack traffic leaving a single provider's network during an Aisuru campaign.\nIt’s worth noting the U.S. doesn't have the most bots. It has bots with more bandwidth. Average U.S. residential connections are faster than those in most countries, so each compromised device can push more attack traffic. As residential broadband speeds increase globally, this geographic concentration will shift. The problem is becoming more distributed and more global.\nThink about what that means for the service providers. Their customers' devices (compromised routers, security cameras, DVRs) are\nall\nblasting DDoS traffic\noutbound\n. That traffic consumes bandwidth that could otherwise be used for legitimate purposes. It strains infrastructure like carrier-grade network address translation gateways (CG-NAT) that weren't designed to handle this kind of load. It generates complaints from peer networks about congestion.\nService providers didn't launch these attacks. Their customers didn't knowingly launch these attacks. But they are paying the costs: in infrastructure strain, in customer support calls, in degraded service quality, and in relationships with peer networks.\nThis is a textbook case of misaligned incentives. The manufacturers who build insecure IoT devices don't bear the costs when those devices are compromised. The customers who buy them don't have the expertise to secure them (or even know they need to). The broadband service providers who host them can't easily control what their customers do with their connections. And the attackers operate with near impunity from jurisdictions where enforcement is difficult or non-existent.\nWhy centralization makes things worse\nThe obvious response is to scale up defenses. If attacks are exceeding 30 Tbps levels, then we need providers who can absorb 30+ Tbps attacks, right? Just funnel all traffic through a handful of mega-providers with the capacity to handle these volumes.\nThis is an intuitive argument, but it's wrong for several reasons.\nFirst, it would concentrate traffic through a small number of chokepoints. That reduces resilience. If one of these mega-providers has problems—technical issues, misconfigurations, or becomes a target itself—the impact would be even more widespread.\nSecond, this is economically unsustainable for most organizations. Diverting all your traffic through a third-party scrubbing center is expensive. Smaller organizations and those in regions where these services aren't well-established can't afford it.\nThird, and most importantly, this approach would not solve the underlying problem—it's like building bigger emergency rooms instead of preventing accidents. The attack traffic would still flood the internet. It would still congest shared infrastructure. It would still create collateral damage. You would just be dealing with it downstream instead of at the source.\nA better approach: Distributed, network-native defense\nInstead, we need the defense that is built into the network fabric itself. That means three things:\nFirst, service providers need to monitor and control outbound attack traffic. This isn't about censorship or restricting what users can do. It's about detecting when thousands of devices on your network are simultaneously blasting traffic at the same target (which is never legitimate behavior) and taking action. The recent attacks make clear that effective and universal outbound DDoS attack suppression can no longer be treated as optional infrastructure.\nSecond, internet exchange points and transit providers need to become active participants in defense. Their internet infrastructure is located at natural chokepoints where DDoS attack traffic can be detected and filtered before it spreads.\nNL-ix, a major European internet exchange\n, has deployed exactly this kind of capability, using\nnetwork-native DDoS protection\nthat filters attacks inline without diverting traffic to remote scrubbing centers. (They even showed a\nlive demo of their anti-DDoS\ncapabilities).\nThird, we need everyone in this global ecosystem to work together to make the internet more secure. Manufacturers need to build more secure devices by default; not because they're altruistic, but because the market and their customers demand it. Service providers need tools and support to detect and mitigate outbound DDoS attacks. And users need better defaults: devices that are secure out of the box, not after reading a 50-page manual on how to make them secure.\nWhat needs to happen\nThe 33 Tbps attack we observed isn't just a milestone. It's a signal that the current approach isn't working. We can't scale our way out of this by building bigger scrubbing centers. We can't ignore it and hope the problem goes away.\nWhat we need is a shift in our thinking.\nDDoS defense needs to be distributed, not centralized. It needs to be proactive, not reactive. It needs to address the economics and incentives, not just the technical capabilities. That means service providers prioritizing outbound controls, internet exchanges and transit providers deploying inline filtering, and manufacturers building more secure devices. None of this is easy.\nThe tragedy of the internet commons is notoriously difficult to solve: it requires coordination, shared standards, and collective action in an ecosystem that prizes autonomy. But the alternative is watching the internet's shared infrastructure buckle under increasingly massive DDoS attacks while we wait for someone else to solve the problem. The internet commons doesn't defend itself. Either we build distributed defense into the fabric of our networks, or we accept that 33 Tbps attacks are just the beginning.\nLearn more about what is fueling the rise of these hyperscale DDoS attacks and about the latest cybersecurity threats in the\nNokia Threat Intelligence Report 2025\n."
  },
  {
    "name": "The network that turns data centers into AI brains",
    "link": "https://www.nokia.com/blog/the-network-that-turns-data-centers-into-ai-brains/",
    "source": "Nokia_blog",
    "main_ideas": [
      "Data centers are evolving rapidly to support AI and data sovereignty demands.",
      "The network is essential for connecting and optimizing data center operations.",
      "High-performance networking solutions are critical for efficient AI processing."
    ],
    "tags": [
      "data-centers",
      "artificial-intelligence",
      "cloud-computing",
      "networking",
      "gpu",
      "data-sovereignty",
      "liquid-cooling",
      "high-performance",
      "quantum-security"
    ],
    "original_text": "The network that turns data centers into AI brains\nby\nRoland Mestric\n22 Oct 2025\nIn just two decades, the cloud has transformed from Amazon’s first storage service to a global platform that powers most consumer and business applications. As the cloud has evolved, so has the infrastructure behind it. Data centers are booming. Their count has jumped from ~250 a decade ago to over 10,000 today. They are getting larger, more complex and are placed closer to the users they serve.\nAll of this makes connectivity within and between these distributed data centers critical. And that’s where\nthe network emerges as a vital element\nin the evolution of the cloud and data center. This evolution has strategic implications for all network operators – from hyperscalers and neocloud providers to communications service providers (CSPs), enterprises, and operators of mission-critical networks.\nAI and sovereignty redefine the data center\nArtificial Intelligence (AI) has radically changed what a data center is and how it is built and run. In parallel, rising global uncertainty has pushed nations to heighten security at their digital borders to safeguard privacy and assert data sovereignty.\nBoth of these change factors create extraordinary constraints on compute power, energy supply and cooling systems.\nThe graphics processing unit (GPU) has become the new currency for data centers. It is the ideal solution for running the complex calculations that power AI. An AI factory for intensive training purposes can house up to a million GPUs.\nOne GPU consumes about 1 kW of power. To put this into perspective, this is the average hourly consumption of a citizen in developing countries like Egypt, Vietnam or Peru. A full rack will soon reach 1 MW – pushing further power-density requirements. Meta just started the construction of its 29\nth\ndata center\ndesigned to scale up to 1 GW of capacity\n.\nBecause servers turn most of that energy into heat, cooling systems must keep pace, necessitating the adoption of liquid cooling. Some companies are even placing\ndata centers underwater\nto exploit ocean currents as natural coolant.\nTo overcome energy and heat dissipation limits, leaders like Jeff Bezos (Amazon) and Eric Schmidt (former Google) have floated the idea of\norbital data centers\nthat could harvest abundant solar energy and enjoy efficient cooling in space.\nBut as the industry debates innovations in compute, energy, cooling and location, let’s not forget another essential component of the data center:\nthe network\n.\nThe hidden network powering data centers\nData centers are nothing without the network.\nClusters rely on the network to form the brain that creates and runs AI. Just as neurons and synapses give the human brain its power, the combination of compute and network makes artificial intelligence possible.\nNetworks are the connective tissue within and between the world’s data centers, supporting the delivery of data, digital services and applications:\nInside a data center\n, the network forms the platform that moves the massive volumes of data between compute resources. It contributes to maximize efficiency and minimize job completion time.\nBetween data centers\n, the network stitches multiple facilities together into a cohesive AI infrastructure, allowing workloads to be shared and collaboration to happen across sites.\nBetween data centers and their users\n, the network ensures the data can reach devices quickly and reliably, delivering the performance modern applications demand.\nWhy the network must evolve too\nAs the cloud evolves to support AI and data sovereignty, network design must respond. This will take more than an incremental upgrade; it calls for a profound and foundational shift:\nAI models shuffle terabytes of training data between storage, compute nodes and external sources. Without sufficient\nbandwidth, speed\nand\nreliability\n, the most expensive GPU farms sit idle, turning multi-million dollar investments into costly waiting rooms.\nComputationally intensive tasks move between data centers to work around space and power limits, generating cascades of data requests and rapid traffic bursts. Therefore, architecting for increased\nscale\nand\nadaptability\nbecomes critical.\nModel training iterates quickly, and real-time inference must deliver instant insights, requiring\nresponsiveness\nand\nlow-latency\ntransmission.\nAI and data-sovereignty requirements for safety, defense, finance and healthcare services, demand extreme\navailability\nand robust\nsecurity\n.\nAnd yet, it’s possible to satisfy these demands with architecture and technologies that deliver ultra-high scale, performance and flexibility.\nDone well, we can level-up data security, cut the environmental impact of AI processing, and unlock the economic, competitive and social benefits that AI promises.\nWhat you should expect from your data center network?\nData center networking solutions should feature a unique set of capabilities to thrive in today’s AI-driven environment.\nHigh performance:\nThe network should provide ultra-high speed, low-latency, loss-less connectivity, leveraging Ethernet to slash cost and power per bit. 800G Ethernet is the new state of the art, with 1.6T Ethernet coming next year.\nQuality-first design\n: Network hardware and software must be built to best-in-class standards and undergo rigorous testing to guarantee reliability and continuous business operation.\nOperational efficiency:\nPrecise, reliable and predictable automation should let the network adapt dynamically to changing demands and to unexpected events.\nDeep security:\nA defense-in-depth approach featuring quantum security and built-in DDoS detection and mitigation must protect the network today and into the future\nas threats evolve\n.\nTake the next step\nNetworks built this way are no longer optional; they’re the only way to keep sovereign AI workloads from becoming bottlenecks. They become strategic differentiators that turn data center infrastructure into a competitive edge.\nIf you want to learn more about the critical role that the network plays in the evolution of the cloud and data centers, start reading our white paper\nNetwork the cloud\n, or visit our web page\nCritical connectivity for modern data centers\n.\nIf you are planning to build a mission-critical data center infrastructure, Nokia can help. Join the many cloud specialists who rely on our proven track record. Our quality-first philosophy is a key reason customers trust us to deliver data center networks that simply work and are easy to operate."
  },
  {
    "title": "Introducing the New Fleet Application Management Release",
    "link": "https://blogs.oracle.com/post/introducing-the-new-fleet-application-management-release",
    "source": "Oracle_blog",
    "main_ideas": [
      "The new fleet application management release enhances operational efficiency.",
      "Users can expect improved user interface and functionality.",
      "The update includes advanced analytics for better decision-making."
    ],
    "tags": [
      "fleet-management",
      "application-release",
      "operational-efficiency",
      "user-interface",
      "analytics"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Simplifying Secure Access: OCI Bastion Connector",
    "link": "https://blogs.oracle.com/post/oci-bastion-connector-private-access",
    "source": "Oracle_blog",
    "main_ideas": [
      "The OCI Bastion Connector simplifies secure access to cloud resources.",
      "It enhances security by providing a controlled access point.",
      "The connector is designed for seamless integration with existing systems."
    ],
    "tags": [
      "oci",
      "bastion-connector",
      "cloud-security",
      "secure-access",
      "cloud-computing",
      "technology",
      "integration"
    ],
    "original_text": "This site requires JavaScript to be enabled."
  },
  {
    "title": "Milliseconds Matter: How BCC Group and OCI Are Redefining Market Data ...",
    "link": "https://blogs.oracle.com/post/milliseconds-matter-bcc-group-and-oci-vs-aws",
    "source": "Oracle_blog",
    "main_ideas": [
      "BCC Group and OCI are innovating market data processing for faster decision-making.",
      "Milliseconds in data delivery can significantly impact trading outcomes.",
      "The collaboration aims to enhance the efficiency of financial market operations."
    ],
    "tags": [
      "market-data",
      "bcc-group",
      "oci",
      "financial-services",
      "data-processing",
      "trading",
      "technology",
      "innovation"
    ],
    "original_text": "This site requires JavaScript to be enabled."
  },
  {
    "title": "OCI Announcement: OpenSearch 3.2 is now available in OCI Search with ...",
    "link": "https://blogs.oracle.com/post/oci-opensearch-32",
    "source": "Oracle_blog",
    "main_ideas": [
      "OpenSearch 3.2 is now available in OCI Search.",
      "The new version includes enhanced features and improvements.",
      "Users can leverage OpenSearch for better search capabilities."
    ],
    "tags": [
      "opensearch",
      "oci",
      "cloud-computing",
      "search-technology",
      "software-release"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Seamless Employee Onboarding: From Oracle Fusion HCM to Simphony, ...",
    "link": "https://blogs.oracle.com/post/employee-onboarding-fusion-hcm-to-simphony",
    "source": "Oracle_blog",
    "main_ideas": [
      "Seamless onboarding enhances employee experience and productivity.",
      "Integration of Oracle Fusion HCM with Simphony streamlines HR processes.",
      "Effective onboarding reduces turnover and improves retention rates."
    ],
    "tags": [
      "employee-onboarding",
      "oracle-fusion-hcm",
      "simphony",
      "hr-tech",
      "productivity",
      "retention",
      "employee-experience"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Designing Transit Routing in Oracle Cloud Infrastructure (Part II)",
    "link": "https://blogs.oracle.com/post/cross-region-transit-routing-in-oci",
    "source": "Oracle_blog",
    "main_ideas": [
      "The article discusses advanced techniques for transit routing in Oracle Cloud Infrastructure.",
      "It emphasizes the importance of optimizing routing algorithms for efficiency.",
      "The integration of machine learning can enhance transit routing capabilities."
    ],
    "tags": [
      "oracle",
      "cloud-infrastructure",
      "transit-routing",
      "routing-algorithms",
      "machine-learning"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Modernizing Cloud Workflows: Replacing AWS Step Functions with OCI ...",
    "link": "https://blogs.oracle.com/post/replacing-aws-step-functions",
    "source": "Oracle_blog",
    "main_ideas": [
      "The article discusses modernizing cloud workflows by replacing AWS Step Functions.",
      "Oracle Cloud Infrastructure (OCI) offers alternatives to traditional cloud workflow solutions.",
      "The transition to OCI aims to enhance efficiency and reduce costs in cloud operations."
    ],
    "tags": [
      "cloud-computing",
      "oracle",
      "aws",
      "workflow-automation",
      "infrastructure",
      "technology",
      "cost-reduction",
      "efficiency"
    ],
    "original_text": "Click to view our Accessibility Policy\nSkip to content\nOracle Blogs\nWe can't find the page you were looking for.\nThe page may have been moved or deleted, or a referring link may be incorrect.\nBack to\nOracle Blogs home\nSearch Oracle Blogs\nReceive the latest blog updates\nSubscribe to Oracle Connect email updates\nResources for\nAbout\nCareers\nDevelopers\nInvestors\nPartners\nStartups\nWhy Oracle\nAnalyst Reports\nBest CRM\nCloud Economics\nCorporate Responsibility\nDiversity and Inclusion\nSecurity Practices\nLearn\nWhat is Customer Service?\nWhat is ERP?\nWhat is Marketing Automation?\nWhat is Procurement?\nWhat is Talent Management?\nWhat is VM?\nWhat's New\nTry Oracle Cloud Free Tier\nOracle Sustainability\nOracle COVID-19 Response\nOracle and SailGP\nOracle and Premier League\nOracle and Red Bull Racing Honda\nContact Us\nUS Sales 1.800.633.0738\nHow can we help?\nSubscribe to Oracle Content\nTry Oracle Cloud Free Tier\nEvents\nNews\n© 2025 Oracle\nSite Map\nPrivacy\n/\nDo Not Sell My Info\nCookie Preferences\nAd Choices\nCareers"
  },
  {
    "title": "Oracle Cloud Infrastructure: Uncompromising cloud security across all ...",
    "link": "https://blogs.oracle.com/post/cloud-security-us-government-classification",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle Cloud Infrastructure prioritizes security in its cloud services.",
      "The platform offers robust features to protect data and applications.",
      "Compliance with industry standards is a key focus for Oracle Cloud."
    ],
    "tags": [
      "oracle",
      "cloud-infrastructure",
      "cloud-security",
      "data-protection",
      "compliance",
      "technology",
      "cloud-computing"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Introducing AI Agent Marketplace",
    "link": "https://blogs.oracle.com/fusioninsider/introducing-ai-agent-marketplace",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle AI Agent Marketplace offers pre-built AI agents for Fusion Applications.",
      "The marketplace allows customization of workflows and integration with enterprise data.",
      "Partner-developed agents enhance domain knowledge and industry expertise for businesses."
    ],
    "tags": [
      "oracle",
      "ai-agent-marketplace",
      "enterprise-ai",
      "fusion-applications",
      "automation",
      "llms",
      "partner-agents",
      "business-solutions",
      "erp",
      "hcm"
    ],
    "original_text": "The promise of agentic AI is clear: automation that goes beyond simple, pre-defined tasks. However, creating complex, multi-step AI workflows from scratch requires time, specialized skills, and an understanding of how to integrate large language models (LLMs) with enterprise data and APIs.\nOracle AI Agent Studio\naddresses this challenge with pre-built agent templates you can use to easily build, test, and deploy agents in Oracle Fusion Applications to solve real business problems. AI Agent Studio agent templates are available to Fusion Applications customers at no additional charge. In addition to agent templates built by Oracle, you now have access to a growing ecosystem of partner-built agents through\nOracle AI Agent Marketplace\n. This post will explain what it is, how it works, and its benefits.\nWhat is Oracle AI Agent Marketplace?\nOracle AI Agent Marketplace is a new offering that allows Fusion Applications customers to easily find and deploy agents built by trusted system integrators such as Infosys, IBM Consulting, KPMG, Apex IT, and Huron, and ISVs like Box, Stripe, and RChilli. A growing list of partner-developed agents is already available across ERP, HCM, SCM, and CX, each ready for rapid deployment. Like the agent templates provided by Oracle, partner-built agents can be modified, allowing teams to customize workflows, adjust prompts, pick different LLMs, add tools and data sources, and insert human-in-the-loop approval steps to align with their specific business needs.\nUnlike standalone marketplaces, AI Agent Marketplace is embedded natively in AI Agent Studio. This means you can discover, deploy, and manage Oracle- and partner-built agents side-by-side in the same user experience. It also means the agents work seamlessly within your existing workflows, with direct access to Fusion Applications data and respecting Fusion Applications’ security and role-based access controls. Oracle vets the agents with the same 21-point enterprise readiness checklist used on Oracle’s own agents—and Oracle provides support for partner agents.\nThere’s no separate fee for installing marketplace agents. And partners do not charge for their templates. You may engage partners for optional implementation services as desired.\nWhy Oracle AI Agent Marketplace is important\nAI Agent Studio can have a big impact on how organizations adopt and scale enterprise AI, shifting the focus (and resources) from building AI to deploying it. And AI Agent Marketplace makes it possible for you to take advantage of partners’ domain and industry knowledge.\nExamples\nHere are some of the agent templates available in AI Agent Marketplace:\nHire to Retire agent (Infosys):\nhelps HR managers access and update employee data such as contract details, role assignments, or reporting lines.\nPurchase Order Item Price History agent (KPMG):\nhelps buyers make more informed decisions by providing information on previous suppliers, purchase dates, price, and pricing insights.\nSmart Sales Order Entry Assistant agent (IBM):\nUses natural language to automate sales order creation, validation, and management.\nTalent Data Refresh agent (RChilli):\nstreamlines the job application process by enriching outdated candidate profiles and resumes with information from public sources.\nIn conclusion\nThe Oracle AI Agent Marketplace provides you with a catalog of pre-built, partner-developed AI agents that can be deployed within Oracle Fusion Applications to address a range of business needs across ERP, HCM, SCM, and CX. Because these agents are managed and validated by Oracle, you benefit from standardized security and functionality while tapping into partners’ domain and industry expertise.\nRelated posts you might like\nAI Agent Studio provides new tools for automation\nApps update—AI agents, AI marketplace, and more\n25D roadmaps—new agents for ERP, HCM, SCM, and CX\nIf you’re an Oracle customer and want to get new stories from\nThe Fusion Insider\nby email, sign up for\nOracle Cloud Customer Connect\n. If you’re an Oracle Partner and want to learn more, visit the\nOracle Partner Community\n."
  },
  {
    "title": "Apps update—AI agents, AI marketplace, and more",
    "link": "https://blogs.oracle.com/fusioninsider/apps-2025-update-ai-agents-ai-marketplace-and-more",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle introduces AI Agent Marketplace and AI Agent Studio for enhanced business efficiency.",
      "Over 600 embedded AI agents are now available in Oracle Fusion Cloud Applications.",
      "Oracle's AI innovations focus on practical applications to solve real business problems."
    ],
    "tags": [
      "oracle",
      "ai-agents",
      "cloud-applications",
      "business-efficiency",
      "ai-marketplace",
      "fusion-apps",
      "automation",
      "data-security",
      "technology-innovation"
    ],
    "original_text": "Key takeaways\nAI Agent Marketplace, AI Agent Studio, and more than 600 embedded AI agents are now available to customers of Oracle Fusion Cloud Applications and Oracle Industry Applications.\nRole-based access controls established in Fusion Apps apply to agents created by AI Agent Studio, and customer data is not used to train LLMs.\nFusion Apps customers like Milwaukee Tool and BHE Energy are using the complete suite of Fusion Apps and rolling out AI assistants and agents to simplify processes and improve efficiency.\nExecutive Vice President Steve Miranda’s keynote at Oracle AI World showcased how new AI capabilities in Oracle Applications are helping customers solve real business problems today. Embedded AI features including\nAI agents and assistants\n, the\nOracle AI Agent Studio\n, and the new\nAI Agent Marketplace\nmake it possible to automate workflows, eliminate manual processes, make smarter, data-driven decisions, and deliver better service. It’s worth\nwatching the keynote replay\n. You’ll see AI agent and AI Agent Marketplace demos, get insights from Oracle customers, and learn how to adopt AI in your own business. If you prefer to read, key points from the keynote are below.\nAI is the focus\nOracle Application development teams are focused on delivering practical, impactful AI capabilities that help customers’ businesses succeed. Highlights from the keynote include:\nEmbedded and custom agents:\nCustomers have access to more than 600 embedded AI agents and assistants (400 in Oracle Fusion Cloud Applications and 200 in Oracle Industry Applications). AI Agent Studio, the no-code AI agent development platform for Fusion Apps, enables you to build, test, and deploy agents customized to your own business needs.\nThriving AI ecosystem:\nSteve announced the availability of the new AI Agent Marketplace. It allows customers to find and deploy AI agents developed by system integrator partners like Accenture, Deloitte, and IBM, and by ISV partners like Box and Stripe, all of which are vetted and supported by Oracle. More than 32,000 experts at our partners and customers have already completed training for AI Agent Studio and are certified to build agents with it. In addition, Oracle Applications support open frameworks like Model Context Protocol (MCP), which standardizes how large language models (LLMs) and AI agents integrate with and share data with your applications and data sources, and Agent2Agent (A2A), which allows different agents to communicate and collaborate regardless of their underlying frameworks.\nVertically integrated technology stack:\nOracle Applications run on Oracle Cloud Infrastructure (OCI), so customers benefit from its security, speed, and reliability. And AI agents in Oracle Apps have access to the most advanced AI reasoning power because OCI hosts the world’s leading LLMs from OpenAI, Anthropic, Cohere, Google, Meta, and xAI.\nAI innovation you can trust:\nGetting the most out of AI agents requires giving them access to your business data. AI agents uphold the existing role-based access controls set up in your Fusion Apps. That means embedded AI agents can only read data that the human user interfacing with them is authorized to see, and new agents built or customized in AI Agent Studio uphold your existing security configurations, policies, and access controls. In Fusion Apps, your data is not used to train the underlying LLMs.\nOur commitment to customer success\nSteve welcomed customer executives to the stage to discuss how they use the complete Fusion Apps Suite, adopt AI innovations, and collaborate with Oracle.\nMark Molitor, CIO at Milwaukee Tool, shared how Oracle’s modern, integrated cloud suite regularly delivers the technology innovations to support their explosive growth. Fusion Apps have improved efficiency and scalability in distribution, order fulfillment, and supply chain management while embedded agents help them implement AI at scale.\nBHE Renewables CEO Matt Finnegan successfully moved six subsidiaries from disparate legacy systems (including SAP, PeopleSoft, and E-Business Suite) to Fusion Apps. With a complete application suite and unified data, his company has dramatically simplified processes and improved efficiency. And BHE Renewables is already using embedded AI agents in procurement and HR.\nBoth leaders attribute their success with Fusion Apps to close partnerships with Oracle that began before implementation and have continued through multiple update cycles.\nClick here to watch the replay of the Oracle Applications keynote on YouTube.\nConclusion\nAI innovations covered in Steve’s keynote are available in Release 25D and can be adopted through Fusion Apps quarterly updates.\nThis article\ngives you an overview of the update process and shares resources to help it go smoothly. For more on AI agents in Fusion Applications, check out\nthis list of available agents\n.\nRelated posts you might like\nGet started guide—design and build AI agent teams\nUse this plan to roll out AI across finance, HR, and more\nQuarterly updates made easy\nIf you’re an Oracle customer and want to get new stories from\nThe Fusion Insider\nby email, sign up for\nOracle Cloud Customer Connect\n. If you’re an Oracle Partner and want to learn more, visit the\nOracle Partner Community\n."
  },
  {
    "title": "AI Agent Studio provides new tools for automation",
    "link": "https://blogs.oracle.com/fusioninsider/ai-agent-studio-provides-new-tools-for-automation",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle AI Agent Studio enables the creation and deployment of AI agents for business automation.",
      "The platform includes templates and tools for building workflow-enabled agents.",
      "New features enhance observability, testing, and governance for AI agents."
    ],
    "tags": [
      "oracle",
      "ai-agent-studio",
      "automation",
      "workflow-enabled",
      "enterprise-ai",
      "fusion-applications",
      "templates",
      "testing-framework",
      "llms"
    ],
    "original_text": "Key takeaways\nOracle AI Agent Studio is the AI development platform for Fusion Applications that lets you build, test, and deploy AI agents to automate more of your business.\nIt includes hundreds of templates from Oracle and its partners to give you a head start on deploying AI-driven automation.\nNew observability and testing features help build trust and oversight of agent development and deployment.\nOracle AI Agent Studio is the AI development platform for Fusion Applications that lets you build, test, and deploy AI agents to automate more of your business.\nWe introduced AI Agent Studio earlier,\nand now we’re sharing\nan updated demo\nthat illustrates some of the most important product advancements. These include an expansion of its standards-driven ecosystem, the introduction of workflow-enabled agents, and new tools for measurement and evaluation.\nWhat you’ll see\nThe demo follows Marie, a power user in a shared service center who wants to help employees automate self-service requisitioning. She begins by reviewing agent templates in AI Agent Studio. These include templates delivered by partners as part of the new\nAI Agent Marketplace\n, the trusted source for partner-developed, Oracle-certified AI agents. Next, Marie notices important controls that she can use to guide agents, limit their scope where appropriate, and provide access to third-party tools.\nMarie selects the Quote-to-Purchase Requisition Assistant from the list of available templates. It is a workflow-enabled agent team designed to convert supplier quote documents into purchase requisitions in Oracle Self Service Procurement. She sees a clear, graphical representation of the workflow and reviews how it ingests supplier quotes, analyzes them, and calls on specific Fusion Apps data and functions to create a purchase requisition.\nThe template is a good starting point, but Marie decides to customize the workflow by adding an explicit approval step (i.e., human in the loop) and removing the now superfluous email notification. After making these changes, she publishes the agent.\nYou’ll then see the agent in action as an end user named Eric uses it to upload a PDF document detailing a supplier quote. The agent processes the document and then asks for confirmation from Eric before creating the requisition.\nWhy it matters\nThis demo shows new or significantly expanded capabilities in AI Agent Studio, including:\nOpen, standards-based ecosystem\n: AI Agent Studio is part of Fusion Applications, and it works with non-Fusion applications, too. It supports open standards such as Model Context Protocol (\nMCP\n) and Agent2Agent Protocol (\nA2A\n) , and REST APIs. And while it comes with access to LLMs by OpenAI, Meta, and Cohere, you can choose others to best suit your needs (i.e., LLMs by Anthropic, Google, xAI, etc.).\nAI Agent Marketplace:\nOffered from within AI Agent Studio, this is the source for partner-delivered agent templates. Oracle tests, approves, and supports partner templates.\nWorkflow-enabled agents:\nAI Agent Studio now supports agents that follow a specific, defined workflow. The addition of these deterministic agents may be the most important functional advancement on this list. Each one combines branching logic, triggers, and nodes that connect worker agents, apps, LLMs, and vector databases, allowing multiple agents to work together to accomplish a goal following a clear, step-by-step execution plan. This means that they can generate the same output from the same input (unlike probabilistic agents, whose output varies even with the same input), and also use reasoning capabilities to complete tasks (e.g., this number isn’t labeled but looks like a SKU, so the agent treats it as such).\nExplainable and measurable AI:\nIn the context of enterprise AI, governance and trust are key. AI Agent Studio features a testing framework that provides an expanded set of tools for evaluating semantic accuracy (i.e., outputs that correctly represent the underlying facts and context), tracing (i.e., what steps an agent takes), and agent performance (i.e., speed, accuracy, etc.). It includes features like dataset management, A/B comparisons, performance monitoring, token usage, debugging, and agent-level guardrails.\nSumming up\nAI Agent Studio is an important part of Oracle’s AI strategy and for automation in Fusion Applications, and it is included with your Fusion Applications subscription. We’re growing its standards-driven ecosystem, expanding capabilities with workflow-enabled agents, and providing you with new tools for measurement and evaluation. Our goal is to help developers, application administrators, and power (or super) users bring agent-driven automation to your business. For more details, see “\nOracle AI Agents for Fusion Applications\n.”\nClick to watch the AI Agent Studio demo on Oracle Video Hub.\nRelated posts you might like\nSee how (almost) anyone can build agents in Fusion Apps\nGet started guide—design and build AI agent teams\n25D roadmaps—new agents for ERP, HCM, SCM, CX\nIf you’re an Oracle customer and want to get new stories from\nThe Fusion Insider\nby email, sign up for\nOracle Cloud Customer Connect\n. If you’re an Oracle Partner and want to learn more, visit the\nOracle Partner Community\n."
  },
  {
    "title": "25D roadmaps—new agents for ERP, HCM, SCM, CX",
    "link": "https://blogs.oracle.com/fusioninsider/roadmaps",
    "source": "Oracle_blog",
    "main_ideas": [
      "Release 25D introduces significant AI enhancements across Oracle Fusion Cloud Applications.",
      "New AI agents streamline processes in ERP, HCM, SCM, and CX modules.",
      "Oracle provides detailed roadmaps for upcoming features and updates in Fusion Apps."
    ],
    "tags": [
      "oracle",
      "fusion-cloud",
      "ai-agents",
      "erp",
      "hcm",
      "scm",
      "cx",
      "cloud-computing",
      "product-roadmaps"
    ],
    "original_text": "Key takeaways\nProduct roadmaps for Release 25D show new and upcoming features in Oracle Fusion Cloud Applications.\nRelease 25D marks a significant increase in AI capabilities, including many new embedded AI agents and assistants across the Fusion Apps Suite.\nCustomers can download the latest roadmaps from\nOracle Cloud Customer Connect\n(login required).\nOracle Fusion Cloud Applications development teams constantly improve our applications to help you and your organization succeed. Every quarter we deliver hundreds of product updates and new features across the Fusion Apps Suite—and solidify plans for future updates. Release 25D provides a significant increase in AI capabilities, introducing many new AI agents and assistants. For example:\nIn Oracle Fusion Cloud ERP,\nupdates include touchless processing for all corporate card expenses, AI-assisted sourcing for procurement, and expanded narrative reporting for Oracle Cloud EPM. A new AI agent, the\nAccess Request Assistant\n, streamlines the process of granting ERP roles and strengthens access controls.\nIn Oracle Fusion Cloud HCM,\na host of embedded AI agents deliver personalized guidance to workers and managers to help with onboarding, talent management, timecards, scheduling, and more. A case analyzer agent and two new payroll agents assist HR help desk teams with complex inquiries.\nIn Oracle Fusion Cloud SCM,\nnew AI agents help with sales orders, order exceptions, fulfillment, equipment maintenance and diagnostics, and more. For example, the Product 360 Advisor agent lets employees quickly get information about product data, availability, and usage. Many of these AI features are available via new Redwood user experience pages, which are rolling out widely across Oracle Cloud SCM.\nIn Oracle Fusion Cloud CX,\nkey updates focus on efficiency across Sales, Service, and Marketing. In Sales, GenAI features help summarize complex quotes and contracts—and there is a new agent for reporting. In Service, a new work order agent helps resolve issues faster. Marketing leverages GenAI to create content and adds new data science models for deeper audience insights.\nNew 25D roadmaps now available\nThe roadmaps for Release 25D will give you a more complete picture of new updates and features. There are approximately 40 of them, which are published and shared on the roadmaps page on\nOracle Cloud Customer Connect (OCCC)\n, login required. They are named based on calendar year and quarter, so in 2025 the roadmaps for the first three quarters were 25A, 25B, and 25C, while the fourth quarter roadmaps are 25D.\nWe publish two types of roadmaps:\n1. High-level roadmap:\nprovides an overview of the most important updates for Fusion Apps (i.e., Oracle Fusion Cloud ERP, HCM, SCM, and CX)\n2.\nSolution-level roadmap:\ndrills into updates and plans for specific product families within each pillar (e.g., within ERP, you’ll find Financial Management, Procurement, Project Management, ERP Analytics, etc.)\nWith 25D, we introduced a new roadmap for\nOracle AI Agent Studio\n, the no-code development platform for AI agents within Fusion Apps. We also streamlined the solution-level roadmaps for our CX products, making it easier for you to see what’s planned for Sales, Service, and Marketing.\nEach roadmap divides product enhancements into three columns reflecting different timeframes:\n1. Update:\nprovides highlights delivered in the most recent release\n2. Upcoming:\nshows product enhancements planned for the near term\n3. Future:\ndisplays features and functionality envisioned for a longer-term development window\nAdditional info\nFor more-detailed product information, check out the\nCloud Application Readiness\npage on OCCC, which provides documentation on recent releases and fixes. And don’t miss the OCCC forums, where you can discuss, comment, and vote on product enhancements (in the “Ideas” section).\nRelated posts you might like\nQuarterly updates made easy\nNew—Oracle AI Agent Studio for Fusion Apps\nSee Oracle AI Agent Studio in action (demo video)"
  },
  {
    "title": "Get started guide—design and build AI agent teams",
    "link": "https://blogs.oracle.com/fusioninsider/get-started-guide-design-and-build-ai-agent-teams",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle AI Agent Studio simplifies the creation of custom AI agents for business functions.",
      "Effective AI agent teams require clear problem definition and task specialization.",
      "Providing agents with appropriate tools enhances their ability to complete tasks successfully."
    ],
    "tags": [
      "oracle",
      "ai-agents",
      "cloud-applications",
      "automation",
      "business-intelligence",
      "machine-learning",
      "task-management",
      "team-organization"
    ],
    "original_text": "Thinking about building an AI agent but not sure where to start? Oracle AI Agent Studio makes it easier than ever to create custom agents that can handle real work inside Oracle Fusion Cloud Applications—from triaging service requests to pulling real-time data from your ERP. But like any good tool, getting the most out of it takes a little planning. This guide walks you through the basics: how to scope the right kind of problem, how to design an effective team of agents, and what tools to give them so they can get the job done.\nFocus on the problem\nBuilding an agent is similar to establishing a new team of people who will work together to perform a particular business function. Nobody would fund you to hire a team of five people if you didn’t define what problem they were going to solve, who they are solving it for, and what degree of accuracy is needed for the solution. The same is true of agent teams.\nSo stay tightly focused on the job. And remember, agents are not the best solution to every problem. Make sure the challenge you’re tackling is one that leverages AI agents’ particular strengths (i.e., working with ambiguity, decision making, coordination of subtasks, etc.). As you start to map out what your agent team will do, keep on thinking back to whether the problem and the instructions you provide would also be understandable and achievable by a human team member. If not, then you’ll need to provide more tools or more data—or rethink the task.\nDesign your team\nJust as with real team members, agents become more efficient when they’re allowed to specialize. And dividing up tasks helps to ensure quality standards are met. If you give a single agent too much to do, you end up with no way to optimize all the different moving parts needed to get a good result.\nBest practice is to divide tasks between different worker agents, which take instructions from a supervisor agent. The supervisor agent reviews tasks and delegates them to the worker agents, then reviews output from the worker agents and further assigns additional work as needed until the job is complete. The supervisor agent can even make decisions if conflicts arise between worker agents.\nLet’s look at a simple example. Let’s say we’re building an agent team to respond to service requests. We could use a:\nWorker agent that checks for resolutions in a knowledge base\nWorker agent that checks previous ticket resolutions\nSupervisor agent that compares their outputs, determines which one (or what combination of both) is going to best help the user, and writes a response\nIf the user comes back and says the resolution didn’t work, then the supervisor agent can layer additional information from the user onto the request and ask the workers for another pass.\nTools help workers complete tasks\nLarge language models power agents and are good at many things—but not everything (e.g., math). Fortunately, agents can be given tools to use when they are asked to do something they aren’t good at. Examples are:\nDocument tool:\nenables the agent to refer to a PDF or Word doc containing authoritative info relevant to a question (i.e., retrieval-augmented generation, or RAG)\nBusiness object tool:\nenables the agent to query (or write to) tables in the Fusion Apps database to pull information relevant to a given person or entity (Oracle’s architecture ensures that the agent only gets the same access as the user would have ordinarily)\nThird-party APIs:\nenables the agent to call out to other APIs (e.g., for currency exchange rates, weather conditions, or search engine results)\nCalculator:\nhelps the agent do math\nMessaging tool:\nlets the agent send emails (inbound email and more messaging apps coming soon)\nDeep link tool:\nenables the agent to generate links to other objects within Fusion Apps\nConsider your sources of truth\nHallucinations occur when an agent is asked to output more information than it has real knowledge about. It makes up content to fill the gaps. Clearly, you want to avoid this as much as possible. Before starting to build anything, it can be very helpful to map out what the sources of truth will be for the factual information the agents will base their output on.\nOne of the best sources of truth is always going to be a company’s official policies or procedures. A retrieval augmented generation (RAG) step can allow an agent to review official sources of information and ensure its responses come only from that source of truth. As mentioned above, the web search tool provides the option to get information online, but it should be used with caution given the uneven quality of information from internet sources.\nWhen it comes to business-critical information, it’s far better to give the agent a source of truth that a business already trusts. In many cases, that’s going to be the Fusion Apps database the agent already sits on. That’s where the Business Objects Tool comes in. It allows you to quickly and easily give the agent access to the same information in the Fusion Apps database as the user of the agent would ordinarily have. It’s great for tasks like looking up leave/absence balances, or finding the latest statuses of shipments.\nConclusion\nAI Agent Studio makes it easy to set up a team of agents to do work. But, just like with human teams, you won’t get the result you want if the agent team isn’t organized smartly and around a goal its likely to be successful at. Following best practices can help you get the most from your team.\nAdditional resources\nGet started—Oracle AI for Fusion Applications\nExplore AI agents for Oracle Fusion Cloud Applications\nHow do I use AI Agent Studio?\nHow to create an AI agent in 7 steps\nRelated posts you might like\nSee Oracle AI Agent Studio in action (demo video)\nTwo ways you can adopt AI agents in Fusion Apps\n3 AI agents in Fusion HCM you can turn on today\nIf you’re an Oracle customer and want to get new stories from\nThe Fusion Insider\nby email, sign up for\nOracle Cloud Customer Connect\n. If you’re an Oracle Partner and want to learn more, visit the\nOracle Partner Community\n."
  },
  {
    "title": "AI demo—see how AI can help you cut risk",
    "link": "https://blogs.oracle.com/fusioninsider/ai-demo-see-how-ai-can-help-you-cut-risk",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle Fusion Cloud Risk Management automates user access controls and compliance monitoring.",
      "AI analyzes roles and privileges to identify control violations and risks.",
      "The solution enables faster, informed decision-making for access requests."
    ],
    "tags": [
      "oracle",
      "ai",
      "risk-management",
      "cloud-erp",
      "security",
      "compliance",
      "automation",
      "access-control"
    ],
    "original_text": "Oracle Fusion Cloud Risk Management, part of Oracle Fusion Cloud ERP, is an embedded security and audit solution that helps organizations control user access, monitor activity, and enforce regulatory compliance. It uses AI to automate access controls, uncover risks, and restrict access to sensitive functions.\nThis demo video\nshows how it works.\nWhat the demo shows\nFollow Sean, a global procure-to-pay process owner, as he evaluates a user’s request for access to the Accounts Payable Manager role.\nAfter reviewing the approval chain, Sean selects Control Violation. Oracle Fusion Cloud Risk Management uses AI to assess the user’s current roles, requested access, and security policies, analyzing more than 6,000 privileges across Fusion Cloud ERP. It identifies four control violations based on potential toxic combinations.\nPrompted by these findings, Sean checks the AI-generated Role Briefing, which reveals that the user lacks training for this highly sensitive and restricted role. Sean could explore more details, including privilege categories, risk levels, and incident history, but he’s seen enough. He denies the request due to the substantial risk.\nWhy it matters\nAI embedded in Oracle Fusion Applications enables rapid, automated analysis of roles, access, and privileges, surfacing conflicts and control violations with just a few clicks. Generative AI can create security briefings that can clarify risks and highlight key concerns. Automating this process saves time, helps improves decision-making, and strengthens security and compliance.\nSumming up\nOracle Fusion Cloud Risk Management helps process owners to make faster, better-informed access decisions for Oracle ERP Cloud. Oracle AI makes it possible to review thousands of scenarios and to identify control violations within seconds, helping enterprises stay secure and compliant.\nWatch the video\nRelated posts you might like\nGet a 3-step plan for adopting AI in Fusion ERP\nSee how AI agents will work in your ERP and EPM\nTake control of your cash flow with AI—see how\nIf you’re an Oracle customer and want to get new stories from\nThe Fusion Insider\nby email, sign up for\nOracle Cloud Customer Connect\n. If you’re an Oracle Partner and want to learn more, visit the\nOracle Partner Community\n."
  },
  {
    "title": "See how (almost) anyone can build agents in Fusion Apps",
    "link": "https://blogs.oracle.com/fusioninsider/see-how-almost-anyone-can-build-agents-in-fusion-apps",
    "source": "Oracle_blog",
    "main_ideas": [
      "AI agents can enhance automation and efficiency in enterprise applications.",
      "No-code platforms like Oracle AI Agent Studio democratize AI agent development.",
      "Role-based access control ensures security in AI agent creation and deployment.",
      "Super users can quickly adapt AI agents to meet evolving business needs.",
      "AI Agent Studio facilitates integration with existing systems without extensive programming."
    ],
    "tags": [
      "ai-agents",
      "no-code",
      "oracle",
      "automation",
      "enterprise-applications",
      "security",
      "business-integration",
      "super-users",
      "fusion-apps"
    ],
    "original_text": "Using AI agents in embedded enterprise applications can help organizations add automation and efficiency. But there are other, less obvious opportunities as well. Taking advantage of AI agent development platforms can give you the ability to tailor agents to your company’s specific needs—or create entirely new automation workflows. More specifically, by selecting an AI agent development platform that is “no code” or “low code,” like Oracle AI Agent Studio, you can expand the population of AI agent developers beyond highly technical staff. This opens the door to accelerated agent deployment and  tighter alignment between business needs and enabling technology.\nAgents as applications\nAI agents can be thought of as mini applications. They take inputs, process them, and offer useful information in response or trigger a transaction, often in an external system. To date, developing and deploying agents has required significant time and software programming expertise. But now development platforms like Oracle AI Agent Studio make it possible to quickly define process flows and logic visually, then test and deploy working solutions without writing a single line of code.\nNo-code development platforms allow super users, rather than just specialized engineers, to create and deploy AI agents. Super users are technically adept business domain experts who manage the configuration, training, and first-tier support for applications. Visual interfaces and templates can significantly lower barriers to access and proficiency, giving super users the autonomy to address many of their own needs and make process changes quickly and without waiting for IT or long development cycles. The result is a faster pace of experimentation and solution validation, helping companies adapt with minimal delay to new requirements, regulations, or customer feedback.\nAs super users update or modify AI agents themselves, organizations can maintain better alignment between technology and evolving business priorities. While the long-term impact still\ndepends on effective governance\n, no-code AI agent development environments are expected to make automation more accessible, responsive, and relevant to day-to-day business operations.\nWhat about the complicated tech considerations?\nWhile this all sounds well and good, anyone with enterprise apps experience knows there’s more to it. And there is. Previous attempts to open up application development to the masses hit two main stumbling blocks: security, and application integration. Let’s see how AI Agent Studio addresses these.\nSecure at source\nAI Agent Studio relies on Fusion Apps’ role-based access control (RBAC) security model. RBAC governs users’ access to data and application functions based on a set of privileges that are assigned once, then universally applied across Fusion Apps. This has two practical implications. First, in AI Agent Studio, users creating agents can only see, edit, or create data for which they have already been granted access. And second, once agents are deployed, RBAC automatically grants (or denies) end users access based on their existing privileges in Fusion Apps. In other words, no matter who builds an agent, they can’t inadvertently give users access to sensitive information they shouldn’t have.\nApplication integration\nIntegrating custom applications normally requires programmers (at any level of proficiency) to use APIs to connect their apps with existing systems and data sources. This involves some hard-core skills: making REST calls, understanding failure codes and managing contingencies, and handling JSON or some other flavor of payload structures. In AI Agent Studio, agents can access data through business objects, which allow them to get or store data about Fusion Apps entities via an extrapolated layer. The agent’s creator just designates which business object the agent needs from a menu of available options. Similarly, AI Agent Studio allows users to build connectivity between agents and external, agent-based resources using standards-based integration frameworks like the Model Context Protocol and the Agent2Agent protocol.\nIn conclusion\nOracle AI Agent Studio isn’t just about what gets built, but also about who can build it and who gets access. By handling some of the previous obstacles to wider participation in applications development, AI Agent Studio makes it possible for more super users to try extending Fusion Applications functionality to meet their specific, unique needs. This can promote an accelerated, more nimble Fusion Apps deployment, helping to create tighter alignment between business needs and enabling technology.\nRelated posts you might like\nNew—Oracle AI Agent Studio for Fusion Apps\nGet started guide—design and build AI agent teams\nSee Oracle AI Agent Studio in action (demo video)\nIf you’re an Oracle customer and want to get new stories from\nThe Fusion Insider\nby email, sign up for\nOracle Cloud Customer Connect\n. If you’re an Oracle Partner and want to learn more, visit the\nOracle Partner Community\n."
  },
  {
    "title": "Preview the hottest Fusion Apps AI and strategy updates",
    "link": "https://blogs.oracle.com/fusioninsider/preview-the-hottest-fusion-ai-and-strategy-updates",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle AI World will showcase keynotes on AI developments in Fusion Applications.",
      "Sessions will provide guidance on adopting AI in various business functions.",
      "Attendees can learn about maximizing innovation and minimizing downtime with quarterly updates."
    ],
    "tags": [
      "oracle",
      "fusion-apps",
      "artificial-intelligence",
      "cloud-computing",
      "enterprise-resource-planning",
      "human-capital-management",
      "supply-chain-management",
      "customer-experience",
      "ai-adoption"
    ],
    "original_text": "Whether you’re going to Oracle AI World in October or not, knowing what’s on the program can keep you updated on product announcements and direction. To that end, this article shares guidance from Fusion Development product experts on important keynotes and sessions—plus a few hidden gems—with explanations for why they were chosen. This year many of these sessions introduce new AI developments and explain how your organization can adopt them.\nFusion Applications (cross suite)\nAll Oracle Fusion Cloud Applications customers should plan to see Executive Vice President Steve Miranda’s main stage keynote, “\nAccelerate Success with AI in Oracle Applications\n,” and the AI solution keynote, “\nWhat’s New and Next for Oracle AI in Fusion Applications\n,” with Senior Vice President Chris Leone. They’ll give you a glimpse into the future of Fusion Apps for the upcoming year and beyond.\nAnd regardless of your functional area, these four sessions can help you get the most out of your Fusion Apps subscription.\n1.\nHow to Get Started with AI in Oracle Fusion Applications\n:\nThis session gives concrete, real-world guidance to help you launch or grow your AI initiatives.\nWhy we like it: You’ll learn about use cases that deliver immediate value and hear lessons learned from customers who are implementing and using Fusion AI.\n2.\nMaximize Innovation, Minimize Downtime with Fusion Apps Quarterly Maintenance\n:\nThis session provides tips for adopting the new features delivered each quarter instead of merely completing software updates and patching.\nWhy we like it: Oracle delivers new Fusion Apps innovations—including AI features and agents—via quarterly updates, so understanding the update process is critical.\n3.\nWhy Move from On-Premises to Fusion Cloud Applications\n:\nThis session is for on-premises customers that want to embrace AI.\nWhy we like it: Learn why moving to a subscription model can reduce TCO and why SaaS applications give you low-risk, secure access to the latest innovations, including AI agents.\n4.\nFusion Security in Action: Converging Controls, Insights, and Automation\n:\nThis session covers Oracle’s defense-in-depth approach with embedded controls to govern access, monitor activity, and enforce policies.\nWhy we like it: Understanding how we protect your data in Fusion Apps can give you peace of mind and the confidence to adopt new features.\nERP / EPM\nRedefining Finance: Embracing the Era of Agentic AI\n:\nBecause they can process high volumes of data, perform real-time analyses, and summarize information, AI agents are poised to automate many routine finance tasks.\nWhy we like it: Learn best practices and strategies for adopting them in your organization; this session provides practical direction for using AI agents to streamline operations and improve decision-making.\nAlso recommended:\nthe solution keynote for finance\nand\nthe strategy session for EPM\n—both delivered by Fusion Dev execs—and the sessions on\nimproving your financial close\nand\nusing AI agents in cash management\n.\nHCM\nA Path to Success with AI: Lessons from HR Leaders\n:\nIn this session, you’ll hear from HR leaders who are using GenAI and AI agents to improve efficiency, deliver better employee experiences, and meet their hiring and retention goals. They’ll share their strategies for integrating AI into HR processes.\nWhy we like it: Whether you’re just starting to implement AI or fine-tuning AI solutions, this session will deliver practical, how-to advice for AI adoption from Oracle Fusion Cloud HCM customers and the Fusion Center of Excellence.\nAlso recommended:\nthe HCM solution keynote\nfor a preview of new and upcoming innovations, and these sessions on how AI can help you\nfind the best talent\nand\nmake HR operations more efficient\n.\nSCM\nAI Agents for Fusion SCM: Overview of the AI Agent Studio and AI Agents for SCM\n:\nSupply chain teams can use AI agents to streamline planning, automate procurement, optimize logistics, and resolve disruptions. Learn how to align AI agents with your business rules so you can embed them in workflows and deliver relevant, contextual information to frontline workers.\nWhy we like it: SCM product development leaders give you a realistic look at what it takes to build custom AI agents in AI Agent Studio as well as how to deploy embedded agents.\nAlso recommended:\nthe SCM solution keynote\n, focused on new AI and product developments, this timely session on\nmanaging the impact of tariffs\n, and\nthis series of strategy sessions\nthat share roadmaps for supply chain planning, procurement, product lifecycle management, logistics, and more.\nCX—Sales, Service, and Marketing\nCX at the Helm: Why the AI-First Enterprise Starts with Customer Experience\n:\nAI isn’t just changing how you sell, market, and serve. It’s also shaping operating models. In this session, CX leaders can learn how to identify high-value opportunities, rethink job roles, and build internal momentum for AI adoption.\nWhy we like it: The front office has the potential to lead enterprise AI adoption with agents designed to make customer experiences faster and more accurate. Learn where to use AI and how to adapt to resulting changes to workflows and processes.\nAlso recommended:\nthe CX solution keynote\nwith Senior Vice President Rob Pinkerton, and these 20-minute theater sessions on\nusing customer data platforms to increase revenue\nand\nbuilding a plan for AI adoption in CX\n.\nConclusion\nUnderstanding the focus of AI World is valuable for every Fusion Apps customer. If you’re unable to attend, this guide offers a glimpse of the product strategy and AI innovations influencing the future of Fusion Apps. For attendees, this list can save you time sifting through the catalog—and it ensures you’re prioritizing the most impactful content. Remember that if the catalog lists any of these sessions as full you can show up to the room 10 minutes before the session starts and you may be able to find an empty seat. Enjoy the event!\nRelated posts you might like\n3 AI agents in Fusion HCM you can turn on today\nStart here—3 AI agents for Fusion SCM\nGet started with these 3 AI agents for Fusion CX\nIf you’re an Oracle customer and want to get new stories from\nThe Fusion Insider\nby email, sign up for\nOracle Cloud Customer Connect\n. If you’re an Oracle Partner and want to learn more, visit the\nOracle Partner Community\n."
  },
  {
    "title": "Oracle Autonomous AI Lakehouse",
    "link": "https://blogs.oracle.com/database/oracle-autonomous-ai-lakehouse-dbms-guru",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle Autonomous AI Lakehouse integrates data lake and data warehouse functionalities for enhanced analytics.",
      "The platform addresses operational challenges in data management with a unified set of tools.",
      "It supports real-time data access, improving decision-making for AI and analytics.",
      "Oracle's solution is designed for seamless operation across multiple cloud environments."
    ],
    "tags": [
      "oracle",
      "data-lakehouse",
      "artificial-intelligence",
      "cloud-computing",
      "data-management",
      "analytics",
      "real-time-data",
      "data-integration",
      "open-standards"
    ],
    "original_text": "Guest post from Carl Olofson\n,\nPrincipal Analyst, DBMSGuru LLC\nOverview: Why a Lakehouse?\nAI has become a critical key to success in business going forward. But enterprise AI is dependent on the availability of strategic data from across the enterprise, and for that data to be current and of good quality. This is largely dependent on the data management technology in use.\nConventionally, most enterprises have three sets of data management technology. One is operational, with a wide range of databases driving applications that perform business functions. Another is a small set of one or more large databases designed to collect key data from the operational systems and use that data for enterprise-wide analytics. These are commonly called data warehouses.\nOver the past couple of decades, many have added other data collections used either for more narrowly focused, near-term analysis or for business analysis performed via data science. These may contain ordered files or simple, often single table databases in an open table format such as Apache Iceberg and have a heterogeneous collection of data for analysis. This set of data management implementations is called data lakes, and the data is analyzed using Spark, Python scripts, or one of several SQL analytics implementations.\nA data platform designed to leverage the flexibility of the data lake with the rigor of the data warehouse is called a data lakehouse, which pulls and combines data from both types of databases with the addition of more operational data included in an ad hoc basis. As enterprises seek to leverage AI technology for comprehensive data analysis, they need the lakehouse to have depth of data, to support a variety of data formats and models, to scale dynamically, and to be robust, highly performant, and secure.\nOperational Challenges of the Lakehouse\nEnterprises face a number of daunting challenges in building a data lakehouse. These include the following:\nComplex management\n. Some lakehouses are built using separately acquired components. This can lead to performance and management challenges. A range of connectivity and management tools may be required. A lakehouse is always more straightforward to manage when managed with a single set of technologies.\nData transfer and consolidation\n. Some lakehouse offerings provide precious little in terms of enabling timely and flexible data transfer from sources, such as operational databases, to the data lake for analysis. Having a set of such tools from a single vendor, all designed to work as part of a system, is generally best.\nDefinitional metadata\nfor combining data from different sources is preferred to doing the work by hand, manually keeping notes that can be obscure and incomplete regarding what the data means.\nConnectivity\n. Inter-system interoperation and adjustment need to be simple and clean. Use one package here, and another package there, and pretty soon you have a mess on your hands.\nSupport for open standards\n. Building a stable team of developers and ensuring flexible access to all kinds of data and tools requires support for leading open standards and, in many cases, open-source solutions.\nPerformance\n. Many enterprises, in order to support the widest range of data formats and models, employ database systems from a variety of vendors featuring a range of performance characteristics. Such a situation can lead to inconsistent system-wide performance, leading to frustration and lost staff time.\nOracle Autonomous AI Lakehouse: An Open Multicloud Data Platform\nOracle has provided an integrated product solution to the issues described above. This facility enables the user to build and manage a lakehouse with consistent functionality that has been engineered together and includes built-in AI functionality. It addresses the above listed challenges as follows:\nComplex management\n. Instead of dealing with a potpourri of tools for collecting and managing data lakes, the Oracle Autonomous AI Lakehouse provides a simple, consistent set of tooling and user interfaces for all the jobs to be done in finding, defining, collecting and querying the data.\nData transfer and consolidation\n. Oracle provides GoldenGate and Oracle Data Integrator for data movement and synchronization into the data lakehouse from almost any source. For those with a substantial investment in other existing data lake and data warehouse technologies, Oracle Autonomous AI Lakehouse can interoperate with Microsoft Fabric, Amazon EMR, and Databricks.\nDefinitional metadata\nis supported through the Autonomous Data Catalog, which captures definitional metadata for data in databases, data lakes, data platforms, and various catalog-driven systems including Apache Iceberg, AWS Glue, Databricks Unity, and Snowflake Horizon. Instead of users navigating through individual catalogs, databases, and data stores, Oracle organizes the metadata into a single “catalog of catalogs” for ease in finding and understanding the data.\nConnectivity\n. Oracle supports direct, fast access to data in Iceberg tables and object storage through the Data Lake Accelerator, which optimizes such access for smooth, even performance.\nSupport for open standards\n. Although Oracle supports a variety of open standard access methods for Oracle AI Database, the Autonomous AI Lakehouse also provides broad data access capability for Apache Iceberg data, including support for a range of tools in the open-source ecosystem, data access through Apache Spark, Python, Scala, and SQL, and storage of Iceberg tables on object storage. In addition to Iceberg (and its storage format, Parquet), the platform can also access data in CSV, JSON, Avro, and Delta UniForm formats, demonstrating its openness and flexibility for organizations.\nAccess to real-time, operational data\n. Some data warehouse platforms only ingest and store data that represents past events. This means that users or AI agents of such systems are in fact accessing and making decisions based on stale data. In contrast, Autonomous AI Lakehouse has access to real-time, operational data blended with historical data, empowering decisions and taking actions based on up-to-date information.\nPerformance\n. Of course, Oracle Database features comprehensive features and tools for optimal support, but access to Iceberg tables is also highly optimized using the Data Lake Accelerator, which speeds up Iceberg data access for large-scale queries with servers provided on a pay-as-you-go basis. In addition, query performance of frequently accessed Iceberg data is improved by caching data within Oracle Exadata flash storage. So, although your Iceberg data may reside on object storage, accessing it won’t slow down your complex data queries.\nCloud Support Without Limits\nWhile other vendors adapt their platforms to the constraints of different hyperscaler clouds, Oracle Autonomous AI Data Lakehouse operates with no changes across Oracle Cloud Infrastructure (OCI) and  AWS, Google Cloud, and Microsoft Azure. This cloud support without limits enables customers to have the same experience with Autonomous AI Lakehouse wherever their data resides.\nConclusions\nWhatever narrow criteria have been applied for application databases and analytic databases in the past need to be revised in light of AI’s need to blend any data, anytime, and from anywhere, to provide comprehensive answers to questions both tactical and strategic. This AI hunger for data calls for vendors to build a different data lakehouse, one that is open, interoperable, and operates in real time—much like Autonomous AI Lakehouse—with robust connectivity to operational and application data sources as well as a strong data warehouse platform and a catalog of catalogs, allowing users or AI agents to easily search and find the data they need.\nThe data lakehouse providing comprehensive information needed to guide the enterprise in the future must be scalable, performant, and robust. Oracle Autonomous AI Lakehouse addresses these needs, and with its integrated AI capabilities can simplify the task of incorporating AI at every logical level in business management. It would seem clear that anyone looking to build a robust base of data access for their AI and other analytical work should consider the Oracle AI Data Lakehouse very seriously as its enabling data platform."
  },
  {
    "title": "Oracle True Cache – AI World Round-Up + Get Hands On",
    "link": "https://blogs.oracle.com/database/oracle-true-cache-ai-world-roundup-get-hands-on",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle AI World 2025 showcased enterprise AI innovations and strategies.",
      "Oracle True Cache enhances application performance by offloading queries from the primary database.",
      "LiveLabs offers free workshops for hands-on experience with Oracle True Cache."
    ],
    "tags": [
      "oracle",
      "ai-world",
      "true-cache",
      "enterprise-ai",
      "application-performance",
      "live-labs",
      "database",
      "technology",
      "workshops"
    ],
    "original_text": "It’s been an incredible Oracle AI World 2025\nOracle AI World 2025\nhas ended, bringing together customers, partners, and prospects from around the globe to experience our latest enterprise AI innovations and strategies. Relive the energy, excitement, learning, and connections that defined the event by watching this\nroundup video\n. Executive keynotes, deep-dive sessions, and hands-on labs came together for an inspiring celebration of AI and enterprise technology.\nIn my role as a champion of Oracle True Cache to boost application performance, it was amazing to meet many of our customers, partners and development community folks at the AI World 2025. The energy was incredible and this is truly the best part of my job where I can meet the folks that use Oracle products and hear directly from them about their use-cases and see how best we may help address their needs. I truly value the opportunity to meet with the attendees and learn from the collective wisdom of this fantastic community.\nI interacted with folks during the Oracle True Cache session (\nLRN2898\n) as well as at the Hands-On Lab, and also met several during the time at Demo Booth. A lot of you expressed an interest to learn more about True Cache, and I wanted to provide some resources to help with that.\nOracle LiveLabs provides an excellent opportunity to easily explore various labs and technical workshops for Oracle’s tools and technologies. LiveLabs is completely free! To reserve a workshop, simply log in with your Oracle (\noracle.com\n) account. Each LiveLabs reservation provides a self-contained environment to run the workshop. You can learn more here:\nhttps://livelabs.oracle.com/\nOracle True Cache hands-on workshop is available on the LiveLabs platform – So, jump right in and don’t hesitate to give this technology a spin which can be very useful in your journey with databases and applications!\nWhat is Oracle True Cache?\nOracle True Cache is an in-memory, consistent, and automatically managed cache for Oracle Database. True Cache is a SQL cache as well as key-value (object or JSON) cache for the database. It caches all Oracle database objects and types. True Cache is a fully functional, read-only replica of the primary database, except that it’s mostly diskless. One of the most awesome features of True Cache is that it is automatically managed, saving application developers from having to manage the cache in their caching tier, and saving developers from having to worry about managing cache consistency or time-to-live of items in their cache. This is all managed and truly makes the lives of application developers so much easier!\nOracle True Cache provides several business benefits related to application development and performance.\nImproves scalability and performance by offloading queries from the primary database.\nReduces application response time and network latency by deploying True Cache closer to the application. This especially benefits situations where a database is in a different location than the application due to data residency requirements.\nCreates a large, in-memory storage area by dividing data across multiple True Caches. The total size of the cached data across all True Caches can be much larger than it would be for a single primary database or cache.\nAutomatically maintains the cache contents.\nSimplifies development and maintenance by being transparent to the application.\nThere is a lot more to it and\nplease read this blog\nto get a good understanding of Oracle True Cache and the use-cases.\nNow, let’s get to the\nLiveLabs workshop for Oracle True Cache\n.\nOracle True Cache Workshop\nThis is a workshop on Oracle True Cache where you can get a feel for how True Cache can be used to scale reads even without partitioning your data! True Cache can help offload reads from the primary – thereby alleviating the primary database from becoming a bottleneck (this is a critical aspect to many customers and organizations). This also allows you to scale your workloads more efficiently.\nThis workshop is based on a demo application on a compute instance which is connected to a primary database configured with True Cache. The demo application is a java program using the Oracle JDBC driver. It simulates a high number of transactions for the primary database and demonstrates how offloading the read queries to True Cache helps in application performance (you can see the read only transactions per second which is a good indicator that shows the throughput gain).\nThe instructions in the\nLiveLabs\nare easy to follow along. It shows you how to setup the environment, initialization steps, and load data into the database. There is guidance on how you can use True Cache through JDBC, and see a glimpse of the power of using an automatically maintained cache in front of your database.\nDo try it out and also read more about Oracle True Cache in the\ndocumentation section\nand see for yourself how it can greatly benefit your applications. Oracle True Cache helps with relieving load on your primary database, providing higher availability for your systems, and better cost management for your enterprise.\nResources\nOracle True Cache Homepage:\nhttps://www.oracle.com/truecache\nOracle True Cache User’s Guide:\nTrue Cache User’s Guide\nOracle Live Labs Workshop for True Cache:\nLive Labs for True Cache"
  },
  {
    "title": "Oracle TxEventQ and Apache Kafka Integration: Two Powerful Paths to ...",
    "link": "https://blogs.oracle.com/database/oracle-txeventq-and-apache-kafka-integration-two-powerful-paths-to-modern-event-streaming",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle TxEventQ integrates event streaming directly into the Oracle AI Database.",
      "OKafka provides a brokerless alternative for Kafka-compatible applications.",
      "Kafka Connect connectors bridge Oracle AI Database with existing Kafka clusters.",
      "TxEventQ ensures atomicity and exactly-once semantics for message operations.",
      "Setup requires Oracle AI Database 21c or later with specific configurations."
    ],
    "tags": [
      "oracle",
      "txeventq",
      "apache-kafka",
      "event-streaming",
      "database",
      "integration",
      "brokerless",
      "ai-database",
      "kafka-connect"
    ],
    "original_text": "Introduction\nOracle Transactional Event Queues (TxEventQ) brings event streaming natively inside the Oracle AI Database. Built on top of Advanced Queuing (AQ) but enhanced for scale, partitioning, and pub-sub semantics, TxEventQ eliminates the need for a separate broker infrastructure in many architectures.\nTo make integration seamless for Kafka-based systems, Oracle offers two key options:\nKafka Java Client for TxEventQ (OKafka)\n– a brokerless replacement path.\nKafka Connect Source and Sink Connectors for TxEventQ\n– a bridge between Oracle AI Database and existing Kafka clusters.\nEach approach serves a different need—either simplifying your stack or enabling hybrid interoperability.\nOption A: Kafka Java Client for TxEventQ (OKafka)\nWhat It Is\nOKafka is a Kafka-compatible Java client that replaces the external Kafka broker with the Oracle AI Database itself. It implements familiar Kafka APIs such as\nProducer\n,\nConsumer\n, and\nAdmin\n, but routes messages through JDBC and AQ to TxEventQ topics inside the database.\nThis allows existing Kafka applications to run with minimal changes—mostly configuration adjustments.\nHow It Works\nIn the OKafka path, Kafka topics map directly to TxEventQ queues.\nPartitions correspond to database-level partitions, and offsets are maintained transactionally.\nEvery enqueue (produce) and dequeue (consume) operation participates in the same Oracle transaction, guaranteeing atomicity and exactly-once semantics.\nYour producer and consumer code stays nearly identical; you only point\nbootstrap.servers\nto the Oracle listener, configure JDBC or wallet-based credentials, and use uppercase topic names.\nThe Oracle AI Database acts as both the event store and message broker, maintaining persistence, ordering, and recovery automatically.\nSetup Basics\nEnsure you are using Oracle AI Database 21c or later, where TxEventQ is available.\nCreate or grant a user with AQ privileges (\nDBMS_AQADM\n,\nDBMS_AQ\n, etc.).\nSet an appropriate\nSTREAMS_POOL_SIZE\nand ensure the database listener is reachable.\nAdd OKafka and Oracle JDBC/AQ libraries to your application classpath.\nCreate a TxEventQ topic via\nDBMS_AQADM.CREATE_DATABASE_KAFKA_TOPIC\nand reference it from your producer.\nExample Usage\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nProperties props = new Properties();\nprops.put(\"bootstrap.servers\", \"dbhost:1521\");\nprops.put(\"oracle.service.name\", \"ORCLPDB1\");\nprops.put(\"security.protocol\", \"PLAINTEXT\");\nprops.put(\"oracle.net.tns_admin\", \"/path/to/tns\");\n\nAdminClient admin = AdminClient.create(props);\nNewTopic topic = new NewTopic(\"MY_TOPIC\", 3, (short)1);\nadmin.createTopics(Collections.singleton(topic)).all().get();\n\nKafkaProducer<String,String> producer =\nnew KafkaProducer<>(props, new StringSerializer(), new StringSerializer());\nproducer.send(new ProducerRecord<>(\"MY_TOPIC\", \"key\", \"value\")).get();\nproducer.close();\nadmin.close();"
  },
  {
    "title": "Introducing Oracle AI Database 26ai: Next-Gen AI-Native Database for ...",
    "link": "https://blogs.oracle.com/database/oracle-announces-oracle-ai-database-26ai",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle AI Database 26ai is a next-gen AI-native database with integrated AI capabilities.",
      "The database simplifies transitions from Oracle Database 23ai with no upgrade required.",
      "New features include Unified Hybrid Vector Search and enhanced data privacy governance."
    ],
    "tags": [
      "oracle",
      "ai-database",
      "cloud-computing",
      "data-privacy",
      "vector-search",
      "autonomous-database",
      "machine-learning",
      "data-governance",
      "analytics",
      "enterprise-software"
    ],
    "original_text": "We are thrilled to introduce Oracle AI Database 26ai, our next-generation AI-native database, with AI architected into the entire data and development stack. Oracle AI Database enables you to easily deliver trusted AI-powered insights, innovations, and productivity for all your data everywhere, including both operational systems and analytic data lakes. You can now run dynamic agentic AI workflows to provide sophisticated answers and actions that combine private database data with public information.\nOracle AI Database 26ai replaces Oracle Database 23ai. Transitioning from 23ai to 26ai is simple—just apply the October 2025 release update with no database upgrade or application re-certification. Advanced AI features like AI Vector Search are included at no additional charge.\nSince the introduction of Oracle Database 23ai, we’ve delivered a steady cadence of AI-first capabilities that broaden functionality and increase performance. Those updates:\nextended AI Vector search capabilities,\nexpanded support for combining vector search with all other data types,\nadded support for agentic AI, and\nhardened data privacy governance and observability\npaving the way for Oracle AI Database 26ai’s unified AI experience. In short, 23ai established the foundation; 26ai consolidates and elevates it into a cohesive, AI-native platform for production workloads at scale.\nLet’s take a tour through highlights of capabilities that will be available in Oracle AI Database 26ai, which we’ll refer to as AI Database in the rest of this post.\nFor retrieval and reasoning using multimodal enterprise data, such as PDFs, videos, and images, AI Database introduces Unified Hybrid Vector Search. You can blend vectors with relational, text, JSON, graph, and spatial predicates in a single query to retrieve documents, images, audio, video, and table rows together. Pair that with industry-leading LLMs and the Model Context Protocol (MCP) to enable agentic workflows that iterate, fetch additional context, and deliver higher-quality answers—grounded in your private data.\nWe’ve made agents first-class citizens in the database. Select AI Agent lets you define, run, and govern AI agents inside Autonomous AI Database using in-database tools, external tools over REST, or MCP Servers. For teams that prefer a no-code approach, the Private Agent Factory packages a builder and deployment framework you can run in any environment you control, so you keep data private while benefiting from the full performance and security of the database.\nYou have flexible model choices without losing control of data. Use ONNX embedding models and integrate with LLM providers or run private inference via Private AI Services Container to avoid sending data to third-party AI services. AI Database also supports integration with NVIDIA NIM containers for embeddings and RAG pipelines, and its design accommodates future GPU acceleration for vector indexing with NVIDIA CAGRA and cuVS.\nAI Database expands your analytics surface area without fragmenting it. The new Autonomous AI Lakehouse transforms your warehouse or data lake into a truly open and multi-vendor AI lake house.  Autonomous AI Lakehouse supports reading and writing Apache Iceberg data formats in the object store, so you can bring all the benefits of Oracle Analytics such as Exadata-powered performance and serverless scaling to open lakehouse tables across OCI, AWS, Azure, and Google Cloud.  Autonomous AI Lakehouse is interoperable with Databricks, Snowflake, and many other Iceberg compliant data stores on the same clouds allowing seamless data sharing between data stores without moving the data.\nWith Oracle AI database, Developers get a simpler, more powerful method of working with data. Relational, JSON, and graph are unified, so the same data can be accessed via SQL, as documents, or as graphs—no brittle ETL hops. Data Annotations let you describe purpose, semantics, and constraints, so AI-powered tooling and agents are prepared to generate better code and more accurate answers. For rapid app delivery, the upcoming APEX AI Application Generator will use natural language to build enterprise-grade experiences faster.\nPerformance and elasticity are engineered into the stack. Oracle Exadata for AI offloads vector search to intelligent storage for dramatic speedups and scales both to high-end workloads and, with the new Exascale software architecture, to smaller, lower-cost deployments—ideal for smaller enterprises or workgroups, or teams piloting AI features and then ramping to production. True Cache brings an application-transparent, transactionally consistent mid-tier cache, so you can keep latency low while retaining full SQL compatibility including Oracle Relational, Vector, JSON, Spatial, and Graph query semantics.\nSecurity and data governance are enforced in-database. Built-in Data Privacy Protection will enable row-, column-, and cell-level controls plus dynamic data masking, so both users and AI agents only see authorized data. SQL Firewall adds scalable, in-database protection against unauthorized SQL and injection attacks without adding a mid-tier server that adds extra network latency and management costs. For crypto-agility, AI Database implements NIST-approved quantum-resistant algorithms (ML-KEM) for data-in-flight and already supports quantum-resistant encryption for data-at-rest.\nMission-critical operations are covered from end to end. Oracle Database Zero Data Loss Cloud Protect provides on-premises databases with real-time protection by continuously shipping changed data to the cloud — helping defend against data loss and ransomware. Globally Distributed Database delivers multi-master, active-active deployments with built-in RAFT replication and sub-three-second failover with zero data loss, supporting both ultra-scale and data sovereignty requirements.\nBottom line: Oracle AI Database uniquely brings AI to both mission-critical OLTP systems and data lakes, allowing you to easily build trustworthy, high performance AI solutions on the databases that already run your business. It enables delivery of trusted AI-powered insights, innovations, and productivity for all data, across the cloud, multicloud, and on-premises\n​\n. New AI capabilities are available everywhere, for no additional charge\n​.\nOracle has adopted a cloud-first, developer-first strategy. Pursuant to that strategy we have released Oracle AI Database first on the following cloud platforms:\nOracle Autonomous Database\nOracle Exadata Database Service\nOracle Base Database Service\nOracle Database@Azure\nOracle Database@Google Cloud\nOracle Database@AWS\nOracle Database installed in Oracle Cloud Infrastructure Compute VMs\nFor on-premises, we have released Oracle AI Database on the following platforms:\nExadata Cloud@Customer\nCompute Cloud@Customer\nOracle Exadata Database Machine\nOracle Database Appliance\nOracle Private Cloud Appliance\nTo quickly and easily try AI Database you can simply go to FreeSQL.com.  For development and testing, we have released\nOracle AI Database Free\nfor Linux x86, ARM Linux, and Windows. For larger scale development and testing, we suggest using cloud services such as Oracle Autonomous AI Database, Oracle Exadata Exascale, Oracle Base Database, running your own Oracle AI Database on Oracle Cloud Infrastructure, or enrolling in our\nBeta program\n.\nWhile the date for Oracle AI Database on other platforms has not been announced, we will update\nMy Oracle Support (MOS) Doc ID: 742060.1\nwhen it is announced. Please continue to refer to this MOS document for all Oracle Database release and support schedules."
  },
  {
    "title": "Industry Analysts Comment on Oracle AI Database News at AI World 2025",
    "link": "https://blogs.oracle.com/database/industry-analyst-quotes-on-oracle-ai-database-news-at-ai-world-2025",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle AI Database 26ai integrates AI into data management for enhanced functionality.",
      "The database supports diverse AI applications, enabling custom agentic AI workflows.",
      "Oracle's focus on security and efficiency addresses challenges in AI adoption."
    ],
    "tags": [
      "oracle",
      "ai-database",
      "data-management",
      "agentic-ai",
      "cloud-computing",
      "data-security",
      "enterprise-ai",
      "machine-learning",
      "data-integration"
    ],
    "original_text": "Oracle AI Database 26ai architects AI into the core of data management, furthering Oracle’s commitment to help customers securely bring AI to all their data, everywhere. This milestone advances Oracle’s “AI for Data” vision of a next-generation AI-native database with use of AI across the entire data and development stack, including AI Vector Search, AI for Database Management, AI for Data Development, AI for Application Development, and AI for Analytics. Customers can now run dynamic agentic AI workflows to provide sophisticated answers and actions that combine private database data with public information.\nOracle AI Database’s built-in AI capabilities provide customers wide freedom of choice when building and deploying AI applications including support for: the Apache Iceberg open table format; Model Context Protocol (MCP); industry-leading LLMs; popular agentic AI frameworks; and Open Neural Network Exchange (ONNX) embedding models. Oracle AI Database’s mission-critical functionality brings AI to data securely, efficiently, and reliably wherever it resides—Oracle Cloud, leading hyperscale clouds, private cloud, or on-premises.\nRead the press release\nWhat Industry Experts Are Saying\n“Great AI needs great data. With Oracle AI Database 26ai, customers get both. It’s the single place where their business data lives—current, consistent, and secure. And it’s the best place to use AI on that data without moving it. To help simplify and accelerate AI adoption, AI Database 26ai includes impressive new AI features that go beyond AI Vector Search. A highlight is Oracle’s architecting Agentic AI into the database, enabling customers to build, deploy, and manage their own in-database AI agents using a no-code visual platform that includes pre-built agents. As Oracle’s converged database leadership in transaction processing goes unchallenged, its leadership position in the data and AI space continues to rise sharply as well.”\n—Holger Mueller, Vice President and Principal Analyst, Constellation Research\n“Oracle has cemented its leadership as the database for mission-critical workloads—which are even more critical in the AI era, as agents need transactions to run successfully and they move to create even more transactions than possible with their human counterparts. With Oracle AI Database 26ai, Oracle enables its customers to successfully move into the AI era, leveraging their existing investments in software, skills and know-how. For Oracle customers it’s not ‘bring the data to AI,’ but it’s ‘AI comes to the data’—and with that, organizations can leverage their existing investments and software assets.”\n—Holger Mueller, Vice President and Principal Analyst, Constellation Research\n“Time and complexity are absolutely not the friends of GenAI LLM users. Oracle recognized these issues several years ago and made it their mission to fix these problems. Oracle made huge strides with the release of Oracle AI Database 23ai. But the release of its latest AI Database, 26ai, takes it to a whole new level by significantly accelerating time-to-value while radically reducing complexity. Its innovative AI-powered features are set to transform how organizations unlock insights, boost performance, and reimagine what’s possible with their data.”\n—Marc Staimer, Sr. Contributor to theCUBEresearch\n“The rise of agentic AI is further manifested in the release of Oracle AI Database 26ai. By building agentic AI capabilities directly into its database, Oracle enables a new class of dynamic, data-driven applications where intelligence and automation are native features. No one can match Oracle’s breadth of integrated AI features combined with its focus on enterprise-grade security, data integrity, and massive scalability. This release further raises Oracle’s position as a trusted partner for organizations navigating the complexities of AI-driven transformation.”\n—Steve McDowell, Principal Analyst & Founder, NAND Research\n“As the saying goes ‘there is no AI without data.’ And Oracle databases hold the world’s most valuable data that is now critical for organizations to adopt AI into their business processes. The latest release, Oracle AI Database 26ai, incorporates AI into the core of data management, making it easier for customers to do much more than RAG with AI Vector Search. This new release unifies search across traditional internal data, including real-time operational data, graph, JSON, and AI vectors; enables customers to build, deploy, and manage custom AI agents; and team up agents to work on tasks. Oracle is turning its converged database into an AI powerhouse that even non-Oracle users should consider.”\n—Carl Olofson, Principal Analyst, DBMSGuru LLC\n“IDC surveys show that more than 80% of organizations report having a strategy for adopting and utilizing AI technologies, with nearly all investing in or embedding generative AI across their operations. In a recent IDC survey, 34.3% of organizations view AI as a driver of business transformation. Oracle is aligning with this trend as one of the first cloud database providers to bring AI to data, offering built-in vector embedding and search across LLMs and internal data. With Oracle AI Database 26ai, the company introduces additional built-in AI capabilities that enable customers to build, deploy, and manage custom AI agents, coordinate tasks among teams of agents, and use AI to develop trusted applications. Oracle provides flexibility for customers to implement AI through MCP Server, leading LLMs, agentic frameworks, and ONNX embedding models, available across multicloud, hybrid, and on-premises environments. These enhancements illustrate Oracle’s focus on meeting customer requirements for built-in AI in business processes.”\n—Devin Pratt, Research Director, IDC\n“Oracle AI Database 26ai makes Agentic AI a first-class citizen both inside and outside the database, safely and securely. Inside the database, the embedded MCP Server and storage of data privacy rules with the data ensures that agents won’t breach confidentiality. Outside the database, new Oracle Private AI Services Containers keep those guardrails in place when data is consumed by third-party AI services. And by extending Select AI, SQL developers can now trigger agents at their fingertips.”\n—Tony Baer, Principal, dbInsight\n“Oracle’s integration of AI directly into its AI Database 26ai shifts AI functionality from an add-on to a core capability. Embedding agentic AI enables enterprises to leverage context-rich reasoning across both private and public data, driving more actionable and higher-quality outcomes. This approach sets a new standard for enterprise AI platforms by emphasizing openness, integration, and security—positioning AI Database 26ai as a forward-looking model for building AI-ready data infrastructure.”\n—Matt Kimball, Vice President & Principal Analyst, Moor Insights & Strategy\n“In the era of AI and cloud, security is becoming existential. The threat landscape now extends far beyond ransomware to include AI-specific risks such as data leaks from LLMs, malicious prompts, unauthorized data access by AI agents, and, sooner than many expect, quantum computers capable of breaking today’s encryption. True to its updated branding, Oracle AI Database 26ai takes these challenges seriously, extending its built-in security features to address these AI scenarios. AI agents can now run within the database itself, eliminating data movement risks and ensuring that identity and access controls remain consistent at the database level. Generative Development, Oracle’s new AI-centric infrastructure, enables minimized AI data exposure with Trusted Data APIs and a significant reduction of application risks by restricting LLM inputs and validating outputs. Finally, the company has implemented NIST-approved quantum-resistant algorithms, enabling strong cryptographic agility of the entire platform. Having already led the database vendors in the latest KuppingerCole Leadership Compass on Data Security Platforms, Oracle is clearly aiming to maintain that leadership as security evolves for the age of intelligent data.”\n—Alexei Balaganski, CTO and Lead Analyst, KuppingerCole Analysts\n“Imagine creating your own agent or even a team of agents to perform tasks. With Oracle AI Database 26ai, customers can do just that using the company’s Oracle Select AI Agent, which provides a framework to build, deploy, and manage custom AI Agents. Developers define agents declaratively using PL/SQL or Python. An agent team could, for example, be used to automate finding solutions to database issues using DB logs. They could fetch logs, analyze the issue, and find a solution using RAG. This agent team could then write a report and post it on Slack. This is just one of the many uses for built-in AI. Oracle Database Engineering’s creativity is truly on display with Oracle AI Database 26ai, separating Oracle from many of its principal competitors in providing customers with a competitive edge.”\n—Bradley Shimmin, Vice President & Practice Lead, Data Intelligence, Analytics & Infrastructure The Futurum Group\n“With most enterprises storing different data types in different data siloes, the promise of an enterprise-grade AI solution that brings all of a company’s data together to take full advantage of AI remains an ongoing challenge. What’s needed is a true AI database, one that combines the ability to support all data types in a unified architecture—and bring it together with the rapid advances of AI—such as agentic AI, unified vector search, leading LLMs, MCP Server, NL-to-SQL and more. With its latest release, Oracle has done just that, by introducing an AI database that enables organizations to combine all of their private business data with public data and agentic frameworks to rapidly advance their business forward with AI. The enterprise database for the era of AI has a new name—and it’s Oracle AI Database.”\n—Ron Westfall, VP, Practice Lead, Networking and Infrastructure, HyperFRAME Research\n“In our view, the fastest and safest path to agentic AI for Oracle shops is to bring AI to the data you already govern. Oracle AI Database 26ai embeds key agentic primitives like vectors, RAG, tool use, and multi-step orchestration—directly in the database. This reduces data movement, latency, and risk while keeping policies, lineage, and controls intact. We advise CIOs, CTOs and chief AI officers to validate workload fit and TCO, but for estates running mission-critical Oracle workloads, this is a pragmatic way to pilot and scale AI assistants and teams of agents on harmonized data without rebuilding the entire estate.”\n—Dave Vellante, Co-Founder and Chief Research Officer, theCube Research\n“Data fragmentation and stale data are two of the greatest barriers to AI adoption. By supporting all data types and unifying transactional, analytic and AI workloads within a single, scalable architecture, Oracle AI Database 26ai provides a clear path for organizations to establish a single version of the truth.”\n—David Floyer, CTO, theCUBE Research\n“Oracle AI Database 26ai doesn’t bolt AI onto data, it fuses them. That architectural choice is why Oracle now sets the pace for enterprise-grade AI where many rivals still rely on data pipelines, ETL, basically the equivalent of duct tape, which simply doesn’t scale in the AI era. Plus, agentic AI workflows that combine private database context with public data put Oracle in a different league, where production-ready AI meets real-world enterprise scale for business leaders.”\n—Stephen Catanzano, Senior Analyst, Omdia\n“Today, developers building AI-powered applications are driving technology decisions like never before. Empowering them with frictionless tools is critical to fueling the next wave of innovative, user-centric apps. Oracle AI Database 26ai Free breaks down access barriers, putting advanced AI—which will include in-database AI agents—directly in developers’ hands and enable them to shape the future on their own terms. This move reinforces Oracle’s commitment to the developer community.”\n—Steven Dickens, CEO and Principal Analyst, HyperFRAME Research\n“Oracle AI Database 26ai marks a transformative leap in database technology by embedding AI at its core, enabling seamless integration across diverse data types and workloads. With Agentic AI frameworks, AI-assisted appdev, support for Apache Iceberg, and advanced security measures such as quantum-resistant encryption, Oracle is not only future-proofing data management, but also empowering enterprises to harness AI-driven insights across multicloud and on-premises environments. Oracle AI Database redefines how organizations can securely and efficiently turn data into a strategic asset to accelerate innovation and boost productivity.”\n—Richard Winter, CEO, Wintercorp"
  },
  {
    "title": "Getting Started with Oracle AI Database AI Vector Search",
    "link": "https://blogs.oracle.com/database/getting-started-with-oracle-database-23ai-ai-vector-search",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle Database 23ai introduces AI Vector Search for enhanced similarity search capabilities.",
      "AI Vector Search utilizes vector embeddings to find semantically similar objects efficiently.",
      "The feature supports various use cases including chatbots, data analysis, and image processing."
    ],
    "tags": [
      "oracle",
      "ai-database",
      "vector-search",
      "similarity-search",
      "data-analysis",
      "machine-learning",
      "cloud-computing",
      "natural-language-processing",
      "embedding-models"
    ],
    "original_text": "Oracle\nannounced\nthe availability of Oracle Database 23ai in May 2024. Oracle AI Database adds to the more than 300 new features available in Oracle Database 23ai, so there’s a lot to learn. Dominic Giles highlights several marquee features in his blog\npost\n, but one of the most exciting new features of Oracle AI Database is Oracle AI Vector Search.\nAn excellent introduction to AI Vector Search is available\nhere\n. It covers in quite a bit of detail the additions to Oracle AI Database to support similarity search, the key benefits, and some of the use cases that AI Vector Search addresses.\nThere are also several blogs and labs that walk through the steps needed to create vectors using vector embedding models and run similarity searches. However, there are fewer articles that explain what all these things are and why you need to know about them. In this post, I will provide additional explanations and show examples of how AI Vector Search delivers these capabilities in Oracle AI Database.\nNote:\nSince this post was originally written we have added an Oracle LiveLab where you can try out AI Vector Search and examples similar to what we cover in this post. More details are available in this post:\nNew AI Vector Search LiveLabs Workshop Available\nor you can give it a try\nhere\n.\nAt the heart of AI Vector Search is the ability to do a\nsimilarity\nsearch. A similarity search works with the semantic representations of your data rather than the value (words or pixels) and finds similar objects quickly. For example, find other images or documents that look like this one.  It uses vectors, or more precisely vector embeddings, to search for semantically similar objects based on their proximity to each other. In other words, vector embeddings are a way of representing almost any kind of data, like text, images, videos, and even music, as points in a multidimensional space where the locations of those points and proximity to other data are semantically meaningful.\nTraditionally, relational searches have been based on attribute values or keywords. With AI Vector Search, structured and, more importantly, unstructured data can be searched for similarities based on the semantic meaning of the data. This opens up a whole new world of possibilities, which is why there is so much excitement around this new feature. Use cases like chatbots, natural language processing, data analysis, image processing, and geographic analysis can leverage AI Vector Search in new and exciting ways.\nOracle AI Vector Search includes a collection of features to enable semantic or similarity search within the Oracle AI Database. These features include:\n•    a new\nVECTOR data type\nfor storing vector embeddings\n•\nimporting pre-trained embedding models\ninto Oracle AI Database\n•\ncreating embeddings in the database\nlocally or loading externally generated embeddings\n•    new\nstate-of-the-art vector indexes\nfor fast similarity searches\n•    new\nSQL operators, and syntax\n, to easily combine relational search on business data with semantic search\n•    supports\nRetrieval Augmented Generation (RAG) to augment LLM\nresponses with enterprise specific content\nRather than repeat a description of each of these features, the rest of this post and future posts will walk through examples of these features along with a description of how these features are used to enable and use similarity search.\nGetting Started\nOracle AI Vector Search requires Oracle AI Database. Currently, it is available on Oracle Cloud (including Oracle Autonomous AI Database), Oracle Cloud@Customer,\nOracle Exadata\n, Oracle Database Appliance,\nOracle Database@Azure\n,\nOracle Database@Google Cloud\n,\nOracle Database@AWS\nand\nOracle AI Database Free\n. For the latest information on platform availability, see the MOS Note\nRelease Schedule of Current Database Releases (Doc ID 742060.1)\n.\nSample Data Set\nFor the following examples in this post, we’re going to use part of the crime incidents dataset available on the\nChicago Data Portal\n. This dataset combines both category fields along with a text description that I will use to highlight how to do similarity searches and how they can be combined with attribute filtering to perform relational searches with similarity searches. The data that I downloaded contains roughly 6.8 million rows spanning multiple years.\nWe will be using a subset of the dataset with the following columns in a new table called SEARCH_DATA:\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nSQL> desc search_data\nName Null? Type\n----------------------------- -------- --------------------\nID NUMBER\nDESCRIPTION VARCHAR2(100)\nLOCATION_DESC VARCHAR2(100)\nDISTRICT VARCHAR2(20)\nWARD NUMBER\nCOMMUNITY VARCHAR2(20)\nC_YEAR NUMBER\nThe SEARCH_DATA table has 469,380 rows for the year 2004. The DESCRIPTION column mentioned above has contents like the following:\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nDESCRIPTION\n------------------------------------------------------\nTO PROPERTY\nPOSS: CANNABIS 30GMS OR LESS\nAGGRAVATED: HANDGUN\nOTHER VEHICLE OFFENSE\nAUTOMOBILE\nVector Embedding Models\nTo enable similarity search, we will need to create vector embeddings for the column(s) we would like to search on, which, in our examples, is the DESCRIPTION column. Vector embeddings are stored in a column of data type VECTOR. A vector embedding is a mathematical vector representation of data points or, more simply, an array of numbers. Vector embeddings are generated using Machine Learning models. This is the first place we see AI come into play.\nHow do you decide which embedding model to use? After all, there are open-source embedding models and proprietary embedding models that you might have to pay for, or you could create and train your own embedding models. To add to the confusion, each embedding model has been trained on specific data. The type of embedding model you use will depend on the type of data that you plan to embed and how well that model performs for the searches you or your application need to perform.\nOnce you decide on one or more embedding models to try, you can choose to create vector embeddings outside the database or inside the database by importing the models directly into Oracle AI Database if they are compatible with the Open Neural Network Exchange (ONNX) standard. Since Oracle AI Database implements an ONNX runtime directly within the database, these imported models can be used to generate vector embeddings in Oracle AI Database.\nIn the following examples, we are going to be operating on text-based data, so we will use a sentence-transformer based model. Here is a\nblog post\nthat details converting pre-trained transformer models from Hugging Face, which is a site that hosts open-source Python libraries for deep learning and offers thousands of pre-trained models, into an ONNX format using an Oracle utility called OML4Py. It then details how to load the model(s) into Oracle AI Database.\nHere is another\nblog post\nthat details how to load a pre-built vector embedding model into the database without first augmenting the model with the necessary pre- and post-processing steps to convert it into ONNX format. And finally, here is a\npost\nthat details the types of embedding models that have been tested with AI Vector Search.\nFor our example, we will take the easy path and use the pre-built all-MiniLM-L12-v2 model that was detailed in the blog post about using a pre-built vector embedding model above. It is a compact yet powerful and was built using the sentence-transformers library and will work for our data requirements.  It has been unzipped into an OS directory on the database server, and a database directory called DM_DUMP has been created that points to that OS directory. The following command can then be run to import the ONNX file into the database:\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nSQL> exec dbms_vector.load_onnx_model('DM_DUMP','all_MiniLM_L12_v2.onnx','minilm_l12_v2',\nJSON('{\"function\" : \"embedding\", \"embeddingOutput\" : \"embedding\", \"input\": {\"input\": [\"DATA\"]}}'));\nRunning the following SQL shows that the model name “MINILM_L12_V2” has been loaded into the database:\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nSQL> SELECT model_name, mining_function, algorithm, algorithm_type, model_size\nFROM user_mining_models;\n\nMODEL_NAME MINING_FUNCTION ALGORITHM ALGORITHM_TYPE MODEL_SIZE\n-------------- ---------------- ---------- -------------- ----------\nMINILM_L12_V2 EMBEDDING ONNX NATIVE 133322334\n\nSQL>\nWe can also display the model’s characteristics:\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nSQL> SELECT model_name, attribute_name, attribute_type, data_type, vector_info\nFROM user_mining_model_attributes;\n\nMODEL_NAME ATTRIBUTE_NAME ATTRIBUTE_TYPE DATA_TYPE VECTOR_INFO\n-------------- ---------------- --------------- ----------- -------------------\nMINILM_L12_V2 ORA$ONNXTARGET VECTOR VECTOR VECTOR(384,FLOAT32)\nMINILM_L12_V2 INPUT TEXT VARCHAR2\n\nSQL>\nNotice the VECTOR_INFO column. This shows the dimension format for the model. Dimension formats will be explained further in the section Creating Vector Embeddings.\nWe can test what we have done so far by running a simple query to embed the word ‘hello’:\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nSQL> SELECT TO_VECTOR(VECTOR_EMBEDDING(minilm_l12_v2 USING 'hello' as input));\n\nTO_VECTOR(VECTOR_EMBEDDING(MINILM_L12_v2USING'HELLO'ASINPUT))\n------------------------------------------------------------------------------------------------------------------------------------------------------\n[-7.49069825E-002,-1.44330608E-002,4.86499295E-002,-2.713810\n28E-002,-4.30882089E-002,-1.47763401E-001,6.88331053E-002,-1\n.37038985E-002,-5.35686724E-002,2.69752908E-002,-6.28339127E\n-003,-3.98834869E-002,7.65678426E-003,-3.78089696E-002,-1.17\n558083E-002,-3.46409045E-002,1.29357144E-001,-2.52777878E-00\n2,-1.52099226E-002,7.30356318E-004,-8.06888491E-002,2.693785\n54E-002,-9.87356976E-002,-3.41076851E-002,-2.70294175E-002,-\n7.32003674E-002,5.08588664E-002,-1.72562376E-002,7.28218481E\n\n< A bunch of numbers have been deleted >\n\n41633E-002,5.40374406E-002,4.60668281E-003,4.81108278E-002,-\n1.18950203E-001,-4.22098711E-002,4.28496249E-004,-4.60483041\nE-003,-6.80256784E-002,2.4777215E-002,5.72777987E-002,3.3987\n131E-002,-3.80932316E-002,5.46789682E-003,1.50439981E-002,-1\n.71866838E-003,-4.49497951E-003,8.36174041E-002,3.61522138E-\n002,-2.27608755E-002,1.0930731E-002,-4.64579314E-002,-2.5119\n7945E-002,3.10342927E-002,1.40036559E-002,2.80776881E-002,-7\n.75460666E-003,-3.13466154E-002,5.54159284E-002]\n\nSQL>\nCreating Vector Embeddings\nNow, we’re ready to create vector embeddings for the DESCRIPTION column. First, we need to add a column to our table to store the vector embeddings. The column will be of data type VECTOR. You can optionally specify the number of dimensions and their format. If you don’t specify any of them, you can enter vectors of different dimensions with different formats, although not at the same time. This is a simplification to help you get started with using vectors in Oracle AI Database and avoids having to recreate the vector definition if you later decide to change the vector embedding model and it uses a different number of dimensions and/or format.\nThe number of dimensions must be strictly greater than zero, with a maximum of 65535 vectors.\nThe possible dimension formats are:\n•    INT8 (8-bit integers)\n•    FLOAT32 (32-bit IEEE floating-point numbers)\n•    FLOAT64 (64-bit IEEE floating-point numbers)\n•    BINARY (packed UINT8 bytes where each dimension is a single bit)\nTo add a vector column to an existing table just requires an ALTER TABLE statement:\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nSQL> ALTER TABLE search_data ADD vector_desc VECTOR;\nNotice below in the describe command that when the number of dimensions and the format are not included, you will get a definition of VECTOR(*, *).\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nSQL> desc search_data\nName Null? Type\n----------------------------- -------- --------------------\nID NUMBER\nDESCRIPTION VARCHAR2(100)\nLOCATION_DESC VARCHAR2(100)\nDISTRICT VARCHAR2(20)\nWARD NUMBER\nCOMMUNITY VARCHAR2(20)\nC_YEAR NUMBER\nVECTOR_DESC VECTOR(*, *)\nThere are various ways to generate vector embeddings and load them into a VECTOR data type column. For our example, I chose to run a CREATE TABLE AS SELECT command because I thought that was the easiest and fastest method since we are using an embedding model that has been loaded into the database.\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nSQL> DROP TABLE search_data PURGE;\n\nSQL> CREATE TABLE search_data AS\nSELECT id, description, location_desc, district, ward, community, c_year,\nvector_embedding(minilm_l12_v2 using DESCRIPTION as input) as vector_desc\nFROM chicago_data WHERE c_year = 2004;\nThere are many other ways I could have accomplished the same thing. I could have run an UPDATE statement on the table after adding the VECTOR column, or I could have INSERTed the data into another table using the corresponding id column from the original table. I could have even generated the vector embeddings outside the database and used SQL Loader to load the data just to name a few.\nSimilarity Search\nIt may seem like we have taken a big detour, but now that we have created our vector embeddings we are ready to get back to our crime incident data and explore how we can make use of them. The reason we are interested in using a similarity search is because we want to search our data for information based on semantically similar terms. In our first example, I wanted to see if we could find descriptions of robberies. However, nowhere in our DESCRIPTION column does the word “robbery” appear.\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nSQL> SELECT count(*) FROM search_data\n2 WHERE UPPER(description) LIKE '%ROBBERY%';\n\nCOUNT(*)\n----------\n0\nNow, it’s true that we might be able to sift through the data and come up with semantically similar words on our own and then plug them into the SQL query above. But with large data sets and many different search terms that doesn’t sound very appealing. Let’s see what happens if we run a similarity search with AI Vector Search. The following is the SQL and the result:\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nselect description, TO_NUMBER(vector_distance) as vector_distance\nfrom (\nselect id, description,\nvector_distance(vector_desc, VECTOR_EMBEDDING(minilm_l12_v2 USING 'ROBBERY' as data),\nCOSINE) as vector_distance\nfrom search_data\norder by 3\nfetch exact first 50000 rows only )\ngroup by description, vector_distance\norder by 2\nfetch first 10 rows only ;\n\nDESCRIPTION VECTOR_DISTANCE\n---------------------------------------- ---------------\nRETAIL THEFT .299974263\nATTEMPT THEFT .336217165\nKIDNAPPING .449222624\nPREDATORY .450500667\nOTHER CRIME INVOLVING PROPERTY .462044001\nAGGRAVATED FINANCIAL IDENTITY THEFT .462046862\nEXTORTION .466129601\nFORGERY .481875181\nATTEMPT FINANCIAL IDENTITY THEFT .485770345\nTHEFT/RECOVERY: AUTOMOBILE .494581938\nNotice that the SQL syntax for a similarity search might be a little bit different than what you are used to. Since we are operating on vectors, and their distance to other similar vectors, a new VECTOR_DISTANCE function is used. In this example we are comparing the distance from the vectorized search term ‘ROBBERY’ to the other vectors in our SEARCH_DATA table. I included the vector distance just as a point of reference to how each description moves a bit farther from our search vector.\nAlso notice that the VECTOR_DISTANCE function is part of the ORDER BY clause, the number 3 being used as the column position in the SELECT list which has the VECTOR_DISTANCE calculation. This is because a similarity search looks at the relative distance of the query vector compared to the other vectors in the data set and returns the top-k nearest vectors.\nThe query results look promising. Certainly, descriptions containing the word “theft” would qualify as robberies. In further analysis of the dataset I discovered that there is another attribute called PRIMARY_TYPE that actually categorizes the descriptions of the crime incidents. At first I was disappointed about my discovery. Why bother using AI Vector Search when you could just query on the primary type, which includes the category of ROBBERY, and THEFT and BURGLARY, to determine the different types of robberies? Then I realized that this is really a huge advantage because it provides us with a way to check just how accurate similarity search can be. After all, one of the big advantages of similarity search is the ability to search for semantically similar data.\nHere’s the same query with the PRIMARY_TYPE attribute added (I recreated the table since I hadn’t initially included the PRIMARY_TYPE column and that seemed to be the easiest method of adding the attribute and data):\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nselect primary_type, description\nfrom (\nselect primary_type, description,\nvector_distance(vector_desc, VECTOR_EMBEDDING(minilm_l12_v2 USING 'ROBBERY' as data),\nCOSINE) as vector_distance\nfrom search_data\norder by 3\nfetch exact first 50000 rows only )\ngroup by primary_type, description, vector_distance\norder by TO_NUMBER(vector_distance)\nfetch first 10 rows only ;\n\nPRIMARY_TYPE DESCRIPTION\n-------------------- ----------------------------------------\nTHEFT RETAIL THEFT\nTHEFT ATTEMPT THEFT\nKIDNAPPING KIDNAPPING\nCRIM SEXUAL ASSAULT PREDATORY\nOTHER OFFENSE OTHER CRIME INVOLVING PROPERTY\nDECEPTIVE PRACTICE AGGRAVATED FINANCIAL IDENTITY THEFT\nINTIMIDATION EXTORTION\nDECEPTIVE PRACTICE FORGERY\nTHEFT ATTEMPT FINANCIAL IDENTITY THEFT\nMOTOR VEHICLE THEFT THEFT/RECOVERY: AUTOMOBILE\nComparing the PRIMARY_TYPE and the DESCRIPTION column data it seems that our similarity search did pretty well. We seem to be in the ballpark for robberies and a keyword search using robbery or theft would not have yielded crimes like purse snatching, and we might have missed robberies in other categories like DECEPTIVE PRACTICE and probably MOTOR VEHICLE THEFT. In this example, I think similarity search gave us an advantage, and this is really just the tip of the iceberg. Just think of needing to search data, especially non-textual data, where it is not nearly as easy to see the similarities.\nSummary\nWe have covered a lot of ground in this post and there is a lot more to talk about in future posts. We started off with an introduction to similarity search, the heart of AI Vector Search. We then identified a sample data set, described vector embedding models, and imported one into our database. We then created vector embeddings using our imported model and stored those vector embeddings in a VECTOR data type column. Finally, we ran some similarity searches and looked at the power of semantic comparisons as opposed to simple keyword searches for our text-based data."
  },
  {
    "title": "Graph Analytics for All of Your Data",
    "link": "https://blogs.oracle.com/database/graph-analytics-for-all-of-your-data",
    "source": "Oracle_blog",
    "main_ideas": [
      "Graph analytics uncover hidden relationships in diverse data sources.",
      "Oracle Autonomous AI Database simplifies graph analytics with standardized SQL.",
      "Graph queries enable insights into customer behavior and supply chain optimization."
    ],
    "tags": [
      "graph-analytics",
      "oracle",
      "data-lake",
      "sql",
      "cloud-storage",
      "cybersecurity",
      "supply-chain",
      "machine-learning",
      "data-integration"
    ],
    "original_text": "Today, data is everywhere–in databases, in object stores, or on file systems, from streaming sources, historical data at rest, and more. Hidden in all this data are answers to challenging questions—for example:\nFigure 1: An example of relationships in data\nTracking down logistical bottlenecks in the supply chain\nFinding product-component dependencies in manufacturing processes\nFollowing the flow of money in a financial system to discover unusual patterns that might be fraud\nConnecting clickstream activity to product purchases for better product recommendations\nGraph analytics help answer these complex questions, by enabling developers to navigate relationships in data that are not otherwise immediately obvious. In Figure 1, graph queries highlight a specific pattern of a cycle, which could indicate potential fraud (i.e., money moving in a cycle) in financial services.\nAs these examples show, teams can move beyond traditional analysis to discover patterns, dependencies, and hidden relationships across interconnected data through graph analytics.\nGraph Analytics and the Data Lake\nGiven the power of graph analytics, you may consider expanding the scope of the data for your analysis—such as external data residing in a data lake—and question how easy it is to use graph analytics with it. A data lake, by definition, stores data from different sources in a variety of formats, which suggests that you need different tools and languages. Different tools and multiple languages mean complexity as JSON data, CSV log files, location data, and vector search will all require special-purpose APIs and tools. As a result, developers would spend more time integrating different components in this “traditional” data lake and less time innovating and developing their application. So, you may think that running any type of analytics, let alone graph analytics, is a difficult and complex thing to do.\nThanks to new innovations in Oracle Autonomous AI Database that were just announced, it’s now possible to embrace the simplicity of a unified environment—even as your data lake grows more diverse and complex. Importantly, you can bring together the scalability of cloud object storage and open table formats like Apache Iceberg with fast, deep graph analytics—all inside Oracle Autonomous AI Database:\nUse all types of data\n: With Autonomous AI Database, you can use the power of SQL to analyze practically any and all types of data, from many different data sources. Instead of working with a variety of niche and siloed specialty technologies for different data types and data formats in a “traditional” data lake, you can use one language – SQL – for many kinds of analytics on many types of data. You can unify and integrate all your analytics with Autonomous AI Database, giving AI applications all the data they need.\nProperty graph made easy\n: The simplicity of SQL extends to graph analytics, which traditionally required a special-purpose graph query language. The latest SQL standard publication (SQL:2023) includes new syntax for creating and querying property graphs, enabling advanced graph analytics on any data accessible with SQL. This ability to use standardized SQL with graphs puts graph analytics into the hands of SQL developers, transforming graph analysis from a niche toolset to a widely accessible capability that can be integrated into practically any application workflow. Oracle AI Database was the first commercial database to implement this new graph syntax.\nSimplify external data access\n: Autonomous AI Database, a fully managed Oracle AI Database cloud service, enables practically any external data source to be viewed through the abstraction of a table and accessed with SQL. And any data accessible through SQL can be analyzed as a graph, wherever it is stored (like database tables or object store) in whatever format (like Apache Iceberg or JSON). This means you can connect, query, and analyze object store data—including Iceberg tables—directly, unlocking hidden relationships and patterns across massive volumes of data without moving or duplicating it.\nPowerful pre-built algorithms\n: Autonomous AI Database integrates Graph Server, enabling complex graph algorithms to run in parallel at high speed with patented technology. With the Graph Server, standard graph algorithms and graph machine learning algorithms are available to analyze graphs. Graph machine learning algorithms can create models and use them to find matching patterns and make predictions—for example, “Which customers have similar browsing and buying patterns, and can that help us predict future purchases by a customer?”  Developers can perform this type of prediction by accessing over 80 pre-built algorithms with Python or Java API in an integrated notebook or in a client application.\nAnswering Complex Questions Using Simple Graph Queries with Iceberg Data\nUsing a data platform like Autonomous AI Database, you can perform graph analytics by combining data in an external location with transaction data in the database, using simple SQL syntax. Here we combine clickstream data and product purchase transaction data in one graph (see Figure 2), making questions such as “How many clicks did a customer use to navigate to a product, and what is the impact on whether they buy the product?” easy to answer.\nA graph models data as vertices (also known as nodes; all the circles in Figure 2) and edges (also known as relationships; lines in Figure 2). Vertices represent entities or ‘things’ in data, and edges represent how they are connected. For example, when tracking customer journeys during online shopping, each webpage is modeled as a vertex and navigation by a customer from one page to another is modeled as an edge. For transaction data, each customer and each product is modeled as a vertex, and a customer buying a product is modeled as an edge between them.\nFigure 2: Online customer activity (green nodes) linked\nwith transaction data in the database  (pink nodes)\nBy leveraging graph analytics directly on data in object store formats like Apache Iceberg, you can extract new insights from vast and previously siloed data sources. For example, as shown above, you can track customer journeys during online shopping and link them with transaction data in the database. In online shopping, a customer’s decision to purchase goes through a digital path of browsing, checking user comments, comparing products, saving a product in a digital shopping cart, and so on. You can link activity from web logs and app interactions in a data lake with customer purchases that are stored in the database, for new and improved insights on customer purchase patterns. You can understand relationships between customer browsing patterns and their decisions to buy.\nThere are many other applicable use cases for running graph analytics with data lakes, including:\nCybersecurity\n: Graphs help detect cyberattacks by discovering anomalous patterns in how network packets move in an IT network, finding the repeated occurrences of the matched pattern, thus catching a threat before an attack. The source data for this analysis is in log files that capture network traffic, semi-structured data like JSON, and event triggers.\nSupply chain optimization\n: Supply chains consist of managing constraints between suppliers, shipments, warehouses and delivery companies, which together form a complex network. Potential disruptions and delays are identified by analyzing shipment records, supplier dependencies, raw material constraints, and more. The source data comes from different sources that have to be identified, linked, and tracked.\nMany different data types can be integrated in such a graph. Vector embeddings of unstructured text such as customer reviews of a product can be a property of a vertex or edge, and key-value pairs represented in JSON, such as product descriptions, can be accessed and represented in the graph. A question such as: “What product descriptions match what customers with short browsing journeys have bought?” might indicate that customers know what they want when shopping for these products, and so similar products might sell well too.\nEnterprise-scale Performance and Security\nWhen you are running graph queries in Autonomous AI Database, you can take advantage of its scalability features to scale the performance of complex multi-hop queries as data size grows. Mature performance features like partition pruning and hybrid columnar compression, as well as Autonomous AI Database Data Lake Accelerator, are just some of the key features that enable powerful query performance and scalability.\nIn addition, the retrieval of data using such graph queries can be governed by sophisticated built-in security policies of Autonomous AI Database. As a native feature of the database, all security access policies are available for use.\nConclusion\nWith Autonomous AI Database and Oracle Graph, your organization can harness the power of graph analytics on all your data—including large-scale Iceberg tables in object storage—to uncover connections, patterns, and opportunities that were previously hidden. Simple, standardized SQL provides access for developers, enabling your organization to integrate graph analysis into your application and analytic workflows to drive breakthrough business insight.\nWe’d love to hear from you – Please discuss your experiences, post ideas, or ask questions on the public\nOracle Database Discussions\nforum. Try our LiveLab:\nExplore Operational Property Graphs\n.\nFor more information:\nExplore:\nOracle Graph product page\nExplore:\nOracle Autonomous AI Lakehouse\nRead:\nOracle Graph documentation:\nUsing Oracle Graph with Autonomous AI Database\nOracle Graph blogs\nTry:\nAutonomous AI Database for free"
  },
  {
    "title": "Oracle Autonomous AI Lakehouse Embraces Apache Iceberg to Deliver ...",
    "link": "https://blogs.oracle.com/database/autonomous-ai-lakehouse-announcement",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle Autonomous AI Lakehouse integrates Apache Iceberg for enhanced data interoperability.",
      "The platform eliminates data lock-in while maintaining performance and reliability.",
      "Organizations can access and analyze data across multiple clouds seamlessly."
    ],
    "tags": [
      "oracle",
      "apache-iceberg",
      "data-interoperability",
      "cloud-computing",
      "ai",
      "data-management",
      "analytics",
      "data-lakehouse",
      "enterprise-data"
    ],
    "original_text": "Today, many organizations’ enterprise data assets are still locked in proprietary data storage and are only accessible via a single engine. Supporting multiple data engines often requires duplicating data and maintaining complex pipelines, adding inefficiencies to the enterprise data architecture. Open table formats such as Apache Iceberg are, therefore, immensely appealing to organizations because they offer the promise of complete data interoperability and the elimination of data lock-in.\nHowever, the promise of open table formats has not yet been fulfilled. Organizations continue to rely heavily on proprietary engines to run their complex analytic workloads because of the tradeoffs with Iceberg in areas such as performance, concurrency, updatability, and security.\nAutonomous AI Lakehouse\nnow delivers a data platform without compromises—offering all the performance, reliability, and trust of the Oracle AI Database with the openness and interoperability of Iceberg. Now available on OCI, AWS, Microsoft Azure, and Google Cloud, Autonomous AI Lakehouse empowers organizations to maximize the value of their data on an open, interoperable platform.\nA New Era of Data Management\nIceberg-based platforms are known for their openness, enabling compatibility with open-source tools and analytics engines (such as Spark), as well as their support for popular data formats such as Parquet, CSV, JSON, and Avro on scalable, low-cost object storage. The Oracle data   platform has earned the trust of enterprises for its converged architecture, supporting all leading data types and advanced SQL analytics running on the secure, high-performance Exadata system.\nFigure 1: Oracle Autonomous AI Lakehouse\nNow, with Oracle Autonomous AI Lakehouse, organizations no longer need to sacrifice performance, reliability, or trust for openness—you get the best of both worlds.\nUnifying Data and Accelerating AI\nAutonomous AI Lakehouse is the next generation of Autonomous Data Warehouse. It retains all the functionality of the Oracle AI Database platform — with more than 40 years of innovation—and introduces a number of new capabilities that tightly integrate with Iceberg and other open-source technologies. For example, Autonomous AI Database Catalog, a “catalog of catalogs,” makes it simple to discover, connect, and unify data and metadata across clouds, platforms, and catalogs such as Databricks Unity, AWS Glue, and Snowflake Polaris. With this Catalog, teams can now rapidly discover, access, and analyze all enterprise data assets with ease regardless of where they are. Native Iceberg support delivers plug-and-play, high-performance SQL access to any Iceberg table, without data movement or vendor lock-in. During query executions, the Autonomous AI Database Data Lake Accelerator dynamically scales compute and network bandwidth for fast, efficient queries with flexible, pay-as-you-go billing.\nKey new features of Oracle Autonomous AI Lakehouse include:\nCatalog and lakehouse metadata\nAutonomous AI Database Catalog\n: Gain a unified view of enterprise data across multiple clouds and on-premises assets. With simple connectivity to data lakes, warehouses, data shares, and existing catalogs, it enables rapid data discovery, enrichment, and collaboration.\nPlug-and-Play SQL access\n: Query data instantly i n Iceberg and other catalogs (such as AWS, Databricks, and Snowflake) using new simple SQL syntax via catalog connections, delivering fast insights with zero data movement.\nPerformance for Iceberg tables\nAutonomous AI Database Data Lake Accelerator\n: Execute large-scale queries efficiently across Iceberg tables and object store data, as the accelerator automatically and transparently allocates additional network and compute resources to optimize speed. Costs are optimized through pay-as-you-go billing—activated during query execution and deactivated afterwards.\nExadata table cache\n: Boost Iceberg data performance by caching frequently accessed tables in Oracle Exadata flash storage, delivering the performance of native Exadata tables.\nAI innovation\nSelect AI Agent\n: Build, deploy, and manage AI-powered agents using a simple, secure, and scalable framework within Autonomous AI Database. Automate multi-step workflows through custom and pre-built PL/SQL tools, external tools via REST, and MCP Servers to drive rapid AI innovation.\nData Science Agent\n: Use a pre-built AI assistant to search data catalogs, prepare and explore data, uncover key insights, and transform them into actionable insights—all through natural language.\nData integration and sharing\nOracle GoldenGate for Iceberg\n: Stream data in real-time from hundreds of sources, including operational and analytic systems, directly into Iceberg, enabling organizations to analyze it using Autonomous AI Lakehouse.\nAutonomous AI Database Table Hyperlink\n: Share up-to-date data securely within or beyond your organization with temporary direct links, streamlining collaboration while protecting data privacy.\n“Customers consistently tell us they want to use the tools they already have on top of their data. Databricks is committed to open and interoperable data access for analytics and AI, and Unity Catalog helps make that possible by providing a unified governance layer for formats like Apache Iceberg. We welcome Oracle Autonomous AI Lakehouse’s integration with Unity Catalog, giving joint customers seamless access to their data and the flexibility to use Oracle and Databricks together.” —\nStephen Orban, SVP, Product Ecosystem & Partnerships, Databricks\nGet Deeper Insights Across All Your Data\nAccess to data matters only when you gain actionable insights: Oracle AI Lakehouse has unlocked vast new capabilities for Iceberg tables, all based on the converged Data Platform. Oracle AI Lakehouse delivers the full power of Oracle AI Database for Iceberg tables. You can use sophisticated analytics and AppDev features—such as AI Vector Search, graph analytics, spatial analytics, machine learning, JSON Relational Duality Views, and more—over your Iceberg tables. You can ask natural language questions on Iceberg data and create agentic workflows using Select AI.\nThe Oracle Difference: Lakehouse Without Compromises\nAutonomous AI Lakehouse delivers benefits in three key areas:\nOpen and interoperable\n:  Autonomous AI Lakehouse has complete support for Iceberg tables, meeting organizations’ need for a data platform without data lock-in. Additionally, Autonomous AI Lakehouse offers openness in its choice of cloud platform. Regardless of which cloud platform your organization is using today—whether it’s AWS, Azure, Google Cloud, or OCI–, you can use Autonomous AI Lakehouse and connect to Iceberg tables on Databricks, Snowflake, or any other platform.\nLakehouse without compromises\n: Autonomous AI Lakehouse embraces the openness of Iceberg and combines it with the performance, reliability, and trust of an Oracle AI Database. Autonomous AI Lakehouse also provides the ideal platform for organizations to evolve their on-premises data warehouse into a lakehouse, and adopt Iceberg—all at their own pace, incrementally.\nAI-powered operations: Autonomous AI Database\nprovides Iceberg table access to every Oracle Database—whether on-premises or in the cloud, for both operational and analytics databases.  This enables organizations to uncover insights hidden in Iceberg datasets and integrate them into their core operational systems using built-in AI and analytics. No other vendor offers this level of direct integration between Iceberg and transaction processing systems within core business processes.\nFigure 2: Oracle Autonomous AI Lakehouse benefits\nReady to Experience the Future of Data Management?\nVisit the Autonomous AI Lakehouse page (\noracle.com/ai-lakehouse\n), explore our technical blogs, or try\nOracle Autonomous AI Lakehouse for free\nand discover how you can unlock new value from your enterprise data today.\nFor more information:\nVisit the Autonomous AI Lakehouse page (\noracle.com/ai-lakehouse\n)\nRead the Autonomous AI Lakehouse announcement\npress release\nRead technical blogs for more information:\nAutonomous AI Database Catalog\nAutonomous AI Database Data Lake Accelerator\nAutonomous AI Database Table Hyperlink\nAutonomous AI Database external cache\nAutonomous AI Database Select AI Agent\nOracle GoldenGate’s Iceberg support\nGraph Analytics with Iceberg data\nTry Autonomous AI Lakehouse for free"
  },
  {
    "title": "Workday is not an ERP solution—and that’s an issue",
    "link": "https://blogs.oracle.com/modernfinance/workday-is-not-an-erp-solution-and-thats-an-issue",
    "source": "Oracle_blog",
    "main_ideas": [
      "Workday's architecture consists of disparate applications with separate data models, questioning its ERP viability.",
      "The lack of essential ERP capabilities in Workday complicates integration and hinders operational efficiency.",
      "Workday's fragmented data model creates silos, leading to inconsistent reporting and increased complexity for users."
    ],
    "tags": [
      "workday",
      "erp",
      "data-silos",
      "cloud-computing",
      "integration",
      "analytics",
      "oracle",
      "business-processes",
      "automation"
    ],
    "original_text": "ERP solutions have traditionally been defined by a unified suite of core business applications running on a shared data model, which drives operational efficiency, consistent reporting, and streamlined processes\n[1]\n. Workday, often marketed as a next-generation suite, diverges significantly from this model. Its architecture consists of disparate applications with separate data models, raising questions about its viability as a full ERP system.\nFunctionally, Workday lacks essential ERP capabilities such as distribution, manufacturing, supply chain management (including transportation and warehouse management), IoT, maintenance, order management, product lifecycle management (PLM), most functions of configure-price-quote (CPQ), and risk management\n[2]\n.\nUnlike established ERP vendors like Oracle, Workday does not rely on a singular data model underpinning all modules. Instead, its applications operate on isolated data frameworks. This creates data silos, complicates integration, and hinders end-to-end process automation as well as AI\n[3]\n.\nIndustry critiques highlight how Workday’s siloed approach increases complexity for customers needing cross-functional processes (e.g., linking workforce planning with financial budgeting or procurement with payroll)\n[4]\n. These silos lead to inconsistent enterprise-wide reporting and analytics, undermining the “single source of truth” principle\n[5,6,7]\n. Workday attempts to address this by consolidating data into Prism Analytics, effectively an external data warehouse, rather than solving the architectural fragmentation\n[8]\n.\nMoreover, Workday’s numerous acquisitions add further process and data model inconsistencies, preventing truly seamless end-to-end workflows\n[9]\n. Processes spanning multiple areas—such as recruiting to payroll or order-to-cash to financial close—often require manual handoffs or complex workflow integration\n[10]\n, impairing efficiency and increasing error risk. This fragmentation also complicates compliance, as audit trails and governance are dispersed across systems.\nThis architectural fragmentation poses significant challenges for AI adoption:\nData Incompleteness:\nAI depends on unified, high-quality data. Fragmented systems yield inconsistent and delayed data, reducing AI’s effectiveness.\nAutomation Complexity:\nAI-driven automation struggles with irregular workflows requiring manual intervention.\nPredictive Limitations:\nDisconnected audit trails hamper AI’s ability to trace cause-effect and predict risks.\nCompliance Risks:\nFragmented controls reduce AI’s oversight capabilities for regulatory and fraud detection.\nWorkday’s many data stores.\nHaving many data stores with Workday means:\nMultiple data models and data conversions from one store to another\n[11]\nMultiple security records\nThe need to put all data from the Workday data stores into Workday Prism Analytics (AKA Data Hub) and normalize it\nMaking sure that all the master data and transactional data remains in sync\nComplexities with integration, having to integrate to multiple data stores\nIssues and complexities for developers and system integrators\nUltimately, the complexities can result in higher TCO. Lack of unified workflows and data consistency impedes agility rather than enabling it.\nBeyond lacking a full ERP solution, Workday also misses critical functionalities such as CRM and manufacturing or supply chain planning. Given that nearly all organizations require integrated customer management, Workday’s absence of native CRM forces reliance on separate third-party platforms. This approach inevitably creates data silos, functional gaps, and fragmented business processes, undermining operational consistency and efficiency.\nThere are arguments that one could use to explain Workday’s strategy:\n“It doesn’t matter that Workday doesn’t have ERP, because your company doesn’t need the missing functionality”\n“Your company wants to use cloud solutions from multiple vendors as a premeditated strategy to make sure you’re not dependent on one vendor”\n“Your company prefers to combine solutions from multiple providers that fit your business needs best”\nBut in all three cases, you’d have to ask yourself ten questions:\nAre you sure this will remain the case?\nIt could be that one day you’ll need ERP functionality that Workday doesn’t provide. Do you consider change in your business to be a risk or an opportunity?\nPerhaps you are depending on partners\n(for example) to manufacture products for you, and your company merely designs and markets the product. But from a continuity and recovery point of view, will that stay the same, even in times of significant supply chain upheaval?\nHow stable are all these software vendors?\nAre you sure that the risks associated with relying on multiple vendors doesn’t somehow become bigger than the risk of relying on a single, larger, and more complete vendor?\nHow well can you measure your business\nif you are relying on multiple vendors? Are you sure your employees are productive, your speed to market is adequate, your operational efficiency is as good as can be? Can you fully engage with your customers and business partners online? Is it possible that two people buy the same goods from the same supplier for different prices without realizing it?\nAre you as innovative as you need to be\nin your sector? Are your teams empowered with the right tools, or do they spend more time trying to connect the dots—the disparate data from various application vendors?\nAre you having trouble finding the best talent?\nCould it be that today’s dynamic work force requires more modern, consistent tools and techniques to do their jobs? Do they prefer to use a smart device and a digital assistant? Can they work with multiple systems from different enterprise application vendors?\nCan you build extensions\nto your environment with a single tool in a consistent manner, using the same data model, process model, and security model?\nIs the security consistent\n, not only across your applications, but also at every layer in the technology stack?\nAre you sure that data governance is consistent\nacross your applications? Can you commit to GDPR, CCPA, FedRAMP?\nRunning your business across multiple platforms and vendors:\nAre you confident this approach delivers the full potential of AI? While AI is inherently powerful, feeding it fragmented and potentially conflicting data sources undermines its effectiveness and limits its ability to generate truly intelligent insights.\nChances are that you will answer “no” to a few of these questions. The potential issues described here are directly attributable to the fact that Workday is incomplete and inconsistent with its multiple data stores.\nIn comparison, Oracle has a complete suite of\nERP applications\nand a consistent\ncloud platform\n, running on the Oracle database.\nOracle built a completely, brand new set of business capabilities for the cloud from the ground up, using a single data model for all line-of-business challenges. It is modular and composable by design but engineered to work together for seamless extension.\nCompanies need to move toward a portfolio that is more adaptable to business change, with composable applications that can be assembled, reassembled, and extended. This is more important than the notion of suite vs. best-of-breed. Oracle can provide these composable applications because we have the entire suite of applications: ERP, EPM, CRM, HCM, and SCM. Many cloud providers started with one of those—like Workday with HCM, or SalesForce with CRM, and SAP with HCM (with the acquisition of SuccessFactors)—but with just one or two of these cloud solutions, they can’t offer the composition capabilities that Oracle can.\nOracle can offer a SaaS-based, business-centric application to complement any customer’s on-premises footprint. It adds immediate value, and we can seamlessly extend this partnership over time. With Oracle you have the possibility to compose this all into one cohesive suite, engineered to work together. No other vendor can do this right now. For a more detailed comparison between Oracle Cloud ERP and Workday, see\nhttps://www.oracle.com/erp/oracle-vs-workday/\n.\n[1]\nhttps://www.investopedia.com/terms/e/erp.asp\n[2]\nWorkday versus a traditional ERP\n(April 2025), [Workday]\n“lacks the extensive supply chain and manufacturing tools, customer relationship management (CRM) capabilities and broader logistics functionality (like inventory management and production planning) found in traditional ERPs.”\nhttps://www.armanino.com/articles/workday-ultimate-guide\n[3]\n“Reimagining Enterprise Productivity with Workday Illuminate: A Framework for Generative AI Adoption Across HCM and Finance” (Feb 2025). “Prism Analytics: Extends the data core to incorporate external data sources while maintaining governance and security.”\n[4]\n“Why your employees no longer love Workday and what you can do about\nit”\n(2023):\n“Many enterprises today have HR Technology stacked on top of one another like a wobbling Jenga stack, cobbled together with fragile integrations and a disjointed and siloed user experience.”\nhttps://www.applaudhr.com/blog/employee-experience/why-your-employees-no-longer-love-workday\n.\n[5]\n“Workday Prism Analytics: Use Cases for Technology and Software”\n(no publication date):\n“That’s not always easy in a complex data architecture with various legacy data stores and multiple systems for operations, HCM, financial management, and middle office functions. Not to mention the huge volumes of data in inconsistent formats and varying levels of transaction detail\n”\nhttps://www.workday.com/content/dam/web/en-us/documents/datasheets/ucb-enus-tcm-ucb-prism-use-case-brief-for-technology-software-202005.pdf\n[6]\n“What are the advantages and disadvantages of data warehousing ?”\n(June 2024):\n“\nDisadvantage\ns include high cost, complexity, data latency, scalability issues, risk of data breaches, integration issues, over-reliance on warehouse data, technical complexities, and change management”.\nhttps://global.trocco.io/blogs/what-are-the-advantages-and-disadvantages-of-data-warehousing\n[7]\nWorkday Prism Analytics\n(no date):\n“Govern disparate data sources and provide decision-makers with one source of truth”\nhttps://www.workday.com/content/dam/web/uk/documents/datasheets/datasheet-workday-prism-analytics.pdf\n[8]\nData from any source. Directly in your flow of work.\n(no date): “\nHR and finance often require data beyond Workday for better decision-making and planning. With Workday Prism Analytics, IT teams can securely integrate and deliver that data across our AI platform—seamlessly embedding insights into the flow of work.”\n[9]\nComprehensive Guide to Workday Integration: Challenges, Benefits, and Steps\n(May 2025): “Example impact: Data inconsistencies, broken workflows, and manual workarounds.”\nhttps://www.putitforward.com/guide-to-workday-integration\n[10]\nWorkday has separate data models for example for Adaptive Planning,\nhttps://www.workday.com/content/dam/web/en-us/documents/datasheets/enus-pln-da-workday-adaptive-planning-integration.pdf\nand VNDLY\nhttps://www.workday.com/content/dam/web/en-us/documents/datasheets/workday-vndly-datasheet-vms.pdf\nand Peakon\nhttps://www.workday.com/content/dam/web/en-us/documents/datasheets/workday-peakon-employee-voice-integration-datasheet-enus.pdf\n[11]\nhttps://www.workday.com/content/dam/web/en-us/documents/datasheets/workday-peakon-employee-voice-integration-datasheet-enus.pdf\nshows that Workday Peakon for Employee Voice requires integration with Workday HCM. This proves that Workday is not a suite with one data model. The report “The Workday Economy – As AI Disrupts, A New Strategy Emerges” (June 2025) describes how Workday is evolving to a partner-driven ecosystem, which means partner solutions have their own data model and thus need integration with Workday core HCM and Financials\nhttps://joshbersin.com/2025/06/the-workday-economy-a-bold-new-strategy-emerges/"
  },
  {
    "title": "3 reasons why EDM is the right solution for the right time",
    "link": "https://blogs.oracle.com/modernfinance/3-reasons-why-edm-is-the-right-solution-for-the-right-time",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle EDM provides a user-friendly interface for business users to manage data dimensions.",
      "The platform supports an agile approach to master data management, allowing for organic growth.",
      "EDM facilitates efficient handling of significant business events like mergers and reorganizations."
    ],
    "tags": [
      "oracle",
      "edm",
      "data-management",
      "cloud-computing",
      "business-agility",
      "mergers",
      "financial-reporting",
      "enterprise-resource-planning",
      "supply-chain-management"
    ],
    "original_text": "In today’s fast-paced business environment, agility is essential. Companies must be able to respond quickly to market changes, adopt new business models, and navigate mergers and reorganizations. To achieve this, it is crucial that core systems, such as enterprise resource planning (ERP) and supply chain management (SCM), are flexible and can adapt rapidly. As business leaders and decision-makers, you play a vital role in establishing a strong master data foundation. Without this foundation, even minor changes can lead to inaccuracies and delays in financial reporting, making it challenging to manage significant business transformations effectively.\nFortunately,\nOracle Cloud Enterprise Data Management\n(EDM) is the right solution at the right time to address these data management challenges. In this post, I’d like to focus on three ways organizations have realized value from their investment in Oracle EDM.\n1. Business user focus\nEDM provides a visual, intuitive user interface designed for business users. EDM is\nnot\nan IT tool. With EDM, business users can manage dimensions, or measures of value. Dimension examples include GL account, cost center, department, and channel, that provide answers to common business inquiries, such as\nwho\nbought\nhow much\nof\nwhich\nitem through\nwhat\nchannel. Dimensions can then be organized into parent-child relationships (or reporting hierarchies) in a chart of accounts, which allows a business to classify, analyze, and aggregate transactions to answer inquiries in a meaningful way. With intuitive drag-and-drop and point-and-click actions in EDM, business users can manage dimensions and reporting hierarchies. Spreadsheets are utilized for bulk updates. As changes are made to hierarchies, they are visually highlighted for review,\nbefore\nthe changes are committed.\nCareFirst\n(Blue Cross Blue Shield of Maryland), the largest healthcare insurer in the mid-Atlantic region, took advantage of these self-service capabilities, enabling the cost accounting team to maintain several dimensions and dozens of hierarchies for their profitability and cost management models. CareFirst transitioned from managing dimensions and hierarchies in an on-premises solution to a centralized, cloud master data solution—which significantly reduced the effort of master data management, freeing up the team to focus on other tasks. Oracle EDM also eliminated the need for internal servers and provides the company with a tool that can be used by other applications, which was a huge win:\n“…we were looking for a master data management tool that can manage primary and alternate hierarchies with ease of maintenance. This was one of our key pain points. Oracle EDM helped greatly in achieving that. With Cloud EDM, long term integration of data management across multiple applications in the Oracle EPM suite will be more seamless.”\n—\nSaikumar Kongara, Technical Delivery Manager, CareFirst BlueCross BlueShield\n2. Agile, evolutionary approach\nTraditionally, master data management implementations have been approached from a centralized, top-down perspective. While Oracle EDM can support these more traditional approaches, it provides the opportunity to move to a more agile, evolutionary approach.\nUsing built-in connectors, Oracle EDM establishes a “contract” with each system to ensure the master data conforms to the rules of that system. At the same time, Oracle EDM provides functionality to ensure shared hierarchies are aligned across applications, with updates managed in a controlled and governed fashion. This allows hierarchies to organically grow and align in a bottom-up fashion.\nThomas Jefferson University\n(TJU), a major university and hospital system in the northeastern United States, recently implemented Oracle EDM. Its on-premises-to-cloud journey involved multiple Hyperion Planning applications; the team recognized that they needed a master data tool to manage reporting structures for a rapidly-growing higher education institution. With Oracle EDM as the underpinning, the FP&A organization has been able to deploy multiple enterprise planning models (financial, capital, strategic, and workforce).\nSoon, the financial reporting organization will deploy\nOracle Cloud EPM\nfor financial consolidation and close, also supported by EDM:\n“While we are still in the implementation stages of EDM, the future advantages to the enterprise have crystallized and have helped foster conversations around business process improvements that otherwise would not have been addressed. This product’s value is immeasurable as it aids in ensuring ‘one truth’ from a data standpoint, despite the use of disparate systems. For the finance department that has struggled with reconciliation of reports from different sources, this application is a game changer.”\n—\nTanesha N. Thomas-McClain, PMP, Sr. Director Financial Systems and Reporting, TJU Enterprise Finance\n3. Transformational events\nSignificant business events (mergers, divestitures, reorganizations) are challenging for any organization, regardless of industry, size, or location. Without a master data solution, the challenges are even more daunting.\nWillScot and Mobile Mini\nare two industry leaders in portable storage solutions, mobile offices, and other temporary storage products. The two organizations recently merged. Coincidentally, Alithya was in the middle of an on-premises-to-cloud EPM project as the merger was being negotiated and finalized.\nAs with most mergers, both companies brought forward a disparate set of legacy, on-premises systems including multiple ERP, EPM, and other operational systems—along with two chart of accounts (CoA). The finance organizations from both sides tried to standardize on a single CoA by managing spreadsheets and communicating updates via email and video conferences. They realized a more efficient process was required to meet the deadline. In just a few weeks, WillScot-Mobile Mini used Oracle EDM to finalize their go-forward CoA structure, including mappings with legacy systems.\nThe team also benefited from the real-time collaboration features of Oracle EDM, which lets multiple users collaborate and update hierarchies in real-time. In this time of virtual work, the collaboration features were invaluable.\n“I loved the ease with which we could move accounts around as we were trying to align the chart of accounts.  It would not have been so easy to do in Excel, which was our original plan.”\n— Marisa Breslow, Senior Manager, FP&A, WillScot Mobile Mini\n“The tool gave us a single source of truth and allowed instant visualization of what the hierarchy looks like. It also was extremely easy to realign accounts or entities without having to manage various spreadsheets… Extremely efficient way to manage the hierarchy.”\n—\nMatthew Jacobsen, VP Finance, WillScot Mobile Mini\nEnterprise Data Management (EDM) enables organizations to accelerate their transition to the cloud and effectively manage major events, including mergers and acquisitions, as well as business reorganizations. In today’s environment, where real-time collaboration and consistent data across systems are vital, EDM provides the agility and control that modern businesses and their employees require. Oracle EDM continues to evolve rapidly, with significant features introduced each quarter. Recent enhancements include advanced mappings, integration with non-Oracle and on-premises systems, change management dashboards, and operational master data management features including deduplication and match/merge.\nLearn more about Oracle Cloud Enterprise Data Management."
  },
  {
    "title": "Ready for the future? Oracle Cloud EPM is the smart alternative to ...",
    "link": "https://blogs.oracle.com/modernfinance/ready-future-oracle-cloud-epm-smart-alternative-sap-bpc",
    "source": "Oracle_blog",
    "main_ideas": [
      "SAP BPC users are migrating to Oracle Cloud EPM due to SAP's end of support.",
      "Oracle Cloud EPM offers a unified platform that simplifies planning and budgeting processes.",
      "SAP's hybrid planning approach may complicate integration and increase costs for users."
    ],
    "tags": [
      "oracle",
      "sap",
      "cloud-epm",
      "migration",
      "planning",
      "budgeting",
      "ai",
      "ml",
      "enterprise-planning"
    ],
    "original_text": "For over 18 years, SAP Business Planning and Consolidation (SAP BPC) has been the primary on-premises planning solution for SAP customers. But BPC has not kept pace with EPM innovation\n[1]\n. As organizations worldwide continue to migrate to modern cloud platforms, Oracle Cloud EPM has become a\nleading solution\nsuite that many SAP BPC users have already, or are considering migrating to.\nDue to SAP’s fast-approaching end of support for various versions of SAP BPC (See Figure 1), many BPC users are considering what direction they will take. They have the option to migrate their BPC applications to other SAP tools such as SAP Analytics Cloud for Planning, S/4 HANA, and/or other SAP 3rd party partner tools, or they can consider other modern, cloud-based EPM solutions that are available today.\nSource:\nSAP\nSAP BPC customers realize that they need to transition to a modern Cloud EPM platform to meet their goals of modernizing their finance processes with AI/ML-driven technologies, extended planning and analysis (\nxP&A\n[2]\n), and other EPM processes beyond FP&A in order to achieve enterprise-wide connected planning that generates high-value and strategic business outcomes.\nExamples of some challenges SAP BPC users are facing:\nHow do we leverage our HR systems to plan for attracting, hiring and retaining top talent?\nHow do we leverage AI and Machine Learning to modernize planning in finance and across other lines of business?\nHow do we connect and collaborate with line of business plans across the enterprise?\nHow do we quickly and cost-effectively migrate to a modern and complete cloud EPM platform?\nShould we take a Hybrid planning approach with SAP Analytics Cloud for Planning and other dissimilar tools, or utilize just one complete and unified EPM solution?\nWhere do we start? Who can help guide us?\nWill we be able to migrate fast enough to enable our business the grow and thrive?\nAs an SAP BPC customer, you have the choice of either redeveloping your existing BPC applications with other SAP offerings which are predominantly based on some newer, some legacy, and some third-party partner-based tools, or you can move to a modern cloud EPM solution which has everything you need in one common, unified, and integrated platform that is developed and supported by a single provder. Let’s look at these two options in more detail.\nMigrating to SAP tools\nRather than building a complete, purpose-built cloud EPM solution suite that addresses all EPM business processes in a single integrated and unified platform, SAP has taken a siloed approach by providing planning capabilities in SAP Analytics Cloud for Planning, Consolidations in SAP BFC, S/4HANA, and several other EPM processes using additional legacy SAP tools, and others such as Account Reconciliation, Tax, and Narrative reporting using third party partner tools.\nTo accommodate their legacy BPC customers, SAP has also proposed a hybrid planning\n[3]\nshort-term solution that may work for some BPC customers, but careful consideration of various costs and effort associated with implementing this approach is recommended, as it requires multiple technical considerations\n[4]\nand potentially involves multiple platforms and tools (see Figure 2).\nThis approach involves combining SAP Analytics Cloud for Planning with BPC which may seem easy to do, but SAP’s own documentation\n[5]\nindicates that this requires comprehensive knowledge to integrate both platforms at the data, application, and workflow layers. This is not required with Oracle Cloud EPM as it virtually eliminates this multi-tool approach by delivering a single, and complete platform for all cloud EPM use case requirements.\nTechnically, and with enough time, money, and specialized resources, all these SAP tools and platforms could conceivably be made to work together, but BPC customers would likely need to deal with potential challenges such as:\nDifferent user interfaces (UI)\nDifferent tool technologies (languages, platforms, etc.)\nA mix of Cloud and on-premises deployments\nMultiple points of vendor support\nMultiple points of tool integration\nMultiple tool administration\nDifferent skill set requirements\nDifferent and questionable underlying AI capabilities\nMultiple tool upgrade cycles and version control efforts between tools\nAll of these can drive higher TCO and overall implementation and ongoing administration complexity while potentially impacting system stability and availability if any one of these disparate tools develops issues.\nOracle Cloud EPM as the better migration path\nOracle Cloud EPM delivers a\ncomplete\n, integrated, and unified software-as-a-service (SaaS) EPM suite. The depth of Oracle Cloud EPM’s capability includes advanced AI innovation such as predictive planning and automated data analysis which can deliver fast business value.\nWith Oracle Cloud EPM, SAP BPC customers can enhance and optimize their financial close and planning and budgeting processes to run in a unified, single platform which is purpose-built to support all other EPM use case requirements without having to depend on multiple tools, platforms, and vendors. This can significantly lower your migration, integration, and administration costs while speeding up time to value and making it easy for you to implement other Oracle Cloud EPM modules at your own pace.\nWhy Oracle Cloud EPM is the Smart Alternative for SAP BPC Customers\nOracle Cloud EPM is a Leader in several\nleading Analyst reports\n[6]\n.\nOracle Cloud EPM provides comprehensive capabilities in a complete and unified Cloud EPM platform.\nOracle Connected Enterprise Planning (\nxP&A\n) is a fully mature and proven solution that is part of the complete Oracle Cloud EPM developed and supported by one vendor, Oracle.\nOracle Cloud EPM is a mature, proven, intelligent EPM suite on a single platform with leading AI and ML innovation.\nIf you are considering extended EPM capabilities in the cloud such as Consolidations, Account Reconciliation, Narrative reporting, Tax, etc., these processes are already part of the complete Oracle Cloud EPM suite.\nOracle Cloud EPM has built-in Analytics, advanced reporting, and real-time integration with\nOracle Analytics Cloud\nif you require more comprehensive analytics capabilities across your enterprise.\nOracle has experienced SAP BPC migration partners to help you migrate successfully.\nOracle helps you develop your own EPM Center of Excellence (CoE) which helps drive continuous innovation.\nLearn how to create and run an EPM center of excellence.\nDiscover Oracle Cloud EPM today\nTake the first step to migrate to Oracle Cloud EPM. Customers are choosing Oracle for our complete and purpose-built cloud EPM platform instead of struggling with the complex implementation, administration, and added costs related to other vendors’ incomplete and fragmented tools and technologies. Oracle Cloud EPM addresses all your EPM use case requirements in a single, unified, and complete cloud EPM platform developed and supported by Oracle.\nWhy settle for an incomplete portfolio that also relies on additional tools from different vendors to fill EPM application gaps in order to get all the functionality you need? Or waiting for a costly, time-consuming, integration, and customized development effort? Take the next step and contact us to explore the vast benefits thousands of Oracle Cloud EPM customers are experiencing today with the leading complete cloud EPM suite of applications.\nContact us today to get started on your migration path to Oracle Cloud EPM.\nAdditional resources\nOracle Cloud EPM for Planning, Budgeting, and Forecasting\nWhy companies choose Oracle Fusion Cloud EPM over the competition\nCompare Oracle EPM to SAP for more details\nWhy migrate from SAP to Oracle Cloud EPM?\n[1]\nhttps://community.sap.com/t5/financial-management-blog-posts-by-sap/maintenance-timelines-for-sap-business-planning-and-consolidation-sap-bpc/ba-p/13551547\n[2]\nhttps://www.gartner.com/en/documents/4005024\n[3]\nhttps://blogs.sap.com/2023/03/01/sap-bpc-move-to-sac-work-with-bpc-planning-sequences-in-sap-analytics-cloud/\n[4]\nhttps://blogs.sap.com/2023/03/01/sap-bpc-move-to-sac-work-with-bpc-planning-sequences-in-sap-analytics-cloud/\n[5]\nhttps://blogs.sap.com/2023/03/01/sap-bpc-move-to-sac-work-with-bpc-planning-sequences-in-sap-analytics-cloud/\n[6]\nhttps://www.oracle.com/corporate/analyst-reports/applications/"
  },
  {
    "title": "How Enterprise Data Management (EDM) can reduce finance’s ...",
    "link": "https://blogs.oracle.com/modernfinance/how-enterprise-data-management-edm-can-reduce-finances-reliance-on-it",
    "source": "Oracle_blog",
    "main_ideas": [
      "Companies need agile data management solutions to adapt to economic changes.",
      "Traditional master data management (MDM) approaches create complexity and hinder agility.",
      "Oracle Enterprise Data Management (EDM) offers a modern, collaborative approach to data management."
    ],
    "tags": [
      "enterprise-data",
      "data-management",
      "oracle",
      "cloud-computing",
      "mdm",
      "business-agility",
      "data-integration",
      "financial-systems",
      "analytics"
    ],
    "original_text": "Global economic and trade challenges have significantly changed the world as we knew it. Companies are facing challenges through shifting global trade agreements, acquisitions, changes in consumer spending driving the need for new business models, redesigning business processes, and dealing with data integration and management challenges as a reslt of moving to cloud, multi-cloud, or a hybrid approach of cloud and on-premises systems. The new normal is all about being highly agile to rapid and unpredicable changes, and companies are looking for innovative data management platforms to help them succeed.\nModern cloud applications are a critical part of the change process, but consistent enterprise data is key to supporting these transformational changes. Traditionally, companies have used MDM (master data management) to keep their data consistent and reliable. But traditional MDM requires a set of technical tools, and it relies on a centralized, IT-driven approach that creates complexity in today’s dynamic, data-driven enterprises. Companies need a next-generation enterprise data management solution that reduces reliance on IT. It should support flexible modeling and let business decision makers manage data changes collaboratively.\nWhat is enterprise data?\nEnterprise data provides the valuable insights that helps companies record, report, and plan their business—even in uncertain economic times. If we unpack this further, enterprise data includes master data, reference data, and metadata that describes the data used in line-of-business applications (such as finance or HR).\nEnterprise data can be illustrated by a simple example:\nWhen you buy something, you get a purchase receipt that itemizes the products and services, the merchant location, the employee that served you, the transaction date, and other buyer and payment details. Typically, this transaction is posted to a revenue account, and any associated costs are posted to an expense account within a general ledger. A cost center typically records the entity, location or department related to this transaction. Metrics such as gross margin represent a rollup of underlying revenue and expense accounts. To consistently calculate margin across the enterprise, your systems use reporting metadata to indicate consolidation at each rollup level.\nMoreover, every enterprise has its own unique terminology to describe market segments, industry classifications, and geographic locations. Through enterprise data definition, you organize products, markets, customers, and regions in a language that everyone in the company shares. This helps ensure that you can accurately record and report on business performance. All these data elements associated with the purchase transaction, and the descriptive elements about the transaction, represent enterprise data.\nExamples of enterprise data in the CFO’s office may include:\nChart of accounts\nOrganization or cost center structures\nLegal entity and ownership hierarchies\nMarket segments\nProduct categories\nWhy traditional MDM approaches fall short\nCompanies need transformational agility more than ever before and managing enterprise data can either help or hinder these transformations. Traditional MDM is not designed with agility in mind, resulting in reconciliation issues, inconsistent and unreliable data, difficult or unmanageable acquisitions or re-orgs, and heavy reliance on IT governance.\nTypical MDM limitations can include:\nTop down, big bang approach\n: Companies are faced with long projects, limited early wins, and a higher probability of failure—or, at best, late delivery.\nUpfront consensus\n: Organizations are pressured to align terms, definitions, data sharing policies, governance workflows, and reporting hierarchies at the start of a project.\nLack of context\n: Traditional MDM has an overwhelming reliance on a common, abstracted maintenance structure that fails to capture application-specific nuances and lacks adequate context to be compelling to business audiences.\nInflexible\n: MDM is often unable to absorb new projects or new applications due to modeling, sharing, filtering, security, or rationalization complexities.\nVendors like SAP rely on traditional IT centric MDM tools. This means that implementing SAP’s MDM to manage data across enterprise applications may require more IT involvement. To reduce implementation risk, increase speed and agility, and support an iterative implementation with business user buy-in, companies need a more modern set of data management tools:\nOracle Enterprise Data Management\n(EDM).\nThe Oracle EDM difference\nOracle EDM can help your company respond to change faster with a powerful set of data stewardship, quality, governance, collaboration, comparison, and data sharing tools. It helps ensure that your mission-critical enterprise data is accurate, consistent, contextually relevant, and ready to use across all business contexts.\nThe Oracle EDM approach is distinctive, and an industry-first in several areas. Advantages include:\nElastic approach\n: Facilitates a bottom-up approach that results in an incremental, iterative implementation. Quick and easy implementation creates a snowball effect across your enterprise.\nSecure\n. Secure data sharing across application contexts is a conscious act of opening permissions and policies for collaboration and reuse at the right grain. The upshot: No more big-bang MDM projects!\nInformal\n: No need for full blown, upfront preparedness. Start small, maybe in a single department.  Begin crowdsourcing changes with your colleagues. Initiate data sharing on day one, letting manual data comparison and alignment evolve into formal data permissions, governance policies, and automated change subscriptions through incremental refinement.\nContextual\n: Shelters users from complicated master data models or corporate-level abstractions; their journey should begin and end with familiar business perspectives similar to those in the software they use everyday. Changes made in one context cascade organically across applications. Tailor enterprise workflows as needed to provide cross-application views and instill data accountability that drive incremental, rather than all-or-nothing change activities.\nMultiple views to match reality\n: While the master data is common, each application has its own nuanced view of data, relationships, attributions, and application metadata. EDM helps companies manage multiple business perspectives to match needs of each staff member.\nCloud EDM value\nSpeed.\nEDM speeds up migration to the cloud and promotes transformation at your own pace by letting you model your application structures prior to deployment. It makes it easier to run your ERP and EPM applications in a pure cloud or hybrid coexistence across multi-cloud environments.\nUnderstand the impact before committing to changes.\nCompanies can use EDM as an enterprise modeling platform to see how new organizational structures of acquisitions, reorganizations (and their associated sales territories), product hierarchies, locations, and chart of accounts impact the entire company.\nRisk reduction.\nStructural changes don’t lend themselves well to spreadsheets—yet many companies still use them to communicate routine changes or share complex futures. Worse yet, business users rely on spreadsheets to communicate semantic data maps that aren’t the subject area of their more technical counterparts. EDM provides concurrent collaboration and management, change visualization, structural comparison, and automated reconciliation, so business users can work digitally as a cross-functional team, secure approvals, and synchronize systems easily. This reduces transformation risk, creates shared accountability, and delivers audit transparency for compliance peace-of-mind.\nWith Oracle Cloud EDM, you now have a system of entry, a system of reference, and a system of engagement for your enterprise data. It helps assure alignment, not only across financial systems such as\nOracle Enterprise Resource Planning (ERP)\nand\nOracle Enterprise Performance Management (EPM)\n, but also corporate reporting, analytics, and line of business applications for procurement, supply chain, workforce planning, and customer experience.\nEffectively managing your enterprise data in an agile manner throughout your transformations is key to surviving and thriving in this new normal. We invite you to look beyond traditional MDM tools and explore the many benefits you can realize with Oracle EDM.\nLearn more about Oracle Enterprise Data Management."
  },
  {
    "title": "Exploring the benefits of replacing SAP BFC with Oracle Cloud EPM ...",
    "link": "https://blogs.oracle.com/modernfinance/ready-for-future-oracle-cloud-epm-smart-alternative-sap-bfc",
    "source": "Oracle_blog",
    "main_ideas": [
      "SAP BFC users are considering migration options due to impending end of support.",
      "Oracle Cloud EPM offers a unified solution for financial consolidation and reporting.",
      "Migrating to Oracle Cloud EPM can reduce costs and complexity compared to SAP tools."
    ],
    "tags": [
      "sap",
      "oracle",
      "cloud-epm",
      "financial-consolidation",
      "enterprise-performance-management",
      "migration",
      "ai",
      "machine-learning",
      "reporting"
    ],
    "original_text": "Due to SAP’s fast-approaching end of support for SAP BFC (See Figure 1), many SAP BFC users are considering what direction they will take. They have the option to migrate their BFC consolidation processes to SAP S/4 HANA, and other SAP partner tools for extended financial close and reporting processes, or they can consider other modern and complete Cloud EPM Financial Close solutions that are available today.\nYou may be a more recent SAP BFC customer, or a long-time user back when it was known as Cartesis Magnitude. Cartesis was a Paris France-based company that was founded in 1990\n[1]\nand its flagship product was known as Cartesis Magnitude, which was one of the few web-based solutions for strategic financial management, more popularly referred to as enterprise performance management (EPM) today.\nFast forward 17 years and Cartesis built a customer base of approximately 1300\n[2]\n, mostly in France and parts of the European region, but then in April 2007, they were acquired by the legacy business intelligence software company, Business Objects for $300 million\n[3]\n, and six months later Business Objects was acquired by SAP\n[4]\nwhich then renamed Cartesis to SAP BOFC, and then to SAP BFC\n[5]\n, and finally to SAP Financial Consolidation (SAP FC)\n[6]\nwhich is most likely what you are familiar with and using today.\nSince 1990, SAP BFC (formerly Cartesis) has been the primary solution for SAP customers, but like several other Business Objects acquired products such as SAP BPC, BFC has not kept pace with EPM innovation. As organizations worldwide continue to migrate to modern cloud financial consolidation and close platforms, Oracle Cloud EPM has become a leading solution\n[7]\nsuite that potential SAP BFC users have or are considering migrating to.\nSource:\nSAP\nSAP BFC customers realize that they need to transition to a modern financial consolidation solution supported by a complete and unified EPM platform to meet their goals of modernizing their financial consolidation and reporting processes. Today’s CFO’s are investing significantly in AI-driven financial consolidation solutions in addition to implementing additional integrated EPM business processes to support their modern finance initiatives and achieve enterprise-wide financial consolidations that generate high-value and strategic business insights.\nExamples of some questions SAP Financial Consolidations users are asking:\nHow do we meet current statutory consolidation regulation requirements?\nIs SAP S/4HANA our only option to migrate from our legacy SAP Financial Consolidation platform?\nHow do we leverage AI and Machine Learning to modernize and automate leading financial consolidations and reporting best practices?\nHow do we leverage modern and innovative consolidation reporting capabilities without using a mix of disparate SAP and 3rd party partner tools and platforms?\nHow do we leverage the modern capabilities of Microsoft Office integration?\nHow do we incorporate innovative, intelligent integration and advanced enterprise data management capabilities with source systems?\nHow do we quickly and cost-effectively migrate to a modern and complete cloud EPM platform?\nWhere do we start? What resources are available to help us migrate successfully?\nAs an SAP BFC user, you have the choice of either reimplementing your legacy SAP Financial Consolidation processes using SAP S4/HANA combined with 3rd party SAP partner tools to address your financial consolidation and reporting requirements or, you can move to a modern and fully complete Cloud EPM platform that has everything you need for modern financial consolidations and regulatory reporting delivered in one common and integrated Cloud EPM platform. Let’s look at these two options a more detail.\nMigrating to SAP tools\nRather than building a complete, purpose-built cloud EPM solution suite that addresses all financial consolidations, reporting, and extended EPM business processes in a single integrated and unified platform, SAP has taken a siloed approach by providing financial consolidations in S/4HANA in addition to other SAP and third-party partner tools to support processes such as Account Reconciliation, Tax, and Narrative Reporting.\nSAP may offer several migration options for BFC customers, but careful consideration of the various costs and effort associated with migrating from your current SAP BFC platform is recommended as you may be introducing more complexity and costs by implementing and managing multiple platforms and tools.\nTechnically, and with enough time, money, and specialized resources, these SAP and added partner tools could conceivably be made to work together, but SAP BFC customers would likely need to deal with potential challenges such as:\nDifferent user interfaces (UI)\nDifferent tool technologies (languages, platforms, etc.)\nA mix of Cloud and on-premises deployments\nMultiple points of vendor support\nMultiple points of tool integration\nMultiple tool administration\nDifferent skill set requirements\nDifferent and questionable underlying AI capabilities\nMultiple tool upgrade cycles and version control efforts between tools\nAll of these can drive higher TCO and overall implementation and ongoing administration complexity while potentially impacting system stability and availability if any one of these disparate tools develops issues.\nOracle Cloud EPM as the better migration path\nOracle Cloud EPM\ndelivers a complete, integrated, and unified software-as-a-service (SaaS) EPM suite. The depth of Oracle Cloud EPM’s complete end-to-end financial close delivers intelligent process automation (IPA) using advanced AI to enable you to automate consolidations, orchestrate a connected close, and automate narratives in reports.\nWith Oracle Cloud EPM, SAP BFC customers can migrate and optimize their legacy BFC applications to run in a unified, single platform that is purpose-built to support all your current and future financial consolidation and close use case requirements without having to depend on multiple tools, platforms, and vendors. This can significantly lower your migration, integration, and administration costs while speeding up time to value and making it easy for you to implement Oracle Cloud EPM financial consolidations and other EPM modules at your own pace.\nWhy Oracle Cloud EPM is the smart alternative for SAP BFC customers\nOracle Cloud EPM covers the entire end-to-end close process including financial consolidation, account reconciliation, tax provision, narrative reporting, and more in one solution without the need for additional 3rd party tools.\nOracle Cloud EPM Financial Consolidation and Close is a fully mature and proven solution that is part of the complete Oracle Cloud EPM developed and supported by one vendor, Oracle.\nOracle Cloud EPM is a mature, proven, intelligent performance management platform with leading AI and ML innovation to deliver modern, Intelligent process automation (IPA) for your entire end-to-end financial close use case requirements.\nIf you are considering extended EPM capabilities in the cloud such as enterprise\nconnected planning\n, these purpose-built capabilities are already part of the complete Oracle Cloud EPM suite.\nOracle Cloud EPM has built-in Analytics, advanced reporting, and real-time integration with\nOracle Analytics Cloud\nif you require more comprehensive analytics capabilities across your enterprise.\nOracle has experienced SAP BFC migration partners to help you migrate successfully.\nOracle helps you develop your own EPM Center of Excellence (CoE) which helps drive continuous innovation.\nLearn how to create and run an EPM center of excellence.\nDiscover Oracle Cloud EPM today\nTake the first step to migrate to Oracle Cloud EPM. Customers are choosing Oracle for our complete and purpose-built cloud EPM platform instead of struggling with the complex implementation, administration, and added costs related to other vendors’ incomplete and fragmented tools and technologies. Oracle Cloud EPM helps address all your requirements in a single, unified, and complete cloud EPM platform developed and supported by Oracle.\nWhy settle for an incomplete SAP portfolio that may have you implement multiple tools from different vendors to fill financial close and reporting gaps, or wait for a costly, time-consuming, integration, and customized development effort? We invite you to take the next step and allow us to explore with you the vast benefits thousands of Oracle Cloud EPM customers are experiencing today with the leading complete cloud EPM suite for an end-to-end financial close.\nContact us today to get started on your migration path to Oracle Cloud EPM Financial Consolidation and Close.\nAdditional resources:\nOracle Cloud EPM for Financial Consolidation and Close\nWhy companies choose Oracle Fusion Cloud EPM over the competition\nCompare Oracle EPM to SAP for more details\nWhy migrate from SAP to Oracle Cloud EPM?\n[1] https://www.cbinsights.com/company/cartesis\n[2] https://www.cbinsights.com/company/cartesis\n[3] https://www.cfo.com/news/business-objects-to-buy-cartesis/674911/\n[4] https://www.sap.com/investors/en/financial-news/ad-hoc-news/2007/10/238209.html\n[5] https://answers.sap.com/questions/8382735/bpc-vs-bfc.html\n[6] https://support.sap.com/en/product/support-by-product/01200314690800000356.html\n[7] https://www.oracle.com/ca-en/corporate/analyst-reports/applications/"
  },
  {
    "title": "Shift your perspective: Turn your enterprise data into valuable ...",
    "link": "https://blogs.oracle.com/modernfinance/shift-perspective-turn-enterprise-data-into-valuable-products",
    "source": "Oracle_blog",
    "main_ideas": [
      "Data should be treated as a product to unlock its true value.",
      "Data Product Managers play a crucial role in managing data products.",
      "Oracle Cloud EDM facilitates the creation and sharing of high-quality data products."
    ],
    "tags": [
      "data-as-a-product",
      "data-product-manager",
      "oracle-cloud",
      "data-mesh",
      "enterprise-data",
      "data-governance",
      "data-quality",
      "innovation",
      "cloud-computing"
    ],
    "original_text": "In today’s data-driven world, we’re swimming in information. But is that data truly working for us, or is it often trapped in silos, difficult to access, and inconsistent across applications? It’s time for a paradigm shift. Let’s move beyond thinking of data as a mere byproduct of our operations and start treating it as a first-class citizen: data as a product.\nThe concept, significantly shaped by pioneers like\nThoughtworks in their Data Mesh principles\n, encourages us to think differently. Instead of monolithic data warehouses or lakes often managed centrally, imagine curated, trustworthy, and easily discoverable datasets designed for specific consumer needs – much like any other product your company offers.\nWhy embrace data products? Unlocking true value\nMoving towards a “data as a product” mindset unlocks immense potential, whether you’re adopting a fully distributed agile approach or taking more measured steps:\nEnhanced discoverability and accessibility:\nData products are designed to be found and used. They come with clear ownership, documentation, and defined access methods.\nImproved trust and quality:\nReliability is a core tenet. Data products have defined quality standards and Service Level Objectives (SLOs), fostering confidence in their use for decision-making and operations.\nAccelerated innovation:\nWhen teams can easily find and trust the data they need, they can build new applications, analytics, and insights faster.\nDomain ownership and expertise:\nDomain experts who understand the data set typically own data products, leading to higher quality and relevance.\nEnter the Data Product Manager: Your data champion\nCreating valuable data products doesn’t happen by accident. It requires dedicated ownership. Enter the Data Product Manager. This emerging, crucial role bridges business needs and technical implementation for a specific data domain.\nTheir responsibilities include:\nUnderstanding consumer needs:\nIdentifying who needs the data product and for what purpose.\nDefining the product:\nSpecifying the data attributes, quality standards, access patterns, and SLAs.\nSource data wrangling:\nCollaborating with source system owners and IT to gather, match, merge, cleanse, and integrate data from disparate systems.\nLifecycle management:\nOverseeing the development, deployment, maintenance, and eventual retirement of the data product.\nDriving adoption:\nEvangelizing the data product and ensuring it delivers value to its consumers.\nMonitoring and improvement:\nTracking usage and quality metrics to continuously enhance the product.\nMeasuring what matters: Tracking your data product journey\nHow do you know if your data product strategy is succeeding? Focus on metrics that reflect value and adoption:\nAdoption rate:\nHow many downstream applications or users consume the data product?\nData quality score:\nAre you meeting the defined quality thresholds (completeness, accuracy, timeliness)?\nConsumer satisfaction (NPS for data):\nAre the users finding that the data product fits their purpose?\nTime-to-value:\nHow quickly can new consumers access and derive value from the data product?\nReduction in data wrangling effort:\nAre downstream teams spending less time cleaning and preparing data because the product is reliable?\nThe powerhouse behind the product: Multi-domain data mastering with Oracle Fusion Cloud Enterprise Data Management (EDM)\nCreating robust, trustworthy data products, especially across different business domains (like Customers, Products, Finance, Locations, etc.), requires a solid foundation. This is where a multi-domain data mastering service like\nOracle Cloud EDM\nbecomes invaluable.\nOracle Cloud EDM helps enterprises:\nIdentify and define data domains:\nIt provides the tools to logically segment your enterprise data into manageable, governable domains – the natural starting point for defining data products.\nBuild domain-specific data products:\nEDM allows you to model, cleanse, enrich, and govern the master and reference data within these domains, forming the core of high-quality data products.\nCollaboration and agility: An evolutionary path\nBuilding enterprise-wide data products isn’t always a big bang. Oracle Cloud EDM supports an evolutionary, eventually consistent design. This agility is crucial:\nDistributed collaboration:\nDifferent teams, potentially across organizational boundaries, can work together within EDM’s real-time, multi-user environment. They can propose changes, participate in workflows, and reach consensus on data definitions and values.\nBuilding reusable assets:\nAs you master data within a domain (e.g., defining your official chart of accounts or product hierarchy), that mastered data becomes a reliable, reusable asset – a data product – that benefits the entire organization.\nEngendering trust:\nTransparent workflows, clear ownership, fully reconciled alternate hierarchies, and auditable change histories within EDM build trust in the data and the processes used to manage it. This trust is fundamental for successful data product adoption.\nHarmonize, transform, automate: EDM in action\nOracle EDM Cloud goes beyond simple data storage; it actively facilitates the creation and sharing of data products:\nIntelligent subscriptions:\nApplications don’t just passively receive data. EDM subscriptions allow downstream systems to listen for changes in source or master applications. When changes occur (e.g., a new cost center is added), EDM automatically propagates these changes.\nSeamless transformation:\nData rarely fits perfectly everywhere. EDM subscriptions can transform data structures and values on the fly as they are shared. This ensures data is delivered in the specific format required by consuming applications, accelerating secure sharing without manual intervention. Imagine harmonizing different charts of accounts or product coding schemes automatically.\nAutomated data sharing:\nBy automating the synchronization and transformation process, EDM drastically reduces manual effort, minimizes errors, and ensures data consistency across your application landscape.\nStart building your data products today\nShifting to a “data as a product” mindset is key to unlocking the strategic value hidden within your enterprise information. It fosters trust, accelerates innovation, and empowers your teams.\nOracle Cloud EDM provides the robust, collaborative, and intelligent platform you need to identify your data domains, build high-quality data products, and automate their secure sharing across your organization.\nAre you ready to transform your data from a liability into your next great asset? Explore\nOracle Cloud EDM\nand begin building your enterprise data products today!"
  },
  {
    "title": "Oracle is a Continued Leader in Three Gartner Magic Quadrant Reports ...",
    "link": "https://blogs.oracle.com/modernfinance/oracle-continued-leader-three-gartner-magic-quadrant-reports-assessing-finance-capabilities",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle has been recognized as a Leader in three Gartner Magic Quadrant reports for finance capabilities.",
      "The company emphasizes AI-driven finance transformation to enhance productivity and decision-making.",
      "Over 10,000 organizations utilize Oracle Cloud ERP for improved financial and operational processes."
    ],
    "tags": [
      "oracle",
      "gartner",
      "cloud-erp",
      "ai-driven-finance",
      "financial-planning",
      "enterprise-resource-planning",
      "automation",
      "predictive-insights",
      "business-value"
    ],
    "original_text": "Previously posted on Oracle.com\nOracle has once again been named a Leader in three Gartner reports assessing finance capabilities: the\n2024 Gartner® Magic Quadrant for Cloud ERP for Service-Centric Enterprises\n, the\n2024 Gartner® Magic Quadrant for Cloud ERP for Product-Centric Enterprises\n, and the\n2024 Gartner® Magic Quadrant™ for Financial Planning Software\n. In each of these reports, Oracle was recognized as a Leader for its “Ability to Execute” and “Completeness of Vision” for\nOracle Fusion Cloud Enterprise Resource Planning (ERP)\n.\n“We have entered a new phase of finance transformation—AI-driven finance. As traditional finance processes are eclipsed by AI-driven workflows, we are offering customers a distinct competitive advantage by enabling them to seamlessly adopt capabilities that can unlock new opportunities for growth,” said Rondy Ng, executive vice president of applications development at Oracle. “Gartner’s recognition further underscores our track record of stability, highlights our unwavering commitment to innovation, and reinforces our relentless focus on customers, making Oracle the ultimate financial transformation partner.”\nWith embedded predictive, generative, and agentic AI innovations, Oracle continues to pioneer capabilities that reimagine core financial functions to drive efficiency, insight, and enduring value for customers across all industries. Oracle Cloud ERP’s embedded AI enables touchless operations, predictive insights, and connected actions to help customers enhance productivity, deliver business value, and fundamentally redefine what is possible for finance and operations processes.\nWith Oracle Cloud ERP, organizations can:\nImprove productivity and efficiency with touchless processes:\nCritical agentic AI capabilities simplify and automate workflows, including the onboarding of complex integrations for third parties via the document IO agent. The ledger agent reduces manual effort by identifying exceptions and anomalies in transaction data and automates daily accounting operations, and descriptive generative AI content and visualization capabilities enhance the narrative reporting preparation process.\nEnhance decision-making with AI-powered predictive insights:\nEssential AI capabilities enable organizations to continually monitor plans, forecasts, and variances, identify patterns in financial and operational data, predict outcomes, and help make better business decisions. The generative AI-driven advanced prediction agent helps organizations support multivariate AI prediction models, leveraging financial and operational as well as external factors in predictive forecasting.\nDrive cross-divisional opportunities and execution with connected actions:\nTouchless operations and predictive insights provide the connective tissue to help customers proactively action and leverage the Oracle B2B network of financial institutions and logistic service providers on the Oracle SaaS ecosystem.\nOrganizations across all industries are leveraging Oracle Cloud ERP to help increase productivity, reduce costs, and improve controls, including one of the world’s leading logistics providers, DHL Supply Chain; one of the largest life insurers in the United States, Guardian; and the world’s largest dedicated online supermarket, Ocado Retail.\n“With Oracle Cloud ERP, we have transformed our accounting services by standardizing financial processes across 40+ countries to improve efficiency, reduce cost, and accelerate decision-making,” said\nDietrich Franz, Chief Financial Officer, DHL Supply Chain\n.\n“We have been able to expand insights, accelerate our financial close, and increase efficiency. With our core financials in the cloud and a complete view of our data, we can embrace Oracle’s embedded AI capabilities to further increase productivity,” said\nMarcel Esqueu, vice president, financial systems transformation, Guardian\n.\n“With Oracle Cloud ERP’s automation capabilities, controls, and data insights, we can focus more time on our mission to change the way people shop for their groceries and ultimately make our customers’ lives easier,” said\nRebecca Burn, Oracle systems manager, finance, Ocado Retail\n.\nOver 10,000 organizations spanning nearly every industry and geography turn to Oracle Cloud ERP applications to run their businesses. As more enterprises join Oracle’s community of innovators, they will benefit from a comprehensive set of enterprise finance and operations capabilities, including\ndedicated AI agents\n,\npowerful AI and generative AI capabilities\n,\nfinancials\n,\naccounting hub\n,\nprocurement\n,\nproject management\n,\nenterprise performance management\n,\nrisk management\n,\nsubscription management\n,\nsupply chain management & manufacturing\n, and\nOracle B2B\n, which help revolutionizes the way organizations transact, pay, finance, and ship sustainably across the globe.\nGartner Disclaimer\nGartner is a registered trademark and service mark and Magic Quadrant is a registered trademark of Gartner, Inc. and/or its affiliates in the U.S. and internationally and are used herein with permission. All rights reserved.\nGartner does not endorse any vendor, product or service depicted in its research publications and does not advise technology users to select only those vendors with the highest ratings or other designation. Gartner research publications consist of the opinions of Gartner’s research organization and should not be construed as statements of fact. Gartner disclaims all warranties, expressed or implied, with respect to this research, including any warranties of merchantability or fitness for a particular purpose."
  },
  {
    "title": "How Cisco transformed FP&A with Oracle Cloud EPM: A strategic ...",
    "link": "https://blogs.oracle.com/modernfinance/cisco-transformed-fpa-oracle-cloud-epm-strategic-implementation-blueprint-finance-leaders",
    "source": "Oracle_blog",
    "main_ideas": [
      "Cisco adopted Oracle Cloud EPM to drive innovation and agility in financial operations.",
      "Oracle Cloud EPM offers a unified platform for financial planning, enhancing collaboration and efficiency.",
      "A holistic approach to cloud implementation ensures alignment with business objectives and stakeholder engagement."
    ],
    "tags": [
      "oracle-cloud",
      "epm",
      "financial-planning",
      "cloud-computing",
      "data-integration",
      "predictive-analytics",
      "business-transformation",
      "cisco",
      "ai",
      "machine-learning"
    ],
    "original_text": "Cloud technology has evolved from a buzzword to becoming fundamental to modern business operations. While many financial planning and analysis (FP&A) teams recognize the potential of cloud adoption, they often seek clarity on its specific benefits. As organizations embark on their\nOracle Cloud Enterprise Performance Management\n(EPM) journey, it is critical to build a holistic strategy that leverages cloud as a transformation agent to drive business value, ensures operational readiness for the target-state architecture, and addresses financial challenges required for the transformation.\nCloud EPM as a transformation agent\nOracle Cloud EPM enables organizations to reinvent themselves and their operations. While cloud technology offers clear infrastructure cost benefits, its true value lies in creating new opportunities for innovation and efficiency. Many companies take a “lift-and-shift” approach to cloud migration, which often fails to capitalize on the cloud’s transformative potential.\nAt Cisco, we chose to bypass traditional on-premises implementations and moved directly to implement Oracle Cloud EPM capabilities. This bold approach reflected our commitment to innovation and agility and helped us build a compelling business case while and avoiding the fatigue often associated with gradual cloud transitions.\nKey innovations of Oracle Cloud EPM Planning\nOracle Cloud EPM Planning\ndelivers several transformative capabilities that revolutionize financial planning, budgeting, and forecasting.\nUnified platform for financial planning:\nOracle Cloud EPM Planning provides a single, consolidated\nplatform\nfor financial planning, forecasting, and reporting, enabling organizations to manage their entire planning process in one place. This reduces the complexity with multiple systems and improves cross-departmental collaboration.\nPredictive analytics and AI/ML-driven insights:\nLeveraging machine learning and AI, Oracle Cloud EPM Planning offers predictive capabilities that help FP&A teams identify trends and make data-driven decisions. These insights help businesses anticipate financial outcomes, enabling proactive rather than reactive planning.\nScenario modeling and driver-based planning:\nOne of the most valuable innovations in Oracle Cloud EPM is the ability to create detailed scenario models and perform driver-based planning. This allows organizations to model different business scenarios (such as changes in sales, costs, or market conditions) and understand their impact on financial outcomes, leading to more informed decision-making.\nCollaborative, connected planning:\nOracle Cloud EPM enables\nbetter collaboration between finance and other business units\n. By providing shared planning workspaces and workflows, teams can work together to create more accurate and aligned financial plans. This reduces silos and enhances alignment between strategy and execution.\nData integration architecture\nData integration forms the cornerstone of any Cloud EPM transformation, powering strategic decision-making through comprehensive insights. One of the most critical decisions in designing an integration architecture for cloud is choosing between a\nloosely-coupled and a tightly-coupled architecture\n, considering several key factors. While tightly-coupled architectures can be simpler to implement initially, they often incur higher long-term maintenance and upgrade costs. Loosely-coupled systems provide organic growth potential, whereas tightly-coupled systems might require comprehensive overhauls to scale. We made a deliberate decision to implement a loosely-coupled data integration architecture powered by Oracle EPM Automate and Cloud EPM APIs. This choice was not just about technology—it was about creating a future-ready foundation for our business. For instance, we automated the extraction of financial data from our data warehouse system and used the EPM Automate API for seamless transformation and ingestion into Oracle Cloud EPM for reporting and forecasting.\nFigure 1. Data flow architecture\nPerformance\nWhile organizations often focus on functionality and data migration, one critical aspect that ensures implementation success, but is often overlooked, is performance testing. Performance testing acts as the safety net that ensures your Oracle Cloud EPM solution performs optimally under real-world conditions, delivering a seamless experience for users and meets the demands of your business. The purpose-built tools within Cloud EPM test environments enable organizations to\nSimulate high volumes of concurrent users performing key tasks\nTest critical processes under peak load conditions\nIdentify and resolve performance bottlenecks before go-live\nA holistic approach to implementation\nThe key to successful transformation lies in adopting a comprehensive approach that:\nAligns technology implementation with business objectives\nEnsures meaningful stakeholder engagement throughout the process\nIntegrates processes seamlessly across the organization\nConclusion\nOracle Cloud EPM transformation represents more than a technical upgrade—it’s a strategic initiative that can revolutionize how organizations approach FP&A. Success requires careful attention to integration architecture, performance optimization, and change management. By taking a holistic approach that combines technical excellence with business strategy, organizations can leverage Oracle Cloud EPM to achieve greater agility, efficiency, and innovation in their financial operations.\nThe journey to a cloud-based EPM may seem daunting, but with proper planning and a clear understanding of organizational objectives, it becomes a powerful catalyst for business transformation. As demonstrated by Cisco’s experience, organizations that embrace cloud capabilities fully—rather than incrementally—often realize greater benefits and position themselves better for future growth and innovation.\nLearn more about Oracle Cloud EPM Planning."
  },
  {
    "title": "RightNow Road to Fusion: The Path to the Future of Customer Service",
    "link": "https://blogs.oracle.com/cx/rightnow-road-to-fusion-the-path-to-the-future-of-customer-service",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle Fusion Service automates customer service requests using AI technology.",
      "Organizations face pressure to adopt AI for improved customer service operations.",
      "Fusion Service integrates seamlessly with existing Oracle applications for enhanced visibility."
    ],
    "tags": [
      "customer-service",
      "artificial-intelligence",
      "oracle-fusion",
      "automation",
      "self-service",
      "data-integration",
      "field-service",
      "user-experience",
      "cloud-computing"
    ],
    "original_text": "What if your next service request could be resolved without a human ever seeing it?\nThat’s not a future possibility—it’s happening today with\nOracle Fusion Service\n. The world has changed. Customer expectations have changed. Your customer service must change with it.\nThe Cost of Standing Still\nEven though your current support application might be serving you well, chances are it wasn’t built for AI or hyper-connected operations. Holding onto it now means missing out on the biggest tech leap in a generation.\nAccording to Gartner, 79% of customer service leaders are under pressure to adopt AI to improve operations.\n1\nAt the same time, contact center agent attrition remains high—often between 30–45% annually—due to outdated tools and overwhelming workloads.\n2\n60% of Gen Z like to solve problems using self-service, and 57% want to get a response from customer service within 24 hours or less.\n3\nGartner confirms that customer service teams are facing executive pressure to automate their operations—not to replace people, but to enable them to do more.\n4\nUnderstaffed and reactive systems can’t support that transformation. Delaying migration doesn’t buy time—it costs agility. Time spent on outdated systems means lost AI gains, rising support costs, and gaps in customer experience.\nFusion Service: Built for Tomorrow\nOracle Fusion Service\nisn’t an upgrade. It’s a new foundation.\nDesigned for an AI-first, data-driven world, Fusion connects service with sales, quoting, logistics, and subscriptions—all on a single platform. It brings together generative AI, a unified data model, and an open ecosystem to support any service model: B2B, B2C, hybrid, or XaaS.\nAutomate resolutions for routine requests using an AI-powered Resolution Agent and curated knowledge base.\nGuide customer service teams and technicians with smart suggestions drawn from historical context, policies, and live data.\nTrigger proactive service using IoT signals and asset monitoring—before customers even know there’s an issue.\nOrchestrate field, digital, and call-center operations with a consistent, scalable experience.\nWhat Makes Fusion Service Different\nSeamless Integration with Fusion Applications\nFusion connects directly with Oracle’s broader business applications, giving you a single, unified view of customer, product, asset, and service data. For organizations with complex operations—especially those managing physical assets, supply chains, or field services—this integration eliminates costly middleware and provides unprecedented end-to-end visibility.\nNo need to build or maintain integrations between your service desk and your ERP, asset management, or field-service systems—what took months of custom development now just works out of the box.\nThe AI Advantage\nGartner advises customer-support and service leaders to shift from human-centric operations to AI-driven leadership models, deploying automation at scale to embed service throughout the enterprise.\n5\nFusion Service includes more than 20 AI-powered features built directly into the platform:\nService Request Triage and Resolution Agents that automatically categorize issues and suggest solutions.\nKnowledge Search and Chat Agents that surface contextually relevant information.\nWork Order Creation Agents that automatically generate field-service tasks based on asset conditions.\nGenerative AI capabilities for summarization, content creation, and response assistance.\nThese capabilities help service teams resolve issues faster, guide field technicians with smart recommendations, and power self-service tools that customers actually want to use—all without requiring separate licenses or additional spend.\nModern User Experience That Works\nBuilt on Oracle’s\nRedwood Design System\n, Fusion offers an intuitive, modern interface that reduces training time and helps service teams be more productive from day one. Streamlined workflows mean fewer clicks, less navigation, and better multitasking—especially valuable for complex scenarios involving multiple systems, asset histories, or field coordination.\nYou can also customize and extend workflows with low-code\nVisual Builder\ntools, giving you flexibility without the traditional IT burden.\nComplete Service Automation\nFusion automates the entire service lifecycle across every channel:\nSelf-Service:\nEmpower customers to resolve issues on their own with intuitive, AI-enhanced self-service.\nService Rep-Assisted Service:\nAugment your service reps with AI—so every interaction is faster, smarter, and more consistent.\nField Service:\nPredict, schedule, and optimize service in the field with built-in intelligence.\nEmployee Service:\nStreamline employee support with a unified service platform spanning HR, IT, marketing, sales, finance, legal, and operations.\nFor asset-intensive businesses, this means seamless handoffs between digital support, contact-center reps, and field technicians—all working from the same unified data.\nProving the Value\nOrganizations across industries are seeing significant results:\nBadger Infrastructure Solutions achieved a 30% reduction in operational work, a 60% reduction in credit and rebills, and significantly reduced accounts-receivable aging.\nBanco Promerica reduced average operating time from 6.56 minutes to 6.31 and customer-call abandonment rates from 5% to less than 2%.\nEven within Oracle’s own operations, Fusion Service powers support for more than 6,000 service reps and handles over 3,500 service requests daily across complex global operations.\nWhy Now\nOracle’s innovation focus on Fusion. All new AI, automation, and experience enhancements are being built on the Fusion platform.\nMarket pressures aren’t easing. With service teams stretched thin and customer expectations rising, automation is the only path to sustainable scaling.\nMigration support is provided every step of the way. Oracle has a dedicated team actively supporting RightNow customers through their transition with proven tools, expert guidance, and commercial benefits.\nIs Fusion Right for Your Organization?\nFusion Service is the best fit for organizations ready to scale, automate, and unify their customer-service operations—especially those with field service or asset-based business models, or those already using other Oracle Fusion applications.\nEven if you don’t fit those profiles exactly, you may still benefit from a migration—especially if you’re ready to embrace AI, reduce manual effort, and modernize your service experience.\nYour Next Step Forward\nThe future of service is automated, connected, and intelligent. Organizations that act now gain competitive advantages through AI-powered efficiency, reduced operational costs, and enhanced customer experiences.\nSchedule a personalized\nFusion Service demo\nto see the platform’s capabilities in action.\nTalk to your Oracle Account Representative to assess your environment and plan your transition with the extended support team.\nTake advantage of Oracle’s migration incentive: receive 12 months of B2C Service at no cost when you commit to a 36-month Fusion Service contract.\nWith Oracle Fusion Service, you don’t just keep up with change—you lead it.\nReady to explore how Fusion Service can transform your operations? Visit the\nOracle website\nor contact your representative to begin your migration journey.\n1, 4, 5\nLeading Service and Support Into the Future, Gartner, 2025\n2\nKey Causes of Call Center Turnover and Ways To Reduce It\n3\nSelf-Service: Why Gen Z Prefers Solving Problems On Their Own, Forbes"
  },
  {
    "title": "Smarter Job Management: User-Defined Scheduling and Email ...",
    "link": "https://blogs.oracle.com/cx/smarter-job-management-userdefined-scheduling-and-email-notifications-in-oracle-b2c-service",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle B2C Service enhances Job Scheduler with user-defined scheduling and email notifications.",
      "User-defined scheduling allows admins to customize job execution times for better flexibility.",
      "Email notifications keep stakeholders informed about job statuses, improving transparency and responsiveness."
    ],
    "tags": [
      "oracle",
      "job-scheduler",
      "email-notifications",
      "automation",
      "b2c-service",
      "workflow-management",
      "user-defined-scheduling",
      "business-efficiency"
    ],
    "original_text": "The first blog\nEffortless scheduling of jobs in Oracle Service Cloud\nprovided a glimpse of Job Scheduler and its capabilities. Over the past releases couple of enhancements were added to Job Scheduler. With the 25C release, Oracle B2C Service is further enhancing Job Scheduler with two powerful new features:\nUser-Defined Job Scheduling\nand\nIntegrated Email Notifications\n.\nManaging and automating recurring tasks is essential for streamlined operations and timely service delivery. The new\nUser-Defined Job Scheduling\nfeature empowers admins to set up, customize, and manage scheduled jobs tailored to their unique business needs—all within an intuitive, user-friendly interface. Whether it’s nightly data syncs, weekly report generation, or monthly maintenance tasks, scheduling is now in your hands.\nBut automation is only half the story. To ensure stakeholders stay informed and proactive, we’ve added\nEmail Notifications\nthat work hand-in-hand with scheduled jobs. Whether a job completes successfully or encounters an error, designated admins or staff groups will automatically receive detailed notifications. This keeps everyone in the loop, enables faster response to issues, and strengthens accountability across teams.\nTogether, these enhancements offer a smarter, more responsive way to manage your workflows—reducing manual effort, improving transparency, and helping you stay ahead of operational demands.\nUser-Defined Job Scheduling in Oracle B2C\nAn enhanced feature for\nuser-defined job schedules\nhas been introduced into the Oracle B2C’s Job Scheduler.\nThe goal is to enable admins to specify timestamps within the day for job execution, providing greater flexibility and control over routine automation.\nAdmins can now configure jobs to run at\ncustom timestamps\n, in\n5-minute intervals\n, across a full 24-hour day. These schedules can be combined with existing frequency types to suit a wide range of operational needs:\nMonthly\nYearly\nBUI Enhancements\nThe Browser User Interface (BUI) has been updated to support this feature with intuitive controls:\nA new\nUser-defined\noption is available in the\nFrequency\nfield\nVisual dropdowns enable admins to select specific hours and minutes, supporting batch selections within a single hour. Time slots are available from 12:00 AM to 11:55 PM in 5-minute increments, offering precise control over job scheduling.\nA clear summary view displays all selected schedule times for easy review.\nWith this update, we can now accommodate schedules in the formats listed below.\nRun at 09:00 AM, 10:00 AM, 11:00 AM up to 6:00 PM every day.\nRun at 10:30 AM, 11:20 AM every Monday and Friday.\nRun at 12:00 AM, 12:05 AM, 12:10 AM up to 11:55 PM every first day of the month.\nRun at 03:55 AM, 5:20 PM, 10:05 PM\nevery day in January and July\nBenefits\nHigh Precision & Customization:\nEnables organizations to fine-tune and precisely control job execution times, meeting complex business requirements.\nOperational Efficiency:\nStreamlines operations and improves overall workflow efficiency by aligning job schedules with business processes.\nBusiness Flexibility:\nOffers the ability to address specialized scheduling needs that cannot be met with standard interval or calendar-based options.\nLimitations\nNo Arbitrary Date/Time Lists:\nDoes not support scheduling jobs based on arbitrary lists of dates or times.\nNo Complex Cron Patterns:\nLacks support for advanced cron-like patterns (e.g., running every 2 and 5 minutes).\nThe\nUser-Defined Job Scheduling\nfeature brings a new level of precision and customization to Oracle B2C’s Job Scheduler. By enabling fine-tuned control over job execution times, it helps organizations streamline operations, meet complex business requirements, and improve overall workflow efficiency.\nIntroducing Email Notifications for Job Scheduler: Stay Informed, Stay Ahead\nFor many admins, monitoring the outcome of scheduled jobs has been a manual task—checking logs, statuses, and hoping to catch failures before they become critical. We’re excited to announce a significant enhancement to our Job Scheduler that changes this:\nEmail Notifications for Job Scheduler\n.\nWith this new feature, you can receive automatic email notifications whenever a scheduled job completes—whether it’s a success or an error. These emails will include comprehensive details such as the job information, execution logs, and the run status. This proactive notification system empowers admins to quickly identify and fix any configuration or scripting issues, making job management more transparent and less error prone.\nUser Interface Enhancements\nThe Job Scheduler UI has been updated to include email notification fields:\nAdmins could activate email notifications for scheduled jobs. They can specify individual email addresses, choose staff members or groups to receive notifications, and configure conditions—for example, to send notifications only when a job encounters errors.\nSample Email Notifications\nEach notification email follows a clear, consistent template that presents job details and execution logs in an easy-to-read format—making it simple to understand what happened at a glance.\nBenefits\nImmediate Notifications:\nNotifies users or administrators as soon as a job completes, fails, or encounters issues, enabling prompt action.\nEnhanced Monitoring:\nProvides continuous visibility into scheduled tasks without the need for manual log inspection or application monitoring.\nImproved Responsiveness:\nEnables faster response to job failures or critical events, reducing downtime and potential business impact.\nAccountability and Auditability:\nCreates an audit trail of job executions and outcomes, useful for compliance and post-incident investigations.\nStakeholder Communication:\nAutomatically keeps stakeholders informed about business process automation, reducing the need for manual status updates.\nImportant Note: –\nFrequently scheduled jobs\ncan lead to mailboxes being flooded with notifications.\nGet Started Today!\nNo more manual checks or missed notifications.\nWith this new feature, staying on top of your scheduled jobs has never been easier. No more wondering whether a job ran successfully or encountered issues — your inbox will tell you as soon as something happens!\nThis feature is all about making your job scheduling experience smarter, more responsive, and easie\nr\nto manage.\nFor more details refer\nhttps://documentation.custhelp.com/euf/assets/devdocs/buiadmin/topicrefs/c_overview_of_job_scheduler.html\nStay tuned for the next episode of Job Scheduler, where we’ll introduce even more powerful features."
  },
  {
    "title": "Oracle Recognized as a Leader in the 2025 Gartner® Magic Quadrant™ ...",
    "link": "https://blogs.oracle.com/cx/oracle-recognized-as-a-leader-in-the-2025-gartner-magic-quadrant-for-crm-customer-engagement-center",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle is recognized as a leader in the Gartner Magic Quadrant for CRM Customer Engagement Center.",
      "The AI-first model transforms customer service from reactive to proactive, improving efficiency and satisfaction.",
      "AI and human collaboration enhances problem-solving and creates automated processes for known issues."
    ],
    "tags": [
      "oracle",
      "gartner",
      "customer-service",
      "artificial-intelligence",
      "crm",
      "automation",
      "data",
      "customer-engagement",
      "ai-agents"
    ],
    "original_text": "Customer service is at a crossroads. Companies are challenged by rising costs, 24/7 customer expectations, and high employee-attrition rates across customer service organizations. Traditional customer service applications are designed to handle customer interactions manually, by initiating various individual tasks to fulfill those requests. This has created fragmented and broken workflows that are in desperate need of modernization.\nThis is where Oracle comes in. Our strategy for customer service is redefining the space, where AI Agents and humans work together as a team, orchestrating cross-enterprise, autonomous workflows at scale.\nWe are honored that Oracle has been named a Leader in the Gartner® Magic Quadrant™ for the CRM Customer Engagement Center for 13 consecutive times. We believe this sustained recognition validates our vision, strategy, and execution of offering an AI-first service solution.\nDownload the complimentary 2025 Gartner® Magic Quadrant™ for the CRM Customer Engagement Center report\nto see why Oracle is a Leader.\n“We believe this recognition reflects our commitment to transforming service from a reactive cost center to a proactive revenue driver. In our AI-first model, the system handles the knowns, allowing humans to do what they do best: solve novel problems and design the customer experiences of tomorrow. It’s a future where AI leads, and human expertise matters more than ever.”\nFrom Reaction to Orchestration\nThe traditional service model is reactive. Our\nAI-first model\nis proactive, beginning with AI and analytics working together to spot problems before they escalate. Instead of waiting for a flood of tickets, the system automatically\nclusters similar service requests\n, identifying fast-growing issues and resolving the known ones instantly.\nWhen the Triage Agent flags a novel issue, an “unknown,” it intelligently loops in the right human experts. This is where the partnership comes to life. The experts solve the problem once, that solution is captured as knowledge, and the\nResolution Agent\nhelps turn today’s exception into tomorrow’s standard, automated process.\nWhere Humans Matter More\nWith AI handling the knowns, service teams can finally be freed from repetitive tasks to focus on high-value, high-empathy work. Their role shifts from reactive fixer to strategic orchestrator. They are elevated to focus on the moments that build lasting trust: providing expert guidance and white-glove support when it’s needed most, or building new AI agents and workflows to expedite resolution of the complex problems of tomorrow. This AI-first model directly impacts the bottom line, driving faster resolutions, higher customer satisfaction, and reduced costs.\nEnterprise-Ready AI: The Difference is the Data\nThis sophisticated human-AI partnership fails without a single source of truth. While many AI projects stall at the proof-of-concept phase,\nOracle’s platform\nprovides the guidance and guardrails for enterprise success. Our AI is natively fused with data across CX, SCM, and ERP, providing the critical context needed for accurate, secure, and scalable autonomous service.\nLearn more about Oracle Service\nand how it delivers seamless service at scale.\nAlready an Oracle Service customer and want to learn more about the AI Agent setup?\nRead more here.\nWatch our webcasts on-demand\nto learn how Oracle Service helps organizations embrace this shift with AI agents.\nGartner, Magic Quadrant for the CRM Customer Engagement Center, Pri Rathnayake, Drew Kraus, Francesco Vicchi, Jim Robinson, 27 October 2025\nGARTNER is a registered trademark and service mark, and MAGIC QUADRANT is a registered trademark of Gartner, Inc. and/or its affiliates in the U.S. and internationally and are used herein with permission. All rights reserved.\nGartner does not endorse any vendor, product or service depicted in its research publications, and does not advise technology users to select only those vendors with the highest ratings or other designation. Gartner research publications consist of the opinions of Gartner’s research organization and should not be construed as statements of fact. Gartner disclaims all warranties, expressed or implied, with respect to this research, including any warranties of merchantability or fitness for a particular purpose.\nThis graphic was published by Gartner, Inc. as part of a larger research document and should be evaluated in the context of the entire document. The Gartner document is available upon request from Oracle.\nThe report was titled as\nMagic Quadrant for CRM Customer Service Contact Centers\nin 2012."
  },
  {
    "title": "Rethinking Enterprise Software: From UI to Agents",
    "link": "https://blogs.oracle.com/cx/rethinking-enterprise-software-from-ui-to-agents",
    "source": "Oracle_blog",
    "main_ideas": [
      "Enterprise software is shifting from user-driven interfaces to AI-driven agents.",
      "AI agents simplify workflows by orchestrating tasks across various systems.",
      "Dashboards are becoming optional as agents provide real-time, contextual insights."
    ],
    "tags": [
      "enterprise-software",
      "artificial-intelligence",
      "workflow-automation",
      "oracle",
      "sales-technology",
      "data-integration",
      "ai-agents",
      "user-experience",
      "cloud-computing"
    ],
    "original_text": "For decades, enterprise software has evolved around the user interface. New visual layers made it easier to navigate complex systems, but the underlying paradigm stayed the same: users had to drive the software.\nThat era is ending.\nWe’re entering a new phase, led by AI agents that don’t just enhance the UI. They replace the need for one. Work isn’t about clicking through modules anymore. It’s about outcomes, and AI agents are here to deliver them.\nThe End of Navigation\nMost workflows today are designed around the limitations of software modules. Just consider what it takes for a sales rep to generate a quote: jumping across CPQ, CRM, and ERP systems to get basic work done.\nIn an agent-first world, that complexity disappears. Agents know who you are, what you’re trying to achieve, and what data and systems are required to get there. They orchestrate the work across departments and systems, so users don’t have to.\nThis shift redefines what enterprise software is. It’s no longer a series of applications to navigate. It’s an intelligent layer that does the navigating for you. That’s why we challenge software vendors simply bolting agents onto their existing UIs to think about what true transformation means, It’s rethinking the very structure of how enterprise software works. If users still have to click through dashboards and modules to get work done, then AI is just accessorizing the existing problem, not solving it.\nFrom Dashboards to Decisions\nFor example, dashboards once represented progress – a way to visualize complex sets of data, and then AI came along to help summarize it. But if you need AI to explain a chart, why show the chart at all?\nWe’re flipping the model. Rather than static dashboards, agents now surface what matters most – proactively, in real time, and in context. The user doesn’t search for answers. The agent brings them to you, with suggested actions included.\nDashboards aren’t evolving. They’re becoming optional.\nSales as a Navigational Experience\nThe quote is the destination in every sales cycle. Everything else (discovery, qualification, solution design) is a means to that end.\nAgentic AI reverses this workflow. It starts from the goal and works backward. Like a GPS for sales, the system guides the rep to the quote, rerouting as needed. And because agents reason, not just retrieve, they recognize what’s missing, prompt for it, and adapt dynamically.\nThis is AI not just as assistant, but as partner: navigating complexity so sales teams can focus on relationships and outcomes.\nWhy This Works at Oracle\nThis transformation is only possible when data, processes, and workflows are unified. Oracle’s Fusion architecture delivers that foundation.\nBecause we can control the full stack of apps, data, and infrastructure, Oracle’s agents can move fluidly across sales, finance, service, and operations. The result: a seamless, secure, cost-effective experience that’s grounded in reality, not pieced together through integration.\nThis architecture is real. The agents are live. The future of enterprise software is agent-led, and it’s already underway.\nAt Oracle AI World, join\nThe Future of Sales: Unify at Scale or Fragment and Fail\nto see how Oracle’s connected AI turns data into action and relationships into measurable outcomes. The future of sales belongs to those who unify, not those who fragment. Register\nhere\n."
  },
  {
    "title": "Enhancing Customer Engagement with Personalized Outbound SMS from ...",
    "link": "https://blogs.oracle.com/cx/enhancing-customer-engagement-with-personalized-outbound-sms-from-oracle-b2c-service-via-oracle-responsyseloqua",
    "source": "Oracle_blog",
    "main_ideas": [
      "Personalized SMS notifications enhance customer engagement during service requests.",
      "Oracle B2C Service integration with Responsys and Eloqua simplifies SMS communication.",
      "Real-time updates via SMS reduce customer anxiety and improve service efficiency.",
      "Automated SMS notifications eliminate the need for follow-ups from customers.",
      "Personalization at scale fosters trust and satisfaction among customers."
    ],
    "tags": [
      "customer-engagement",
      "sms-notifications",
      "oracle-b2c-service",
      "responsys",
      "eloqua",
      "automation",
      "service-requests",
      "customer-experience",
      "real-time-updates"
    ],
    "original_text": "Have you ever submitted a service request and found yourself wondering when you’ll hear back? Like many end-users, you don’t want to constantly check the portal or contact the helpdesk for updates. Instead, a timely, real-time, and short notification delivered on the channel you use every day, like SMS, is highly appreciated. And your customers are entitled to the same.\nAs an administrator of\nOracle B2C Service\nwith a subscription to\nOracle Responsys\nor\nEloqua\nfrom the Oracle Marketing suite, delivering timely customer updates has never been easier and more effective.\nCurrent Customer Engagement Limitations\nIt is common for customers to feel anxious after submitting a service request about the resolution time and further communication about their service request. This often leads customers to follow up on their service requests, with subsequent communication occurring primarily through traditional channels such as email. It will not only undermine the customer experience, but also creates inefficiencies for service teams by increasing the workload and prolonging resolution times.\nModern Channels for Customer Engagement\nEven as preferences change, SMS continues to be a proven and dependable way to keep customers informed when it matters most. With our new point-to-point integration, you can deliver personalized SMS notifications at every stage of the service request in Oracle B2C Service\npowered by Oracle Responsys or Eloqua.\nThe Outbound SMS feature using Oracle Responsys or Eloqua includes a simple setup process, where administrators can enter their credentials and activate the integration in a few steps. They can also specify which countries should receive SMS messages. This integration is designed specifically to send SMS notifications from Oracle B2C Service to your customers, using Responsys or Eloqua as the delivery platform.\nConfigurator in Oracle B2C Service for Responsys Integration\nConfigurator in Oracle B2C Service for Eloqua Integration\nThis feature allows administrators to easily view and understand how many SMS messages were sent, delivered, or failed over any selected time period, helping them track the effectiveness of their communications.\nBusiness Value of the feature:\nEffortless Setup:\nConfigure integration in just a few clicks. Enter your credentials and activate.\nPowerful Automation:\nUse\nEnhanced Business Rules\nto trigger SMS for incident create or update —like a service request acknowledgment or status change.\nZero Follow-ups:\nCustomers are instantly notified as their service request progresses, reducing delay in communication and eliminating follow ups.\nPersonalization at Scale:\nCraft personalized messages for every scenario using Oracle B2C Service’s\nStandard Text Editor.\nActionable Insights:\nView statistics on sent, skipped, and bounced messages in Oracle B2C Service without the need to toggle between products.\nA Day in the Life: Sara’s Seamless Support Experience\nLet’s walk through a customer journey to see the value in action:\nSara raises a Service Request:\nShe experiences an issue and quickly submits a service request.\nAutomatic acknowledgment:\nSara receives an instant SMS confirming her request has been received.\nReal-time Updates:\nAs her request progresses, a key incident field—such as a custom “Additional Information” field, is set by the support team. When this field is set to “Yes” to request further details, Sara receives an immediate, personalized SMS notification demanding additional information.\nPrompt customer action:\nNotified by SMS, Sara responds with the requested information right away, significantly reducing resolution time.\nClosure and trust:\nOnce her issue is resolved, Sara gets a closure notification. She appreciates the transparency, feels valued, and is more likely to trust and advocate for the brand.\nDocumentation Reference:\nOutbound SMS via Oracle Responsys –\nIntegrating Oracle CX Marketing (Responsys) with Oracle B2C Service\nOutbound SMS via Oracle Eloqua –\nIntegrating Oracle CX Marketing (Eloqua) with Oracle B2C Service\nReady To Get Started?\nFor assistance with setup or to request a demonstration, please refer to the resources provided or you could reach our team via:\nama_service_cloud_ww_grp@oracle.com\n. We welcome your feedback. Thank you."
  },
  {
    "title": "Building the AI-Ready Marketing Organization",
    "link": "https://blogs.oracle.com/cx/building-the-aiready-marketing-organization",
    "source": "Oracle_blog",
    "main_ideas": [
      "AI requires a strong foundation of data governance for successful implementation.",
      "New marketing roles are essential for bridging the gap between AI and marketing operations.",
      "AI should be integrated across all teams to maximize its benefits and learning."
    ],
    "tags": [
      "artificial-intelligence",
      "data-governance",
      "marketing-operations",
      "ai-integration",
      "revenue-impact",
      "culture-of-experimentation",
      "campaign-optimization",
      "customer-data-platform",
      "decision-accelerators"
    ],
    "original_text": "Preparing Your Marketing Organization for the AI Era\nOver the past 15 years, I’ve led product teams through three major waves of marketing technology. The first was automation, which gave marketers the ability to scale outreach with unprecedented efficiency (but declining effectiveness). The second was the rise of data-driven targeting, using account-based strategies, third-party intent, and personalization to move from volume to relevance. Now we’re entering the third wave, Agentic AI, where intelligence is embedded directly into workflows, enabling marketers to act on signals in real time and orchestrate experiences that adapt continuously.\nAI is no different from earlier shifts in one respect: success won’t come from plugging in a model or running a pilot in isolation. It requires building the cultural, structural, and skill foundations that let AI deliver real business impact. Here’s how to prepare your marketing organization for the AI era.\n1. Make Data Governance Your North Star\nAI projects stumble when data is inconsistent, ungoverned, or siloed. Before you spin up your first model or agentic workflow:\nEstablish clear ownership:\nAssign “data stewards” who promote and enforce quality standards, metadata tagging, and privacy controls.\nGovern collaboratively:\nStand up a cross-functional governance council that meets regularly to resolve conflicts, authorize new data sources, and hold teams accountable.\nAutomate policy enforcement:\nUse your CDP’s built-in enrichment, normalization, and consent policies to embed privacy and security rules at data ingest, ensuring every downstream AI process respects governance.\nBy institutionalizing governance, you turn data from a liability into a trusted asset, and give your AI initiatives a rock-solid foundation.\n2. Redefine Roles Around AI-Fluent Marketing Operations\nMarketers and data scientists rarely work from the same playbook. To bridge that gap, organizations need a new kind of marketing operations role—one that pairs business context with AI fluency:\nStrategy translators:\nThese individuals understand campaign and revenue goals but also know enough about model behavior to spot bias, drift, or unreliable outputs in identifying target audiences and buying group definitions.\nAI workflow designers:\nThey don’t just write prompts—they configure how AI agents plug into campaign orchestration, the tools they can leverage, and ensure outputs respect governance, brand, and compliance.\nDecision accelerators:\nBy embedding AI-driven insights directly into planning and execution tools, they help teams act faster and with more confidence.\nUpskilling existing operations leaders or data-driven marketers into this role ensures AI adoption scales across the enterprise—not as a “black box,” but as a transparent and trusted partner in decision-making.\n3. Embed AI Across Every Team\nAI shouldn’t live in a lab or be bolted on — it must be woven into every function:\nProduct & Engineering:\nShip APIs and SDKs that let marketing teams plug AI agents directly into workflows.\nCampaign & Creative:\nIntegrate generative content suggestions into the campaign builder, so teams see prescriptive insights at the moment of creation.\nSales Alignment:\nSurface unified account intelligence (scores, next-best-actions, fatigue metrics) in your CRM so sellers and marketers collaborate on the same data.\nWhen AI becomes embedded as part of daily workflows, every team shares in both the benefits and the learning.\n4. Shift KPIs from Volume to Revenue Impact\nAI won’t prove its value if you’re still measuring vanity metrics. Counting emails sent or campaigns launched doesn’t explain whether work moved the business forward. Instead, reframe metrics around outcomes:\nPipeline and revenue influence:\nTie AI-driven recommendations, like next best offer or channel selection, to measurable deal progression and revenue.\nDecision velocity:\nTrack the time from insight detection to action. Faster loops mean AI is embedded in workflows, not sitting idle in dashboards.\nTrust and reliability:\nMonitor accuracy, bias, and drift with rigor. The moment confidence in outputs erodes, adoption slows.\nThis shift aligns marketing, sales, and finance on what matters most: AI as a driver of growth, not just efficiency.\n5. Foster a Culture of Experimentation\nAI thrives in environments where failing fast is part of the roadmap:\nRun rapid pilots:\nKick off small, contained “sense-and-respond” use cases like AI-driven lead routing or adaptive creative tests, and measure results in weeks or months, not quarters.\nInstitutionalize learnings:\nDocument both wins and failures in a central knowledge base so insights compound across teams.\nReward risk-taking:\nCelebrate bold experiments, even if they flop, to reinforce that innovation beats inertia.\nAn experimentation culture turns AI from a buzzword into a living capability—one that continuously evolves as your markets and customers change.\nFinal Thoughts\nTransforming your marketing organization for AI is a multi-year journey of culture, capability, and continuous learning. By governing your data, redefining roles, distributing ownership, rethinking KPIs, and embracing experimentation, you’ll build a resilient, growth-oriented team ready to harness AI’s full potential.\nTo explore how modern marketing teams are operationalizing AI readiness at scale, check out these\nOracle AI World\nsessions:\nAvoiding the AI Stall Out: How to Unblock AI Momentum in CX\nIT Leaders: Your Marketing Team Bought a Customer Data Platform… Now What?\nHarnessing Data and AI to Deliver on C-Suite Goals: A Marketer’s Panel"
  },
  {
    "title": "Oracle named a Leader in the 2025 Gartner® Magic Quadrant™ for B2B ...",
    "link": "https://blogs.oracle.com/cx/oracle-named-a-leader-in-the-2025-gartner-magic-quadrant-for-b2b-marketing-automation-platforms",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle Eloqua is recognized as a Leader in the 2025 Gartner Magic Quadrant for B2B Marketing Automation.",
      "Eloqua integrates AI to enhance marketing strategies and streamline workflows for B2B marketers.",
      "The platform supports complex multichannel campaigns, enabling better engagement with buying groups."
    ],
    "tags": [
      "oracle",
      "eloqua",
      "b2b-marketing",
      "marketing-automation",
      "gartner",
      "artificial-intelligence",
      "customer-engagement",
      "data-integration",
      "enterprise-software"
    ],
    "original_text": "B2B marketers are under more pressure than ever to engage complex buying groups, deliver measurable impact, and adapt quickly to new technologies like AI. Meeting these demands requires more than basic automation—it calls for a platform that can scale, integrate seamlessly across the enterprise, and help revenue teams work in unison.\nThat’s where\nOracle Eloqua\ncomes in. Designed to orchestrate sophisticated campaigns and unify data across business units and systems, Eloqua combines enterprise-grade marketing automation with embedded AI to help teams create smarter content, score leads more effectively, and accelerate buyer engagement.\nWe believe reflecting these capabilities, Oracle has been named a Leader in the\n2025 Gartner® Magic Quadrant™ for B2B Marketing Automation Platforms\n.\nWhat Gartner Says About Leaders\nAccording to Gartner, “Leaders possess capabilities that enable them to provide deep support across nearly all B2B MAP product requirements… They demonstrate the ability to address the needs of large enterprise clients, in part, due to their strength in managing integrations. Leaders’ product roadmaps balance continued investments in agentic AI with other enhancements that aim to improve customer engagement and demand generation effectiveness and efficiency.”\nWhat Sets Eloqua Apart\nFrom our perspective,\nOracle Eloqua\nis uniquely equipped to help enterprises manage the growing complexity of B2B marketing. Built for scale, Eloqua supports sophisticated multichannel campaigns that span buying groups, product lines, and business units, giving marketers the flexibility to adapt to today’s long and dynamic sales cycles.\nAI is built into Eloqua to simplify workflows — from lead scoring to campaign design — so marketers can spend less time on manual processes and more time on strategy, creativity, and engagement. This makes it easier to deliver consistent, relevant campaigns without adding cost or complexity.\nEloqua also integrates seamlessly with a broad ecosystem of applications, including multiple CRMs, CDPs, and third-party tools, so that\nmarketing and sales\nteams can align around a shared customer view. The result is a marketing automation platform designed to deliver measurable growth, improved collaboration, and more relevant customer experiences at scale.\nLooking Ahead\nOracle is extending Eloqua’s strengths with deeper AI capabilities and tighter integration across the enterprise. By embedding AI directly into Eloqua and connecting it with\nFusion Unity Data Platform\n, marketers can unify fragmented customer data into a trusted foundation that spans both front- and back-office systems. This unified view ensures campaigns aren’t built on partial insights, but on a complete understanding of accounts, buying groups, and individual preferences.\nWith this foundation in place, Eloqua enables marketers to go beyond surface-level engagement metrics and focus on driving meaningful business outcomes. Teams can identify high-value buying groups, personalize journeys with precision, and accelerate revenue opportunities. AI plays a central role here, helping create smarter content, refine lead scoring, and adapt journeys in real time based on signals across the enterprise.\nLooking further ahead, Oracle’s roadmap builds on this momentum with Oracle AI Agent Studio and deep integration with Fusion Unity. These advancements are designed to help\nmarketing and sales\nteams work from the same customer truth, orchestrating journeys that are guided by AI but anchored in reliable enterprise data. The result is a marketing automation platform that not only meets today’s complexity but also positions enterprises to compete and thrive in an AI-driven future.\nOur Commitment\nWe believe this recognition highlights Oracle’s continued commitment to innovation and to empowering enterprises with marketing automation that delivers measurable business outcomes.\nGet your copy of\n2025 Gartner® Magic Quadrant™ for B2B Marketing Automation Platforms\n.\nGartner, Magic Quadrant for B2B Marketing Automation Platforms, Jeff Cohen, Upasna Chandna, Alan Lopez, Sarah Brennan, Nicholas Mortensen, 23 September 2025.\nGartner is a registered trademark and service mark, and Magic Quadrant is a registered trademark of Gartner, Inc. and/or its affiliates in the U.S. and internationally and are used herein with permission. All rights reserved.\nGartner does not endorse any vendor, product or service depicted in its research publications, and does not advise technology users to select only those vendors with the highest ratings or other designation. Gartner research publications consist of the opinions of Gartner’s research organization and should not be construed as statements of fact. Gartner disclaims all warranties, expressed or implied, with respect to this research, including any warranties of merchantability or fitness for a particular purpose.\nThis graphic was published by Gartner, Inc. as part of a larger research document and should be evaluated in the context of the entire document. The Gartner document is available upon request from Oracle."
  },
  {
    "title": "From Syntactic to Semantic: A New Era of AI-First Revenue Applications",
    "link": "https://blogs.oracle.com/cx/from-syntactic-to-semantic-a-new-era-of-aifirst-revenue-applications",
    "source": "Oracle_blog",
    "main_ideas": [
      "AI is transforming enterprise sales from rigid workflows to intuitive, semantic interactions.",
      "Sales reps can now describe needs in plain language for AI to deliver solutions.",
      "The shift to AI-first systems simplifies complexity and accelerates revenue growth."
    ],
    "tags": [
      "artificial-intelligence",
      "enterprise-sales",
      "revenue-operations",
      "oracle",
      "sales-automation",
      "semantic-processing",
      "business-growth",
      "customer-experience",
      "ai-agents"
    ],
    "original_text": "For decades, enterprise sales has been trapped in a world of rigid rules and endless clicks. Every opportunity, quote, and order has required navigating pre-programmed decision trees built by armies of specialists. Success meant translating human needs into the highly structured, syntactic definitions that systems could understand. If you’ve worked in revenue operations, you know this drill, and you know its costs.\nBut AI agents are poised to shatter this paradigm entirely, moving sales\nfrom syntactic to semantic\n. Instead of forcing buyers and sellers through rigid workflows, AI can now understand a request expressed in plain language and can map it directly to the right solutions.\nConsider this: A sales rep tells the system,\n“I need a bundled solution for my customer: a 500-person financial services firm expanding into three European markets with a $75K IT budget and strict data residency requirements.”\nWithin seconds, an AI agent can interpret this prompt, factor in the customer’s purchase history, data residency constraints, optimal configurations, real-time inventory, supply chain dependencies, and dynamic pricing to deliver a solution. No decision trees. No manual configuration. No specialist required.\nThe move from syntactic to semantic processes unlocks two game-changing advantages:\nRadical simplicity.\nEnterprise buying can become intuitive. Complexity can be abstracted away, empowering more people across the organization (not just specialists) to configure and transact.\nFaster value realization.\nAI is designed to interpret context, recommend optimal bundles, and even anticipate needs buyers haven’t expressed yet, to enable deals to close faster.\nThis is more than a potential productivity gain. It’s empowering a foundational redefinition of how companies buy and sell. The future of sales could be simple: people describe what they need, and AI agents handle the complexity behind the scenes.\nAI-first enterprise systems are emerging that blend structured data (the backbone of your business) with unstructured content (the nuance and context of real-world selling). Together, they enable outcomes-focused experiences that help remove friction and accelerate growth.\nAt\nOracle AI World\nthis October\n, we’ll showcase how this shift is already happening inside\nOracle Sales\n,\nCPQ\n,\nCommerce\n, and\nOrder\n&\nSubscription Management\n. You’ll see how AI agents can be used to simplify complexity across the entire revenue lifecycle. If you want to see what the next era of selling looks like, you won’t want to miss it. I look forward to seeing you there."
  },
  {
    "title": "Database CI/CD with the Oracle Database Operator for Kubernetes, ...",
    "link": "https://blogs.oracle.com/post/database-cicd-with-the-oracle-database-operator-for-kubernetes-github-actions-and-liquibase-take-2",
    "source": "Oracle_blog",
    "main_ideas": [
      "Automating database provisioning reduced setup time from days to minutes.",
      "Kubernetes and GitHub Actions streamline database management for developers.",
      "Implementing Infrastructure-as-Code transformed databases into manageable resources."
    ],
    "tags": [
      "kubernetes",
      "devops",
      "oracle",
      "github-actions",
      "database-automation",
      "cloud-native",
      "infrastructure-as-code",
      "oci",
      "liquibase",
      "kustomize"
    ],
    "original_text": "“Can you provision a database for my feature branch?”\nThis simple request used to trigger a 2–3 day process: create a ticket, wait for the DBA team to pick it up, manual database creation, configuration, connection details sent back, inevitably something is misconfigured, back to the DBA team…\nBy the time the database was ready, the developer had moved on to something else, context was lost, and momentum was dead.\nWe decided to fix this. What started as a simple automation project became a deep dive into Kubernetes internals, authentication patterns, and the challenges of managing stateful applications in cloud-native environments.\nThis is the story of that implementation — the problems we faced, the solutions we found, and the lessons we learned.\nI presented this with a live workflow at the recent Oracle AI World in Las Vegas. See\nmy slides\n.\nThe Problem: Development Database Bottleneck\nOur development workflow was broken. We had three teams working on different features of our application, all needing their own database environments for testing. But our infrastructure couldn’t keep up:\nFor Developers:\nShared development database meant constant conflicts — your schema change broke someone else’s work\nManual provisioning took days, killing momentum\nNo two development environments were configured the same way\n“Works on my machine” problems were constant\nFor DBAs:\nManaging 15+ manual database requests per week\nTracking which database belongs to which feature in spreadsheets\nForgotten test databases are consuming cloud resources and budget\nNo standardization — every database was a snowflake\nFor the Business:\nFeatures are taking 20–30% longer due to infrastructure delays\nMonthly cloud bills included $5,000 in orphaned test databases\nProduction issues from schema changes that weren’t properly tested\nDeveloper frustration leading to retention concerns\nWe needed a better way.\nThe Vision: Database-as-Code\nThe initial implementation was performed by\nNorman Aberin’s work\n; we envisioned a simple workflow:\nThe developer creates a feature branch:\nfeature/user-authentication\nDeveloper pushes code\nMagic happens\n15 minutes later, they have a fully configured Oracle database with schemas deployed\nA developer works on their feature with an isolated database\nThe developer deletes the branch\nThe database automatically cleans up\nNo tickets. No waiting. No manual intervention.\nInfrastructure-as-Code, but for databases.\nThe Architecture\nHere’s what you can achieve (I’ve only implemented a test-db feature branch)\nArchitecture diagram showing GitHub → GitHub Actions → OKE Cluster with namespaces\nKey Components:\nOracle Kubernetes Engine (OKE)\n: Our container orchestration platform\nOracle Database Operator\n: Manages the database lifecycle as a Kubernetes resource\nGitHub Actions\n: Orchestrates the entire workflow\nKustomize\n: Handles configuration management\nLiquibase\n: Manages schema versioning and deployment\nEach feature branch gets its own namespace in the Kubernetes cluster, complete with an isolated Oracle database instance.\nThe flow looks like this:\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nGitHub Repository (feature branches)\n↓\nGitHub Actions (triggered on push)\n↓\nOKE Cluster\n├─ Namespace: feature-user-auth\n│ ├─ Oracle Database Pod\n│ ├─ LoadBalancer Service\n│ └─ Persistent Volume\n└─ Namespace: feature-payment-system\n├─ Oracle Database Pod\n├─ LoadBalancer Service\n└─ Persistent Volume\nThe Journey: Four Major Challenges\nWhat seemed straightforward in theory hit reality hard. Here are the four major technical challenges we faced and how we solved them.\nChallenge 1: Authentication Hell\nThe Problem\nWe needed GitHub Actions to authenticate with our OKE cluster. Oracle provides a GitHub Action (\noracle-actions/configure-kubectl-oke\n) that's supposed to handle this. We followed the documentation, configured our secrets, ran the workflow, and...\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nError: Authentication failed\nThe required information to complete authentication\nwas not provided or was incorrect.\nWe spent three days trying different combinations of credentials, regions, and configuration options. The error messages were generic and unhelpful.\nThe Investigation\nOCI authentication uses a private key and a fingerprint of that key’s public component. The Oracle action expected us to provide the fingerprint as a GitHub secret. But we kept getting mismatches — the fingerprint we stored didn’t match what the actual key generated.\nThen the breakthrough:\nWhat if we don’t store the fingerprint at all? What if we generate it from the private key at runtime?\nThe Solution\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\n- name: Setup OCI CLI and Configure kubectl\nrun: |\n# Install OCI CLI\nbash -c \"$(curl -L https://raw.githubusercontent.com/oracle/oci-cli/master/scripts/install/install.sh)\" -- --accept-all-defaults\nexport PATH=\"$HOME/bin:$PATH\"\n\n# Create private key from GitHub secret\nmkdir -p ~/.oci\necho \"${{ secrets.OCI_KEY_FILE }}\" > ~/.oci/key.pem\nchmod 600 ~/.oci/key.pem\n\n# Generate fingerprint from actual key (not from secret!)\nFINGERPRINT=$(openssl rsa -pubout -outform DER \\\n-in ~/.oci/key.pem 2>/dev/null | \\\nopenssl md5 -c | awk -F'= ' '{print $2}')\n\n# Create OCI config with generated fingerprint\ncat > ~/.oci/config << EOF\n[DEFAULT]\nuser=${{ secrets.OCI_USER_OCID }}\nfingerprint=${FINGERPRINT}\ntenancy=${{ secrets.OCI_TENANCY_OCID }}\nregion=${{ secrets.OCI_REGION }}\nkey_file=$HOME/.oci/key.pem\nEOF\n\n# Configure kubectl\n$HOME/bin/oci ce cluster create-kubeconfig \\\n--cluster-id ${{ secrets.OKE_CLUSTER_OCID }} \\\n--file ~/.kube/config \\\n--region '${{ secrets.OCI_REGION }}' \\\n--token-version 2.0.0\nKey Insight\nStore only what you must. Generate what you can.\nThe fingerprint is derived from the key, so derive it at runtime. This guarantees they match because they come from the same source.\nImpact:\nAuthentication went from 0% success rate to 100%.\nChallenge 2: The Kustomize Naming Nightmare\nThe Problem\nWe had a base database configuration named\nfreedb-lite-sample\n. We wanted to add the branch name as a suffix, so for the branch\ntest-db\n, we'd get\ndb-test-db\n. Simple, right?\nWe used Kustomize’s\nnamesuffix\nfeature:\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nkustomize edit set namesuffix test-db\nThe result?\nfreedb-lite-sampletest-db\nKustomize appended the suffix directly to the existing name. Our monitoring scripts were looking for\ndb-test-db\n, but the database was actually named\nfreedb-lite-sampletest-db\n.\nWe spent hours debugging “database not found” errors when the database was right there — just with the wrong name.\nThe Solution\nWe switched\nnamesuffix\nto\nJSON patches\n, which give complete control:\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\ncat > kustomization.yaml << EOF\napiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nnamespace: feature-test-dbresources:\n- base/sidb-free-litepatches:\n- patch: |-\n- op: replace\npath: /metadata/name\nvalue: db-test-db\ntarget:\nkind: SingleInstanceDatabase\nEOF\nThe patch says: “Find the\nSingleInstanceDatabase\nresource and replace its metadata name with\nexactly\nthis value.\" No ambiguity, full control.\nLesson Learned\nKustomize’s convenience features are great for simple cases, but for precise control, JSON patches are worth the extra verbosity.\nChallenge 3: Namespaces That Won’t Die\nThe Problem\nThis was perhaps the most frustrating issue. We’d run our delete workflow to clean up an old database. The workflow completed successfully. But when we tried to create a new database with the same name:\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nError from server (AlreadyExists): object is being deleted:\nnamespaces \"feature-test-db\" already exists\nThe namespace was stuck in the “Terminating” state. For hours.\nIn one case, over 6 hours.\nKubernetes was trying to delete the namespace, but couldn’t because resources inside it had\n“finalizers”\n— cleanup handlers that must complete before deletion. The\nSingleInstanceDatabase\ncustom resource had a finalizer for proper database shutdown. Something was preventing that finalizer from completing, so the namespace was stuck in limbo forever.\nDevelopers couldn’t create new databases because the namespace name was technically “taken” even though nothing was actually running.\nThe Investigation\nWhen I examined the namespace status, I found:\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\n\"message\": \"Some content in the namespace has finalizers remaining:\ndatabase.oracle.com/singleinstancedatabasefinalizer in 1 resource instances\"\nThe database resource was blocking namespace deletion. But the database pod was long gone. The finalizer was waiting for something that would never happen.\nThe Solution\nWe had to force the issue by removing finalizers:\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\n- name: Force delete stuck namespace and resources\nrun: |\nNAMESPACE=\"feature-${{ steps.getname.outputs.idname }}\"\n\nif kubectl get namespace $NAMESPACE 2>/dev/null | grep -q Terminating; then\necho \"Namespace stuck, removing resources...\"\n\n# Remove finalizers from database resources first\nfor db in $(kubectl get singleinstancedatabase -n $NAMESPACE -o name); do\nkubectl patch $db -n $NAMESPACE \\\n-p '{\"metadata\":{\"finalizers\":[]}}' --type=merge\ndone\n\n# Remove finalizers from namespace\nkubectl patch namespace $NAMESPACE \\\n-p '{\"metadata\":{\"finalizers\":[]}}' --type=merge\n\n# Force delete if still exists\nsleep 15\nkubectl delete namespace $NAMESPACE --force --grace-period=0\nfi\nWe run this check before creating a new namespace. If an old one is stuck, we forcibly remove the finalizers and delete it.\nLessons Learned\nKubernetes finalizers are powerful for ensuring proper cleanup, but they can create deadlocks.\nAlways have a force-cleanup mechanism for production workflows. Custom Resource Definitions are especially prone to this issue.\nImpact:\nWorkflow success rate went from ~60% (blocked by stuck namespaces) to 95%+.\nChallenge 4: The Connectivity Conundrum\nThe Problem\nDatabase created successfully. Pod running. Everything looked perfect in the Kubernetes dashboard. But when Liquibase tried to connect from GitHub Actions:\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nORA-12541: Cannot connect. No listener at host 10.0.10.10 port 30328\nnc: connect to 10.0.10.10 port 30328 (tcp) failed: Connection timed out\nWe verified credentials. Checked firewall rules. Tested from different networks. Nothing worked.\nThen I realized:\n10.0.10.10\nis an internal Kubernetes IP (ClusterIP)\n. It's only accessible from inside the cluster. GitHub Actions runs on GitHub's infrastructure, completely outside our cluster. They're in different networks with no connectivity.\nThe Root Cause\nThe Oracle Database Operator created a ClusterIP service by default:\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\napiVersion: v1\nkind: Service\nmetadata:\nname: db-service\nspec:\ntype: ClusterIP # Internal only!\nclusterIP: 10.0.10.10\nports:\n- port: 1521\nClusterIP is perfect for pod-to-pod communication within the cluster. But it’s invisible to the outside world.\nThe Solution\nWe needed to expose the database externally via a\nLoadBalancer\n:\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\n- name: Expose database externally\nrun: |\nkubectl apply -f - <<EOF\napiVersion: v1\nkind: Service\nmetadata:\nname: db-external\nnamespace: feature-test-db\nspec:\ntype: LoadBalancer\nselector:\napp: db-test-db\nports:\n- port: 1521\ntargetPort: 1521\nEOF\n\n# Wait for external IP\nkubectl wait --for=jsonpath='{.status.loadBalancer.ingress[0].ip}' \\\nservice/db-external --timeout=300s\nIn Oracle Cloud, the LoadBalancer service automatically provisions an OCI Load Balancer with a public IP address. The flow becomes:\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nLiquibase (GitHub Actions)\n→ External IP (OCI Load Balancer)\n→ ClusterIP (Kubernetes Service)\n→ Database Pod\nWe wait for the external IP assignment (takes 2–3 minutes) before proceeding with Liquibase.\nLessons Learned\nKubernetes networking has layers.\nClusterIP is internal-only, NodePort exposes on node IPs, and LoadBalancer gets a cloud provider’s load balancer. Choose based on your access patterns.\nSecurity Note:\nFor production, you’d restrict access to this LoadBalancer (IP allowlists, VPN, etc.). For temporary development databases with non-sensitive data, external access is acceptable.\nAlternative Approach:\nWe’re considering running Liquibase as a Kubernetes Job inside the cluster for future iterations. This would keep the database internal-only and eliminate the need for external exposure.\nReal World Performance\nHere’s what a typical execution looks like:\nWorkflow execution timeline or screenshot from GitHub Actions\nWhat you get:\n1 Oracle Database instance (19c or 21c)\n1 Kubernetes namespace (isolated)\n3+ application schemas (fully deployed)\n1 external IP for connectivity\nAutomatic cleanup on branch deletion\nCompare this to our previous process: a minimum of 2–3 days.\nThe Impact\nQuantitative Results\nBefore:\nAverage database provisioning time:\n2–3 days\nMonthly orphaned database costs:\n~$5,000\nDeveloper satisfaction score (infrastructure):\n4.2/10\nFeatures delayed by database availability:\n20–30%\nAfter:\nAverage database provisioning time:\n15–20 minutes\n(99.5% reduction)\nMonthly orphaned database costs:\n~$200\n(96% reduction)\nDeveloper satisfaction score (infrastructure):\n8.7/10\nFeatures delayed by database availability:\n<2%\nQualitative Benefits\nDevelopers:\n“I can experiment freely without worrying about breaking someone else’s work”\n“Testing schema changes is so much easier now”\n“I love that I can just push code and come back to a ready database”\nDBAs:\n“I’ve gone from managing 15+ manual requests per week to zero”\n“Everything is standardized now — I know exactly how every database is configured”\n“The automatic cleanup is amazing for cost control”\nProject Managers:\n“Features are shipping faster”\n“Our cloud bill dropped significantly”\n“Developers are happier, which helps with retention”\nLessons Learned\n1. Authentication: Store Less, Generate More\nDon’t store credentials you can derive. We went from storing five pieces of authentication data to storing two (private key and region), generating everything else at runtime. This reduced secret management complexity and eliminated mismatch errors.\n2. Kubernetes: Plan for Finalizers\nCustom Resource Definitions often have finalizers. In a perfect world, they clean up gracefully. In reality, they can deadlock. Always have force-cleanup mechanisms for production workflows.\n3. Networking: Internal vs External Matters\nClusterIP vs LoadBalancer isn’t just about exposure — it fundamentally changes who can access your services. Understand your access patterns before choosing service types.\n4. Debugging: Add Observability Early\nEvery step in our workflow now echoes what it’s doing and the results. When something fails at 2 AM, these logs are invaluable. Don’t wait for production failures to add debugging.\n5. Automation: Perfect is the Enemy of Done\nOur first version worked for 60% of cases. We shipped it, learned from failures, and iterated. Waiting for perfection would have meant developers still waiting days for databases.\nFuture Improvements\nWe’re not done. Here’s what we’re planning:\nSecurity:\nRun Liquibase as a Kubernetes Job (keep databases internal)\nAdd network policies (restrict database access to specific pods)\nMigrate from GitHub Secrets to OCI Vault (better secret management)\nImplement TLS/SSL for database connections\nOperations:\nAutomated backups before schema changes\nPrometheus metrics for database health\nCost tracking by feature branch\nSlack notifications for deployment status\nDeveloper Experience:\nDatabase seeding with realistic test data\nSchema diff tool (compare feature branch to main)\nDirect kubectl access for troubleshooting\nRollback capability for schema changes\nTools and Resources\nThis implementation wouldn’t have been possible without standing on the shoulders of others:\nCore Technologies:\nOracle Database Operator for Kubernetes\nOracle Kubernetes Engine (OKE)\nGitHub Actions\nLiquibase\nKustomize\nInspiration:\nNorman Aberin’s blog post\nprovided the initial architecture and approach\nDocumentation & Community:\nOracle Cloud Infrastructure documentation\nKubernetes documentation (especially on finalizers and service types)\nStack Overflow for specific troubleshooting\nClaude AI for debugging strategies and troubleshooting guidance\nTry It Yourself\nWant to implement this in your environment? Here’s where to start:\nGitHub - Kuassim/AiWorld: Oracle AI World demo\nSet up an OKE cluster\nwith the Oracle Database Operator installed\nConfigure GitHub secrets\nfor OCI authentication\nCreate base database configuration\nusing Oracle DB Operator manifests\nImplement the create workflow,\nstarting with authentication\nAdd Kustomize\nfor configuration management\nIntegrate Liquibase\nfor schema deployment\nBuild the delete workflow\nfor cleanup\nStart simple. Get authentication working first. Then add one piece at a time. Each challenge we faced taught us something valuable about the technology stack.\nConclusion\nFrom 2–3 days to 15–20 minutes. From manual spreadsheet tracking to automated GitOps. From $5,000 in wasted resources to $200. From frustrated developers to delighted ones.\nBut more than the metrics, what we built is a\nculture shift\n. Databases are no longer special snowflakes that require manual care. They’re infrastructure-as-code, just like everything else in our cloud-native stack.\nEvery developer on our team can now provision a database with a\ngit push\n. They can experiment freely, test thoroughly, and ship confidently. The database is no longer a bottleneck — it's an enabler.\nThat’s the real value of automation: not just time saved, but possibilities created.\nHave you implemented similar database automation in your environment? What challenges did you face? I’d love to hear your experiences in the comments.\nTags:\n#Kubernetes #DevOps #Oracle #GitHubActions #DatabaseAutomation #CloudNative #InfrastructureAsCode #OCI #Liquibase #Kustomize"
  },
  {
    "title": "Staying Compatible: Keeping Your OKE Clusters Up to Date with DevOps ...",
    "link": "https://blogs.oracle.com/post/staying-compatible-keeping-your-oke-clusters-up-to-date-with-devops-deploys-helm-client-upgrades",
    "source": "Oracle_blog",
    "main_ideas": [
      "Keeping OKE clusters updated is crucial for optimal performance and security.",
      "DevOps practices enhance the efficiency of managing OKE cluster updates.",
      "Regular updates help in maintaining compatibility with new features and technologies."
    ],
    "tags": [
      "oke",
      "devops",
      "cloud-computing",
      "cluster-management",
      "software-updates"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Talking to Your ERP: NetSuite Meets Claude via MCP",
    "link": "https://blogs.oracle.com/post/talking-to-your-erp-netsuite-meets-claude-via-mcp",
    "source": "Oracle_blog",
    "main_ideas": [
      "NetSuite integrates with Claude through the MCP for enhanced ERP capabilities.",
      "The collaboration aims to improve business processes and decision-making.",
      "Artificial intelligence is leveraged to optimize ERP functionalities."
    ],
    "tags": [
      "netsuite",
      "claude",
      "mcp",
      "erp",
      "artificial-intelligence",
      "business-optimization",
      "cloud-computing"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Verifying GPU Accelerator Access Isolation in OCI Kubernetes Engine ...",
    "link": "https://blogs.oracle.com/post/verifying-gpu-accelerator-isolation-oci-kubernetes-engine-oke",
    "source": "Oracle_blog",
    "main_ideas": [
      "The article discusses GPU accelerator access isolation in OCI Kubernetes Engine.",
      "It highlights the importance of security in cloud-native environments.",
      "Best practices for implementing GPU isolation in Kubernetes are outlined."
    ],
    "tags": [
      "gpu-accelerators",
      "kubernetes",
      "oci",
      "cloud-security",
      "containerization",
      "cloud-native",
      "virtualization"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Autoscaling GPU Workloads with OCI Kubernetes Engine (OKE)",
    "link": "https://blogs.oracle.com/post/autoscaling-gpu-workloads-oci-kubernetes-engine-oke",
    "source": "Oracle_blog",
    "main_ideas": [
      "OCI Kubernetes Engine enables efficient management of GPU workloads.",
      "Autoscaling features optimize resource allocation for GPU-intensive applications.",
      "Integration with OCI enhances performance and scalability for cloud-native workloads."
    ],
    "tags": [
      "gpu",
      "kubernetes",
      "autoscaling",
      "oci",
      "cloud-computing",
      "containerization",
      "cloud-native",
      "performance",
      "scalability"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Building with AI at the Core: Oracle's Latest Innovations for ...",
    "link": "https://blogs.oracle.com/post/building-with-ai-at-the-core-oracles-latest-innovations-for-developers",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle is integrating AI technologies into its latest product offerings.",
      "The innovations aim to enhance cloud computing capabilities for businesses.",
      "AI-driven solutions are designed to improve operational efficiency and decision-making."
    ],
    "tags": [
      "oracle",
      "artificial-intelligence",
      "cloud-computing",
      "innovation",
      "technology",
      "business-solutions",
      "digital-transformation"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Setup External Objects and Integrations in Oracle Service Cloud for ...",
    "link": "https://blogs.oracle.com/post/service-cloud-create-xo",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle Service Cloud allows integration with external objects for enhanced functionality.",
      "Setting up external integrations can streamline customer service processes.",
      "Utilizing external objects improves data accessibility within Oracle Service Cloud."
    ],
    "tags": [
      "oracle",
      "service-cloud",
      "integrations",
      "external-objects",
      "customer-service"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Best Practices for AI Microservices, Containers, K8s, and Oracle ...",
    "link": "https://blogs.oracle.com/post/best-practices-for-ai-microservices-containers-k8s-and-oracle-database",
    "source": "Oracle_blog",
    "main_ideas": [
      "Implementing AI microservices enhances scalability and flexibility in applications.",
      "Containers streamline deployment and management of microservices in cloud environments.",
      "Kubernetes (K8s) orchestrates containerized applications for improved resource utilization.",
      "Oracle technologies support robust data management for AI-driven applications.",
      "Best practices ensure security and efficiency in AI microservices architecture."
    ],
    "tags": [
      "ai",
      "microservices",
      "containers",
      "kubernetes",
      "oracle",
      "cloud-computing",
      "data-management",
      "best-practices",
      "scalability"
    ],
    "original_text": "This site requires JavaScript to be enabled."
  },
  {
    "title": "Alt Text: Best Practices & Evolving Concerns",
    "link": "https://blogs.oracle.com/marketingcloud/alt-text-best-practices",
    "source": "Oracle_blog",
    "main_ideas": [
      "Alt text provides essential context for images in digital content.",
      "Different types of images require specific alt text strategies.",
      "Generative AI may assist in creating alt text but has limitations."
    ],
    "tags": [
      "alt-text",
      "accessibility",
      "digital-content",
      "marketing",
      "user-experience",
      "generative-ai",
      "html",
      "image-optimization"
    ],
    "original_text": "On websites and in marketing emails, social posts, and other online content,\nalt\ntext helps a wide range of people fully understand your content by providing a plain-text alternative to images. However, using\nalt\ntext optimally isn’t as simple as just inserting a text description into an image’s\nalt\ntag.\nBut before we get into how to determine the most appropriate\nalt\ntext to use, let’s clarify exactly…\nWhen\nAlt\nText Is Used\nThere are five primary instances when\nalt\ntext appears or is used:\nWhen people use screen readers and other assistive technologies to interact with digital content\n. These tools help people with visual and reading disabilities like dyslexia, as well as cognitive and attention disabilities like ADHD. In these cases, the\nalt\ntext is typically read aloud to the user.\nWhen people mouse or hover over an image that has\nalt\ntext.\nWhen that happens, the\nalt\ntext appears, often in a small box, and supplements the person’s visual understanding of the image.\nWhen people don’t automatically download Images\n. In today’s privacy-conscious world, many people chose to block images online and in their inboxes for a variety of reasons. The security settings at their place of business may also result in images being blocked in some cases. In these cases, the images don’t render and the\nalt\ntext is displayed instead in the place where the image would have been.\nWhen people have spotty internet connections or experience slow service and images don’t load\n. In addition to sometimes experiencing connectivity issues because of their device, people also encounter bad connections because of where they are. In cities, basements, subways, elevators, and other places are known to disrupt signals. In rural areas, cell service is known to be spotty away from major highways. And, of course, service can also be slow in airplanes and on trains. In these cases, the HTML text and\nalt\ntext load first, allowing the people to understand the message before images load, if they ever do.\nWhen emails are viewed in the spam folder\n. Images are blocked by default in spam folders, and even some emails that are delivered to the inbox can have their images blocked if the email appears suspicious. In these instances, only the HTML text and\nalt\ntext load.\nSo, no matter who your recipient is, they are likely to experience the benefits of you using\nalt\ntext at some point—or suffer the lack of it.\nRelated on-demand webinar:\n6 Common Accessibility Myths that Cost Brands Customers\nDetermining the Most Appropriate\nAlt\nText\nFor every image in your design, answer the following two questions to determine the most appropriate\nalt\ntext to use.\nAs you’re crafting your\nalt\ntext, keep in mind that only the first 100 characters or so are generally displayed or used. So, be thoughtful and don’t repeat any of the information that’s contained in nearby HTML text. Also, there’s no need to preface your\nalt\ntext with phrases like “image of” or “graphic of.”\n1. What’s the content of the image?\nDepending on the content of an image and its purpose, marketers will want to use different approaches to\nalt\ntext. Here are six common image types and the most appropriate\nalt\ntext strategy to use with each.\nImages containing graphical text\n. Although HTML text is highly recommended over graphical text whenever possible, sometimes integrating text into an image is the only way to get the desired effect. In these cases, the most appropriate\nalt\ntext for the images replicates the text embedded in the image.\nThat said, even if the graphical text is in all caps, your alt text never should be, as that can lead to bad experiences for users of screen readers, voice assistants, and other devices. Unusual spacing and creative spellings can also cause unintended and awkward experiences.\nalt=”Essence of Autumn”\nRelated post:\nVoice Assistants Reading Emails: How to Create Voice-Friendly Campaigns\nInformative images\n. These images convey important concepts or visual instructions. Sometimes, these images are\nanimated\n. For these, the most appropriate\nalt\ntext should briefly explain the information being presented.\nalt=”These classy cocktail glasses are made from clear silicon so they bend instead of breaking”\nDecorative images\n. Rather than communicating anything concrete, these images are more about conveying a vibe, mood, or feeling. In other words, if you removed these images, the substance of the message wouldn’t change. Examples of decorative images include lifestyle and mood-setting images like sunsets, clouds, forests, and cityscapes. Decorative images also include product images, software screenshots, and other images when they’re adjacent to HTML text that describes them adequately.\nFor these images, adding\nalt\ntext would be redundant. So, it’s best to leave the\nalt\ntag empty (\nalt=””\n). But don’t leave the\nalt\ntag out, as that will cause bad experiences for some people.\nalt=””\nComplex images\n. The information contained in an image can be so complex that it’s impossible to adequately describe it in 100 characters or less. A brief generalization is sometimes appropriate, but more often we find that the surrounding text renders these complex images effectively decorative, making it appropriate to leave the\nalt\ntag empty (\nalt=””\n).\nalt=””\nGroups of images\n. Sometimes multiple images are placed together to convey one singular message. Other times, an image is sliced up into several images for design reasons, but still functions as one single image. In these instances, the most appropriate approach is to have descriptive\nalt\ntext for the first image, but then to leave the\nalt\ntag empty for the remaining ones.\nalt=”3.5 out of 5 stars”\nalt=””\nalt=””\nalt=””\nalt=””\nDynamic content\n. The final kind of image is one that’s personalized (i.e., product recommendations) or based on\nlive content\n(i.e., countdown timers, weather feeds). Because this content can vary wildly based on the parameters of the dynamic content, the most appropriate\nalt\ntext describes it generally.\nalt=”The weather at your destination”\nThis is the kind of image that we see most often not having any\nalt\ntags. Sometimes an entire email is composed of personalized content and no discernable messaging survives when images are blocked.\nRelated post:\nLive Content in Emails: The Best Use Cases\n2. Is the image functional?\nIf an image isn’t hyperlinked, then whatever\nalt\ntext you crafted based on the image type is fine. However, if the image is linked, then it has a function and you’ll want to amend your\nalt\ntext to help people understand where the link is taking them. This is especially critical for users of screen readers, who can ‘hop’ from link to link on a page or message.\nTypically, you can simply add a comma or dash at the end of your alt text and then add a link destination descriptor, such as “buy the shirt,” “links to the basketball store,” “explore Hawaii,” or “make an appointment.”\nalt=”The Patriots held a joint practice with the Washington Commanders – watch the highlights”\nUsing Generative AI to Automatically Create\nAlt\nText\nGiven the current emphasis on automation and AI, many brands have been curious about using generative AI to automatically create\nalt\ntext for every image that is added to their content management system (CMS) or digital asset management (DAM) platform. While that might seem like a time-saver, it’s ill-advised for a few reasons.\nFirst, genAI would need to understand when a specific or generalized description of the image’s content is appropriate. Second, it would need to understand when an image is decorative. Third, genAI would need to understand when adjacent HTML text makes\nalt\ntext unnecessary. And fourth, it would need to understand when an image is linked and understand the destination of any link so it can amend\nalt\ntext appropriately.\nAll of these could potentially be appropriate alt tags for this image:\nalt=””\nalt=”black t-shirt on palm tree fronds”\nalt=”Hi Kingdom of Hawaii Classic t-shirt in black”\nalt=”Hi Kingdom of Hawaii Classic t-shirt, links to t-shirt”\nEven if a genAI model could understand all of those parameters, they would change depending on the context of their usage. So, while it may eventually be possible for genAI to automatically create\nalt\ntext, it would do so after a webpage, email, or other piece of content was drafted, not preemptively before usage.\nUntil that day comes, one great use of genAI is to shorten\nalt\ntext that is longer than 100 characters and therefore in danger of being truncated.\nRelated on-demand webinar:\nAI Opportunities Throughout the Email Production Process\nAlt\nText Is No Substitution for HTML Text\nAs essential as it is to craft appropriate\nalt\ntext, HTML text is even more essential, as well as more versatile. Even though\nalt\ntext styling is supported on some platforms, HTML text gives you far more and much more reliable control over the font, font size, font color, background color, and more. Plus, it doesn’t have character limits.\nSmart use of\nalt\ntext isn’t your license to create all-image webpages or emails. We still see far too many of those. Sure,\nalt\ntext saves your message from incomprehensibility, but you lose message hierarchy entirely, since all\nalt\ntext is the same default size. HTML text is the primary fallback for image blocking and screen readers and voice assistants—\nalt\ntext is the secondary fallback.\nGenerative AI systems seem to recognize this. For instance, in most cases, Apple Intelligence and Android AI ignore\nalt\ntext when creating\nAI summaries for emails\n.\nSo, while\nalt\ntext is a key design tool,\nbrands should not over-rely on it or use it to justify shortcuts in design, like using only images to convey your messages.\n—————\nNeed help with the design of your websites or campaigns?\nOracle Digital Experience Agency\nhas hundreds of marketing and communication experts ready to help\nResponsys\n,\nEloqua\n,\nUnity\n, and other\nOracle\ncustomers create stronger connections with their customers and employees—even if they’re not using an Oracle platform as the foundation of that experience. With an NPS of 66, our clients are thrilled with the\naward-winning work\nour creative, strategy, and other specialists do for them.\nFor help overcoming your challenges or seizing your opportunities, talk to your Oracle account manager,\nvisit us online\n, or email us at\nOracleAgency_US@Oracle.com\n.\nTo stay up to date on customer experience best practices and news, subscribe to Oracle Digital Experience Agency’s award-winning, twice-monthly newsletter.\nView archive and subscribe →"
  },
  {
    "title": "The Bridge to an Omnichannel Digital Marketing Future: 3 Foundational ...",
    "link": "https://blogs.oracle.com/marketingcloud/the-bridge-to-an-omnichannel-digital-marketing-future",
    "source": "Oracle_blog",
    "main_ideas": [
      "Consumers have adopted omnichannel behavior, but brands struggle with siloed operations.",
      "Customer Data Platforms are essential for unifying and optimizing customer data.",
      "Omnichannel orchestration and customer-centric analytics enhance coordinated marketing efforts."
    ],
    "tags": [
      "omnichannel",
      "customer-data-platform",
      "digital-marketing",
      "analytics",
      "customer-experience",
      "personalization",
      "oracle",
      "b2b",
      "data-integration"
    ],
    "original_text": "Consumers have been omnichannel in their behavior for at least a decade, seamlessly shifting from one channel to another on their journey toward getting what they want. And B2B buyers have also gone omnichannel. To their frustration, however, most brands have struggled to move beyond their siloed multichannel operations. That has meant disconnected experiences and outdated messaging, which has been to the detriment of customer satisfaction and profits.\nThankfully, brands now have the tools available to them to finally catch up to the channel-hopping speed of their customers. With the following three components in place, brands are finally able to use real-time customer data from cross-channel behaviors to drive coordinated and cohesive customer experiences across channels with visibility into the impact on customer lifetime value.\n1. Customer Data Platform\nThe personalization, segmentation, and automation of your messaging can only ever be as good as the data that’s flowing into your marketing platforms. That’s why\ncustomer data platforms (CDPs)\nare a critical starting point in upleveling your customer experiences. CDPs:\nAre an enterprise package solution (and therefore you should ideally only have one in your entire organization)\nAggregate all customer data in one location from across your organization, giving you a single source of truth\nResolve identifies, de-duping contacts and stitching together data based on customer, account, household, vehicle, and other information\nHave real-time capabilities, so data is up to date\nProvide data accessibility to all other systems for analysis and activation to create customer experiences\nCDPs also provide a reliable data foundation for AI modeling and other tools, whether those are part of an omnichannel orchestration engine, an analytics package, or something else.\nRelated post:\nCDP vs. MDW vs. CRM vs. CDM vs. DMP: How They Differ & How They Might Work Together\n2. Omnichannel Orchestration\nOmnichannel orchestration allows brands to coordinate their digital marketing channels to create cohesive, unified campaigns across channels. This is accomplished through tight integrations between the platforms that drive individual channels, such as email, SMS, and mobile push marketing.\n3. Customer-Centric Analytics\nMost brands are drowning in campaign performance data and channel performance data. But this data doesn’t allow brands to understand how campaigns work together to drive successful customer journeys, especially when those journeys involve multiple channels, which most do.\nThis channel-centric view of performance also causes marketers to optimize individual campaign touchpoints instead of complete customer journeys, or to optimize specific channels instead of the overall customer experience. It also saddles them with\nattribution models\nthat usually pit channels against each other instead of having them and their teams working collaboratively.\nThe alternative is to make the leap from data to insights through analytics and embrace longitudinal customer-centric metrics like customer lifetime value and annual revenue per customer. Along with\nholdout testing\nand\nA/B testing\n, optimizing for those metrics over time help prevent message fatigue and churn, both of which compromise long-term value.\nAt the tactical level, customer-centric analytics and predictive modeling can drive segmentation and personalization efforts. Some modeling to consider include:\nRFM modeling to determine which customers are in-market and which are not based on the recency of their last purchase, frequency of purchases, and monetary value of their purchases\nActivity modeling to determine which customers are likely to engage if messaged\nFatigue modeling to determine which customers are likely to churn out of a channel if messaged again\nChannel affinity to determine which channel to message a customer based on their engagement with the channels they’ve opted into\nNext best action to determine which action a customer is most likely to take based on their recent actions\nProduct category affinity to determine which categories a customer is most interested in\nPrice sensitivity to determine the price bands a customer is most likely to respond to\nDiscount receptivity to determine how a customer responds to different discount levels\nWhile some CDPs have analytics capabilities, most don’t, or they have very limited functionality. Therefore, most organizations will want to bring more sophisticated analytics to bear.\nRelated post:\n7 Advanced Digital Marketing Metrics Most Brands Don’t Use, But Should\nAll for One\nWithout all three of these components, digital marketing programs face significant failures. Without omnichannel orchestration, campaigns are uncoordinated and disjointed across channels. Without a customer data platform, customer data is siloed, outdated, and incomplete and duplicative records are created due to poor identity resolution. And without customer-centric analytics, campaigns and channels are optimized to the detriment of long-term customer value.\nBut with all three of these components, brands can finally create the kinds of experiences that consumers have expected from them for more than a decade.\n—————\nNeed help moving into an omnichannel future?\nOracle Digital Experience Agency\nhas hundreds of marketing and communication experts ready to help\nResponsys\n,\nEloqua\n,\nUnity\n, and other\nOracle\ncustomers create stronger connections with their customers and employees—even if they’re not using an Oracle platform as the foundation of that experience. With an NPS of 66, our clients are thrilled with the\naward-winning work\nour creative, strategy, and other specialists do for them.\nFor help overcoming your challenges or seizing your opportunities, talk to your Oracle account manager,\nvisit us online\n, or email us at\nOracleAgency_US@Oracle.com\n.\nTo stay up to date on customer experience best practices and news, subscribe to Oracle Digital Experience Agency’s award-winning, twice-monthly newsletter.\nView archive and subscribe →"
  },
  {
    "title": "Welcome Email Best Practices: Making a Great First Impression",
    "link": "https://blogs.oracle.com/marketingcloud/welcome-email-best-practices-making-a-great-first-impression",
    "source": "Oracle_blog",
    "main_ideas": [
      "Welcome emails should be sent immediately after signup to avoid confusion.",
      "Using a friendly and descriptive sender name enhances engagement.",
      "A welcome email series can effectively guide new subscribers through key information."
    ],
    "tags": [
      "email-marketing",
      "welcome-emails",
      "customer-engagement",
      "automated-campaigns",
      "best-practices",
      "user-experience",
      "call-to-action",
      "marketing-strategy"
    ],
    "original_text": "When someone signs up to receive your promotional emails, it marks the start of what is hopefully a long and mutually beneficial relationship. Start it off right by sending the most effective welcome email possible.\nHere are nine best practices to follow:\n1. Send welcomes immediately.\nThe days of batched welcome email sends are long, long gone. Today, welcome emails are like order confirmation emails in that consumers assume either they did something wrong or your systems don’t work if they don’t get one immediately after they sign up. Don’t disappoint or confuse them. Trigger yours immediately.\nThe only exception to this rule is when that signup is paired with a product activation period, account setup time, or some other process. If this delay is only minutes long, then waiting to send a welcome may make the most sense. That way, when they get the welcome they’re able to take action. However, if the delay is, say, 15 minutes or longer, then immediately sending a brief email confirming the signup and then following with a proper welcome when the process is complete may make more sense.\nRelated checklist:\n110+ Automated Campaign Ideas\n2. Use a marketing-appropriate sender name.\nIn some cases, welcome emails feel like they were sent by the legal department because they use sender names like “BrandName Inc.” or “BrandName Corp.” when their subsequent emails don’t use those stuffy, meaningless additions. Sender names like “BrandName Account,” “BrandName Account Services,” and “BrandName Account Member Services” also don’t add much and feel cold.\nThat’s not to say that there aren’t opportunities to\nextend your sender name with purpose\n. In the case of welcome emails, we recommend testing “BrandName Welcome,” “BrandName – Welcome,” or “BrandName | Welcome.” It’s descriptive and concise, but also friendly.\nRelated post:\nEmail from Name Extension Strategies that Differentiate Your Messages\n3. Use a high-value call-to-action.\nYour welcome email is among the most anticipated emails you’ll ever send. Don’t waste this golden opportunity by simply confirming for the recipient they signed up successfully. You can and should do so much more than that.\nAsk them to do something that will generate a lot of value. Not sure what that is?\nExamine the behaviors of your best, most loyal customers\n, then try to encourage those same behaviors or prerequisite steps toward those behaviors.\nThere are six principle messaging strategies for welcome email calls-to-action:\nPromotion.\nThe welcome tries to drive a purchase through incentives or product promotions, since getting a purchase—especially the first purchase—is a major predictor of getting future purchases, especially for retail and ecommerce brands.\nProfiling.\nThe welcome tries to gather more information about the new subscriber so that the company can serve them more relevant messaging going forward. While analytics are great for the long-term understanding of a customer, profiling efforts are superior in the short-term when you don’t have much, if any, customer behavior data to leverage.\nEducation.\nThe welcome tries to deepen brand affinity and loyalty by educating the new subscriber about your brand’s history, products, services, values, and social causes. Today’s consumers—especially Millennials and Generation Z—want to feel good about the companies they buy from, so this approach can pay dividends long-term.\nHow to.\nThe welcome explains how your service works or provides a quick start guide to encourage conversions.\nExpansion.\nThe welcome tries to connect with the new subscriber through additional channels by promoting their mobile app, SMS messages, social channels, direct mail catalog, and other channels. The more channels that a customer uses to engage with your brand, the more valuable that customer tends to be. The welcome may also ask the subscriber to deepen their relationship via email, asking them to opt up into additional mailstreams.\nEvangelism.\nThe welcome tries to get the new subscriber to refer their friends or colleagues. Often this is incentivized by offering a discount to the referrer for each referee that makes a purchase or takes some other desired action.\nThose last two messaging strategies tend to do best when they’re part of the tailend of a welcome series (which we’ll talk about in a minute), rather than part of that initial welcome. This gives new subscribers time to experience your email program for a while before you’re asking them to opt into additional channels or spread the word to their friends and family members.\nRelated post:\nOptimizing Email Marketing Calls-to-Action: A 4-Point Plan\n4. Keep your copy and design focused.\nWhile some welcome emails don’t ask new subscribers to do anything, others ask too much. When welcomes are packed with CTA after CTA after CTA, the path forward gets muddied. The subscriber pays less attention and is less likely to engage, particularly with CTAs that are farther toward the bottom of your welcome.\nIf you suspect that you’re packing too much into your welcome email …\n5. Use a welcome email series.\nThe perfect remedy for an overactive welcome email is turning it into a welcome series, which is a strategy that roughly half of B2C have adopted. By having each email focus on a theme, your messages have more focus and your subscribers have an easier time understanding it at a glance.\nHere are some of the themes we’ve seen used in welcome campaigns (along with the messaging strategy it falls under):\nMake your first purchase using this special discount (Promotion)\nLearn about what makes our company, products, and services special (Education)\nLearn about our in-store, concierge, private shopper, and other services (Education)\nLearn about our most popular features (Education/How to)\nLearn how to import your data, set up your account, etc. (How to)\nTell us more about your preferences, interests, etc. (Profiling)\nJoin our loyalty program (Profiling/Promotion)\nApply for our private label credit card (Profiling/Promotion)\nSign up for emails from additional departments or on other topics (Expansion)\nSign up for emails from our sister brands (Expansion)\nDownload our mobile app (Expansion)\nConnect with us on social media (Expansion)\nRefer a friend (Evangelism)\nAs you’re constructing your welcome series, consider how each topic builds on the last. If you’re unsure of what the most logical order is, test it. In addition to the number of emails to have in your welcome series, other issues to consider and test include:\nWhether to send your welcome emails sequentially, suppressing your broadcast and seasonal promotional emails until the full series has been sent, or whether to send them periodically over the course of weeks, with new subscribers receiving your promotional emails in between your welcomes\nWhether to suppress or skip certain emails in your welcome series based on the actions that subscriber has taken (such as suppressing a first-time buyer incentive email to new subscribers who have already made a purchase), the acquisition source of the subscriber (more on that next), or other factors\nWhether to add a final welcome series email that’s acts like a\nconfirmed opt-in request\nthat’s only sent to\nnever-actives\n, which are those subscribers who haven’t responded to any of your emails since signing up\nWhether you’re sending a series of welcomes or a solo welcome, you should also decide whether to…\n6. Send different welcomes based on acquisition source.\nOnce you start thinking about different potential welcome themes, you may realize that not all of your new subscribers need to hear all of those themes. That’s likely true, because every new subscriber is bringing different experiences with your brand into the email relationship.\nFor example, a new subscriber who signed up during checkout via your mobile app doesn’t need a welcome message asking them to download your mobile app. However, someone signing up during an online or in-store checkout would likely benefit from that message.\nSimilarly, a customer who opts in during checkout should be messaged differently than a non-customer who opts in on your homepage. The latter needs a lot more education about your brand, and is also a much better candidate for a welcome incentive as well.\nRelated checklist:\n18 Audience Acquisition Source Ideas\n7.  Craft user-friendly welcomes.\nDesign-wise, your welcome emails should be as user-friendly as possible, because if they’re not, then new subscribers will assume your subsequent emails won’t be either. That means creating welcomes that are:\nResponsive, so that they render well on both small phone screens and large desktop monitors\nDark mode-optimized\n, so they render well in both light mode and dark mode\nAccessible and inclusive\n, so that people with a range of abilities can engage with your messaging\nIf you’ve recently invested in better usability for your promotional emails, make sure you’ve extended those same improvements to your automated campaigns, most especially your welcomes.\nRelated checklist:\n30+ Accessibility & Inclusive Design Ideas\n8. QA and optimize your welcomes often.\nAlong with other triggered emails, welcomes have an unfortunate reputation as being “set it and forget it” programs. That couldn’t be further from the truth. Unlike one-time sends,\nyour triggered programs are living and breathing programs\n, which means that they need ongoing care and nurturing. Unfortunately, most brands don’t provide that.\nIn terms of quality assurance, triggered and transactional campaigns often go at least a few quarters before they’re re-tested to ensure they’re functioning and rendering as intended across email clients. That means a rendering issue caused by an update at an inbox provider or a broken link caused by a change on your website could affect your subscribers for months before it’s caught. That’s devastating for any triggered campaign, but particularly so for a welcome email when you’re trying to make a good first impression.\nAnd in terms of optimization, brands are far less likely to A/B test welcomes and other automated campaigns than they are to A/B test their promotional campaigns. That’s a missed opportunity because automated campaigns generate much higher performance, so every bit of incremental improvement you achieve through testing generates a higher return than you’d get with the same improvement to a promotional email.\nRelated post:\nA/B Testing Pitfalls: How Marketers Can Avoid Costly Mistakes\nOne way to help ensure that you’re regularly QAing and A/B testing is to…\n9. Seasonally update your welcomes.\nWhether you’re a nonprofit trying to drive end-of-year donations during December, a travel company trying to drive warm-weather destinations in January, or a retailer trying to drive back-to-school shopping in July and August, adding or updating welcome content should be a part of any broader\nseasonal automated campaign strategy\n.\nFor your welcome, consider adding:\nSeasonal imagery\n, such as hearts for Valentine’s Day if you’re a jewelry or gifts retailer\nSeasonal navigation bar links\n, such as a “Gifts” or “Holiday” link to the nav bar during the holiday season\nSeasonal messaging\n, such as promoting your annual user conference if you’re a B2B brand\nRelated post:\nMaking Seasonal Adjustments to Automated Campaigns to Boost Results\nFollow those nine best practices\nand you’ll find that your new subscribers are more engaged early in the subscriber lifecycle and doing more of the activities that will make them better customers long-term.\n—————\nNeed help with your welcome campaigns?\nOracle Digital Experience Agency\nhas hundreds of marketing and communication experts ready to help\nResponsys\n,\nEloqua\n,\nUnity\n, and other\nOracle\ncustomers create stronger connections with their customers and employees—even if they’re not using an Oracle platform as the foundation of that experience. With an NPS of 66, our clients are thrilled with the\naward-winning work\nour creative, strategy, and other specialists do for them.\nFor help overcoming your challenges or seizing your opportunities, talk to your Oracle account manager,\nvisit us online\n, or email us at\nOracleAgency_US@Oracle.com\n.\nNow updated, this blog post was originally published on Nov. 17, 2020 by Chad S. White, with contributions from Amy McNeil, Clint Kaiser, Brooke Dahmer, Marisa Crawford, Chris Wilson, and Katie Baril."
  },
  {
    "title": "Using AI Subject Line & Copywriting Tools Successfully",
    "link": "https://blogs.oracle.com/marketingcloud/using-ai-subject-line-and-copywriting-tools-successfully",
    "source": "Oracle_blog",
    "main_ideas": [
      "Machine learning tools enhance email performance by analyzing past campaign data.",
      "Brands should optimize subject lines for clicks or conversions, not just opens.",
      "Maintaining brand consistency is crucial when using machine learning for copywriting."
    ],
    "tags": [
      "machine-learning",
      "email-marketing",
      "copywriting",
      "persado",
      "jacquard",
      "generative-ai",
      "brand-consistency",
      "email-optimization",
      "marketing-strategy"
    ],
    "original_text": "Machine learning tools like\nPersado\nand\nJacquard\nwere writing promotional email subject lines and other copy long before generative AI came along. But unlike genAI, which is\nprimarily about saving time\n, machine learning-powered copywriting tools are all about increasing performance.\nWhat words and phrases should I use to communicate most effectively?\nThat is the question these tools have sought to answer by analyzing years-worth of campaigns and connecting higher performance with certain words and lower performance with others.\nWho Are These ML Tools for?\nThese tools aren’t for every brand. A good candidate has a list of at least 1 million active subscribers. Having a large audience allows tests across more segments.\nAn ideal candidate also sends campaigns at least a few times a week. That’s because larger audiences and higher frequencies give these machine learning systems the scale they need to adequately understand which particular words and patterns of words resonate with your unique audience.\nThe less scale you have the slower the model is to learn and the less confident its recommendations will be.\nWhat About the Results?\nUnfortunately, even when Oracle Digital Experience Agency clients have had more than adequate scale, they’ve experienced mixed results. The two most common complaints we’ve heard are:\nThe lift in email performance wasn’t sustainable beyond a few months\nThe results in general didn’t justify the expense\nIf you’re considering these tools, we have some advice to get you on the path to success.\nFirst, Optimize for the Correct Metric\nOne problem is that many brands using machine learning subject line writing tools are optimizing for opens. That can happen for a few reasons.\nThe most common one is that these ML-powered subject line tools often use opens as the default optimizing criteria.\nMarketers may not change that default or actually switch the optimizing criteria to opens because they think that more opens equal more clicks. This is a common misconception that leads brands to use vague, curiosity-peaking, and “clever” subject lines that are poorly aligned with the content of their emails. Those subject lines may boost opens, but then clicks fall off because the subject line enticed the wrong subscribers to open. (Making things even worse, these kinds of subject lines also tend to erode engagement long-term as subscribers feel tricked into wasting their time on content that isn’t relevant to them and therefore open fewer emails in the future.)\nThe truth is the goal of a promotional subject line is to get the subscribers who are most likely to convert to open the email. Given that, you want to optimize your subject lines to drive action as far down the funnel as possible. Ideally, that’s conversions. However, for most programs, reaching statistical significance on conversions takes too long, making it difficult to be nimble in their testing. Email clicks are an acceptable compromise that gets you to statistical significance much more quickly with a metric that correlates to conversions far better than opens do.\nThat brings us to the final reason that some brands optimize their subject lines for opens: It allows them to reach statistical significance much more quickly than if they were using clicks or conversions. That’s true, but being quickly certain about the influence of an unreliable indicator is not the path to consistently better performance.\nRelated post:\n6 Ways that Subject Line Writing Has Changed\nSecond, Stay on Brand\nDespite being trained on the historical performance of your subject lines, these ML subject line writing tools often don’t understand your brand, so they will suggest copy that’s off-brand—sometimes wildly off-brand. As the protector of your brand, it’s up to you to recognize these off-brand suggestions and reject them.\nWe’ve seen many instances where suggested subject lines:\nInclude lots of shouty ALL CAPS\nWildly overuse urgency as a tactic, undermining its usefulness\nBegin with “RE:” to give the false impression that the email is a reply (which is a violation of the CAN-SPAM Act)\nThese tools generally include the ability to establish from brand guidelines, including do-not-use lists of words. We highly recommend maximizing your use of these features.\nAt the same time, we recommend keeping a close eye on opportunities to use branded language that your AI isn’t likely to suggest, such as the names of your products, words from your jingle, and other words that have special brand meaning. So, it’s as much about leveraging your brand in your wording as avoiding words that go off brand.\nRelated post:\nAI-Generated Text: Generative AI Concerns & Opportunities for Marketers\nAnd Third, Don’t Blindly Test\nWhile all the major providers of ML subject line writing tools have accumulated enough real-world experience into their databases to be able to provide good suggestions, it won’t have any experience with your particular subscribers in the beginning. Building up that experience takes time.\nYour vendor will likely encourage you to test at a high frequency—and across channels, if they offer that functionality. That’s fine. As we mentioned earlier, more tests equals faster learning.\nHowever, even once your vendor does have significant experience with your audience, we still recommend always testing ML-created subject lines against a control subject line or two that your team creates. Human-generated subject lines, especially ones from experienced copywriters who are close to your brand, can outperform ML-generated ones a significant percentage of the time. Don’t assume the algorithm will always win.\nRelated post:\nA/B Testing Pitfalls: How Marketers Can Avoid Costly Mistakes\nThe Bottom Line\nWhile machine learning tools for optimizing email send times and recommending products have been far more successful to date, we believe ML-powered copywriting tools have a bright future, especially as more brands leverage\ngenerative AI for copy\n. As these two AI tools merge, machine learning will bring increased performance to the time-savings generated by generative AI.\nBut this evolutionary convergence may take a while. In time, we expect more competition, lower infrastructure costs, and perhaps different pricing models will change the return on investment calculus that have caused some of our clients to walk away from this technology.\nIn the meantime, you can maximize your chances of success by:\nOptimizing your subject lines for clicks (or conversions) rather than opens\nRejecting off-brand subject lines you wouldn’t accept from a human\nConfirming the performance of AI-suggested subject lines by testing against human-created control subject lines\nDoing so will ensure that you stay in firm control of the experience you’re creating for your subscribers and that those experiences perform.\n—————\nNeed help with your email optimization and copywriting?\nOracle Digital Experience Agency\nhas hundreds of marketing and communication experts ready to help\nResponsys\n,\nEloqua\n,\nUnity\n, and other\nOracle\ncustomers create stronger connections with their customers and employees—even if they’re not using an Oracle platform as the foundation of that experience. With an NPS of 66, our clients are thrilled with the\naward-winning work\nour creative, strategy, and other specialists do for them.\nFor help overcoming your challenges or seizing your opportunities, talk to your Oracle account manager,\nvisit us online\n, or email us at\nOracleAgency_US@Oracle.com\n.\nNow updated, this blog post was originally published on May 28, 2019 by Chad S. White, with contributions from Mark Sambor, Bradford Johnson, and Peter Briggs."
  },
  {
    "title": "Key Lead Nurturing Campaigns by Industry",
    "link": "https://blogs.oracle.com/marketingcloud/key-lead-nurturing-campaigns-by-industry",
    "source": "Oracle_blog",
    "main_ideas": [
      "Lead nurturing campaigns vary by industry, addressing unique customer behaviors and product offerings.",
      "Financial services benefit from onboarding, cross-selling, and application abandonment campaigns.",
      "Logistics and distribution companies focus on service cross-sells and promotional nurtures.",
      "Manufacturers nurture dealer relationships and promote direct-to-business offerings based on product lifecycle.",
      "Sports and entertainment venues prioritize season ticket holder engagement and event day experiences."
    ],
    "tags": [
      "lead-nurturing",
      "financial-services",
      "logistics",
      "manufacturing",
      "sports",
      "entertainment",
      "customer-engagement",
      "cross-selling",
      "campaign-strategies"
    ],
    "original_text": "Some\nlead nurturing campaigns\nare fairly universal, easily finding an effective role in nearly any business. However, most industries have unique products and customer behaviors that can benefit from their own specific nurture flows.\nLet’s discuss some important nurture campaigns that are common in the following industries:\nFinancial services\nLogistics & distribution\nManufacturing\nSports & entertainment\nRelated post:\nLead Nurture Campaigns Every B2B Brand Needs\nFinancial Services\nBanks, brokerages, insurance firms, and other financial services companies have unique nurture campaign opportunities, including:\nNew account holders onboarding\n. In addition to educating new customers on how to use their account online, a key goal of these nurture campaigns is often to have them visit a branch and meet with a rep, who can help with onboarding as well as identify potential cross-sell opportunities. Many brands include incentives like gift cards to encourage branch traffic early on.\nProduct cross-sell\n. These campaigns try to get customers to buy products that are complementary to the ones they already own. For example, if a customer has a small business checking account, the campaign would promote small business credit card accounts.\nApplication abandonment\n. Financial services applications are complex and often involve multiple steps, which sometimes involve partners and third parties. For those reasons, a one-size-fits-all abandonment campaign isn’t sufficient. Brands need to have abandonment series that fit the particular demands of different kinds of applications.\nProspect nurtures\n. On the B2B side, financial services firms can nurture interested prospective financial advisors and institutions to encourage them to transition to their broker-dealer.\nRelated checklist:\n110+ Automated Campaign Ideas\nLogistics & Distribution\nCarriers, warehousing, delivery, and other logistics and distribution companies have unique nurture campaign opportunities, including:\nService cross-sell\n. These campaigns promote complementary services. For example, a customer using a provider’s warehousing services might promote drop shipping services to handle both the warehousing and delivery of larger products.\nPromotional nurtures\n. These nurture campaigns raise awareness of and promote products that aren’t related to products or services currently being used by a customer. For example, a distribution company might promote used vehicle sales, offering discounts and deals on financing. Contacts remain in the nurture until they engage or until the nurture series ends, at which point they’re moved into a non-engaged nurture or re-engagement campaign that reminds the contact about used vehicle sales periodically.\nRelated on-demand webinar:\nEvolving Your Account-Based Marketing Program\nManufacturing\nAutomotive makers, factory equipment producers, heavy industry, and other manufacturing companies have unique nurture campaign opportunities, including:\nDealer relationship-building nurtures\n. Many manufacturers make most of their sales through dealers and wholesalers, especially for smaller buyers. To nurture these relationships, many provide updates on their latest products and services, spotlight partners and dealers, and offer new sales kits and collateral to use with customers. They also highlight industry news and events.\nDirect-to-business nurtures\n. Many manufacturers maintain direct relationships with their biggest customers. Their nurtures are often pegged to the lifecycle of a customer’s existing products, promoting new products and trade-in offers as a product nears its end of life. Other nurtures revolve around product education and usage.\nRelated post:\nMessaging & Content Strategies for Long-Lifespan Products\nSports & Entertainment\nOperators of sports stadiums, festivals, concert halls, theaters, and other entertainment venues have unique nurture campaign opportunities, including:\nSeason ticket holder nurtures\n. Because these have the highest lifetime value of all their customers, venues wisely pay extra attention to them. And they pay even more attention to suite-holders. These nurtures include insider content and interviews, presale ticket buying opportunities, discounts at stadium merchandise stores, and season ticket renewal messaging, among others.\nEvent day nurtures\n. Repeat purchases depend on fans having not only a great time at the event, but as few hassles as possible coming and going. As appropriate, these “Before You Go” campaigns coach fans through the entire experience, including how best to get to the venue, where to park, any pre-event activities, the location of on-premise eateries and stores, and more.\nChances are that your business has unique nurture opportunities as well. You can identify them by examining your customers’ pain points, as well as\nlooking at the behaviors of your best customers\nand trying to nurture those in your other customers.\n—————\nNeed help with your lead nurture campaigns?\nOracle Digital Experience Agency\nhas hundreds of marketing and communication experts ready to help\nResponsys\n,\nEloqua\n,\nUnity\n, and other\nOracle\ncustomers create stronger connections with their customers and employees—even if they’re not using an Oracle platform as the foundation of that experience. With an NPS of 66, our clients are thrilled with the\naward-winning work\nour creative, strategy, and other specialists do for them.\nFor help overcoming your challenges or seizing your opportunities, talk to your Oracle account manager,\nvisit us online\n, or email us at\nOracleAgency_US@Oracle.com\n.\nTo stay up to date on customer experience best practices and news, subscribe to Oracle Digital Experience Agency’s award-winning, twice-monthly newsletter.\nView archive and subscribe →"
  },
  {
    "title": "The AI ROI Killer Lurking in Your Architecture: Data Access Charges",
    "link": "https://blogs.oracle.com/marketingcloud/the-ai-roi-killer-lurking-in-your-architecture-data-access-charges",
    "source": "Oracle_blog",
    "main_ideas": [
      "Data access costs significantly impact the ROI of AI solutions.",
      "Companies must evaluate their data access charges across different time horizons.",
      "Integrating AI directly into applications can reduce costs and improve efficiency."
    ],
    "tags": [
      "data-access",
      "artificial-intelligence",
      "roi",
      "cloud-computing",
      "oracle",
      "data-architecture",
      "api-costs",
      "data-integration",
      "predictive-ai"
    ],
    "original_text": "Even when you have a first-rate artificial intelligence solution, so much of your success with it comes down to the data you have to fuel it.\nDo you have quality data to drive the AI solution?\nDo you have\nthe necessary depth\nof quality data to drive the AI solution?\nDo you have all the necessary data consolidated to drive the AI solution?\nHave you transformed the data so it’s interoperable?\nIs the data available in a timely fashion?\nWe’ve found that those are a few of the most common reasons\nwhy AI solutions fail\n. However, there’s another major pitfall to look out for that won’t cause your AI solution to not work, but will cause it to underdeliver on its return on investment. That pitfall is the cost structure to access all the data your AI solution needs.\nRelated post:\nWhy Your AI Solutions May Not Be Working as Expected\nTimely & Low-Cost Data Access\nThe 4 C’s of data apply to AI as much, if not more, as any other use, especially as companies adopt agentic AI. So, in addition to the above, you want to make sure your data is Complete, Consistent, Correct, and Current.\nTechnically,\ncurrent\nmeans on the same timeframe across sources, not necessarily that all the data is real-time and up-to-date. However, as the number of AI solutions proliferates across organizations, some of them will need frequent data refreshes, if not near real-time data.\nBecause of that growing reality, data access costs are becoming more critical to success with AI. Designed to offset vendors’ CPU usage expenses, those costs typically come in one of two forms:\nAPI call costs.\nIf your technology providers charge you per API call to retrieve your data from their system—many popular operational platforms charge fees for API calls to reduce the number of calls made against their systems—those costs can add up quickly and drastically undermine the ROI of your AI solutions.\nUsage fees.\nAlong with, or instead of, per-query charges, some vendors charge for data egress or extraction. This can come in the form of fees for storage and for moving data from their cloud to somewhere else.\nRelated on-demand webinar:\nHow to Overcome Common AI Mistakes\nTaking Inventory of Your Data Access Costs\nAs you prepare for a future where AI solutions are more involved with all aspects of your business operations, it’s critical to take an inventory of your data access charges across all of your applications. Do so with an eye on three different time horizons:\nCurrent state:\nWhat’s your current exposure to data access charges? Is your current exposure constraining how you’d like to use AI and other solutions? Are you currently hitting your existing API or Usage caps on systems where critical data resides? Do you have the ability to pull the data from high cost systems periodically into a separate solution where you can leverage it for analytics or AI many times without additional costs?\nNear-term horizon:\nGiven your AI plans for the next 12-18 months, how much are your data access needs likely to increase? Given the current data access charges associated with each of your platform providers, how much more will your increased data access needs cost you per year?\nLong-term horizon:\nProject your increased data access needs over the next 5 years. Given that increase, what changes to your tech stack and data architecture do you need to make to lower your data access costs? Have you considered a centralized data platform with built in AI to meet your future requirements?\nWe see the long-term goal for companies to reduce overall data access costs while simultaneously providing access to more data, more often. To achieve this, look for tech stack components that are highly integrated, if not natively integrated by being part of the same system architecture. And for AI specifically, look for providers where AI is embedded directly in their applications rather than bolted on or sitting outside the app.\nAll of those characteristics are a part of Oracle’s current vision for its applications. For instance, our entire\nOracle Fusion Cloud Application Suite\nis built on the same\nOracle Cloud Infrastructure\n, making them seamlessly integrated.\nOracle Data Platform\nand Oracle’s\nCustomer Data Platform\nprovide critical data hubs around which your apps work. And predictive AI, generative AI, and AI agents are\nembedded directly in our Fusion apps\n, reducing costs and increasing speed.\nRegardless of the vendors you choose, paying close attention to data access costs will be important as you deploy more data-hungry AI solutions.\n—————\nNeed help with your AI solutions or data architecture?\nOracle Digital Experience Agency\nhas hundreds of marketing and communication experts ready to help\nResponsys\n,\nEloqua\n,\nUnity\n, and other\nOracle\ncustomers create stronger connections with their customers and employees—even if they’re not using an Oracle platform as the foundation of that experience. With an NPS of 66, our clients are thrilled with the\naward-winning work\nour creative, strategy, and other specialists do for them.\nFor help overcoming your challenges or seizing your opportunities, talk to your Oracle account manager,\nvisit us online\n, or email us at\nOracleAgency_US@Oracle.com\n.\nTo stay up to date on customer experience best practices and news, subscribe to Oracle Digital Experience Agency’s award-winning, twice-monthly newsletter.\nView archive and subscribe →"
  },
  {
    "title": "Lead Nurture Campaigns Every B2B Brand Needs",
    "link": "https://blogs.oracle.com/marketingcloud/6-examples-of-lead-nurturing-campaigns",
    "source": "Oracle_blog",
    "main_ideas": [
      "Lead nurture campaigns automate marketing to guide prospects through the sales funnel.",
      "Different campaigns target various funnel stages, from pre-purchase to post-purchase.",
      "Personalization and pacing are crucial for effective lead nurturing."
    ],
    "tags": [
      "lead-nurture",
      "b2b-marketing",
      "sales-funnel",
      "customer-satisfaction",
      "automation",
      "personalization",
      "digital-marketing",
      "oracle",
      "software-as-a-service"
    ],
    "original_text": "Lead nurture campaigns are automated digital marketing flows that are designed to respond to interest by prospects by delivering content that educates, persuades, or otherwise nudges them farther down the funnel and closer to conversion. Because of that goal of movement down the funnel, different nurture campaigns are aligned with different stages of the funnel and are generally triggered by the transition from one funnel stage to another.\nLet’s talk about four nurture campaigns that every B2B brand needs to efficiently move prospects through the sales funnel.\n1. Traditional lead nurture campaigns\nThese campaigns span the pre-purchase portion of the funnel and are triggered by a prospect becoming a marketing qualified lead. Components include:\nTo move prospects through the\nInterest & Consideration\nstage of the funnel, these campaigns include educational content around the problems, issues, processes, industries, and roles addressed by the brand and its products and services.\nTo aid prospects in the\nEvaluation\nstage, these campaigns generally answer the question of “Why us?” It highlights unique products and service capabilities, and explains why the brand is a better choice than their competitors.\nAnd to get the deal over the line in the\nConversion\nstage, these campaigns make the argument for buying now, providing justifications for not waiting.\nRelated webinar:\nEvolving Your Account-Based Marketing Program\n2. Post-purchase nurture campaigns\nWhile nurturing prospects so they become buyers is important, so is nurturing new customers so they become satisfied customers. This is especially vital for software-as-a-service and other subscription-based businesses, as well as businesses that sell single-use and other highly consumable products, like many medical and janitorial supplies.\nThese campaigns span the post-purchase stages of the funnel. Components include:\nTo move customers through the\nOnboarding\nstage, these campaigns provide installation information and quick-start tips, access to training and how-to information, highlight answers to frequently asked questions and customer communities, and more. It’s all with the goal of ensuring new customers see the value of their purchases as quickly as possible.\nOnce customers are in the\nLoyalty\nstage, the goal shifts to maximizing customer satisfaction over the longer term. This messaging might include updates about the customer’s products (e.g., maintenance, free software updates, eventual replacement) and NPS surveys. The latter can be used to identify at-risk customers who need attention, as well as happy customers who would be willing to evangelize and advocate for your brand (e.g., customer referrals, provide testimonials, speak at events with you). These campaigns can also include evangelism opportunities, such as encouraging or rewarding customers to share content on social and elsewhere.\nRelated checklist:\n110+ Automated Campaign Ideas\n3. Non-buying path nurture campaigns\nNot everyone in your audience is a customer. Some are simply users of your products through their employers (although they might become customers in their own right in the future). Their engagement and satisfaction is just as important as that of your customers, because dissatisfied users often lead to their employer becoming dissatisfied.\nParalleling post-purchase nurture campaigns, these campaigns span the post-purchase stages of the funnel. Components include:\nTo move non-buyers through the\nOnboarding\nstage, these campaigns provide welcome information to get them up to speed on the new product or service. This content may focus on particular user types or roles to increase relevance.\nOnce customers are in the\nLoyalty\nstage, the goal similarly shifts to user satisfaction, with a focus on maintaining engagement through valuable content and virtual and in-person events.\nRelated post:\nMessaging & Content Strategies for Long-Lifespan Products\n4. Mini-nurture campaigns\nThink of these as micro-experiences. Often they’re tied to a specific product. For example, if a prospect were to sign up for a 30-day software trial, you would craft a nurture campaign that spans the trial period.\nThat campaign could start by supplying quick-start tips, providing answers to frequently asked questions, and featuring how-to videos. It could end with a countdown to the trial expiration that provides social proof and other information to overcome objections to moving forward. And in between those beginning and end phases, messaging could be personalized based on the prospect’s use (or lack of use) of the software.\nAdditional Messaging & Design Considerations\nWhen implementing these nurture campaigns, keep the following considerations top of mind.\nPacing\nThe pacing of your nurture campaigns should reflect the duration of your sales cycle. If you have a long sales cycle of a year or more, then you’ll want to adopt a slow-burn approach, where the messages in your nurture campaign arrive, say, every few weeks. However, if you have a short sales cycle of only weeks or a few months, you’ll want to have a faster nurture journey.\nPersonas\nFor each of those nurture campaigns, use personalization or segmentation to ensure your different audiences are getting messaging that’s geared toward them. For example, these campaigns could be tailored by industry (e.g., government, manufacturing, retail), customer type (e.g., partner, dealer, end user), company size (e.g., SMB, enterprise), and other factors.\nRelated post:\n7 Types of Customer Attributes for Segmentation & Personalization\nReflecting a Deepening Relationship\nAs a prospect moves farther down the funnel, the content and design of your nurture campaign messages should reflect the deepening of your relationship. For instance, the level of personalization should increase as you move down the funnel. Also, while\nInterest & Consideration\nstage messaging is likely best sent under your brand name and heavily designed, much of the\nEvaluation & Conversion\nstage messaging is probably best sent dynamically from the local sales rep and be text only.\nYour calls-to-action should also change to align with your prospect’s progression down the funnel. In the\nInterest & Consideration\nstage, most of your CTAs should be low-commitment—meaning they don’t entail any commitment to purchase or to speak to a rep. However, once a prospect progresses to the\nEvaluation & Conversion\nstage, CTAs shift more toward being high-commitment, such as beginning a free trial, seeing a live demo, getting an estimate, or speaking with a sales rep. Be careful, as sending messages with high-commitment CTAs prematurely can have a chilling effect on a new prospect.\n*   *   *\nLead nurture campaigns are amazingly powerful. They help your brand accelerate your prospects’ journeys down the funnel and better qualify leads before a sales rep speaks with them. Ultimately, this makes your entire sales process faster and more efficient.\nIf you’re not currently using lead nurture campaigns, start small with one of these and expand from there. If you already have some in place, consider this your reminder to audit them to see if they’re functioning properly, are up to date with the latest messaging and assets, and are performing well.\n—————\nNeed help with your lead nurture campaigns?\nOracle Digital Experience Agency\nhas hundreds of marketing and communication experts ready to help\nResponsys\n,\nEloqua\n,\nUnity\n, and other\nOracle\ncustomers create stronger connections with their customers and employees—even if they’re not using an Oracle platform as the foundation of that experience. With a 94% satisfaction rate, our clients are thrilled with the\naward-winning work\nour creative, strategy, and other specialists do for them, giving us an outstanding NPS of 82.\nFor help overcoming your challenges or seizing your opportunities, talk to your Oracle account manager,\nvisit us online\n, or email us at\nOracleAgency_US@Oracle.com\n.\nTo stay up to date on customer experience best practices and news, subscribe to Oracle Digital Experience Agency’s award-winning, twice-monthly newsletter.\nView archive and subscribe →\nNow completely updated, this post was originally published on Dec. 23, 2021 by Autumn Black."
  },
  {
    "title": "Why Your AI Solutions May Not Be Working as Expected",
    "link": "https://blogs.oracle.com/marketingcloud/why-your-ai-solutions-may-not-be-working-as-expected",
    "source": "Oracle_blog",
    "main_ideas": [
      "Organizations struggle to implement AI effectively due to unclear goals and inadequate data.",
      "Quality and quantity of data are critical for successful AI solutions.",
      "Timely activation of AI outputs is essential for achieving desired results."
    ],
    "tags": [
      "artificial-intelligence",
      "data-quality",
      "ai-implementation",
      "data-strategy",
      "customer-experience",
      "oracle",
      "machine-learning",
      "data-management"
    ],
    "original_text": "Every organization is excited about the potential of AI to improve their operations, but many are finding it difficult to make AI at scale a reality. If your brand is struggling to achieve what they expected with AI, answering these questions can help you identify common reasons for AI failures.\nDo you have a clearly defined task and goal for the AI solution?\nWhen crafting use cases for AI, it’s critical to understand the relationship between data, behaviors, and your goals. While some AI solutions can help you uncover relationships you weren’t aware of, in most cases you’ll need to understand those relationships from the beginning so you can be sure to provide the right data to the model.\nRelated post:\nUnderstanding AI: 5 Frameworks for Marketers\nDo you have quality data to drive the AI solution?\nIf you have unreliable, low-quality data, then the output of your AI solution will be similarly unreliable and low-quality. You might also not have any data that you need.\nFor example, we had a client that wanted to drive cross-sells using AI. However, they’d never cross-sold their products before and hadn’t even cataloged their services. Moreover, they also couldn’t identify competing products, complimentary products, or related products sold in bundles. So, they not only didn’t have any data for the AI solution to learn from, but didn’t have a data structure or strategy in place to begin collecting data. To make an AI solution feasible, they first had to put a strategy in place to do a variety of cross-selling and collect data in a way that could facilitate the former.\nDo you have\nthe necessary depth of\nquality data to\ndrive the AI solution?\nIt’s not enough to have high-quality data. You generally need lots of it.\nFor instance, if you’re using AI to drive seasonal product promotions, but you only have data for the past 12 months, then your output will be heavily biased toward the last year’s buying patterns, which may or may not be representative of longer term trends.\nThis is a snag that affects many AI applications that are supposed to work out of the box. For example, if a Next Best Offer model was built for the short sales cycles of the average retailer and you sell manufacturing equipment where sales cycles are over a year long, this model won’t function properly for you.\nDo you have all the necessary data consolidated to drive the AI solution?\nYour organization has the proper data, but it’s trapped in various systems the AI solution doesn’t have access to, or which impose large usage fees for retrieving data every time an AI model requires rescoring. You’ll want to assemble it all in one place where it can be collected, standardized, normalized, and properly managed for consistency, so the AI solution can act on it and draw correct conclusions from it.\nIn some cases, the operational platforms where this data is siloed charge per API call, making your AI output much more expensive. That may mean migrating to a platform that has a more AI-friendly billing model or is able to push data into a service bus for access without impacting business critical operations.\nRelated post:\nCDP vs. MDW vs. CRM vs. CDM vs. DMP: How They Differ & How They Might Work Together\nHave you transformed the data so it’s interoperable?\nDifferent systems store the same information differently, so you’ll need to transform data so it’s all following the same format and using the same values. For example, you might have challenges with data consistency across similar platforms, such as\nStatus\nin multiple systems reusing certain values for different meanings.\nRather than forcing your AI’s interpretation layer to constantly adjust for various usage patterns, leverage a centralized data platform to manage the consistency and standardization of data that’s fed into the model to eliminate these potential issues.\nDo you have the ability to activate the AI’s output?\nIt’s not enough to get high-quality output from an AI solution. You need to activate it. There are three primary groups that you might be passing that output along to.\nFirst, you could be passing it to a sales rep, customer service rep, or other people who need to act on the intelligence. In these instances, make sure they understand what the output means and how to use it. That can be much more easily achieved if the model’s output is translated into everyday language and clear actions for the end user to take. This is often an overlooked part of the experience design that is critical to a successful launch.\nSecond, you could be passing it to an AI agent, chatbot, marketing orchestration platform, inventory management system, or another system for activation. Make sure those systems are also properly interpreting and acting on the AI’s output.\nAnd lastly, you could be passing it to another AI solution or set of AI solutions. This is often the case when solving more complex problems like managing cross-channel messaging or doing advanced personalization. In these instances, make sure that all of the involved AI systems are properly architected to work in concert to solve the problem.\nDo you have the ability to activate the AI’s output\nin a timely fashion\n?\nSome decisions don’t need to be made within seconds of getting information, but some do. That can be a major structural barrier if one or more of your operational platforms don’t support the high concurrency to retrieve data in real-time that’s needed for some AI use cases.\nThis is where doing proper discovery and planning is again critical. If you take the time to define your use case and locate system data, you will uncover where you may have time constraints.\nRelated webinar:\nHow to Overcome Common AI Mistakes\nDid the AI solution accomplish the goal without unintended consequences?\nAuditing AI is critical. Even if it clearly accomplished your desired goal, you’ll want to see if there were any unintended consequences, like negative outcomes elsewhere.\nFor example, we had a client who used AI to reduce email subscriber churn. The model quickly learned that the most churn came from new subscribers, so the model stopped emailing new subscribers. While the model achieved its goal of reducing churn, it did so at the cost of not engaging new subscribers. Obviously, that’s not a desirable outcome. The client had to go back and have the AI solution treat new subscribers and established subscribers differently.\nIn other cases, an AI may boost conversions for one product or service at the expense of others such that overall revenue is lower. Depending on the circumstances, that may be okay, but it may not.\nAuditing over time is also important, as the modeling may fall out of sync with either your customers’ behaviors or your business operations.\n*   *   *\nIf you answered\nNo\nto any of those questions,\nthen you’ve identified the reason why your AI solution isn’t delivering the results you expected. Even better, if you’re asking these questions\nbefore\nimplementing an AI solution, then you’ve proactively identified pitfalls you’ll want to avoid.\n—————\nNeed help with getting the most out of your AI solutions?\nOracle Digital Experience Agency\nhas hundreds of marketing and communication experts ready to help\nResponsys\n,\nEloqua\n,\nUnity\n, and other\nOracle\ncustomers create stronger connections with their customers and employees—even if they’re not using an Oracle platform as the foundation of that experience. With a 94% satisfaction rate, our clients are thrilled with the\naward-winning work\nour creative, strategy, and other specialists do for them, giving us an outstanding NPS of 82.\nFor help overcoming your challenges or seizing your opportunities, talk to your Oracle account manager,\nvisit us online\n, or email us at\nOracleAgency_US@Oracle.com\n.\nTo stay up to date on customer experience best practices and news, subscribe to Oracle Digital Experience Agency’s award-winning, twice-monthly newsletter.\nView archive and subscribe →"
  },
  {
    "title": "Quiz yourself: Serializing a primitive with ObjectOutputStream",
    "link": "https://blogs.oracle.com/javamagazine/java-quiz-serialize-primitive-value",
    "source": "Oracle_blog",
    "main_ideas": [
      "Java serialization allows primitives to be serialized directly without boxing.",
      "ObjectOutputStream provides methods for serializing objects and primitives.",
      "Option D is the correct method for serializing a long primitive value."
    ],
    "tags": [
      "java",
      "serialization",
      "objectoutputstream",
      "primitives",
      "dataoutput",
      "programming",
      "software-development"
    ],
    "original_text": "Primitives? Objects? What should you do?\nMore quiz questions available\nhere\nYou need to serialize a\nlong\nprimitive value, and you have been given the following code:\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nlong l = 5L;\ntry (ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(filename))) {\n... //\n}\nWhich statement is true?\nChoose one.\nA.\nThe code must box the primitive using\noos.writeObject(Long.valueOf(l))\n.\nB.\nThe primitive must be included in the outer Java class as an instance variable to be serialized.\nC.\nThe serialization should be implemented as\noos.writeObject(l)\n.\nD.\nThe serialization should be implemented as\noos.writeLong(l)\n.\nE.\nThe serialization must delegate to the\nDataOutput\nclass for writing primitives.\nAnswer.\nJava serialization provides a way to represent a graph of objects as a byte sequence. This mechanism also supports primitive data directly, as part of objects. Primitive wrapper classes also implement the\nSerializable\ninterface and can be serialized too. Commonly, the byte sequence that results from serialization is written to disk for long-term storage or is transmitted across a network.\nIn most cases, you will use the class\nObjectOutputStream\nto create the serialized byte stream. This class provides the\nwriteObject\nmethod proposed in option C, and that method readily handles serializing an entire graph of objects. The result can be transparently restored using the\nObjectInputStream\nclass. Note, however, that the argument to the\nwriteObject\nmethod is an\nobject\n, not a primitive.\nThe previous discussion tells you something about option C: If it’s used, autoboxing would occur and you would not serialize the primitive value. Instead, you would have a serialized representation of the wrapper that was created. At this point in analyzing the exam question, it’s probably too early to reject this option, but you must decide whether any other answer is a better match with the proposition of the question—which does, after all, specifically mention that you are serializing a primitive value.\nIt turns out that\nObjectOutputStream\nimplements the\njava.io.DataOutput\ninterface. That interface defines\nwriteXXX\nmethods for all primitives. As a side note,\nDataOutput\nis also implemented by the class\njava.io.DataOutputStream\n, but although that class works with primitives and strings, it cannot perform serialization. This capability is described in option D, and it will allow you to use the\noos\nobject to serialize the primitive directly. From this you can determine that option D is correct. It’s definitely better than option C, and you can now confidently reject option C as incorrect.\nAlthough you should feel confident in the correctness of option D, you should still verify that the other options are incorrect. In an exam, you might discover another option that seems correct, which would cause you to revisit your reasoning. But if you’re tight on time, you might go with the first answer that appears correct.\nOption A is incorrect: The\nObjectOutputStream\nis able to serialize primitives directly, which means that boxing is not necessary. Of course, if your application calls for it, you\ncan\nbox or autobox the primitive, but it’s not necessary. Further, the result will take substantially more space in the resulting byte sequence.\nOption B is also incorrect for essentially for the same reason as with options A and C. Certainly primitives that are members of objects are handled correctly, but it’s not necessary to wrap a primitive in such an object just to get it out into the byte sequence.\nOption E is incorrect, because, as discussed earlier,\njava.io.DataOutput\nis an interface, not a class, as is suggested in the stem. The interface declares the signatures of various methods, including the\nwriteLong\nmethod you will use, but\nwriteLong\nis (and, in fact, all the methods of this interface are) abstract. The implementation is provided by the\njava.io.ObjectOutputStream\nclass; therefore, delegation in the code is not necessary or possible.\nConclusion.\nThe correct answer is option D.\nRelated quizzes\nQuiz yourself: Deserializing objects with readObject\nQuiz yourself: Secure serialization and deserialization\nQuiz yourself: Read and write objects by using serialization\nQuiz yourself: Deserializing objects that have a nonserializable parent"
  },
  {
    "title": "JCON World 2023: A virtual conference for Java developers",
    "link": "https://blogs.oracle.com/javamagazine/java-jcon-world-2023",
    "source": "Oracle_blog",
    "main_ideas": [
      "JCON World 2023 is a global virtual conference for Java developers.",
      "The event will take place from November 20 to November 22.",
      "Last year's JCON World attracted over 2,600 developers from more than 80 countries."
    ],
    "tags": [
      "java",
      "conference",
      "virtual-event",
      "cloud-native",
      "microservices",
      "global-participation",
      "developer-community",
      "innovation",
      "collaboration"
    ],
    "original_text": "Attend this online gathering.\nHave you heard about JCON 2023? This conference’s Java developer gatherings aren’t merely events; they are a three-part journey—a journey that traverses physical spaces and digital domains, all while celebrating the essence of Java. From the serene Slovenian shores to the cinematic spectacles of Cologne and the digital domain spanning six continents, celebrate the spirit of Java at JCON.\nTwo of the events have passed, but I’ll tell you a little bit about them—and then encourage you to attend the November event virtually.\nJCON OpenBlend Slovenia 2023\nSet against the scenic backdrop of Portorož, the Convention Centre Portus played host to this vibrant gathering from June 1 to June 2. A collaborative effort of the\nOpenBlend\nand\nSIOUG\nuser groups in association with JCON, this in-person event was an enriching experience for attendees, who reveled in the confluence of diverse Java minds while converging on the serene Slovenian coast.\nJCON Europe 2023\nThe big screen met the world of Java from June 20 to June 23. JCON Europe 2023 took place at the Cinedom multiplex cinema in Cologne, Germany, and it was a larger-than-life experience. It was a return to in-person events, and attendees soaked in Java knowledge on colossal cinema screens that transformed learning into an immersive spectacle.\nJCON World 2023\nThe grand finale of the JCON trio is a truly global affair. Catering to the Java community spread across six continents from November 20 to November 22,\nJCON World 2023\nwill be the ultimate online event. No matter where you are, this digital fiesta will ensure that you’re connected with the crème de la crème of the Java universe, all from the comfort of your home.\nA groundbreaking success in 2022, JCON World (formerly known as JCON Online) witnessed an unparalleled assembly of more than 2,600 developers from around the globe. Last year’s event had attendees from more than 80 countries and included more than 150 sessions. There was an emphasis on pivotal themes, notably cloud native Java and microservices.\nThere were unforgettable moments as well, with one speaker improvising amidst a power outage in Mexico and another joining from the tranquility of the Swedish forests.\nIf 2022 was about setting benchmarks, 2023 promises to transcend them through\nGlobal integration: Building on the previous year’s momentum, expect even wider global participation.\nExpanded topics: While cloud native Java and microservices were the stars last year, 2023 aims to delve deeper into unexplored terrains of Java development.\nAs the countdown begins for JCON World 2023, the promise is that it’ll be not just an event but an experience—an experience where boundaries blur, where Java enthusiasts from all corners of the globe converge, and where the future of Java development takes shape.\nJoin us as we embark on another journey of innovation, collaboration, and inspiration. JCON World 2023 awaits. Get a free ticket by using code\nJAVA-MAGAZINE\n."
  },
  {
    "title": "Java 21 is here: Virtual threads, string templates, and more",
    "link": "https://blogs.oracle.com/javamagazine/java-21-now-available",
    "source": "Oracle_blog",
    "main_ideas": [
      "Java 21 introduces significant production-ready features and enhancements.",
      "Key initiatives include Project Loom, Project Amber, Project Panama, and Project Valhalla.",
      "Java 21 supports long-term maintenance with at least eight years of support."
    ],
    "tags": [
      "java",
      "programming",
      "software-development",
      "openjdk",
      "virtual-threads",
      "project-loom",
      "project-amber",
      "long-term-support",
      "garbage-collection"
    ],
    "original_text": "The JEPs in Java 21 deliver several important production-ready advances to the platform.\nJava 21 is officially here, as of its general availability launch on September 19, 2023. This release represents the 12th feature release of the platform using the now-standard semiannual cadence. (You should expect to see Java 22 in March 2024.)\nThere’s a tremendous wealth of information in the\nJava 21 release notes\n, and this article will hit some of the highlights. You may also want to review Mohamed Taman’s “\nJava 21 sneak peek\n” and Nicolai Parlog’s “\nGoing inside Java 21’s rich, upcoming goodness\n.”\nAs described in the\nofficial release blog post\n, Java 21 delivers dozens of new features and enhancements. Fifteen of those appeared as JEPs, which included eight ready-to-use production features. The others are preview and incubator features, which are meant for you and your organization to explore, but which aren’t ready for production use yet, because those features may change in future Java releases.\nMuch of the new functionality in Java 21 applies to four major platform initiatives:\nProject Amber\n(improving developer productivity),\nProject Loom\n(reimagining threading),\nProject Panama\n(bridging Java and other platforms), and\nProject Valhalla\n(augmenting the Java object model with value objects).\nOther JEPs enhance Java’s core libraries and garbage collectors, while a few prepare outdated Java features for removal in future platform releases.\nProduction-ready JEPs\nThe following are the ready-for-production JEPs included in the Java 21 release.\nJEP 431:\nSequenced collections\n.\nThis JEP introduces new interfaces to represent collections with a defined encounter order. Each such collection has a well-defined first element, second element, and so forth, up to the last element. It also provides uniform APIs for accessing a collection’s first and last elements, and for processing its elements in reverse order.\nJEP 439:\nGenerational ZGC\n.\nThis JEP improves application performance by extending the\nZ Garbage Collector (ZGC)\nto maintain separate\ngenerations\nfor young and old objects. Applications running with Generational ZGC should enjoy lower risk of allocation stalls, lower required heap memory overhead, and lower garbage collection CPU overhead.\nJEP 440:\nRecord patterns\n.\nThis JEP enhances the Java programming language by extending pattern matching to instances of record classes, enabling more-sophisticated data queries. It also adds nested patterns, which can help you create more-composable data queries.\nJEP 441:\nPattern matching for switch\n.\nThis JEP improves the productivity of the Java programming language by making it more semantic, so complex data-oriented queries can be expressed concisely and safely. It does so by allowing patterns to appear in case labels, while also requiring that pattern switch statements cover all possible input values.\nJEP 444:\nVirtual threads\n.\nVirtual threads can dramatically reduce the effort of writing, maintaining, and observing high-throughput concurrent applications. This JEP enables server applications written in the simple thread-per-request style to scale with near-optimal hardware utilization, and it also lets existing code that uses the\njava.lang.Thread\nAPI adopt virtual threads with minimal change.\nJEP 449:\nDeprecate the Windows 32-bit x86 port for removal\n.\nThe 32-bit version of Windows on x86 processors is obsolescent. It’s supported in Java 21, but it’s going away in the future. This JEP updates the build system to issue an error message when an attempt is made to configure a build for Windows 32-bit x86 (x86-32). The error message will be suppressible via a new configuration option, but the goal is to urge you to move beyond that platform.\nJEP 451:\nPrepare to disallow the dynamic loading of agents\n.\nThis JEP prepares you for a future release of the JDK that will, by default, disallow the loading of agents into a running JVM. It does so by issuing warnings when agents are loaded dynamically into a running JVM. Note that serviceability tools that load agents at startup will not cause warnings to be issued in any release. This JEP aligns the ability to load agents dynamically with other so-called “superpower” capabilities, such as\ndeep reflection\n.\nJEP 452:\nKey encapsulation mechanism API\n.\nKey encapsulation mechanisms (KEMs) provide modern cryptographic techniques that secure symmetric keys using asymmetric or public key cryptography. This API lets you use several KEM algorithms, and it also allows security providers to implement KEM algorithms in either Java code or native code.\nPreview and incubator JEPs\nThe following are the previews and incubators in Java 21. To use these JEPs, you’ll need to use the appropriate flags; refer to each JEP’s documentation for details.\nJEP 430:\nString templates (preview)\n.\nThis JEP simplifies the writing of Java programs by making it easy to express strings that include values computed at runtime and by enhancing the readability of expressions that mix text and expressions, whether the text fits on a single source line or spans several source lines. It also improves the security of Java programs that compose strings from user-provided values and pass them to other systems.\nJEP 442:\nForeign function and memory API (third preview)\n.\nThis JEP provides a new API that helps Java programs interoperate with code and data outside of the Java runtime. By efficiently invoking foreign functions (code outside the JVM) and by safely accessing foreign memory (memory not managed by the JVM), the API enables Java programs to call native libraries and process native data without the brittleness and danger of Java Native Interface (JNI).\nJEP 443:\nUnnamed patterns and variables (preview)\n.\nThis JEP enhances the Java language with unnamed patterns, which match a record component without stating the component’s name or type, and unnamed variables, which can be initialized but not used. Both are denoted by an underscore character, _.\nJEP 445:\nUnnamed classes and instance main methods (preview)\n.\nThis JEP offers a smooth on-ramp to Java so educators can introduce programming concepts in a gradual manner. It does so by reducing the boilerplate and ceremony so that students can write their first programs without needing to understand language features designed for large programs; at the same time, it doesn’t introduce a separate beginner’s dialect for Java or a separate toolchain.\nJEP 446:\nScoped values (preview)\n.\nThis JEP provides a programming model to share data both within a thread and with child threads, to simplify reasoning about data flow. The model ensures that data shared by a caller can be retrieved only by legitimate callees, and it also treats shared data as immutable to allow sharing by many threads and to enable runtime optimizations.\nJEP 448:\nVector API (sixth incubator)\n.\nThis new API expresses vector computations that reliably compile, at runtime, to optimal vector instructions on supported CPU architectures, thus achieving performance superior to equivalent scalar computations. It also adds the exclusive or (XOR) operation to vector masks, and it improves the performance of vector shuffles, especially when they are used to rearrange the elements of a vector or convert between vectors.\nJEP 453:\nStructured concurrency (preview)\n.\nThis JEP simplifies concurrent programming by introducing an API for structured concurrency, and it promotes a style of concurrent programming that can eliminate common risks arising from cancellation and shutdown, such as thread leaks and cancellation delays.\nDownload Java 21 and start working today\nThe Java 21 OpenJDK reference implementation can be acquired from\nhttps://jdk.java.net/21/\n. Oracle’s implementation, Java SE 21, can be found at\nhttps://www.oracle.com/java/technologies/downloads/\n.\nOracle’s Java SE 21 is a long-term support (LTS) release. Oracle will offer long term support for Java 21 for at least eight years. This extended support period gives organizations flexibility to keep applications in production longer with minimal maintenance, and to eventually migrate on their own terms.\nPlease note that, based on customer feedback and use in the Java ecosystem, Oracle has also announced that long term support for Java 11 has been extended through at least January 2032, providing at least eight more years of support and updates from Oracle.\nDig deeper\nJava 21 release notes\nOfficial Java 21 release blog\nOracle Java SE 21 reference implementations\nOpenJDK builds at https://jdk.java.net/21/\nOracle Java 21 press release\nMohamed Taman’s Java 21 sneak peek\nNicolai Parlog’s Going inside Java 21’s rich, upcoming goodness"
  },
  {
    "title": "Simplifying data access with MySQL and Jakarta Data",
    "link": "https://blogs.oracle.com/javamagazine/jakarta-data-mysql",
    "source": "Oracle_blog",
    "main_ideas": [
      "Jakarta Data simplifies data access for application developers using the Repository pattern.",
      "CRUD operations are essential for data persistence in applications, especially with relational databases.",
      "Jakarta Data reduces boilerplate code, enhancing developer productivity and code quality.",
      "MySQL remains a popular choice for relational database management due to its accessibility and support.",
      "The article provides a practical example of using Jakarta Data with MySQL."
    ],
    "tags": [
      "jakarta-data",
      "mysql",
      "data-access",
      "crud",
      "orm",
      "repository-pattern",
      "java",
      "enterprise",
      "persistence",
      "open-source"
    ],
    "original_text": "See how the Jakarta Data specification simplifies persistence.\nMany applications, especially in the enterprise domain, persist or access data in some form. Relational databases are still by far the most used persistence mechanism even though they are being challenged by technologies such as NoSQL databases. This article explores some concepts for data access and looks at how the new\nJakarta Data specification\nmakes data access simpler than ever for application developers.\nData persistence\nI begin this discussion by reviewing persistence concepts. If you are familiar with these concepts, feel free to skip this part and dive right into the next section, which contains sample code.\nCRUD.\nThe most common operations used in applications that persist data are create, read, update, and delete (CRUD) operations. CRUD operations are commonly associated with relational databases but can be applied to any persistence mechanisms. Writing code for these operations is usually repetitive work consisting mostly of boilerplate code.\nORM.\nObject-relational mapping (ORM), as the name suggests, takes care of mapping objects in an object-oriented language to data in a relational database. There are numerous ORM frameworks available to help developers with this task.\nJakarta Persistence\n, previously referred to as\nJPA\n, is a specification that standardizes persistence management and object-relational mapping for Java applications.\nThe Repository pattern.\nThere are several patterns and strategies—such as Data Access Object (DAO), Repository, Active Record, and others—that are commonly used for structuring the code associated with CRUD operations. In this article, I use the Repository pattern.\nThe intention of the Repository pattern (which you can read about in Martin Fowler’s\nPatterns of Enterprise Application Architecture\n) is to keep the specifics regarding persistence outside the application’s domain model. The repositories are classes that encapsulate the data access logic, thus decoupling the persistence mechanism from the domain model.\nThe Repository pattern has become popular and is widely used due to technologies such as\nSpring Data\n; it is no secret that Spring Data is the inspiration for Jakarta Data.\nJakarta Data.\nJakarta Data\nis a new specification proposed to be included in\nJakarta EE 11\n, which is planned to be released in the first half of 2024. By implementing the Repository pattern, Jakarta Data simplifies data access and reduces the amount of boilerplate code needed. Developers only need to define an interface representing the repository and an entity representing the database table. The implementation of Jakarta Data will supply the actual implementation of the repository.\nA simple example with MySQL\nThis very simple example shows how Jakarta Data simplifies persistence for developers by eliminating the need for boilerplate code. The technologies used in this example are\nMySQL 8.0.34\nOpen Liberty 23.0.0.9-beta\nYou will also need to have Apache Maven and a JDK installed on your computer. This code has been verified on Java 20, but other versions may work as well.\nThe example in this code uses Open Liberty as the runtime. However, when there is another implementation available, you should be able to replace Open Liberty with the other implementation without changing any code.\nStep 1.\nVerify that Apache Maven and a JDK are installed. You should see something such as the following:\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\n$ mvn --version\nApache Maven 3.8.2 (ea98e05a04480131370aa0c110b8c54cf726c06f)\nMaven home: /home/ivar/.sdkman/candidates/maven/current\nJava version: 20.0.1, vendor: Eclipse Adoptium, runtime: /home/ivar/.sdkman/candidates/java/20.0.1-tem\nDefault locale: en_US, platform encoding: UTF-8\nStep 2.\nInstall and set up MySQL after downloading it directly from\nhttps://www.mysql.com/\nor by using your favorite package manager. Here is an example of how to do it if you are using Ubuntu.\n$ sudo apt-get install mysql-server\nStep 3.\nLog in to MySQL Shell.\nsudo mysql -u root\nStep 4.\nCreate a database and user.\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nmysql> create database dukes_data;\nmysql> use dukes_data;\nmysql> create user 'duke'@'localhost' identified by 'duke';\nmysql> grant all privileges on dukes_data to 'duke'@'localhost';\nStep 5.\nGet the code from my\nGitHub repository\n, and then compile and run it with Maven.\n$ mvn liberty:run\nThe application is now ready to try out.\nStep 6.\nThree endpoints are available.\nList all greetings (GET)\nSearch for a greeting by greeter name (GET)\nAdd a greeting (POST)\nHere’s how they work.\nTo list all greetings, use the following:\nhttp://localhost:9080/dukes-data/api/greetings/\nThe following is the expected response because there’s no data yet:\n[]\nTo search for Duke’s greeting, use the following:\nhttp://localhost:9080/dukes-data/api/greetings/duke\nSimilarly, because there’s no data yet, here’s the response.\nduke not found\nTo add Duke’s greeting, use this.\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\n$ echo -n '{\"message\":\"Hello from Duke\", \"name\":\"Duke\"}' | http post :9080/dukes-data/api/greetings\nTo list all greetings again, use this.\nhttp://localhost:9080/dukes-data/api/greetings/\nHere’s the expected response.\n[\n{\nid: 1,\nmessage: \"Hello from Duke\",\nname: \"Duke\"\n}\n]\nFinally, to search for Duke’s greeting again, use the following:\nhttp://localhost:9080/dukes-data/api/greetings/duke\nThe expected response is\nHello from Duke\nThe example code\nThe application consists of four classes: GreetingApplication, GreetingResource, Greeting, and GreetingRepository.\nGreetingApplication configures the Jakarta REST application. In this case, the only thing needed is the application path.\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\npackage dukes.data;\n\nimport jakarta.ws.rs.ApplicationPath;\nimport jakarta.ws.rs.core.Application;\n\n@ApplicationPath(\"/api\")\npublic class GreetingApplication extends Application {\n}\nGreetingResource exposes the three API methods for retrieving all greetings, retrieving one greeting, and adding a greeting.\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\npackage dukes.data;\n\nimport jakarta.inject.Inject;\nimport jakarta.validation.Valid;\nimport jakarta.ws.rs.*;\nimport jakarta.ws.rs.core.MediaType;\nimport jakarta.ws.rs.core.Response;\n\nimport java.util.List;\n\n@Path(\"/greetings\")\npublic class GreetingResource {\n\n@Inject\nprivate GreetingRepository greetingRepository;\n\n@GET\n@Path(\"/{name}\")\n@Produces(MediaType.TEXT_PLAIN)\npublic String findOne(@PathParam(\"name\") String name) {\n\nreturn greetingRepository.findByNameIgnoreCase(name)\n.map(Greeting::getMessage)\n.orElse(name + \" not found\");\n}\n\n@GET\n@Produces(MediaType.APPLICATION_JSON)\npublic List<Greeting> findAll() {\n\nreturn greetingRepository.findAll()\n.toList();\n}\n\n@POST()\n@Consumes(MediaType.APPLICATION_JSON)\npublic Response addGreeting(Greeting greeting) {\n\nGreeting saved = greetingRepository.save(greeting);\nreturn Response.ok(\"Created greeting: \" + greeting.getId()).build();\n}\n}\nThe Greeting class defines the entity that is being persisted in the database. It is a Jakarta Persistence entity with three fields. The\n@Entity\nannotation identifies it as a Jakarta Persistence entity, and the\n@Id\nand\n@GeneratedValue\nannotations define the primary key as well as how it should be generated. Other than that, it is just a plain old Java object.\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\npackage dukes.data;\n\nimport jakarta.persistence.Entity;\nimport jakarta.persistence.GeneratedValue;\nimport jakarta.persistence.GenerationType;\nimport jakarta.persistence.Id;\n\n@Entity\npublic class Greeting {\n\n@Id\n@GeneratedValue(strategy = GenerationType.AUTO)\nprivate Long id;\nprivate String name;\nprivate String message;\n\n// constructor/getters/setters\n}\nThe GreetingRepository is where things get interesting. It is a simple interface that extends CrudRepository and is annotated with\n@Repository\n. This information is enough for the Jakarta Data implementation to generate methods for all the CRUD operations as well as a couple of other convenience methods, such as count, existsById, and various finders.\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\npackage dukes.data;\n\nimport jakarta.data.repository.CrudRepository;\nimport jakarta.data.repository.Repository;\n\nimport java.util.Optional;\n\n@Repository\npublic interface GreetingRepository extends CrudRepository<Greeting, Long> {\n\nOptional<Greeting> findByNameIgnoreCase(String name);\n}\nThe only method defined by the developer is findByNameIgnoreCase. As the name implies, this method searches the database for rows with the provided name. Jakarta Data will generate a method that does exactly that.\nConclusion\nJakarta Data is a very interesting addition to Jakarta EE. It increases developer productivity and code quality by relieving developers from writing error-prone boilerplate code. When Jakarta Data is finalized, it will be available in all products compatible with the Jakarta EE 11 platform.\nJakarta Data and Jakarta Persistence are totally oblivious to the underlying persistence mechanism, so any relational database can be used. In this example, MySQL was used. There are several reasons why MySQL has been popular for a long time and is still one of the most popular databases. For example, it is available freely as open source on a wide range of platforms, it is easy to install and get started with, and documentation and resources are available online. If needed, commercial options are also available.\nAs you can see,\nJakarta Data\nspecifies a comprehensive language and annotations for creating query methods with a wide range of sorting options. Please check it out and provide feedback to the project working on it.\nDig deeper\nFast data access in Java with the Helidon microservices platform\nTransition from Java EE to Jakarta EE\nArquillian: Easy Jakarta EE Testing\nRepository pattern in\nJava Magazine\n’s May/June 2018 issue, page 27"
  },
  {
    "title": "Virtual threads: Are futures a thing of the past?",
    "link": "https://blogs.oracle.com/javamagazine/virtual-threads-futures",
    "source": "Oracle_blog",
    "main_ideas": [
      "Java 21 introduces virtual threads, changing how threading is managed in applications.",
      "Virtual threads may reduce the need for futures, but both can coexist in programming.",
      "The evolution of threading models shows a shift from imperative to functional programming styles."
    ],
    "tags": [
      "java",
      "virtual-threads",
      "futures",
      "concurrency",
      "programming",
      "thread-pools",
      "functional-programming",
      "software-development"
    ],
    "original_text": "See how modern threading differs from concepts such as thread pools and futures.\nJava—and, more generally, the JVM—is in the process of introducing\nvirtual threads\n, which officially debut as part of Java 21’s\nJEP 444\n.\nVirtual threads and futures are heavily discussed among developers, with opinions that range from “Virtual threads will obviate the need for futures” to “You can’t count things such as futures out yet.”\nTo help clarify this point, I’ll discuss several implementations of the same simple server, from Prehistoric (simple or no threads) to Ancient Times (thread pools) to the Middle Ages (futures) to the Renaissance Age (callbacks) to the Modern Age (virtual threads).\nThe goal is to help convey what virtual threads are for, what futures are for, and how virtual threads and futures may (or may not) coexist.\nThe examples are written in Java 21 (early access), but all the exception handling code (and dealing with failures in general) has been omitted for the sake of simplicity. That’s not because exception handling is unimportant: Failure handling is hard in general, and it’s harder still with concurrent programs. Other Java projects, such as\nstructured concurrency (JEP 453)\n, are specifically focused on this.\nPrehistoric: Simple threads\nA student of mine once wrote a service in which users would indicate details of an upcoming trip and receive a custom-made response with information related to the place and time of the trip.\nUsing this service as an inspiration, imagine a server that parses trip data from a request; fetches weather information, restaurant recommendations, and theater schedules from three separate services; and then assembles the combined information into a customized page, as shown in\nListing 1\n.\nListing 1.\nSequential server\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\npublic class Server {\nprivate final ServerSocket server = new ServerSocket(port);\n\npublic void run() {\nwhile (!server.isClosed()) {\nvar socket = server.accept();\nhandleRequest(socket);\n}\n}\n\nvoid handleRequest(Socket socket) {\nvar request = new Request(socket); // parse a request\nvar page = new Page(request); // create a base page\npage.setWeather(Weather.fetch(request)) // add weather info to the page\n.setRestaurants(Restaurants.fetch(request)) // add restaurant info to the page\n.setTheaters(Theaters.fetch(request)). // add theater info to the page\n.send(); // send the page back as a response\n}\n}\nThis server is purely sequential and uses a single thread that does everything. The thread is first blocked on\naccept\n, listening for connections; after a connection is established, all the handling work is performed by that thread before it can go back to waiting for more connections.\nAssume that the durations of the successive steps are as follows:\nParse a request (\nnew Request(socket)\n): 100 milliseconds\nBuild a base page (\nnew Page(request)\n): 100 milliseconds\nFetch the weather (\nWeather.fetch(request)\n): 500 milliseconds\nFetch the restaurants (\nRestaurants.fetch(request)\n): 300 milliseconds\nFetch the theaters (\nTheaters.fetch(request)\n): 200 milliseconds\nIf three requests arrive at the same time, it will take 3.6 seconds to fulfill them at 1.2 seconds per request.\nThe first thing you might want to do is handle multiple connections in parallel. A simple but old-fashioned way to achieve this is to create and start a new thread with each incoming connection, as shown in\nListing 2\n.\nListing 2.\nParallel server, sequential data fetching\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\npublic void run() {\nwhile (!server.isClosed()) {\nvar socket = server.accept();\nnew Thread(() -> handleRequest(socket)).start();\n}\n}\nThe thread that calls\naccept\ncreates and starts a new thread to handle the connection and quickly goes back to accepting more connections. That’s all it does—it’s traditionally called the\nlistening thread\n.\nThe handleRequest method is left unchanged, but it’s now executed in parallel by multiple threads, each handling their connection. The computation time of the previous example goes from 1.2 + 1.2 + 1.2 = 3.6 seconds to max(1.2, 1.2, 1.2) = 1.2 seconds. Of course, that’s assuming no overhead, which is an oversimplification. (This article is actually in large part about overhead.)\nThis is all nice and easy because requests from separate users are completely independent. A more interesting problem is, within a single request, to fetch the weather, restaurant, and theater information in parallel. This can be achieved by creating more threads within the handleRequest method, as shown in\nListing 3\n.\nListing 3.\nParallel data fetching using 4\nn\nthreads on demand\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nvoid handleRequest(Socket socket) {\nvar request = new Request(socket);\nvar page = new Page(request);\n\nThread t1 = new Thread(() -> page.setWeather(Weather.fetch(request)));\nThread t2 = new Thread(() -> page.setRestaurants(Restaurants.fetch(request)));\nThread t3 = new Thread(() -> page.setTheaters(Theaters.fetch(request)));\nt1.start(); t2.start(); t3.start();\n\nt1.join(); t2.join(); t3.join();\npage.send();\n}\nAfter a request is parsed and a base page is set up, three helper threads are created: one to fetch the weather, one to fetch the restaurants, and one to fetch the theaters. The three threads are then started and begin to execute their code in parallel.\nThe\njoin\nmethod is a\nblocking\nmethod that waits for a thread to terminate.\nAfter all three of the helper threads are terminated, the connection-handling thread sends the fully assembled page back, and the time to process a request becomes 0.1 + 0.1 + max(0.5, 0.3, 0.2) = 0.7 seconds.\nThis is a pattern sometimes known as\nfork/join\nor\nscatter/gather\n.\nNote that the page needs to be created before the threads are started, and this page needs to be\nthread-safe\n, because the setWeather, setRestaurants, and setTheaters methods are potentially called concurrently (and presumably could each modify the page).\nThis is an important point, and their setting methods will need to use proper synchronization (such as locks) to make sure the threads don’t interfere with each other in unwanted ways.\nBesides the need for the page to be thread-safe, the main drawback with this approach is uncontrolled and inefficient thread creation. The problem is twofold.\nThere is no upper bound on the number of threads that might be created:\nn\nsimultaneous connections (or connections that are “close enough” in time) could create as many as 4\nn\nthreads.\nThreads are not reused: A thread is created for a single purpose, it’s terminated, and a new one is created next.\nThis results in a suboptimal use of resources because thread creation and teardown are time-consuming, and too many threads running together can be detrimental to performance.\nAn easy place to economize is to eliminate one thread per request. Instead of doing nothing while the three helpers do their work, the connection-handling thread could participate and complete one of the three tasks (such as fetching the theater information) by itself, as shown in\nListing 4\n.\nListing 4.\nParallel data fetching using 3\nn\nthreads on demand\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nvoid handleRequest(Socket socket) {\nvar request = new Request(socket);\nvar page = new Page(request);\n\nThread t1 = new Thread(() -> page.setWeather(Weather.fetch(request)));\nThread t2 = new Thread(() -> page.setRestaurants(Restaurants.fetch(request)));\nt1.start(); t2.start();\n\npage.setTheaters(Theaters.fetch(request));\n\nt1.join(); t2.join();\npage.send();\n}\nThat’s better—3\nn\nthreads instead of 4\nn\n—but it’s still unnecessarily wasteful of threads. A better approach is to pool generic worker threads together and rely on them as tasks occur. (An important point to remember is this: Thread pools were introduced because threads are expensive; when threads become cheaper, the need for pooling decreases.)\nFor the remainder of this article, and for the sake of clarity, I will treat the three fetching tasks homogeneously, even at the cost of an extra thread. Don’t worry: By the end of the article, the project will have eliminated blocking and unnecessary threads entirely, and this choice will not make any difference.\nAncient Times: Thread pools\nA thread-pool variant of the server can be written as shown in\nListing 5\n. It’s not a good way to write it, however.\nListing 5.\nParallel data fetching using a thread pool (incorrect; don’t do this)\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\npublic class Server { // DON'T DO THIS!\nprivate final ServerSocket server = new ServerSocket(port);\nprivate final ExecutorService exec = Executors.newFixedThreadPool(16);\n\npublic void run() {\nwhile (!server.isClosed()) {\nvar socket = server.accept();\nexec.execute(() -> handleRequest(socket));\n}\nexec.close();\n}\n\nvoid handleRequest(Socket socket) {\nvar request = new Request(socket);\nvar page = new Page(request);\nvar done = new CountDownLatch(3);\n\nexec.execute(() -> {\npage.setWeather(Weather.fetch(request));\ndone.countDown();\n});\n\nexec.execute(() -> {\npage.setRestaurants(Restaurants.fetch(request));\ndone.countDown();\n});\n\nexec.execute(() -> {\npage.setTheaters(Theaters.fetch(request));\ndone.countDown();\n});\n\ndone.await();\npage.send();\n}\n}\nA thread pool, which can contain as many as 16 threads, is created. The server will never use more than 17 threads—one listener and 16 workers—and these threads will be reused across connections.\nThat’s the good news, but there’s bad news as well.\nThe first bad news is that the implementation becomes more complicated.\nA call to\nexec.execute(task)\ndispatches a task to the thread pool and lets it run (\nfire-and-forget\n). This is perfect for the listening thread to run independent connection-handling tasks, but it’s not so good with the connection-handling code. Therefore, the server still needs to wait for the weather, restaurant, and theater fetching tasks to finish before sending the page.\nThis is the reason for the countdown latch, whose\nawait\nmethod blocks the connection handling thread until\ncountdown\nhas been called three times: once each by the weather, restaurant, and theater fetching tasks. After that, the complete page can be sent.\nThe second (and worse) bad news is that this implementation does not work: It is\ndeadlock\nprone and might end up in a state in which all the threads in the pool are waiting for each other.\nThis will happen if all the worker threads are used for connection-handling tasks. In that case, all the fetching tasks will be stuck in the queue of the thread pool (waiting for a thread), unable to execute their code and, thus, the necessary\ncountdown\ncalls. Therefore, the worker threads will then be blocked forever on their calls to\nawait\n.\nDeadlocks are not the focus of this article—for that, see Cay Horstmann’s “\nSynchronization in Java, Part 3: Atomic operations and deadlocks\n”—though they are something to be aware of the moment tasks start waiting for other tasks. It’s important to resolve the deadlock issue before continuing. This can be achieved by introducing a second thread pool, as shown in\nListing 6\n.\nListing 6.\nParallel data fetching using two thread pools (deadlock-free)\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\npublic class Server {\nprivate final ServerSocket server = new ServerSocket(port);\nprivate final ExecutorService exec1 = Executors.newFixedThreadPool(4);\nprivate final ExecutorService exec2 = Executors.newFixedThreadPool(12);\n\npublic void run() {\nwhile (!server.isClosed()) {\nvar socket = server.accept();\nexec1.execute(() -> handleRequest(socket));\n}\nexec1.close();\nexec2.close();\n}\n\nvoid handleRequest(Socket socket) {\nvar request = new Request(socket);\nvar page = new Page(request);\nvar done = new CountDownLatch(3);\n\nexec2.execute(() -> {\npage.setWeather(Weather.fetch(request));\ndone.countDown();\n});\n\nexec2.execute(() -> {\npage.setRestaurants(Restaurants.fetch(request));\ndone.countDown();\n});\n\nexec2.execute(() -> {\npage.setTheaters(Theaters.fetch(request));\ndone.countDown();\n});\n\ndone.await();\npage.send();\n}\n}\nConnection-handling threads run in the exec1 pool while the weather, restaurant, and theater fetching tasks run in a separate exec2 pool.\nThis way, tasks never wait on other tasks\nrunning in the same pool\n, and the risk of deadlocks is avoided. (Note that the thread pools here are sized rather arbitrarily. Sizing for best performance is a hard problem. The nonblocking approaches described later alleviate this difficulty.)\nWith deadlocks out of the way, it’s time to deal next with the issue of code complexity, namely the fact that pages have to be thread-safe and the use of a latch. Both are solved by switching to a more functional view of computing that’s centered on futures.\nMiddle Ages: Futures\nThe servers you’ve encountered thus far are very imperative in style: Threads do things, they act on a shared page, and they modify it. A better approach uses futures.\nFutures are a standard Java abstraction that allows concurrent code to shift to a more functional flavor in which threads run\nfunctions\nand produce\nvalues\n, while combining the synchronization capabilities of the latch mechanism used earlier.\nEssentially, a future represents an asynchronously running function and offers mechanisms for threads to wait for the output of the function.\nAs an example, consider the following stars function, which produces a string of stars but is artificially slowed down to take as many seconds as there are stars:\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nstatic String stars(int count) {\nTimeUnit.SECONDS.sleep(count);\nreturn \"*\".repeat(count);\n}\nThis function can be used to create a future of type\nCompletableFuture<String>\n. Creation of the future takes very little time and the (slow) building of the string runs asynchronously in a separate thread, as shown in\nListing 7\n.\nListing 7.\nFutures as asynchronously running functions\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nCompletableFuture<String> future = CompletableFuture.supplyAsync(() -> stars(3));\nfuture.isDone(); // false\nfuture.state(); // RUNNING\nString str1 = future.join(); // blocks, then \"***\" after 3 seconds\nfuture.isDone(); // true\nString str2 = future.join(); // \"***\", immediately\nThe\njoin\nmethod serves a dual purpose: It blocks a calling thread until the future is completed (synchronization) and returns the value produced by the asynchronous task. If a future is completed, the\njoin\nmethod returns immediately.\nIn the server example, the weather, restaurant, and theater fetching tasks can be represented as futures, while page construction still takes place in the connection-handling thread, as shown in\nListing 8\n.\nListing 8.\nParallel data fetching using futures and blocking synchronization\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nvoid handleRequest(Socket socket) {\nvar request = new Request(socket);\nvar futureWeather = CompletableFuture.supplyAsync(() -> Weather.fetch(request), exec2);\nvar futureRestaurants = CompletableFuture.supplyAsync(() -> Restaurants.fetch(request), exec2);\nvar futureTheaters = CompletableFuture.supplyAsync(() -> Theaters.fetch(request), exec2);\n\nnew Page(request)\n.setWeather(futureWeather.join())\n.setRestaurants(futureRestaurants.join())\n.setTheaters(futureTheaters.join())\n.send();\n}\nGiven the durations used in this article (and assuming enough threads are available in exec2 to run all tasks),\nnew Request(socket)\ntakes 0.1 seconds, then\nnew Page(request)\ntakes 0.1 seconds, then\nfutureWeather.join()\nblocks for 0.4 seconds, and\nfutureRestaurants.join()\nand\nfutureTheaters.join()\nreturn immediately.\nThe base page is prepared by the connection-handling thread in parallel with the fetching tasks (which no longer need the page). The time to process a request goes down from 0.1 + 0.1 + max(0.5, 0.3, 0.2) = 0.7 seconds to 0.1 + max(0.1, 0.5, 0.3, 0.2) = 0.6 seconds.\nThe order in which the three futures are joined doesn’t matter, and the following variant would work just as well:\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nnew Page(request)\n.setRestaurants(futureRestaurants.join())\n.setTheaters(futureTheaters.join())\n.setWeather(futureWeather.join())\n.send();\n}\nThe first call to\njoin\nwould block for 0.2 seconds, the second call would proceed immediately, and the third call would block for another 0.2 seconds. The overall duration would remain unchanged: 0.1 + 0.1 + 0.2 + 0.2 = 0.6 seconds.\nThe implementation of the server is fairly straightforward: Simply create a future for any part of the computation that needs to run asynchronously. This approach pools threads for reuse, avoids the latch (futures implement their own synchronization), and, importantly, the page is created and populated by a single thread and\ndoes not need to be thread-safe\nanymore.\nUp until recently, this would have been considered a perfectly reasonable implementation. However, the fact that threads are\nblocked\non the\njoin\nmethod while waiting for futures to be completed remains problematic in two ways.\nThis blocking invites the possibility of deadlocks. The issue was addressed here by using two separate thread pools. On larger, more complex systems, however, the problem can become quite tricky. Multiplying pools or increasing pool sizes to guarantee the absence of deadlocks tends to result in a large number of threads which, when they are\nnot\nblocked, lead to a suboptimal usage of computing resources.\nBlocking and unblocking threads, even in the best of scenarios, has a nonnegligible cost. The actual parking and unparking of threads by the operating system take time. Furthermore, parked threads tend to see their data in processor-level caches overwritten by other threads, resulting in cache misses when the threads resume execution.\nAccordingly, techniques were devised to minimize thread blocking—ideally, to avoid it entirely.\nRenaissance Age: Callbacks\nOne of the oldest strategies is the idea of a\ncallback\n. Instead of waiting for the result of a future, which requires blocking, the developer specifies, as a callback, the computation that will use this result. The server can be rewritten using callbacks, as shown in\nListing 9\n.\nListing 9.\nParallel data fetching using futures and callbacks\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\npublic class Server {\nprivate final ServerSocket server = new ServerSocket(port);\nprivate final ExecutorService exec = Executors.newFixedThreadPool(16);\n\npublic void run() {\nwhile (!server.isClosed()) {\nvar socket = server.accept();\nexec.execute(() -> handleRequest(socket));\n}\nexec.close();\n}\n\nvoid handleRequest(Socket socket) {\nvar request = new Request(socket);\n\nvar futureWeather = CompletableFuture.supplyAsync(() -> Weather.fetch(request), exec);\nvar futureRestaurants = CompletableFuture.supplyAsync(() -> Restaurants.fetch(request), exec);\nvar futureTheaters = CompletableFuture.supplyAsync(() -> Theaters.fetch(request), exec);\n\nvar page = new Page(request);\n\nfutureWeather.thenAccept(weather ->\nfutureRestaurants.thenAccept(restaurants ->\nfutureTheaters.thenAccept(theaters ->\npage.setWeather(weather)\n.setRestaurants(restaurants)\n.setTheaters(theaters)\n.send())));\n}\n}\nThe future thenAccept method takes as its argument the code that will consume the output of the future.\nNote that the invocation of thenAccept only registers this code for later execution; it does not wait for the future to be completed and, thus, it takes very little time. The actual page building will run later, in the thread pool, after the weather, restaurant, and theater information is available. As a result, a single request is processed in 0.6 seconds as before.\nThreads are never blocked in this server, and a single, reasonably sized pool can be used. The code above is free from deadlocks for any pool size. Indeed, setting exec as a single-thread pool would result in a sequential server, like the server in\nListing 1\n, but would not cause any deadlock.\nCallbacks are notoriously hard to write and even harder to debug. You may have noticed that, in the simple illustration used in\nListing 9\n, thenAccept calls are nested three levels deep. Fortunately, modern futures offer other mechanisms to process their value in a nonblocking fashion. In Java, a thenCombine method can be used to combine the results of two futures using a two-argument function, as shown in\nListing 10\n.\nListing 10.\nParallel data fetching using futures and functional composition\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nvoid handleRequest(Socket socket) {\nvar request = new Request(socket);\n\nvar futureWeather = CompletableFuture.supplyAsync(() -> Weather.fetch(request), exec);\nvar futureRestaurants = CompletableFuture.supplyAsync(() -> Restaurants.fetch(request), exec);\nvar futureTheaters = CompletableFuture.supplyAsync(() -> Theaters.fetch(request), exec);\n\nCompletableFuture.completedFuture(new Page(request))\n.thenCombine(futureWeather, Page::setWeather)\n.thenCombine(futureRestaurants, Page::setRestaurants)\n.thenCombine(futureTheaters, Page::setTheaters)\n.thenAccept(Page::send);\n}\nThe handling thread creates a base page, as before, but wraps it in a future so that thenCombine can be called to set the weather information, and then it calls again with the restaurants and theaters. Finally, a callback is used to send the page back.\nNone of this code is blocking. Pool threads jump from weather, restaurant, and theater information fetching to page building and page sending, performing tasks as they become available, even across separate requests.\nIn this case, the only actual processing that the connection-handling thread performs is the building of a base page. This could also be run asynchronously in the thread pool, leaving the connection-handling thread with nothing to do other than register the callback computations, as shown in\nListing 11\n.\nListing 11.\nFully asynchronous data fetching using futures\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\npublic class Server {\nprivate final ServerSocket server = new ServerSocket(port);\nprivate final ExecutorService exec = Executors.newFixedThreadPool(16);\n\npublic void run() {\nwhile (!server.isClosed()) {\nvar socket = server.accept();\nhandleRequest(socket);\n}\nexec.close();\n}\n\nvoid handleRequest(Socket socket) {\nvar futureRequest = CompletableFuture.supplyAsync(() -> new Request(socket), exec);\n\nvar futureWeather = futureRequest.thenApplyAsync(Weather::fetch, exec);\nvar futureRestaurants = futureRequest.thenApplyAsync(Restaurants::fetch, exec);\nvar futureTheaters = futureRequest.thenApplyAsync(Theaters::fetch, exec);\n\nfutureRequest\n.thenApplyAsync(Page::new, exec)\n.thenCombine(futureWeather, Page::setWeather)\n.thenCombine(futureRestaurants, Page::setRestaurants)\n.thenCombine(futureTheaters, Page::setTheaters)\n.thenAccept(Page::send);\n}\n}\nThe base page is created in the thread pool, as a callback of futureRequest, using thenApplyAsync. The handleRequest does nothing but register callbacks. It runs quickly and can even be executed by the listening thread; handleRequest is called directly from within\nrun\n, without using the thread pool.\nNote: For robustness, the developer should make sure that the listening thread is not killed by an unhandled failure within handleRequest. In practice, it might still be worth dispatching the call to a separate thread pool, for instance a single-thread pool such as\nExecutors.newSingleThreadExecutor\nthat replaces its thread if it terminates abruptly.\nHigher-order methods on futures are not the only way to coordinate concurrent tasks without blocking threads. Java’s ForkJoinPool, Go and Kotlin’s coroutines, and Akka’s actors, for instance, all have ways for a task to wait for the result of another task without blocking a thread.\nThe newest member of this family is the JVM virtual thread, which becomes an official reality in Java 21. The Modern Age has begun.\nModern Age: Virtual threads\nJava’s virtual threads are lightweight threads that are created and scheduled by the JVM itself. That’s in contrast to standard threads, which are created and scheduled by the operating system (OS).\nVirtual threads run by mounting an actual OS thread. When blocked, they unmount their OS thread, leaving it free to run the code of other virtual threads.\nListing 12\nshows how to write the example server using virtual threads.\nListing 12.\nParallel data fetching using virtual threads\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\npublic class Server {\nprivate final ServerSocket server = new ServerSocket(port);\n\npublic void run() {\nwhile (!server.isClosed()) {\nvar socket = server.accept();\nThread.startVirtualThread(() -> handleRequest(socket));\n}\n}\n\nvoid handleRequest(Socket socket) {\nvar request = new Request(socket);\nvar page = new Page(request);\n\nThread t1 = Thread.startVirtualThread(() -> page.setWeather(Weather.fetch(request)));\nThread t2 = Thread.startVirtualThread(() -> page.setRestaurants(Restaurants.fetch(request)));\nThread t3 = Thread.startVirtualThread(() -> page.setTheaters(Theaters.fetch(request)));\n\nt1.join(); t2.join(); t3.join();\npage.send();\n}\n}\nContrast\nListing 12\nwith the following code (shown previously in\nListing 3\n), which was the first parallel version in this article and used OS threads:\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nvoid handleRequest(Socket socket) {\nvar request = new Request(socket);\nvar page = new Page(request);\n\nThread t1 = new Thread(() -> page.setWeather(Weather.fetch(request)));\nThread t2 = new Thread(() -> page.setRestaurants(Restaurants.fetch(request)));\nThread t3 = new Thread(() -> page.setTheaters(Theaters.fetch(request)));\nt1.start(); t2.start(); t3.start();\n\nt1.join(); t2.join(); t3.join();\npage.send();\n}\nThe two handleRequest methods look strikingly similar, but the version with virtual threads does not entail any OS-level blocking.\nWhen a virtual thread invokes\njoin\non a thread that is still running, it does not block the underlying OS thread, which continues to run other virtual threads. In effect, the OS threads jump from code to code—as in\nListing 9\n,\nListing 10\n, and\nListing 11\n—when using higher-order methods on futures, and they do so in a familiar programming style. Because they are lightweight, virtual threads are also cheap to create and don’t need to be pooled.\nFutures and promises.\nOne drawback of writing the server this way is that the base page must be thread-safe again and needs to be constructed first, before the fetching tasks are started.\nThis can be avoided by bringing back futures—but having the futures run by virtual threads. Conceptually, a future is created out of a\npromise\n, which represents its yet-to-come value.\nFutures and promises are two sides of the same coin. The terminology is somewhat ambiguous. Some languages, such as JavaScript, tend to refer to their futures as promises while others, such as Java, denote promises as futures instead. Often, the same object is used as a promise in some code and as a future in some other code. A promise is created empty and later given a value. It corresponds to a future, which is incomplete until the promise is fulfilled.\nA variant of the earlier server code from\nListing 7\ncould be written as follows:\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nCompletableFuture<String> promise = new CompletableFuture<>(); // empty promise\n// fulfill the promise later, in another thread:\nnew Thread(() -> promise.complete(stars(3))).start();\nprintln(promise.isDone()); // false\nprintln(promise.state()); // RUNNING\nString str1 = promise.join(); // blocks, then \"***\" after 3 seconds\nprintln(promise.isDone()); // true\nString str2 = promise.join(); // \"***\", immediately\nBy using explicit promises, fulfilled by virtual threads, the server example can be given its functional flavor back, as shown in\nListing 13\n.\nListing 13.\nParallel data fetching using promises and virtual threads\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nvoid handleRequest(Socket socket) {\nvar request = new Request(socket);\n\nvar futureWeather = new CompletableFuture<Weather>();\nvar futureRestaurants = new CompletableFuture<Restaurants>();\nvar futureTheaters = new CompletableFuture<Theaters>();\n\nThread.startVirtualThread(() -> futureWeather.complete(Weather.fetch(request)));\nThread.startVirtualThread(() -> futureRestaurants.complete(Restaurants.fetch(request)));\nThread.startVirtualThread(() -> futureTheaters.complete(Theaters.fetch(request)));\n\nnew Page(request)\n.setWeather(futureWeather.join())\n.setRestaurants(futureRestaurants.join())\n.setTheaters(futureTheaters.join())\n.send();\n}\nThe base page is now created while the fetching tasks are running, and it doesn’t need to be thread-safe. The code is similar to that in\nListing 8\n, which also used\njoin\nto wait for future completion, with the key difference being that\njoin\nis now implemented without blocking an OS thread.\nThis pattern of a promise fulfilled by a virtual thread could be embedded in a custom class. At its simplest—without higher-order methods or any error handling and timeout handling—the code could resemble\nListing 14\n.\nListing 14.\nA simple virtual future\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\npublic class VirtualFuture<A> {\nprivate final CompletableFuture<A> theFuture;\n\npublic VirtualFuture(Supplier<? extends A> task) {\ntheFuture = new CompletableFuture<>();\nThread.startVirtualThread(() -> {\ntry {\ntheFuture.complete(task.get());\n} catch (Exception e) {\ntheFuture.completeExceptionally(e);\n}\n});\n}\n\npublic A join() {\nreturn theFuture.join();\n}\n// export other methods as needed\n}\nUsing this virtual future, the final version of the server would be as shown in\nListing 15\n.\nListing 15.\nParallel data fetching using virtual futures\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nvoid handleRequest(Socket socket) {\nvar request = new Request(socket);\n\nvar futureWeather = new VirtualFuture<>(() -> Weather.fetch(request));\nvar futureRestaurants = new VirtualFuture<>(() -> Restaurants.fetch(request));\nvar futureTheaters = new VirtualFuture<>(() -> Theaters.fetch(request));\n\nnew Page(request)\n.setWeather(futureWeather.join())\n.setRestaurants(futureRestaurants.join())\n.setTheaters(futureTheaters.join())\n.send();\n}\nContrast this with the following version, shown previously in\nListing 11\n, which used only OS threads but relied on higher-order methods on futures to avoid blocking:\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nvoid handleRequest(Socket socket) {\nvar futureRequest = CompletableFuture.supplyAsync(() -> new Request(socket), exec);\n\nvar futureWeather = futureRequest.thenApplyAsync(Weather::fetch, exec);\nvar futureRestaurants = futureRequest.thenApplyAsync(Restaurants::fetch, exec);\nvar futureTheaters = futureRequest.thenApplyAsync(Theaters::fetch, exec);\n\nfutureRequest\n.thenApplyAsync(Page::new, exec)\n.thenCombine(futureWeather, Page::setWeather)\n.thenCombine(futureRestaurants, Page::setRestaurants)\n.thenCombine(futureTheaters, Page::setTheaters)\n.thenAccept(Page::send);\n}\n}\nPerformance-wise, both versions are equivalent—OS threads are reused by pooling and are never blocked—but they are written in two very different styles, one more traditional (imperative) and the other more functional.\nAre virtual threads replacing futures?\nIt’s now time to address the question posed in the title of this article.\nYou could use virtual threads to go back to a programming style centered on\nactions\nperformed by threads on shared mutable objects, without the inconvenience of thread pools and the runtime cost of blocking.\nBut is that wise?\nFutures have been used to eliminate blocking, but they also bring a functional flavor to concurrent programming, which has its own benefits. For example, in this server example, benefits include being able to start fetching tasks before building the base page and not having to use a thread-safe page.\nWhen used in a functional-concurrent programming style, futures typically implement a set of standard higher-order methods that enable well-established functional patterns. For instance, one method could eliminate restaurants that are not registered with the service and replace a list that has fewer than five restaurants with a generic ad for takeout, as follows:\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nvar futureFood = futureRestaurants\n.thenApply(Restaurants::checkRegistrations)\n.thenApply(list -> list.size() >= 5 ? list : Restaurants.genericTakeoutAd());\nHere, checkRegistrations is a function that potentially reduces a list of restaurants by removing those that are not registered. In a second stage, the list is kept unchanged if it contains at least five restaurants; otherwise, the list is replaced.\nOf course, the value of such patterns may depend on a developer’s familiarity with functional programming.\nA possible direction might be to design new implementations of futures, based on virtual threads, that combine functional (higher-order methods) and imperative (a nonblocking\njoin\n) programming styles.\nA known weakness of current nonblocking approaches—regardless of whether they are based on futures, actors, or coroutines—is that they can complicate debugging. In particular, thread dumps and stack traces are often useless in this context.\nBy contrast, virtual threads can provide this debugging information directly, in a form familiar to all developers.\nOn the other hand, a current limitation of virtual threads is that they run only on OS threads from the JVM common pool (an instance of ForkJoinPool). This reduces flexibility by forcing all the virtual threads in an application to run in the same pool.\nAs virtual threads evolve, perhaps they will be accompanied by powerful forms of imperative-functional futures and with a more flexible scheduling on separate thread pools.\nSuggested reading\nFor more details, I recommend my own book,\nFunctional and Concurrent Programming: Core Concepts and Features\n, which introduces functional programming concepts from scratch, covers old-fashioned concurrent programming with threads (including synchronization), and discusses functional-concurrent programming with futures.\nYou can also find details in the API documentation of the\nFuture interface\nand the\nimplementing class FutureTask\n(for imperative, blocking futures) as well as the\nCompletionStage interface\nand the\nimplementing class CompletableFuture\n(for functional futures).\nDig deeper\nExploring the design of Java’s new virtual threads\nGoing inside Java 21’s rich, upcoming goodness\nComing to Java 19: Virtual threads and platform threads\nGoing inside Java’s Project Loom and virtual threads"
  },
  {
    "title": "Quiz yourself: Deserializing objects that have a nonserializable ...",
    "link": "https://blogs.oracle.com/javamagazine/java-quiz-deserialization",
    "source": "Oracle_blog",
    "main_ideas": [
      "The EnhancedPerson class can be serialized but has a null name field after deserialization.",
      "Deserialization does not call constructors in serializable aspects of an object.",
      "A private readObject method can validate deserialized objects to maintain integrity."
    ],
    "tags": [
      "java",
      "serialization",
      "deserialization",
      "object-oriented",
      "programming",
      "software-development",
      "legacy-systems",
      "error-handling"
    ],
    "original_text": "What’s correct and what’s not correct about the Java deserialization process?\nMore quiz questions available\nhere\nYou are working to enhance a legacy application, in particular to add serialization support and add more constraints to new business objects. The legacy application class looks like this.\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\npublic class Person {\nprivate String name = null;\npublic Person() {}\npublic Person(String s) {\nname = s;\n}\n}\nYou’ve also added a new application class.\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\npublic class EnhancedPerson extends Person implements Serializable {\npublic EnhancedPerson(String s) {\nsuper(s);\nif (s == null || s.length() == 0) {\nthrow new IllegalArgumentException(\"Invalid name\");\n}\n}\n}\nWhich statement is correct?\nChoose one.\nA.\nThe\nEnhancedPerson\nclass may not participate in serialization because its superclass is not serializable.\nB.\nThe\nEnhancedPerson\nclass may not participate in serialization because it does not have a zero-argument constructor.\nC.\nThe\nEnhancedPerson\nclass can be serialized but cannot be deserialized.\nD.\nImmediately after deserialization, the\nname\nfield of an\nEnhancedPerson\nwill have a null value.\nE.\nThe\nEnhancedPerson\nclass will always throw\nIllegalArgumentException\nduring deserialization.\nAnswer.\nThis question investigates the deserialization process of an object that has a nonserializable parent type. Of course, every object has a nonserializable parent because, even if nothing else were true,\njava.lang.Object\nitself falls into this category.\nThis first observation tells you that option A must be incorrect because a nonserializable parent type is inevitable and, therefore, cannot possibly prevent serialization and deserialization.\nTwo more rules regarding the serialization system are relevant to answering this question.\nWhen a serializable object is deserialized, the nonserializable parent aspects are initialized by calling an accessible zero-argument constructor in the immediate parent that’s not serializable.\nExcept for record types, deserialization does not use any of the constructor or initialization code for the elements of that object hierarchy that are serializable.\nFrom those two points, you can see that option B is incorrect.\nOption C is also incorrect because nothing in the code prevents deserialization. If the zero-argument constructor of\nPerson\nwere\nprivate\n, or if it did not exist, this option would be correct.\nOption D is correct because the name field belongs to the\nPerson\naspect of the\nEnhancedPerson\nobject. Such fields are not part of the serialized information. As noted earlier, when the\nPerson\ninstance is re-created, this is done by calling the zero-argument constructor of\nPerson\n. Because of this, the\nname\nfield will be initialized to null. Of course, this would also be the case if the assignment of null were not present in the code, because the memory allocated for an object is always zeroed before it becomes available for use as the new object.\nRegarding why option E is incorrect, recall that the deserialization process for (nonrecord) classes does not call any constructor in the\nSerializable\naspects of the object. This means that the code in the\nEnhancedPerson\nconstructor that validates the supplied name will not be called; therefore, no exception can be thrown.\nThis discussion raises questions. In the current design, deserialization creates an\nEnhancedPerson\nobject with a null\nname\nfield. The validation in the constructor is clearly intended to make this impossible. There would be aspects to address in restoring this integrity.\nOne aspect would be to ensure that the name field is immutable (the\nPerson\nclass currently has no setters and\nname\nis private, but the class is clearly a skeleton because it has no usable methods). Alternatively, you could ensure that all changes are controlled by the\nEnhancedPerson\nin a way that keeps it valid.\nThe second aspect, which is more relevant to this question, would be to ensure that any\nEnhancedPerson\nobject deserialized from a data stream conforms to the validity rules. This can be accomplished by providing a\nprivate readObject\nmethod. This method allows you to take control of the deserialization process. In the following example, the object is read from the stream using the default mechanism, but then it’s checked to determine if it is valid. If it’s not valid, the exception that’s thrown will cause the deserialization to be abandoned.\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nprivate void readObject(ObjectInputStream ois) throws\nIOException,\nClassNotFoundException {\nois.defaultReadObject();\nif (name == null || name.length() == 0) {\nthrow new InvalidObjectException(\"Invalid name\");\n}\n}\nConclusion.\nThe correct answer is option D.\nRelated quizzes\nQuiz yourself: Deserializing a record object with readObject\nQuiz yourself: Secure serialization and deserialization\nQuiz yourself: Read and write objects by using serialization\nQuiz yourself: Deserialization of Java enum types and records"
  },
  {
    "title": "Quiz yourself: Deserializing objects with readObject",
    "link": "https://blogs.oracle.com/javamagazine/java-quiz-serialize-deserialize-readobject",
    "source": "Oracle_blog",
    "main_ideas": [
      "The readObject method is essential for deserializing objects in Java.",
      "Option A correctly uses pattern matching for instanceof in Java 16.",
      "Understanding type inference and casting is crucial for successful deserialization."
    ],
    "tags": [
      "java",
      "serialization",
      "deserialization",
      "readObject",
      "instanceof",
      "pattern-matching",
      "programming",
      "software-development"
    ],
    "original_text": "You should know how the readObject method works—and when it won’t compile.\nMore quiz questions available\nhere\nGiven the following Person record\nrecord Person(String name) implements Serializable {}\nand the following method fragment\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\ntry (ObjectInputStream in = new ObjectInputStream(new FileInputStream(filename))) {\n... // code here\nSystem.out.println(person.name());\n}\nAssume that the try block is completed with necessary catch blocks and the file contains a serialized Person and opens correctly.\nThe code from which option, when placed where the comment is, properly deserializes the object and allows the rest of the code to work?\nChoose one.\nA.\nvar person = (Person) null;\nif (in.readObject() instanceof Person p) {\nperson = p;\n}\nB.\nvar person = in.readObject();\nC.\nPerson person = null;\nif (in.readObject() instanceof Person) {\nperson = in.readObject();\n}\nD.\nvar person = null;\nObject o = in.readObject();\nif (o instanceof Person) {\nperson = (Person) o;\n}\nAnswer.\nWe will skip over option A for the moment.\nOption B would read the serialized object from the file, but the return type of the readObject method is declared as Object; therefore, var will infer the type of the person variable to be Object too. This means that\nperson.name()\nwill not compile. From this you can see that option B is incorrect.\nOption C is incorrect for two reasons. The semantics of the code would cause the input stream to be read twice, and the result of the first reading operation would be lost. However, there is a more severe problem; as already mentioned, the return type of readObject is Object, and the following assignment to the person variable (which is declared explicitly as being of type Person in this option) would fail unless an explicit cast were added:\nperson = in.readObject(); // assignment fails!\nThe following cast would fix the problem:\nperson = (Person)in.readObject(); // this could work\nOption D is also incorrect. When var is used to declare a local variable (other than a lambda formal parameter), the compiler must be able to decide, unambiguously, the intended type of the variable based on the expression that is assigned for initialization. The null value does not provide type information—it is assignment-compatible with any reference type. So, compilation would fail.\nChanging the declaration to the following would allow option D to work:\nvar person = (Person) null;\nOption A is correct. It uses the newer “pattern matching for instanceof” feature that was added (after several previews) in Java 16 as\nJEP 394\n. The effect is that if the deserialized object is, in fact, assignment-compatible with the Person type, the variable p is declared and initialized with the reference to that object. The scope of p is such that it’s usable only in the parts of the code where it has definitely been initialized. For example, if there were an\nelse\nclause on the\nif\nstatement, p would be out of scope in that\nelse\nclause.\nConclusion.\nThe correct answer is option A.\nRelated quizzes\nQuiz yourself: Java’s scope of variables and instanceof for pattern matching\nQuiz yourself: Read and write objects by using serialization\nQuiz yourself: Secure serialization and deserialization"
  },
  {
    "title": "Quiz yourself: Collectors, comparators, and type inferencing in Java",
    "link": "https://blogs.oracle.com/javamagazine/java-quiz-collectors-comparators",
    "source": "Oracle_blog",
    "main_ideas": [
      "The article discusses finding the most-frequently used word in a Java Stream.",
      "It evaluates different pipeline expressions for counting word occurrences.",
      "Options A and E are identified as correct implementations for the task."
    ],
    "tags": [
      "java",
      "streams",
      "collectors",
      "programming",
      "type-inferencing",
      "generics",
      "software-development",
      "coding-quiz"
    ],
    "original_text": "You need to find the most-frequently used word in a stream. Where do you start?\nMore quiz questions available\nhere\nYour colleague is working on an application that must find a most-frequently used word in a\nStream<String>\n, and each element of that stream is a single word. The stream is provided by the reference\nstrm\n.\nWhich of these pipeline expressions can perform this task?\nChoose two.\nA.\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nstrm.collect(Collectors.groupingBy(Function.identity(),\nCollectors.counting())).entrySet().stream().sorted((e1,\ne2)-> e2.getValue().compareTo(e1.getValue())).findFirst()\nB.\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nstrm.collect(Collectors.groupingBy((String s) -> s,\nCollectors.counting())).entrySet().stream().sorted(\nMap.Entry.comparingByValue()).findFirst()\nC.\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nstrm.collect(Collectors.groupingBy(a -> a,\nCollectors.counting())).entrySet().stream().sorted(\nMap.Entry::comparingByValue).findFirst()\nD.\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nstrm.collect(Collectors.groupingBy(Function.identity(),\nCollectors.counting())).entrySet().stream().sorted((e1,\ne2)-> e2.getValue() - e1.getValue()).findFirst()\nE.\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nstrm.collect(Collectors.groupingBy(___ -> ___,\nCollectors.counting())).entrySet().stream().max(Comparator.\ncomparing(e -> e.getValue()))\nAnswer.\nThis question investigates aspects of the Collectors utilities, ordering using a Comparator, type conversion rules, and type inferencing in Java’s generics system.\nAll but one of the question’s code fragments take the following four-step approach to the problem, with variations in the implementation details:\nStep 1.\nTake each word and use the groupingBy collector to build a map in which each key is a word from the stream, and the value accumulates the number of occurrences of the word in the stream. The groupingBy method is a factory that builds a collector, and in the form used here it takes two arguments. The first derives a key for the resulting map from the object in the stream. In this case, the object in the stream is the word you want to use as the key, so no change is necessary. The second argument is\nCollectors.counting()\n, which is used as a downstream collector that modifies the value stored against the key in the map to be a count of the number of times the key has been seen, instead of being a list of the objects that produced that key.\nStep 2.\nThe code then extracts a stream from that map. The Map interface cannot directly provide a Stream, but it provides access to a\nSet<Map.Entry>\nusing the entrySet method. A\nMap.Entry<K, V>\nis a single key-value pair (a tuple of K and V, essentially, although Java does not provide tuples at a language syntax level). A Set does allow drawing a Stream directly, which is the next step.\nStep 3.\nSort the stream of entries. This must be done in\ndescending order\nof the value part of the entry since that’s the count of occurrences of the word represented in the key.\nStep 4.\nThe reason that descending order is essential is that the final step is to pull the first entry object from the resulting stream using a findFirst method. If the stream were sorted in ascending order, you’d get the least-used word rather than the most-used one. It’s worth noting that if two or more words tie for top place in usage, you’ll get one of them with no control over which one you get. But you can ignore that possibility in this question; notice the specification says, “\na\nmost-frequently used word,” rather than “\nthe\nmost-frequently used word.” Therefore, you don’t need to worry about a tie.\nOption A is a correct implementation of this approach. The first argument to the groupingBy factory method should be a function that takes the stream object and returns the key. As noted, in this situation the key is the same as the stream object, and\nFunction.identity()\nis a factory for a Function object that returns its own argument unchanged. The second argument is the\ncounting\nfactory, and that’s exactly what was described above. Next, the sorting is performed using Comparator explicitly coded as a lambda expression. The effect is to compare the value of the two entry objects, but because the code is written as\ne2 … compareTo … e1\n, the ordering will be reversed and, therefore, descending.\nOption B is incorrect. Although it is syntactically valid, the stream is sorted in\nascending\norder; therefore, it will return an entry with a least-frequently used word. You could correct this code by reversing the ordering of the comparator, as follows:\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nstrm.collect(Collectors.groupingBy((String s) -> s,\nCollectors.counting())).entrySet().stream().sorted(Map.Entry.<String,\nLong>comparingByValue().reversed()).findAny();\nNotice the use of\n<String, Long>\nbefore\ncomparingByValue().reversed()\n. The code fails to compile without this because the Java compiler cannot infer the generic type parameters in this situation. Therefore, this syntax is used to specify the types explicitly.\nAnother difference in the approach taken by option B, which is valid in isolation, is the replacement of\nFunction.identity()\nwith an explicit lambda:\n(String s) -> s\n. This is valid, and in this code has the same effect of returning its argument unchanged. The argument type is redundant, but it is valid because the objects in the stream are of String type.\nOption C also changes\nFunction.identity()\nto an explicit lambda:\na -> a\n. As with option B, this has the same effect and is not a problem.\nLooking at the second argument to groupingBy—the downstream collector—you know this must be an object of Collector type. However,\nMap.Entry::comparingByValue\nis a method reference; if the code were compilable in this location, it would create an object equivalent to a lambda expression such as\nx -> Map.Entry.comparingByValue(x)\n. That would be a Function that\nreturns\na Comparator. However, Function is not valid at this point, because the code needs an actual Comparator object. From this you can see that option C is incorrect.\nOption D is also incorrect. As already mentioned,\nCollectors.counting()\nreturns a collector that counts the number of occurrences of elements. The total is accumulated as a Long. Later in the hand-coded comparator, Long is subtracted from Long, and this gives a Long result (which could, under appropriate conditions, be autounboxed to a long primitive). However, the return type of the comparator’s compare method must be int, and it’s not legal to convert a Long (or even a long) to an int without an explicit cast. The following code includes the necessary cast and would work correctly:\n(e1, e2)-> (int)(e2.getValue() - e1.getValue())\nOption E changes two things. First, it uses an explicit lambda instead of\nFunction.identity()\n. You saw this in two previous examples, but here the variable name is odd. It’s\n___\n(which is a triple underscore) rather than something more normal such as\ns\nor\na\n. It turns out that this is actually a valid identifier in Java. A\nsingle\nunderscore is a reserved keyword (since Java 9), but a leading underscore followed by more characters (even if they’re just more underscores) or an underscore embedded in the middle of a name is legal. It’s worth noting that using a triple underscore as a variable name would likely get some raised eyebrows in a code review, so don’t tell anyone we said it’s a\ngood\nidea. We definitely are\nnot\nsuggesting that it’s anything other than a curiosity!\nAnother difference in this example is the use of the\nmax\nterminal operation rather than ordering followed by findFirst. This works correctly and might be more efficient because it doesn’t require the processing of the second stream to build a structure containing references to all the elements; instead, only a reference to the largest element so far needs to be kept. In any case, option E is correct.\nHere are three interesting side notes.\nFirst: You can read about the difference between\nFunction.identity()\nand\na -> a\nin our earlier quiz “\nQuiz yourself: Mixing and matching Java primitives with generics in a stream\n.”\nSecond: In the case of English, the most-frequently used word is generally “the,” but in any given body of text, that might not be the case. Of course, this quiz’s code could be used to analyze text in any language.\nThird: The stem of the question mentions that the items listed are expressions. As such they’re not complete Java code but must be used in some larger context, perhaps to provide a value to be assigned to a variable or as an argument to a method invocation. However, a general guide for the exam is that if code is valid as shown but incomplete, you should assume there’s enough supporting code around it to allow it to work if it can do so; you’re being asked solely about the validity of what’s shown, not about what you can’t see. The\nJava SE 17 Developer exam (1Z0-829)\nhas a section called “Assume the following” under the expandable tab “Review exam topics.” Among other things, it specifies the following:\nIf sample code does not include package or import statements, and the question does not explicitly refer to these missing statements, then assume that all sample code is in the same package, or import statements exist to support them.\nConclusion.\nThe correct answers are options A and E.\nRelated quizzes\nQuiz yourself: Using collectors\nQuiz yourself: Reductions with Java streams using collectors\nQuiz yourself: Sorting lists by multiple criteria\nQuiz yourself: How private is a Java private inner class?"
  },
  {
    "title": "Unlocking Enterprise Value: From Experimentation to Impact with OCI ...",
    "link": "https://blogs.oracle.com/ai-and-datascience/oci-generative-ai-dac",
    "source": "Oracle_blog",
    "main_ideas": [
      "OCI's Dedicated AI Clusters enable scalable and secure generative AI deployments for enterprises.",
      "DACs provide a fully managed service that enhances compliance and reduces operational burdens.",
      "Organizations can fine-tune models with proprietary data to gain competitive advantages."
    ],
    "tags": [
      "generative-ai",
      "oracle-cloud",
      "dedicated-ai-clusters",
      "enterprise-solutions",
      "data-compliance",
      "cost-efficiency",
      "ai-deployment",
      "cloud-infrastructure",
      "business-outcomes"
    ],
    "original_text": "How OCI’s Generative AI Dedicated AI Clusters (DACs) enable scalable, secure, and cost-efficient generative AI deployments that drive real business outcomes.\nKey Benefits of Dedicated AI Clusters\nIntroduction\nGenerative AI is generating unprecedented excitement, yet many enterprises face a critical challenge:\nhow to move beyond early experiments to deploy generative AI at enterprise scale with confidence and control\n. The reality is that the technology choices organizations make today will determine whether they capture generative AI’s full business potential or get stuck managing unpredictable, costly pilots.\nOCI’s Generative AI\nDedicated AI Clusters (DACs)\noffer a fully managed service solution designed for this next phase of generative AI evolution. Far from being just another cloud offering, DACs are engineered to provide a\nsecure, scalable, and cost-efficient foundation\nthat empowers organizations to turn generative AI innovations into reliable, revenue-driving operations across industries.\nWhat is a\nDedicated AI Clusters (DACs)?\nA Dedicated AI Cluster is a\nprivate, secure and fully managed\nenvironment within Oracle Cloud Infrastructure (OCI). It allows enterprises to:\nDeploy advanced models such as Cohere or Meta Llama directly into their workflows\nFine-tune models with proprietary business data for differentiated outcomes\nHost up to 50 fine-tuned models from same cohere base model in a single cluster for efficient scaling\nEffortlessly scale DAC up or down to match your business needs\nRetain model versions beyond typical expiration windows, ensuring operational continuity\nIn short, DACs turn generative AI into a\nproduction-ready environment\nbuilt for long-term value.\nEnterprise Generative AI Journey: From Experimentation to Impact\nSix Key Outcomes with Real-World Impact\n1. Risk Reduction and Compliance Assurance\nWith DACs, sensitive workloads run within\nprivate and secure environments\nthat safeguard data privacy and meet regulatory requirements, helping reduce regulatory risk and enhance compliance.\nExample: A healthcare provider can use a large language model(LLM) in DAC to analyze patient records without leaving its secure environment, ensuring HIPAA-equivalent compliance while still accelerating diagnosis workflows.\n2. Predictable Performance for Mission-Critical Generative AI\nDACs deliver\nconsistent, low-latency responses and support extended context (128,000 tokens)\n, enabling applications such as contract analysis, customer service automation, and real-time decision-making to perform reliably at scale.\nExample: A global bank uses DACs to process long legal agreements in real-time during loan approvals, providing faster decisions without sacrificing precision.\n3. Customization That Drives Differentiation\nFine-tuned, proprietary models\nenable organizations to embed unique institutional knowledge and gain competitive advantage, managed with full control over the models’ lifecycle.\nExample: A retail chain fine-tunes models with its customer browsing and purchase data, powering AI shopping assistants uniquely tailored to its product catalog.\n4. ROI Through Cost Efficiency at Scale\nBy hosting multiple (fine-tuned) models on a single cluster, DACs\nmaximize resource usage and lower total cost of ownership\n, enabling scalable generative AI growth without proportional cost increases.\nExample: A Big MNC deploys dozens of specialized LLM models across operations on a single cluster, streamlining costs and deployment complexity.\n5. Global Deployment and Data Residency\nDACs can be deployed\nclose to where the data lives\n, including regulated regions, simplifying compliance and reducing latency for global enterprises.\nExample: A government agency deploys DACs in their region to meet local data privacy laws while benefiting from generative AI capabilities.\n6. Focus on Innovation, Not Management\nOracle fully manages DACs, freeing organizations from operational burdens and letting them focus on\nbuilding innovative generative AI applications that deliver value\n.\nExample: An insurance company accelerates claims processing by focusing its teams on generative AI application development while infrastructure fully managed by Oracle\nFrom Experimentation to Enterprise Advantage\nThe enterprise generative AI journey is accelerating. On-demand services demonstrate generative AI’s promise, but only\nDedicated AI Clusters\ncan deliver:\nRobust risk mitigation\nfor regulatory compliance and data security\nCompetitive differentiation:\nFine-tuned models built on proprietary data\nPredictable, scalable performance:\nStable, low-latency responses with extended context\nCost efficiency:\nHost multiple models on one cluster to optimize spend\nRegional deployment options\naddressing compliance and performance needs\nFully Managed Service:\nOracle handles lifecycle and scaling, speeding innovation\nGenerative AI is redefining competitive advantage. For organizations eager to unlock generative AI’s transformative power, DACs are a\nsecure\n,\ntrusted, and fully managed\nenvironment – helping turn generative AI pilots into long-term, scalable business outcomes.\nWhat’s Next: Deep Dive into DAC Deployment & Architecture\nThis introduction blog has shown how Oracle Generative AI Dedicated AI Clusters unlock enterprise value across industries and use cases. But how do you take the next step moving from strategy to execution?\nIn our next blog, we’ll go beyond the business benefits and\ntake you behind the scenes\n. You’ll learn how to get a DAC up and running, with a hands-on walkthrough of the architecture, deployment process, and best practices for operationalizing generative AI at scale. Whether you’re an IT leader, architect, or AI practitioner, you’ll see how\nsimple and powerful\nit is to put DACs to work for your organization.\nStay tuned for a practical deep dive and get ready to turn vision into reality with production AI!\nTo further explore the potential of Generative AI solutions with Oracle Cloud Infrastructure, check out the following resources:\nLearn about Generative AI\nPretrained Foundational Models in Generative AI\nDedicated AI Cluster Performance Benchmarks\nData Handling in Generative AI"
  },
  {
    "title": "How Deep Tech Innovation-driven Businesses Can Leverage OCI’s VM ...",
    "link": "https://blogs.oracle.com/ai-and-datascience/how-deep-tech-innovation-driven-businesses-can-leverage-ocis-vm-clusters-for-affordable-gpu-accelerated-computational-science-workloads",
    "source": "Oracle_blog",
    "main_ideas": [
      "Deep tech startups require specialized computational resources beyond traditional LLM and deep learning applications.",
      "Oracle Cloud Infrastructure's VM clusters with A10 GPUs enhance performance for computational materials screening.",
      "Machine-Learned Interatomic Potentials significantly accelerate molecular simulations compared to traditional DFT methods."
    ],
    "tags": [
      "deep-tech",
      "gpu-accelerated",
      "oracle-cloud",
      "computational-chemistry",
      "machine-learning",
      "materials-science",
      "aionics",
      "high-throughput",
      "vm-clusters"
    ],
    "original_text": "The recent explosion in LLM usage has skyrocketed demand for GPUs, particularly high-end NVIDIA chips such as H100 and GB200. Deep tech startups, however, typically have computational workloads that fall outside of the LLM and deep learning spaces. Examples include Computational Fluid Dynamics (CFD), Computational Structural Mechanics, Molecular Dynamics (MD), and Density Functional Theory (DFT). The bottlenecks and figures of merit can also be different for startups that utilize these methods to screen new materials or designs at scale, where GPU-hours per data point becomes a more meaningful metric than raw compute power. Innovation-driven businesses looking for solutions to these use cases can accomplish their goals without breaking the bank on premium GPUs or bottlenecking their screening throughput.\nThis blog presents a proof of concept for GPU-accelerated computational materials screening workloads jointly conducted by Aionics, Inc. and Oracle Cloud Infrastructure utilizing a VM cluster accelerated with NVIDIA A10 GPUs. The focus will be on two use cases: molecular density functional theory with GPU4PySCF and high-throughput Machine-Learned Interatomic Potential (MLIP) inference.\nMilestones and Timelines\nFigure 1 shows Expected Timeline for Proof of Concept in calendar days *note it’s not listed in deployment hours we were able to complete this POC four days early:\nArchitecture and Functionality\nFigure 2 shows the reference architecture used for POC:\nThis architecture ensures the user has access to all the tools and workflows typically found in on-premises compute clusters and supercomputing centre:\nLogin and Compute nodes are all connected to a single Network File system (NFS).\nCompute nodes are provisioned on-demand and scaled as needed using a scheduler (e.g. SLURM).\nThe user’s software stack can be managed using an environment module tool (e.g. Lmod or EnvironmentModules) for consistency and modularity.\nPerformance\nFirst, we look at GPU-accelerated atomic orbital DFT. This is a widely utilized computational chemistry framework for studying molecules in electrolyte and drug development. Recently, this framework was engineered for GPU acceleration by Li et al. in the GPU4PySCF Python package [1]. OCI’s A10 GPUs can run geometry relaxation [2] of small-to-medium organic molecules in seconds to minutes, showing up to two-orders-of-magnitude speedup over CPU parallelization (8 tasks) and up to 40% speedup over L4 GPUs, which are of comparable VRAM and pricing.\nFigure 3 – Atomic-orbital DFT structural relaxation wall times for various known electrolyte molecules\nNext, we look at geometry relaxation with a Machine-Learned Interatomic Potential (MLIP) for a molecule-on-a-surface material system. Studying molecular adsorption on surfaces has wide ranging applications from catalysis to energy storage, but using DFT for such studies is typically computationally prohibitive at a large scale. MLIPs are machine learning models that are pretrained on large DFT datasets to predict molecular and/or solid-state material structures. These models can accelerate structural relaxation and screening by multiple orders of magnitude since they essentially replace the iterative solving of high-dimensional equations with ML inference.\nIn this example, we look at average MLIP relaxation wall time for 70 initial configurations of a 27-atom organic molecule on a 300-atom surface, with 6 chemical species in total, using the Orb v2 MLIP [3]. Once again, the data shows a significant speedup of 2.3x for A10 shapes over L4s. The queuing system also enables high-throughput submission of these jobs. At 2.5 minutes per simulation, a single cluster can relax hundreds or thousands of structures in a few hours.\nFigure 4 – Average single-configuration wall times for MLIP relaxations of a medium-sized molecule on a crystal surface\nConclusion\nWhen considering how to design compute infrastructure for your deep tech company, there are a variety of factors to balance: cost, wall time, and the most likely performance bottlenecks. For GPU workloads, it is not enough to think of raw specifications like tensor cores and VRAM. OCI’s VM clusters and A10 shapes enable this flexibility in design, where you can extract the most data points per dollar by increasing GPU utilization while leveraging data parallelism and dynamic resource scheduling.\nAbout Oracle Cloud Infrastructure (OCI)\nOracle Cloud is the first public cloud built from the ground up to be a better cloud for every application. By rethinking core engineering and systems design for cloud computing, OCI created innovations that solve problems that customers have with existing public clouds. OCI accelerate migrations of existing enterprise workloads, deliver better reliability and performance for all applications, and offer the complete services customers need to build innovative cloud applications.\nTo learn more information on OCI creating OKE with GPU instances\nhttps://docs.oracle.com/en-us/iaas/Content/ContEng/Tasks/contengrunninggpunodes.htm\nAbout Aionics, Inc.\nFounded in 2020, Aionics is pioneering a new era of formulation design by combining artificial intelligence, quantum simulation, and proprietary data to develop custom, high-performance materials for mission-critical applications. Headquartered in Palo Alto, Aionics works with leading companies in automotive, aerospace, defense, and energy to design drop-in chemical solutions that improve performance, safety, and sustainability.\nTo learn more, visit\nwww.aionics.io\nContributors\nMohamed K. Elshazly\n, PhD – Aionics, Inc.\nRandy Trampush\n– Oracle Enterprise Cloud Architect\nRyan Helferich\n– Oracle Enterprise Cloud Architect\nMac Stephen\n– Oracle AI-GPU Cloud Engineer\nFootnotes\n[1]\nhttps://arxiv.org/abs/2407.09700\n[2] Relaxations conducted using GeomeTRIC package at the B3LYP/6-31+G* level of theory with density fitting.\n[3]\nhttps://arxiv.org/abs/2410.22570"
  },
  {
    "title": "Introducing the Open Agent Specification (Agent Spec): A Unified ...",
    "link": "https://blogs.oracle.com/ai-and-datascience/introducing-open-agent-specification",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle introduces Open Agent Specification to unify AI agent development.",
      "Agent Spec enhances portability and reusability across different frameworks.",
      "The specification aims to reduce fragmentation in the AI agent ecosystem.",
      "Open sourcing Agent Spec encourages community collaboration and adoption.",
      "Oracle products are integrating Agent Spec for interoperable AI solutions."
    ],
    "tags": [
      "open-agent-specification",
      "oracle",
      "ai-agents",
      "interoperability",
      "cloud-computing",
      "automation",
      "software-development",
      "standardization",
      "machine-learning"
    ],
    "original_text": "AI agents have become core to many modern applications – automating workflows or orchestrating complex tasks. However, a key challenge persists –\nfragmentation\n. Today’s developers rely on frameworks such as AutoGen, LangGraph, and CrewAI, each with its own strengths but lacking a shared foundation. This fragmentation can make it difficult to port agents between frameworks, reuse components, and scale solutions across platforms.\nTo address these challenges, Oracle is introducing\nOpen Agent Specification (Agent Spec)\n– an open, standardized representation that brings\nportability, reusability,\nand\nextensibility\nto the AI agent ecosystem.\nAgent Spec\nis a\nframework-agnostic declarative specification\ndesigned to make AI agents and workflows portable, reusable, and executable across any compatible framework. Inspired by the success of representations like Open Neural Network Exchange (ONNX) for ML models, Agent Spec aims to bring that same level of interoperability and optimization to the AI agent space to foster an ecosystem of tools to develop on top of it.\nKey Benefits\nWith Open Agent Specification, developers can:\nDefine agents once and run them flexibly nearly anywhere –\nfrom local development environments to cloud-based runtimes.\nBuild standalone agents or agentic workflows that can interface with external tools, data sources, and LLMs in a\nconsistent and declarative\nmanner.\nChoose the preferred execution runtime\nwithout rewriting agent logic.\nLeverage a\nstandardized, versioned representation\nto simplify maintenance and collaboration.\nWith Open Agent Specification, an Enterprise can:\nSeamlessly scale AI agents from prototype to production without costly rewrites or reengineering.\nReduce lock-in to specific technology artifact or deployment platform.\nMaintain AI agent deployment via simple configuration update rather than heavy software upgrade.\nExchange AI agents among different internal organizations or with external business partners.\nMuch like how ONNX helped unify model exchange across ML libraries, Agent Spec bridges agent development fragmentation, accelerating the path to open, composable, and intelligent agent systems.\nBuilt to Evolve with the Agent Ecosystem\nAgent Spec is built with and for the community – designed to evolve through real-world use, extensible modules, and support for custom components. Agent Spec provides strong synergies with various standardization efforts like Model Context Protocol (MCP).\nBy supporting MCP servers, Agent Spec enables AI agents to access external APIs through a standardized tool interface (understand your organization’s data and privacy policies before using) – reducing the need for custom adapters for every external API and streamlining tool integrations.\nTo drive adoption and collaboration, we are open sourcing:\nOpen Agent Specification\n– A declarative schema for defining agents and workflows. A detailed technical report is available as well for interested readers.\nAgent Spec SDK\n– Tools to build, validate, and transform Agent Spec definitions.\nAgent Spec Reference runtime\n–\nWayFlow\nas a reference runtime for Open Agent Specification.\nExecution frameworks (e.g., WayFlow, AutoGen, LangGraph) can implement Agent Spec runtime adapters\nto seamlessly interpret and orchestrate agents defined in Agent Spec.\nOpen Agent Specification Design\nOracle Leads the Way in Adoption\nAs we open-source\nOpen Agent Specification\n, several Oracle products are already adopting it to build interoperable, production-grade AI agents. For example, Oracle Applied AI, Oracle Financial Services Global Industries, and Oracle Autonomous Database Select AI are integrating Agent Spec configurations to enable enterprise agents. Agent Spec configurations are planned to be supported on other Oracle platforms in future, including Oracle Cloud Infrastructure.\nQuote from Sandesh Rao, Vice President, Applied AI Technologies\n“With Open Agent Specification and its runtime (WayFlow) integrated in Oracle Private Agent Factory, and in collaboration with Oracle Labs, we are making it easier than ever for enterprise customers to design and deploy production-grade AI agents.”\nQuote from Jason Wynne, Senior Vice President, Financial Services Global Industries Unit\n“\nWith multiple AI Agent use-cases automating financial crime investigations\nalready in\nproduction\n, in close collaboration with Oracle Labs and leveraging WayFlow as Open Agent Specification runtime, we see Agent Spec as a critical enabler for rapidly integrating our agents into different Oracle platforms. This shared foundation accelerates our ability to deploy, manage, and enhance Agentic solutions for financial services compliance and risk mitigation.\n”\nQuote from Mark Hornick, Senior Director, Oracle Database Machine Learning and AI Product Management\n“\nEnterprise users need a convenient and efficient way to exchange and deploy their agentic solutions. Given its focus on enabling database-centric AI-driven apps and reducing time-to-market, Select AI is also adopting Open Agent Specification – enabling interoperability and reusability of agents across platforms. In collaboration with Oracle Labs, we are helping to empower users to seamlessly integrate, manage, and easily enhance enterprise agentic applications.\n”\nContribute to a shared foundation for AI agents.\nStart exploring with Open Agent Specification today to create, share, and scale agents across frameworks. We also provide a\nfull technical report\nfor interested readers.\n👉 Check out\nOpen Agent Specification\nand\nWayFlow\nexamples to get started."
  },
  {
    "title": "Running NIM on OKE: A Scalable Foundation for Enterprise-Grade LLM ...",
    "link": "https://blogs.oracle.com/ai-and-datascience/running-nim-on-oke-for-llm-inference",
    "source": "Oracle_blog",
    "main_ideas": [
      "NVIDIA NIM microservices provide a scalable solution for deploying large language models on Oracle Kubernetes Engine.",
      "OKE offers optimized infrastructure for running AI workloads with features like autoscaling and load balancing.",
      "The article includes a step-by-step guide to deploying LLM inference endpoints using NIM on OKE."
    ],
    "tags": [
      "nvidia",
      "oracle",
      "kubernetes",
      "large-language-models",
      "cloud-computing",
      "ai-workloads",
      "gpu-acceleration",
      "microservices",
      "inference"
    ],
    "original_text": "As Large Language Models (LLMs) continue to evolve and drive a wave of innovation, from copilots and chatbots to document summarization and autonomous agents, one question keeps surfacing in engineering conversations:\n“How do we run these models reliably, securely, and at scale?”\nOne answer: NVIDIA NIM microservices. And when deployed on Oracle Kubernetes Engine (OKE), NIM microservices become a production-ready solution for Enterprise AI workloads, combining performance, portability, and flexibility in a fully containerized, GPU-accelerated architecture.\nThis post explores:\n●    What are NVIDIA NIM microservices and why they matter\n●    Why OKE is an ideal platform for running them\n●    A step-by-step guide to deploying your first LLM inference endpoint with NIM on OKE\nWhat are NVIDIA NIM Microservices?\nNIM are\nprebuilt containers provided by NVIDIA\nthat simplify the deployment of AI foundation models for real-time inference. Each NIM exposes a standardized API and comes fully optimized for GPU acceleration.\nEach NIM microservice includes:\n●    A pre-configured, containerized runtime environment\n●    Optimized model weights and inference engine\n●    A REST API or gRPC interface for easy integration\n●    Support for various foundation models (Meta Llama, Mistral, etc.)\n●    Performance enhancements via NVIDIA TensorRT-LLM and other NVIDIA acceleration libraries\nThese are production-grade containers designed to minimize cold start times, reduce overhead, and streamline enterprise AI deployments.\nWhy Deploy NIM on Oracle Kubernetes Engine (OKE)?\nOKE provides a powerful, managed Kubernetes environment designed for high-performance, scalable AI workloads. When paired with OCI’s NVIDIA accelerated compute and networking stack, it becomes a robust platform for deploying NIM at scale.\nKey benefits:\nGPU-Optimized Infrastructure\nRun NIM on OCI GPU instances (NVIDIA H100, A10, A100, V100) for increased performance and throughput.\nAutoscaling and Load Balancing\nOKE integrates seamlessly with OCI Load Balancers and supports autoscaling to match inference traffic in real-time.\nNative Monitoring and Logging\nEasily observe your inference metrics using OCI Logging and Monitoring or integrate Prometheus/Grafana stacks.\nSecurity and Networking\nRun NIM in isolated VCNs, use OCI Vault for secrets, and expose endpoints securely with ingress controllers or API gateways.\nCost-Effective Multitenancy\nDeploy multiple NIM within a single cluster and scale horizontally, optimizing GPU usage while maintaining separation of concerns.\nStep-by-Step: Deploying a NIM on OKE\nLet’s walk through a basic setup to deploy a Llama 3-based NIM on OKE.\nPrerequisites\nBefore you begin, ensure you have:\nAccess to an OCI tenancy with proper permissions\nA running OKE cluster (v1.26 or later) with GPU nodes\nkubectl configured for your cluster\nHelm installed\nAn NVIDIA API key – please follow\nthese instructions\nDocker or OCI container registry access (for custom container pulls if needed)\n1. Create an OKE Cluster with GPU Nodes\nYou can create an OKE cluster via the OCI Console or CLI. Use\nGPU-enabled shapes\n, such as:\nBM.GPU.H100.8\nBM.GPU.A10.4\nBM.GPU.A100.8\nEnsure your node pool uses a GPU shape and that the “nvidia-container-runtime” is configured. Oracle’s GPU\nMarketplace\nimages already have this pre-installed.\nTo begin, click\nOCI menu – Developer Services\n–\nKubernetes Clusters (OKE)\n.\nClick\nCreate Clusters\n.\nCheck\nQuick create\nis selected and click\nSubmit\n.\nFor this lab, we will pick a Public endpoint, Managed node type and Private workers as the worker nodes.\nSelect Node shape,\nBM.GPU.A10.4\nand node count as\n2\n. You can adapt the shapes according to your needs. For further references on compute shapes visit\nOCI Computer Shapes Documentation\n.\nThe default volume size is 50GB, so we need to increase it to 500GB. Click\nShow advanced options\nand change boot volume size to\n500GB\nand click next.\nClick\nCreate cluster\n.\nCheck\nnode pool status\nis waiting for cluster. You should see the cluster is being created and will take\naround 10 to 15 minutes\nto complete.\nOnce the process is complete, click Access\nCluster\n.\nNow you can use the command Kubernetes commands such as\nkubectl\nto manage your Kubernetes cluster.\nYou can run this locally using OCI CLI or leverage Cloud Shell\nCloud Shell provides:\nAn ephemeral machine to use as a host for a Linux shell, pre-configured with the latest version of the OCI Command Line Interface (CLI) and several useful tools\n5GB of encrypted persistent storage for your home directory\nA persistent frame of the Console which stays active as you navigate to different pages of the console\nFor this example, we will use Cloud Shell because of its simplicity and easy access to OCI resources.\nClick\nLaunch Cloud Shell\nand then\ncopy-and-paste\nthe command to the Cloud Shell and press enter.\nOnce in the Cloud Shell, run the following comands:\nkubectl get nodes\nkubectl get pods –all-namespaces\nThe output should list 2 nodes and the kubernetes systems pods.\nBy now you should have access to your OKE cluster.\nCheck for taints that may prevent deploying to these nodes.\nKubernetes taints are a way to mark a node so that only specific pods can be scheduled on to it, preventing other pods from using that node unless they tolerate the taint.\nkubectl describe nodes | grep -i taints\nIf you identified Taints, remove the\nnvidia.com/gpu:NoSchedule\nwith the following command.\nkubectl taint nodes –all nvidia.com/gpu:NoSchedule-\nWhen the cluster is ready, create the namespace in Kubernetes.\nkubectl create namespace nim\nReplace <insert your NGC_API_KEY> with your NGC API key, then paste the updated command into the Cloud Shell and press Enter.\nexport NGC_API_KEY=<insert your NGC_API_KEY>\n2. Install\nGPU Operator\nInstall the GPU Operator – NVIDIA GPU Operator manages NVIDIA GPU resources in a Kubernetes cluster and automates tasks related to bootstrapping GPU nodes.\nAdd the NVIDIA repository\nhelm repo add nvidia https://helm.ngc.nvidia.com/nvidia \\\n&& helm repo update\nhelm install gpu-operator nvidia/gpu-operator -n nim\nCheck the pods\nkubectl get pods -n nim\nThe GPU opreator installed successfully within 2 minutes.\n3. Install the\nNIM Operator\nInstall the NIM Operator – NIM Operator is a Kubernetes operator that manages the deployment and lifecycle of NVIDIA NIM\nInstall NIM-Operator\nhelm install nim-operator nvidia/k8s-nim-operator -n nim\nCheck the pods.\nkubectl get pods -n nim\n4. Create Secrets\nCreate a secret with specified type.\n•    A docker-registry type secret is for accessing the NGC registry.\n•    The generic type of secret is for accessing NGC catalog.\nkubectl create secret docker-registry ngc-secret \\\n–namespace nim \\\n–docker-server=nvcr.io \\\n–docker-username=’$oauthtoken’ \\\n–docker-password=”$NGC_API_KEY”\nkubectl create secret generic ngc-api-secret \\\n–namespace nim \\\n–from-literal=NGC_API_KEY=”$NGC_API_KEY” \\\n–from-literal=NVIDIA_API_KEY=”$NGC_API_KEY”\nCheck the secret was successfully created within the Kubernetes cluster.\nkubectl get secrets -n nim\n5. Deploy the LLM NIM\nNIM are intended to be run on NVIDIA GPUs, with the type and number of GPUs depending on the model. With the GPU Operator installed you can use Helm to install your LLM.\nCreate a deployment YAML that references the model-specific container. For example, for\nllama-3.1-nemotron-nano-8b-v1\ncat <<ENDEND > oke-nim-llama.yaml\nimage:\nrepository: nvcr.io/nim/nvidia/llama-3.1-nemotron-nano-8b-v1\ntag: 1.8.4\npullSecrets:\n– name: ngc-secret\nmodel:\nname: nvidia/llama-3.1-nemotron-nano-8b-v1\nngcAPISecret: ngc-api-secret\nservice:\ntype: LoadBalancer\nENDEND\nDownload the\nnim-llm\nhelm chart from the NVIDIA NGC repository.\nhelm fetch https://helm.ngc.nvidia.com/nim/charts/nim-llm-1.3.0.tgz –username=’$oauthtoken’ –password=$NGC_API_KEY\nRun the install.\nhelm install my-nim nim-llm-1.3.0.tgz -f oke-nim-llama.yaml -n nim\nCheck the progress of the install.\nkubectl get pods -n nim\nWhen you see the pod status as\nRunning\n, this mean the installation was successful.\nCheck what services are running.\nkubectl get svc -n nim\nLook for the pod name\nmy-nim-nim-llm\nand take note of the\nEXTERNAL-IP\n.\n6. Testing the inference API\nOnce the NIM is live, send a test prompt via curl or Postman. Replace the\n<EXTERNAL_IP>:\nwith the\nEXTERNAL-IP\nfrom the\nmy-nim-nim-llm service\n.\ncurl -X POST http://<EXTERNAL_IP>:8000/v1/chat/completions \\\n-H “Content-Type: application/json” \\\n-d ‘{\n“messages”: [\n{“role”: “system”, “content”: “You are a helpful assistant.”},\n{“role”: “user”, “content”: “”What should I do for a 4 day vacation in Greece?}\n],\n“model”: “meta/llama3-8b-instruct”,\n“max_tokens”: 200\n}’\nYou should see a response like the one below.\n{\n“id”: “cmpl-abc123”,\n“object”: “chat.completion”,\n“created”: 1752132000,\n“model”: “meta/llama3-8b-instruct”,\n“choices”: [\n{\n“index”: 0,\n“message”: {\n“role”: “assistant”,\n“content”: “Day 1: Athens—Acropolis, Acropolis Museum, Plaka. Day 2: Athens—Agora, food tour, Lycabettus at sunset. Day 3: Ferry to Hydra—car‑free island, coastal walk, swim, seafood taverna. Day 4: Hydra morning hike, ferry back and fly out. Tips: buy combo ticket for sites, prebook ferry, carry cash for small tavernas. Budget: €120–€180/day mid‑range; ferries €35–€60 each way.”\n}\n}\n],\n“usage”: {\n“prompt_tokens”: 55,\n“completion_tokens”: 140,\n“total_tokens”: 195\n}\n}\nLet’s send another prompt asking “\nWhat is oracle Autonomous Database?\n“\ncurl -X POST http://<EXTERNAL_IP>:8000/v1/chat/completions \\\n-H “Content-Type: application/json” \\\n-d ‘{\n“messages”: [\n{“role”: “system”, “content”: “You are a helpful assistant.”},\n{“role”: “user”, “content”: “What is oracle Autonomous Database?”}\n],\n“model”: “meta/llama3-8b-instruct”,\n“max_tokens”: 150\n}’\n​​​​​​​\nLLM’s response.\n{\n“id”: “cmpl-xyz987”,\n“object”: “chat.completion”,\n“created”: 1752132500,\n“model”: “meta/llama3-8b-instruct”,\n“choices”: [\n{\n“index”: 0,\n“message”: {\n“role”: “assistant”,\n“content”: “Oracle Autonomous Database is a cloud-based database service that uses machine learning to automate key management tasks such as provisioning, tuning, backups, and patching. It is designed to run without human intervention, reducing administrative overhead while improving performance, reliability, and security. Available in configurations for transaction processing, data warehousing, or mixed workloads, it scales automatically and includes built-in security and analytics capabilities.”\n}\n}\n],\n“usage”: {\n“prompt_tokens”: 19,\n“completion_tokens”: 102,\n“total_tokens”: 150\n}\n}\n​​​​​​​\nAs part of the prompt settings, you can tweak the\nsystem prompt\n,\nmodel\n, and the\nmax_tokens\n. Let’s try updating the system prompt that the size of the\nmax_tokens\n.\ncurl -X POST http://<EXTERNAL_IP>:8000/v1/chat/completions \\\n-H “Content-Type: application/json” \\\n-d ‘{\n“messages”: [\n{“role”: “system”, “content”: “Act as a Software Engineer and respond to the questions towards a new solution development .”},\n{“role”: “user”, “content”: “What is oracle Autonomous Database?”}\n],\n“model”: “meta/llama3-8b-instruct”,\n“max_tokens”: 2048\n}’\n​​​​​​​\nLLM’s response.\n{\n“id”: “cmpl-abc2000”,\n“object”: “chat.completion”,\n“created”: 1752133000,\n“model”: “meta/llama3-8b-instruct”,\n“choices”: [\n{\n“index”: 0,\n“message”: {\n“role”: “assistant”,\n“content”: “Oracle Autonomous Database (ADB) is a fully managed, self-driving cloud database service offered on Oracle Cloud Infrastructure (OCI). It leverages advanced machine learning to automate the full lifecycle of a database — including provisioning, configuring, securing, tuning, scaling, patching, and repairing — without human intervention. This eliminates much of the manual database administration work while improving reliability, security, and performance.\\n\\n**1. Architecture**\\nThe architecture is built on Oracle Database technology running in the OCI environment, enhanced with AI/ML-driven automation. Key layers include:\\n- **Compute Layer**: Dedicated or shared infrastructure, optimized for database workloads.\\n- **Storage Layer**: Exadata storage servers with high-bandwidth, low-latency access to persistent data.\\n- **Automation Layer**: ML models monitor workloads, optimize indexes, allocate CPU/memory dynamically, and detect anomalies.\\n- **Security Layer**: Always-on encryption (TDE), automatic security patching, access controls, and audit logging.\\n\\n**2. Deployment Options**\\n- **Autonomous Transaction Processing (ATP)**: Optimized for OLTP workloads, mobile/web apps, ERP, and CRM systems.\\n- **Autonomous Data Warehouse (ADW)**: Optimized for analytics, BI, data lakes, and reporting.\\n- **Autonomous JSON Database**: For applications requiring a JSON-native store with SQL integration.\\n- **Autonomous Database on Dedicated Exadata Infrastructure**: For isolation, compliance, and predictable performance.\\n\\n**3. Key Features**\\n- **Self-Driving**: Automates provisioning, scaling, backups, tuning, and patching.\\n- **Self-Securing**: Automatically applies security updates, encrypts all data, and protects from malicious attacks.\\n- **Self-Repairing**: Detects and recovers from failures automatically with minimal downtime (99.995% SLA).\\n- **Elastic Scaling**: CPU and storage scale independently without downtime.\\n- **Data Integration**: Native connectors for Oracle Analytics Cloud, GoldenGate, Data Integration, and 3rd-party BI tools.\\n- **Multi-Model Support**: Relational, JSON, spatial, graph, blockchain tables.\\n\\n**4. Benefits**\\n- **Reduced Operational Cost**: Eliminates most DBA repetitive tasks.\\n- **Higher Reliability**: Machine learning reduces misconfiguration risk.\\n- **Performance Optimization**: Automatic indexing and query plan adjustments.\\n- **Security Compliance**: Meets standards like ISO 27001, SOC, PCI-DSS, HIPAA.\\n\\n**5. Use Cases**\\n- Real-time analytics dashboards.\\n- High-transaction e-commerce platforms.\\n- IoT sensor data ingestion and analysis.\\n- Financial fraud detection.\\n- Government and regulated industries requiring high compliance.\\n\\n**6. Technical Specs (OCI ADB)**\\n- Storage: Up to petabytes with Exadata scale-out storage.\\n- Memory: Up to hundreds of GB per instance.\\n- CPUs: Elastic OCPU model (per second billing).\\n- Network: RDMA over Converged Ethernet (RoCE) for ultra-low latency.\\n\\nIn summary, Oracle Autonomous Database combines Oracle’s database expertise with cloud-scale automation to deliver a service that is faster to deploy, easier to maintain, and more secure than traditional database models, freeing up teams to focus on innovation instead of administration.”\n}\n}\n],\n“usage”: {\n“prompt_tokens”: 45,\n“completion_tokens”: 1020,\n“total_tokens”: 1065\n}\n}\n​​​​​​​\nFinal Thoughts\nEnterprise-Grade AI at Scale: Combines NVIDIA GPU acceleration with OKE’s secure, managed infrastructure to reliably run LLMs and other AI models in production.\nPre-Built, Optimized Microservices: NIM include foundation models, optimized inference engines, and standard APIs packaged in ready-to-deploy containers, no complex manual setup required.\nKubernetes-Native Deployment: OKE manages the full container lifecycle (scaling, high availability, upgrades), reducing operational overhead.\nPerformance Boost & Cost Efficiency: Delivers faster inference than open-source inference engines on the same infrastructure, with even greater gains for high-concurrency workloads.\nFlexible Workload Support: Ideal for chatbots, copilots, semantic search, document analysis, computer vision, and more, supporting multiple frameworks and models.\nIntegrated OCI Services: Natively connects to OCI Data Science, Object Storage, API Gateway, and observability tools like Grafana and Prometheus.\nSecurity & Compliance by Design: Encryption, network isolation, access control, and compliance with ISO, SOC, PCI, HIPAA, and other standards.\nFaster Time-to-Value: Go from concept to production inference endpoints in hours, not weeks, with automated deployments and preconfigured stacks.\nFinal Thoughts\nRunning NIM on OKE brings together the best of NVIDIA and Oracle Cloud: performance-optimized model microservices deployed on enterprise-grade, scalable infrastructure.\nWhether you’re deploying a GenAI chatbot, a document Q&A system, or powering a RAG pipeline, this architecture gives you:\n●    Full control over models and infrastructure\n●    The flexibility of Kubernetes with the speed of NVIDIA inference\n●    Seamless integration into your broader OCI AI and data ecosystem\nReady to start? Visit\ncloud.oracle.com\n, provision your OKE cluster, and try deploying your first NIM today\nAcknowledgements\nThis blog post is the result of a strategic and hands-on collaboration between Oracle Cloud Infrastructure (OCI) and NVIDIA, two  industry leaders working together to accelerate enterprise AI innovation. By combining OCI’s enterprise-grade infrastructure, the NVIDIA AI Platform, and cutting-edge LLMs, we’re enabling customers to build, deploy, and scale generative AI workloads with confidence and performance at the core.\nThis post is part of a broader enablement initiative jointly developed with our partners at NVIDIA.\nA special thanks to the engineering teams at NVIDIA and OCI, whose deep expertise and ongoing collaboration have been instrumental in supporting our customers throughout their AI journey. Your contributions continue to shape what’s possible.\nAlejandro Casas,\nOCI Product Marketing\nDimitri Maltezakis Vathypetrou,\nNVIDIA Developer Relations\nAnurag Kuppala,\nNVIDIA AI Solution Architect\nResources\nOracle Cloud Infrastructure Documentation\nOKE Quickstart Guide\nNVIDIA NIM Microservices\nNVIDIA Developer Program\nGitHub Sample: NIM on OKE\nNVIDIA AI Enterprise\n​"
  },
  {
    "title": "Announcing OCI Vision Streaming Video Analysis: Real-Time Insights ...",
    "link": "https://blogs.oracle.com/ai-and-datascience/announcing-oci-vision-streaming-video-analysis",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle Cloud Infrastructure launches Streaming Video Analysis for real-time video insights.",
      "The service uses AI to detect and track objects, faces, and weapons in live streams.",
      "Flexible deployment options include public and private network connectivity for security."
    ],
    "tags": [
      "oracle",
      "cloud-infrastructure",
      "video-analysis",
      "artificial-intelligence",
      "real-time-insights",
      "object-detection",
      "surveillance",
      "retail-analytics",
      "gpu-accelerated"
    ],
    "original_text": "Oracle Cloud Infrastructure (OCI) is excited to announce the general availability of Streaming Video Analysis, a fully managed, GPU-accelerated analytics service delivering real-time video insights from live RTSP streams. Enterprises, security professionals, and developers can now unlock actionable information from live camera feeds—deploying advanced AI-driven analytics at scale.\nWhat Is Streaming Video Analysis?\nStreaming Video Analysis on OCI processes live videos through sophisticated AI models, detecting and tracking objects, labels, text and faces in real time. Designed for low-latency, high-performance environments, it supports high throughput and can be scaled for demanding use cases such as security monitoring, retail analytics, manufacturing, stadiums, and more.\nKey Features\nObject Detection – Detects objects (e.g., people, vehicles, text, labels) and returns bounding boxes.\nFace Detection – Identifies faces with bounding box outputs.\nWeapon Detection – Identifies guns(other weapon types will be included later) across streams with bounding box outputs.\nObject Tracking – Object Tracking feature enables tracking of detected objects (currently limited to faces, guns) across video frames. By assigning a unique identifier (tracking ID) to each face, the system maintains continuity of identity as a person moves through the camera view.  In case of Face Tracking, both single camera tracking and multi-camera tracking are supported.\nSingle Camera Tracking: Tracks faces within the bounds of a single camera stream. This allows accurate identification and tracking of individuals as they move through the field of view of a specific camera.\nMulti-Camera Tracking: Multi-camera tracking enables identity consistency across multiple camera streams. Cameras can be logically grouped so that a face detected in one stream can be recognized in another stream. (Gun detection is not yet supported across multiple cameras.)\nTechnical Highlights\nPerformance & Recommendations\nTo achieve optimal results:\n• Use cameras with consistent frame rates of 30FPS.\n• Ensure camera resolution is above 720p.\n• Maintain well-lit environments and recommended subject proximity (15–20 meters).\nFlexible Deployment Models\nOCI Vision Streaming Video Analysis supports both public and private network connectivity:\n• Public Endpoint: Exposes streams to the internet via a public IP, suitable for flexible or temporary setups.\n• Private Endpoint: Keeps streams private through OCI’s VCN for production-grade security. Integrate seamlessly with your enterprise networking using site-to-site VPN or private endpoints.\nGetting Started\n• Camera Setup: Connect your camera to your network (LAN or Wi-Fi), configure static IPs and required port forwarding for public endpoints, or use VPN/private routing for secure deployments.\n• VCN/Subnet Configuration: Provision necessary OCI networking resources and subnets to support camera feeds and video analysis jobs.\n• IAM Policies & Security: Assign precise access control with OCI policies for Vision service, networking, and resource management—via dynamic groups or all-in-one policies for streamlined administration.\n• SDK Support: Manage and monitor streaming jobs through the OCI SDK, leveraging example code and integrated object storage for results.\nUse Cases\n• Smart Surveillance: Monitor sites in real time for personnel safety, access violations, or unusual events.\n• Retail Analytics: Track customer footfall, behavior, and optimize layouts using live video.\n• Manufacturing/Facilities: Detect protective gear, monitor processes, and ensure compliance dynamically.\n• Sports/Entertainment: Real-time ad placement, event highlights, and identity tracking across multiple views.\nFor more information, see the following resources:\nOCI Vision Stream Video Analysis Technical Documentation\nOCI Vision AI"
  },
  {
    "title": "Learning Never Stops for Top AI Talent – Join Oracle Race to ...",
    "link": "https://blogs.oracle.com/ai-and-datascience/learning-never-stops-for-top-ai-talent-race-to-certification",
    "source": "Oracle_blog",
    "main_ideas": [
      "Continuous learning and upskilling are essential in the rapidly evolving AI job market.",
      "Oracle offers free digital training and certifications to enhance AI skills.",
      "The demand for specialized AI roles is increasing, emphasizing skills over traditional experience."
    ],
    "tags": [
      "artificial-intelligence",
      "oracle",
      "upskilling",
      "certification",
      "generative-ai",
      "data-science",
      "ai-training",
      "job-market",
      "skills-based-hiring"
    ],
    "original_text": "Stay ahead at the pace of AI\nGenerative AI is innovating at an exponential rate, propelled by advancements in model capabilities, increased investment, and rapid adoption across industries.\nThere are several drivers, including:\nContinued advancements in computing power and hardware which are essential for training and running increasingly complex models.\nData availability and curation, given the availability of massive datasets for training.\nOpen-source momentum, democratizing access to generative AI and empowering a broader community of developers.\nThe availability of pre-trained models and plug-and-play APIs lowering the barrier to custom AI workflows.\nWith this pace of change in AI, continuous learning, workforce adaptation, and upskilling are critical.\nYour competitive AI edge\nThe tech job market is a mixed bag, characterized by both strong demand in specialized areas and increased competition. This is coupled with a robust pace of change thanks in large part to GenAI. Specialized roles such as AI Engineer and Data Scientist are facing competitiveness that has recalibrated to specific, high-value skills.\nAccording to Robert Half, a global talent solutions and business consulting firm, there’s a shift to skills-based hiring, ranking current skills and proven outcomes over traditional experience and education (\nRobert Half, June 2025\n).\nWe’re seeing that:\nContinuous learning is essentia\nl – Upskilling and reskilling are crucial to stay relevant in this pace of innovation.\nDemonstrable skills are important\n– Learning opportunities with recognized credentials and certification are more important than ever.\nAdaptability is the name of the game\n– The market is dynamic, and engineers, architects, and developers who stay current with learning opportunities and certifications are prepared for what’s next.\nThe power of Oracle learning and certifications for today’s demanding AI roles\nOracle is an established database juggernaut, has cultivated a significant position in the hyperscaler ranks, and is also keeping a dizzying pace of innovation in AI.\nOracle is recognized as a key AI player, as determined by the company’s performance tied to AI, our strategic investments in AI infrastructure, our product innovation and integration of AI, and numerous customer successes. You don’t have to take my word for it. Read\nOracle Is No Longer AI’s Dark Horse\nby\nThe Wall Street Journal\n’s Dan Gallagher.\nOur AI innovation is matched with equal gusto in our efforts to provide engineers, architects, and developers opportunities for continued learning and certification.\nOracle University\nprovides a comprehensive portfolio of training, certification, and digital adoption solutions to empower organizations to gain the skills and expertise needed to be successful with AI.\nJoin Oracle’s Race to Certification 2025\nOracle has launched\nRace to Certification 2025\n, offering FREE digital training and certifications in AI until October 31. Brush up on new skills and go deeper in expertise – while gaining credentials from an AI leader that are broadly recognized and respected.\nWith the\nRace to Certification\n, gain highly coveted AI expertise with Oracle’s AI learning paths. Start with\nOCI AI Foundations\n—no prior experience needed— and then advance through certifications in\nOCI Generative AI\n,\nOCI Data Science\n, and\nOracle AI Vector Search\n. Learn to design, build, and deploy real-world AI solutions using Oracle’s enterprise-grade AI infrastructure, Generative AI services, AI Data Platform, and Machine Learning tools built for every layer of the stack. Apply your expertise to real-world use cases and stand out as a skilled AI practitioner.\nAcquire highly coveted AI capabilities, today\nThe job market continues to be competitive and the pace of change, particularly with AI, means that continuous learning is a necessity. The skills development and certification opportunities offered by the\nRace to Certification\ncan demonstrate that you have the skills and expertise required to work with Oracle technologies.\nJoin the 440,000 people (Aug. 27 update: 535,000+ and counting) who have accessed sought-after digital training and certifications in AI, for FREE.\nJoin the Race today\n!\nLearn more about all of Oracle University’s learning and certification opportunities\nFollow Oracle University on LinkedIn\nExplore Oracle AI"
  },
  {
    "title": "Use OpenAI’s Open Weight Models in OCI Data Science’s No ...",
    "link": "https://blogs.oracle.com/ai-and-datascience/openais-open-weight-models-in-ai-quick-actions",
    "source": "Oracle_blog",
    "main_ideas": [
      "OpenAI released two open weight models, gpt-oss-120b and gpt-oss-20b.",
      "These models perform on par with OpenAI's internal models and excel in various tasks.",
      "OCI Data Science offers a no-code interface for deploying and fine-tuning these models.",
      "Users can access enterprise-grade GPUs for model deployment in OCI Data Science.",
      "AI Quick Actions simplify the process of working with OpenAI's latest models."
    ],
    "tags": [
      "openai",
      "gpt-oss",
      "oci-data-science",
      "cloud-computing",
      "artificial-intelligence",
      "machine-learning",
      "model-deployment",
      "no-code",
      "gpu"
    ],
    "original_text": "Open AI recently\nreleased two open weight models\ngpt-oss-120b and gpt-oss-20b, their first since GPT-2.  OpenAI trained these models with a mix of reinforcement learning and techniques based on OpenAI’s other internal models. According to OpenAI, their performance are on par or exceed OpenAI’s internal models, and both models perform strongly on tool use, few-shot function calling, CoT reasoning and HealthBench.\nHere are the new OpenAI open weight models:\ngpt-oss-120b — designed for production, general-purpose and high-reasoning use cases.  The model has 117B parameters with 5.1B active parameters\ngpt-oss-20b — designed for lower latency and local or specialized use cases.   The model has 21B parameters with 3.6B active parameters\nIn our previous\nblog,\nwe described how customers can use a\nBring Your Own Container approach\nto deploy and fine tune these models in OCI (Oracle Cloud Infrastructure) Data Science.  Both models are available in OCI Data Science\nAI Quick Actions\n, a no-code interface for working with generative AI models.   The models are cached in our service and readily available to be deployed and fine tuned in AI Quick Actions, without the need for users to bring in the model artifacts from external sites.\nWorking with OpenAI open weight models in AI Quick Actions\nBy using AI Quick Actions, customers can leverage our service managed container with the latest\nvllm\nversion that supports both of the models, eliminating the need to build or bring your own container for working with the models.  To access the latest models, users need to deactivate and reactivate the notebook session they use with AI Quick Actions.  Alternatively, they can create a new notebook session. When users first launch AI Quick Actions, they can find the model cards in the Model Explorer as shown in figure 1.   Upon clicking on the model card, users will see the options to deploy or fine tune the model as shown in figure 2.  To deploy the model, users can choose the shape for deployment and logging options as shown in figure 3.   OCI Data Science currently\nsupports multiple GPUs\nincluding A10, A100, H100 and H200. gpt-oss-120b can be deployed with A100, H100 and H200 while gpt-oss-20b can be deployed with an A10.4, A100, H100 and H200.\nFigure 1: Both OpenAI’s open weight models are available in AI Quick Actions’ model explorer\nFigure 2: Clicking on the model card leads to the model information page where users can choose to deploy or finetune the model\nFigure 3: User can choose the compute shape for model deployment\nUsing AI Quick Actions to inference on gpt-oss models\nThe example below shows how to send a chat completion request to a gpt-oss model.  This would also work with any other open-source LLM deployed via AI Quick Actions.  We use  the ads.aqua.get_httpx_client() utility from Oracle\nAccelerated Data Science\nSDK to enable the OpenAI client to work more seamlessly with OCI’s authentication and networking. The endpoint URL and authentication method must be updated according to your model deployment configuration.\nCopy code snippet\nCopied to Clipboard\nError: Could not Copy\nCopied to Clipboard\nError: Could not Copy\nimport ads\nimport ads.aqua\nfrom openai import OpenAI\n\n# Authenticate with OCI using your preferred method.\n# Here we use 'security_token', which must be configured in your environment.\n# Alternatively the auth=\"resource_principal\" can be used\nads.set_auth(auth=\"security_token\")\n\n# Replace <OCID> with the OCID of your deployed model\n# and update the region in the endpoint URL accordingly.\nENDPOINT = \"https://<MD_OCID>/\"\n\n# Create an OpenAI client configured to call the OCI Model Deployment service.\n# - api_key is set to \"OCI\"\n# - base_url points to your deployment's predict endpoint\n# - http_client is provided by ads.aqua to handle OCI request signing\nclient = OpenAI(\napi_key=\"OCI\",\nbase_url=f\"{ENDPOINT}/predict/v1/\",\nhttp_client=ads.aqua.get_httpx_client(),\n)\n\n# Send a chat-completion request to the deployed model.\n# The model name is \"odsc-llm\" for single-model deployments,\nresponse = client.chat.completions.create(\nmodel=\"odsc-llm\",\nmessages=[\n{\n\"role\": \"user\",\n\"content\": \"Who was the first president of the US?\",\n}\n],\n)\n\n# Print the raw response object from the model.\nprint(response)\nWhy use OCI Data Science AI Quick Actions for OpenAI’s open weight models?\nAI Quick Actions help make it easy for you to stay on top of AI innovations. You can deploy and fine-tune OpenAI’s latest open weight models in a no code environment.\nManaged infrastructure: You can focus on working with the model, not the setup.  Access enterprise grade GPUs in a managed service.\nMinimal set up: Leverage AI Quick Actions’ service managed container for deployment and fine tuning\nFull lifecycle support: From development to deployment and monitoring.\nOpenAI’s open weight models, combined with the scalability of Oracle Cloud Infrastructure, could help accelerate your AI journey from concept to deployment.\nResources\nOCI Data Science Documentation\nAI Quick Actions Overview\nOCI Data Science GitHub"
  },
  {
    "title": "OCI Data Science Now Offers NVIDIA Nemotron Family of Open Reasoning ...",
    "link": "https://blogs.oracle.com/ai-and-datascience/oci-data-science-now-offers-nvidia-nemotron-models",
    "source": "Oracle_blog",
    "main_ideas": [
      "OCI Data Science now offers NVIDIA Nemotron models for enterprise-grade reasoning.",
      "Agentic AI is increasingly adopted to enhance productivity and automate workflows.",
      "Nemotron models provide transparency and customization for businesses using open-source data.",
      "The models are optimized for various enterprise needs, including real-time automation and complex workflows.",
      "OCI Data Science simplifies the deployment and management of machine learning models."
    ],
    "tags": [
      "nvidia",
      "oci-data-science",
      "agentic-ai",
      "open-source",
      "machine-learning",
      "enterprise-grade",
      "cloud-computing",
      "model-deployment",
      "automation"
    ],
    "original_text": "In the rapidly evolving landscape of artificial intelligence, enterprises are turning to agentic AI to help supercharge productivity, automate complex workflows, and drive intelligent decision-making. At Oracle, we remain committed to providing our customers access to leading reasoning models through both OCI Generative AI and OCI Data Science. Today, we’re thrilled to announce that OCI Data Science is making another family of enterprise-grade models available, furthering our commitment to customer choice. The\nNVIDIA Nemotron\nfamily of models can be enabled on OCI Data Science Model Deployment, providing a new option for open-source multimodal reasoning models. These models are designed to support a wide range of enterprise agentic tasks with leading compute efficiency. Furthermore, NVIDIA has used open-source data to train the models to provide full transparency and offers tools to easily customize and deploy the models, empowering businesses to adopt them with greater visibility and control.\nGreater Value for Enterprises, More Options for Access\nModel deployments are a managed resource in the OCI Data Science service used to deploy models as HTTP endpoints in OCI. Customers can clone the\nNVIDIA\nNIM\ncontainer from NVIDIA NGC to Oracle Cloud Container Registry (OCIR) and then deploy the Nemotron models to the OCI Data Science Model Deploy service. This allows customers to use these models in their own workflows, leveraging Oracle’s robust cloud infrastructure for scalable, secure AI development. After the models are deployed, OCI Data Science handles all infrastructure operations, including compute provisioning and load balancing for the model deployment.\nStep-by-step instructions on how to access and deploy these models in OCI Data Science.\nThe Rise of Agentic AI and the Need for Advanced Reasoning\nEnterprises are increasingly adopting agentic AI to help streamline operations and boost efficiency. As AI agents evolve from simple task executors to autonomous systems, reasoning models will become the cornerstone of their intelligence. These models enable agents to perceive, understand, and act across multiple modalities, including text, images, audio, video, and structured data.\nHowever, adopting existing reasoning models can present significant challenges. Many top models are proprietary, limiting customization and control over data. Open-source models, while offering flexibility, can suffer from inconsistent quality and be subject to security vulnerabilities, which erode trust. Building custom models from scratch demands enormous expertise, high-quality data, and massive compute resources, creating high barriers for most organizations.\nThe\nNVIDIA Nemotron family of models\naddress these pain points and deliver enterprise-grade reasoning and greater trust at a lower barrier to entry for organizations. Built on popular open-source foundation models like Llama, Mistral, and Qwen, Nemotron models are then post-trained with NVIDIA’s high-quality synthetic data and advanced techniques, including reinforcement learning for human-like reasoning. This results in a family of models that, according to NVIDIA, think fast and explore deeper and more diverse reasoning paths to achieve better outcomes.\nNemotron models are optimized for various enterprise needs:\nNano: Offering the highest efficiency and lowest latency, perfect for edge agents that need to deliver real-time automation.\nSuper: Delivers the highest accuracy and leading throughput on a single\nNVIDIA H100 GPU\n—ideal for balanced performance in mid-scale deployments.\nUltra: Increased accuracy for complex, multi-agent workflows, such as customer service automation, supply chain management, and IT security in data centers.\nBuild, train, deploy, and manage machine learning (ML) models\nOCI Data Science provides customers with a streamlined, efficient environment to work with foundational models from a variety of model providers. Users can choose from a growing catalog of enterprise-ready models or import any LLM from OCI Object Storage, then fine-tune and deploy via an easy-to-use interface.\nLearn more about OCI Data Science"
  },
  {
    "title": "From Air Force to Oracle: Tachina’s mission to empower veterans ...",
    "link": "https://blogs.oracle.com/jobsatoracle/from-air-force-to-oracle-tachinas-mission-to-empower-veterans-in-tech",
    "source": "Oracle_blog",
    "main_ideas": [
      "Onboarding programs are essential for veterans transitioning to civilian careers.",
      "Tachina Eva's journey from the Air Force to Oracle highlights the value of military skills in tech.",
      "Oracle fosters a supportive culture that encourages veterans to leverage their unique backgrounds."
    ],
    "tags": [
      "veterans",
      "onboarding",
      "oracle",
      "military-transition",
      "tech-industry",
      "career-development",
      "employee-retention",
      "data-centers",
      "leadership"
    ],
    "original_text": "The right onboarding program can be life-changing, offering people the opportunity to transition into new careers, gain valuable experience, and make meaningful contributions. For veterans, these programs serve as crucial bridges\nfrom military service to civilian life\nthat leverage their unique skills and experiences. Oracle recognizes the immense value that veterans bring, and we’re committed to supporting their journeys.\nMilitary to tech\nTachina Eva’s path from the Air Force to Oracle exemplifies the seamless transition veterans can achieve with the right support and opportunities.\n“Mostly it (the military) was a great background to have when you are jumping into new things,” she shares. “We are conditioned in the military to be flexible, having a learning mindset, and to embrace change. This was key in this environment because this type of work (at Oracle) is very similar in that flavor.”\nMore than five years as an aircraft maintenance officer had instilled in her a resilience and adaptability that proved invaluable in her new career. At Oracle, Tachina found an environment that valued her skills and encouraged her to take the initiative.\n“Mostly it allowed room to help when there was a void or a need. Some organizations don’t like that sort of thing and strictly want you to stay in your lane or pay grade. Here it was very much, ‘oh you have skills? Please help! We will take any ideas you have!’ I loved that aspect. I was able to use a lot of my skills that I used in aircraft maintenance.”\nThis supportive culture enabled her to apply her military-honed leadership and organizational abilities to make a significant impact from day one. It also empowered her to accelerate her growth and take on new challenges.\nRecently, Tachina accepted a new role that brought her experience full circle. Now, she’s focused on building new onboarding tailored to early career hires in our data centers. It’s challenging, rewarding, and gives her a chance to give back to the cycle of support that she benefited from herself.\n“The company genuinely supports internal growth, career exploration, and the pursuit of new interests,” she adds. “For those coming from military service, this means your journey doesn’t end when you secure your first job at Oracle. Instead, you’ll find avenues to expand your career, leverage your unique background across different teams, and keep growing in ways that match your ambitions and evolving skill set.”\nOnboarding and training for all\nAt our\nAbilene data center\n, Tachina took the initiative to design and improve onboarding and training programs, ensuring they’re accessible and welcoming to all, including anyone transitioning from military roles.\n“I have been doing grassroots designing of our onboarding and training program at Abilene—ensuring our leaders’ direction is followed in a tangible and data-driven way,” she adds. “I am dedicated to spreading the love, as it were, when it comes to helping others design programs related to the onboard/training process!”\nHer approach focuses on simplicity and flexibility, aiming to make the process straightforward so that individuals from all backgrounds can easily navigate and feel invested. A big part of this is emphasizing the importance of continuous improvement and documentation to avoid wasted effort.\n“Most of it was documenting the design of the training and onboarding programs at our new data center so we understood what was done, what worked, and most importantly, ‘why?’. A common issue we have seen was that there was a ‘reinventing the wheel’ phenomenon with many issues, so I started to write stuff down to provide future data centers a guide on how to set up training programs from scratch.”\nThis approach ensures that best practices are shared and implemented across Oracle’s data centers.\nMeasuring success\nFor Tachina, the success of these programs is measured by employee retention and development.\n“Less turnover and more development. I want people to want to stay well past the ‘respectable time.’ I want them to feel like their time at Oracle is worth more than a paycheck. I want them to have tangible and realistic avenues towards certifications, promotions, and more.”\nThis commitment to continuous improvement ensures that employees are not only welcomed but also have clear pathways for growth and advancement (like fellow veteran\nAdam Brady\n). She also highlights the importance of a supportive onboarding experience:\n“I think the key to ensuring an onboarding process is accessible and welcoming is ensuring it is always evolving to the needs of the current flow of people. I also think it’s important to have a full cradle-to-grave tracking system. We want our new onboards to know Oracle hired them for a reason. We have to show we care about their entry to our team, their onboarding experience, their training and development, and also that human touch that makes them feel wanted and valued.”\nBy focusing on the individual needs of new hires, Tachina ensures that each employee feels valued and supported from day one.\nVeterans Day reflections\nAs\nVeterans Day\napproaches, Tachina reflects on its significance in relation to her career and contributions at Oracle:\n“I once used to feel that it would be the last time I would feel I was part of something bigger than myself. Now I feel like I am part of history. Perhaps even bigger in ways—sort of like the Apollo project of sorts. My military service was a great steppingstone for a role at Oracle.”\nShe also emphasizes the importance of recognizing and honoring veterans beyond Veterans Day, ensuring their skills and experiences are valued year-round.\n“Unleash the veterans and you will get the job done,” she advises. “Giving avenues for them to show their leadership skills and creativity is the best way to make a veteran feel valued.”\nBy providing opportunities for veterans to lead and innovate, organizations can fully harness their potential.\nVeterans moving to tech\nFor veterans contemplating a transition into data center operations or the tech industry, Tachina is clear with her advice—embrace learning opportunities as a path to progression. Even unlikely ones.\n“Don’t be afraid to start small. You might be in a different career field or something, but that military edge will raise you to the top like oil on water. So don’t be too prideful to take the risk of a lower-end role to your military skill set. It’s honestly more helpful to learn from the bottom up than to try and fit in at the top.”\nThis perspective underscores the value of humility and the willingness to learn, which can lead to significant growth and success in any new field.\nOracle’s commitment\nWe’re dedicated to supporting veterans through our programs and initiatives. Our\nveteran services\noffer resources and opportunities tailored to veterans, helping them translate their military skills into civilian careers. Programs like the Oracle Veteran Academy and the Oracle Veteran Internship Program, meanwhile, provide training and development opportunities to facilitate a smooth transition into the tech industry. By fostering a supportive environment, we ensure that people like Tachina can thrive and continue to make meaningful contributions. If you’re looking to transition into a rewarding career in tech, Oracle offers a supportive community and numerous opportunities to succeed.\nWe value the unique skills and experiences that veterans bring to our workforce—explore our latest\ncareer opportunities\nto learn more. Plus, join the\nOracle Veteran Talent Network\nfor advice, insights, and more."
  },
  {
    "title": "Oracle Opportunities in Nashville: Building a Thriving Tech Career",
    "link": "https://blogs.oracle.com/jobsatoracle/oracle-opportunities-in-nashville-building-a-thriving-tech-career",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle is expanding its presence in Nashville, creating opportunities for tech careers.",
      "Franziska Eckerlin emphasizes the importance of adaptability and curiosity in hiring.",
      "Nashville's vibrant culture and educational partnerships foster innovation and community growth."
    ],
    "tags": [
      "oracle",
      "nashville",
      "tech-careers",
      "cloud-infrastructure",
      "innovation",
      "education-partnerships",
      "employee-development",
      "leadership",
      "community-growth"
    ],
    "original_text": "Franziska Eckerlin\nSenior Vice President of Business Operations and Programs\nFranziska Eckerlin, Senior Vice President of Business Operations and Programs at Oracle Cloud Infrastructure (OCI), brings over two decades of global tech experience and leadership experience to Oracle. Having been at Oracle’s Seattle hub for the past four years, she now sees Nashville as a prime destination for career growth and opportunity.\nWe spoke with Franziska to explore\nwhy Nashville\nis an exciting place to build a career with Oracle and what it takes to succeed in this dynamic environment.\nA Global Perspective on Oracle’s Culture\nWith a career in multiple corporate organizations and roles spanning from operations, to tech sales and cloud engineering, Franziska was drawn to Oracle’s market-shaping vision. “Oracle isn’t just competing for market share—it’s transforming the industry with remarkable momentum,” she says. This vision is particularly evident in Nashville, where Oracle’s campus development is accelerating and the team is creating a hub for technology innovation through education partnerships and infrastructure investments.\nNashville’s unique blend of Southern hospitality, creativity, and ambition sets it apart. “The city is hungry for growth, but has not lost its warmth and authenticity as it expands,” Franziska notes. Originally from Germany, she finds Nashville’s cultural vibrancy inspiring. “Every Uber driver I meet has their own unique idea and is so positive pursuing it. Nashville is characterized by many cultures and it creates an amazing energy and entrepreneurial spirit that I can identify with.”\nOracle’s Investment in Nashville\nOracle’s presence in Nashville extends beyond job creation. “We’re fostering a new communal feel around the tech industry,” Franziska explains. Through partnerships with local universities, Oracle is driving innovation, shaping curriculums, and providing students with hands-on tech experience. The city’s proximity to top universities such as Vanderbilt, Belmont, and Lipscomb further establishes it as a magnet for tech talent. This commitment creates a robust ecosystem that benefits both the company and the community.\nThe Nashville office offers a wide range of roles, from development engineers and product managers to data scientists and technical program managers. “We’re expanding across technical, operations, and corporate functions,” Franziska says. Oracle’s investment in employee development, including access to resources like Oracle University, ensures diverse career paths and opportunities to work on varied services, products, and infrastructure.\nBuilding a Team for Success\nWhen hiring, Franziska prioritizes adaptability, ownership, and curiosity. “Technical skills are essential, but a leading with learner’s mindset, driving accountability and direct communication are what drive success at OCI,” she emphasizes. Oracle supports career growth through robust resources, including career pathing tools and expert guidance, empowering candidates to build their desired futures from day one.\nFranziska also values creating a safe, inclusive environment where employees feel they belong. This culture, combined with Oracle’s focus on development, fosters a workplace where individuals can thrive.\nLeadership and Growth\nFor those aspiring to leadership, Franziska advises staying curious, grounded, and connected. “Leadership isn’t about having all the answers—it’s about creating an environment where people feel part of a team,” she says. At OCI, accountability and collaboration are key, enabling teams to drive innovation and achieve shared goals.\nNashville embodies this collaborative spirit, making it an ideal place to grow as a leader—whether in technical, operational, or strategic roles. With competitive relocation options, there’s no better time to join Oracle’s Nashville team.\nWhy Nashville?\n“Nashville’s ambitious community makes me feel at home,” Franziska says. For those ready to shape the future of tech, Oracle’s Nashville hub offers a unique opportunity to combine career growth with a vibrant, welcoming community. Take the leap and join a team where innovation, collaboration, and leadership converge to create lasting impact. Explore roles in Nashville\nhere\n."
  },
  {
    "title": "Oracle AI World 2025: Accelerating the AI Age",
    "link": "https://blogs.oracle.com/jobsatoracle/oracle-ai-world-2025-accelerating-the-ai-age",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle AI World 2025 emphasizes AI's transformative role in enterprise technology.",
      "The event introduced the AI Agent Marketplace for deploying AI agents in applications.",
      "Oracle launched the next-generation AI-native Oracle Database 26ai for diverse data workloads.",
      "OCI Zettascale10 offers unprecedented computational power for demanding AI workloads.",
      "The AI Data Platform simplifies the integration of generative AI with enterprise data."
    ],
    "tags": [
      "oracle",
      "artificial-intelligence",
      "cloud-computing",
      "database",
      "ai-agent-marketplace",
      "oci",
      "data-platform",
      "enterprise-technology",
      "innovation"
    ],
    "original_text": "Oracle AI World 2025 kicked off with renewed energy this year in Las Vegas, marking a transformative moment in enterprise technology. This inaugural event (formerly known as Oracle CloudWorld) underscored Oracle’s commitment to integrating AI across its product suite, empowering businesses to innovate and thrive in the AI era.\nThe four-day event was packed with reveals and keynotes that will define the next 12 months in tech. And as Oracle CEO, Mike Sicilia, put it, “We’re not just experiencing the world of AI, we’re shaping it.”\nLet’s take a look at the main announcements.\nA whole new world\nThe rename reflects the pivotal role AI now has in Oracle’s strategy. As Jennifer Smith, senior vice president of marketing services, said, “AI technologies, delivered from the cloud, are becoming the biggest differentiator for business success.” This event showcased Oracle’s dedication to embedding AI into every layer of its technology stack, from data platforms to cloud infrastructure and applications. Larry Ellison, chairman of the board and CTO of Oracle, took us deeper into the potential and shared his vision for our AI future.\nWatch Larry Ellison’s keynote\nLearn more about the AI World rebrand\nLaunch of the AI Agent Marketplace\nA conference highlight was the unveiling of the Oracle Fusion Applications AI Agent Marketplace,—an online store that lets customers buy and deploy AI agents directly within their Oracle Fusion Cloud applications. With contributions from more than two dozen partners, including Accenture, Deloitte, and IBM, the marketplace has more than 100 certified agents designed to enhance productivity and streamline processes. Executive Vice President of Fusion Application Development Steve Miranda emphasized the potential, “Because these agents are embedded inside Fusion applications, it builds context,” freeing up resources and creating new efficiencies at scale.\nLearn more about the AI Agent Marketplace\nIntroducing Oracle AI Database 26ai\nOracle also announced the next-generation AI-native Oracle Database 26ai. This release integrates AI across all major data types and workloads, including AI vector search, and supports open standards like Apache Iceberg and Model Context Protocol. Executive Vice President of Database Technologies Juan Loaiza highlighted how “In this monumental release, Oracle has architected AI and data together to create a next-generation, AI-native database… So, our enterprise customers have freedom of choice when building and deploying AI applications.”\nLearn more about AI Database 26ai\nOracle Cloud Infrastructure (OCI) AI advances\nThis year’s conference also featured the debut of OCI Zettascale10, a supercluster delivering 16 zettaFLOPS of performance across multiple data centers with up to 800,000 NVIDIA GPUs. In direct response to rising AI appetite, this infrastructure handles the most demanding AI workloads, providing businesses with unparalleled computational power. Additionally, Oracle introduced Acceleron, a high-speed ethernet-based network interconnect that enhances data flow efficiency within these superclusters.\nLearn more about Oracle’s infrastructure advances\nFueling innovation with the AI Data Platform\nWe also unveiled the AI Data Platform, a comprehensive solution that enables customers to securely connect generative AI models with their enterprise data, applications, and workflows. By combining automated data ingestion, semantic enrichment, and vector indexing with built-in generative AI tools, the platform simplifies the journey from raw data to production-grade AI. T.K. Anand, executive vice president at Oracle, noted, “By unifying data and simplifying the entire AI lifecycle, Oracle AI Data Platform is the most comprehensive foundation for enterprises seeking to harness the power of AI with confidence, security, and agility.”\nLearn more about the AI Data Platform\nShaping the future\nOf course, these innovations are just the start and our dedication to making AI accessible and actionable for businesses of all sizes was woven into the whole event. By embedding AI into core products and offering robust infrastructure, we empower organizations to harness AI’s potential to drive efficiency, innovation, and growth. For tech professionals, this evolution presents exciting opportunities to work on cutting-edge projects that shape the future of enterprise technology.\nRelive the highlights\nCouldn’t make it to Las Vegas? We have you covered! Catch every reveal, insight, and announcement whenever works for you by registering for your free on-demand pass. You’ll be able to access all available content plus subscribe to save $100 on next year’s event.\nFind out more and sign up\nWork for a company that innovates the latest AI technologies and leads the strategies that empower global business\n.\nExplore our\nlatest open roles\ntoday, and join the\nOracle Talent Network\nfor advice, insights, and more."
  },
  {
    "title": "Oracle in Nashville: A bright future for careers (and what we’re ...",
    "link": "https://blogs.oracle.com/jobsatoracle/we-are-hiring-in-nashville-scott-twaddle",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle is investing significantly in its cloud infrastructure operations in Nashville.",
      "Nashville offers a vibrant culture and local talent, aligning with Oracle's growth strategy.",
      "Oracle aims to engage with the community while creating job opportunities in Nashville.",
      "The company is focused on hiring diverse roles to drive innovation in cloud technology.",
      "Scott Twaddle emphasizes the importance of attitude and emotional intelligence in leadership roles."
    ],
    "tags": [
      "oracle",
      "nashville",
      "cloud-infrastructure",
      "job-opportunities",
      "innovation",
      "community-engagement",
      "tech-industry",
      "leadership",
      "relocation"
    ],
    "original_text": "Scott Twaddle\nSVP of OCI Product Development\nSenior Vice President of Oracle Cloud Infrastructure (OCI) Product Development, Scott Twaddle values and drives innovation and growth. After more than nine years in leadership with OCI, he’s developed a unique perspective on what it takes to succeed at the cutting edge of cloud infrastructure. Recently, we had the opportunity to sit down with Scott and discuss his exciting\nnew chapter in Nashville\n, where Oracle is making significant investments in OCI operations.\nPushing the boundaries\nScott’s journey with Oracle began in 2016, when he was drawn to the company’s mission to build the\nnext generation of cloud infrastructure\n. He fondly recalls the opportunity “to build, to create new things” as his main attractor to OCI.\nAs he reflects on the last decade and looks to the future, he recognizes that the core mission hasn’t changed. His excitement is evident as he enthusiastically acknowledges that at OCI, “we’re pushing the boundaries of cloud infrastructure delivery models, driving AI innovation, rethinking security parameters, and delivering a consistent cloud experience to companies, governments and industries that require transformational technology change.”\nAs SVP of product development, no two days are the same in such a dynamic and rapidly evolving landscape. “That’s one of my favorite things about it,” he says. “Our business is growing at a crazy rate, and that means the challenges we had yesterday are not the same challenges we have today.” Scott’s zeal for a customer-centered mindset is evident as he acknowledges that customer use cases are the epicenter of the dynamic growth. He shared that OCI customers are “constantly innovating and adding new use cases with our technology, which creates new opportunities and challenges that we need to overcome.”\nWhy Nashville?\nAs a fast-growing part of the company’s future, the location is proving itself as both an innovation center and a place to accelerate career growth. The same eagerness to build and create that brought him to OCI almost a decade ago is sparking his enthusiam about Nashville. “I’m actually a newcomer to Nashville myself,” Scott shares. “I had been to the city a few times, and now I’m excited to call it home.” After reflecting on why Nashville feels aligned with OCI’s next phase of growth, Scott shared that “Nashville has the right ingredients—a strong culture, a great place to live, and a lot of local talent.”\nThe city has always had an energy that’s uniquely its own and that’s reflected in its thriving music scene, pro sports teams, and historical sites. From the Grand Ole Opry to the local eateries serving up that famous hot chicken, there’s always something to do in Music City. In fact, Nashville’s own\nVisit Music City\nsite is great for tapping into the social and networking scene. As is the\nNashville Area Chamber of Commerce\n.\nIt’s also a city that offers a unique blend of benefits, from no individual state income tax to a high concentration of quality colleges and universities, and even two years of free community college or technical school tuition for high school seniors through the Tennessee Promise Program.\nThe culture is very much open to innovation and forward momentum in Scott’s mind. “It’s a city that’s leaning into its growth and is positioning itself on the global stage,” he says. Scott shared that what makes Nashville so appealing to him is its “balance of grounded work ethic and charm.” He shared his anecdotal experience that when he visits the Oracle office there, “it’s humming with energy—lots of people working on complex challenges and whiteboarding solutions.” Building on that hum and planning for the future go hand-in-hand. Scott shared that the growth strategy is fueled by “balancing hiring as much local talent as possible with bringing great new talent to the region to augment our teams.”\nAs a prominent business hub with a dynamic startup scene, established corporations, and a growing tech community, Nashville is already a major healthcare center that’s becoming a major player in the tech world. The growing buzz is evident to Scott who shared that “it’s already a beehive of activity here, and I think that’s indicative of the type of energy we want to build.”\nThe Oracle advantage\nThe city is set to gain from Oracle’s growing presence in more ways than one. “We’re bringing jobs, but it’s not just about the numbers,” Scott explains. “We want to be a company that’s\nengaged in the community\n, investing in the community, and bringing public benefits. We’re building a campus that will be integrated into the community. We want to be a core business partner for the city and the state, and we’re committed to growing with the city and acting as a catalyst for further growth in the tech industry.”\nAs for the types of roles and teams Oracle is building in Nashville, Scott is enthusiastic. “We’re hiring all kinds of different roles as part of Oracle Cloud Infrastructure, we’re making major investments in developers, product managers, and program managers to help drive the next phases of growth.”\nAs someone making the move to Nashville himself, Scott understands the kind of pressures that professionals (and their families) can face when relocating. He’s keen to stress that relocation packages are available to help with the transition and make it as smooth as possible. That’s along with our established\nsuite of benefits\nranging from health and wellness to family supports. “We’re focused on bringing the right talent to Nashville, regardless of where they are now,” he says. “Ideally, we find people locally, but where we can’t, we’re open to supporting a move. We’re looking for people who are bold thinkers, ambitious, and focused on building and solving hard problems.”\nTaking the lead\nNashville is full of opportunities to advance as a leader or pivot to people management from individual contributor roles. And with growth on the horizon, this is only going to accelerate. “We’re going to be hiring for many positions, including senior leaders,” Scott explains. “We’re looking for people who can create and sell a vision, who can bring people along, and who have a balance of persistence and emotional intelligence. It’s not just about deep industry knowledge—attitude is more important than specific skills. I look for people who are hungry, who want to lean in and make a difference, and who can overcome challenges and deliver results.”\nAs Scott prepares to embark on his new adventure in Nashville, he’s excited about the opportunities ahead. “Joining now means you’ll be getting in on the ground floor and there’s a lot of opportunity that comes with that,” he says. “We’re bringing innovative work to Nashville, and I fully expect the OCI Nashville office to be a wellspring of ideas and innovation that identify, create, and deliver our next generations of innovation.”\nIf you’re a program manager, applied scientist, or simply someone passionate about tech, Oracle’s Nashville office may be the perfect place to build your career, innovate on interesting challenges, and enjoy an excellent standard of living in Music City. With easy relocation and a commitment to growth, there’s never been a better time to join the team.\nLead the way at Oracle in Nashville and help drive the solutions that transform the world. Explore OCI’s\nlatest opportunities\nnow and join the\nOracle Talent Network\nfor advice, insights, and more."
  },
  {
    "title": "Breaking barriers, building dreams: Cosmo’s Oracle journey from ...",
    "link": "https://blogs.oracle.com/jobsatoracle/breaking-barriers-building-dreams-cosmos-oracle-journey-from-intern-to-pro",
    "source": "Oracle_blog",
    "main_ideas": [
      "Cosmo Trikes emphasizes resilience and adaptation in his journey as a wheelchair user.",
      "His internship at Oracle was pivotal for personal and professional growth.",
      "Cosmo aims to inspire others through his blog, WheelchairDNA, and bodybuilding pursuits."
    ],
    "tags": [
      "oracle",
      "wheelchair-user",
      "resilience",
      "bodybuilding",
      "internship",
      "personal-growth",
      "mental-health",
      "inspiration",
      "technology"
    ],
    "original_text": "A few years can seem like a lifetime or just the blink of an eye, depending on your perspective. For Cosmo Trikes, a software engineer at Oracle, time has sped by in a whirlwind of growth, challenge, and achievement—both personal and professional.\nWhen we last checked in\n, Cosmo was finishing his internship and already making a name for himself with his determination and creativity. As it turns out, he was just getting started. Today, Cosmo’s story is not only about climbing the ranks at Oracle—it’s about reaching goals and finding the flexibility to live life on his own terms.\nCosmo Trikes\nSoftware Engineer, Oracle\nNew goals, new challenges\n“So much has happened in the past two years! I think I’d hardly recognize myself if I went back,” Cosmo shares. After his internship, Cosmo achieved a series of goals many would consider out of reach—especially while balancing recovery and life as a wheelchair user. A stem cell treatment journey in Germany, bodybuilding aspirations, and an ongoing mission to walk again have defined the last year.\n“Unfortunately, the stem cell treatment didn’t work at all. I know I did everything I could, and while I was there, I gave full effort in physical therapy. The entire journey before, during, and after taught me a lot about discipline and that there are parts of life out of my control no matter how hard I work. Most importantly, I haven’t given up in the slightest on walking again. I still journal my affirmations daily, one of them being ‘I will walk!’”\nBut if there’s one theme Cosmo returns to, it’s adaptation, resilience, and just keeping going, no matter the obstacles. “While I actively wait, I have this goal on the back burner so I can bring to the front the parts of life that had to be on pause.”\nA place to grow\nIt’s an attitude he tracks all the way back before his intern days, and Cosmo’s\nOracle growth journey\nhas moved steadily uphill thanks to\na culture\nthat understands its people. “My trajectory seems like exactly what I’d expect,” he adds. “I work hard, I have a good team, I get lucky, and I get opportunities for growth. I can say that I’ve done my part of putting in the effort. It really is a testament to the great team and managers I’ve had. Those first few promotions required my manager to advocate for me and give me opportunities.”\nVisiting Oracle’s office in Singapore\nAlthough for Cosmo, it’s never just about job titles. “I’m less focused on the promotion as much as I’m focused on learning from experience and putting in my best effort each day. To me what matters is the skills and experience gained because that’s tangible.”\nBefore, he’d put a lot of stock in reaching the leadership track as soon as possible, but as his experience has grown, he sees things differently. “The more I learn, the more I realize how much more I don’t know. It’s not discouraging as much as realistic, and if anything, it motivates me because it means that the path is much longer than I thought and still full of unknowns, but I’ve got a more complete map.”\nThinking like this can benefit anyone at any career level, which is why we always encourage our people to\nbuild a career plan\nthat fits their needs and goals.\nLifting others up\nCosmo’s energy doesn’t end at Oracle’s doors. His blog,\nWheelchairDNA\nchronicles life, innovation, and big thinking as a wheelchair user, showing others what’s possible. It’s an area where the motivation was always clear. “All I knew at the time was myself, I didn’t think about how abnormal it was for me to do as much as I did. I figured I could make a few videos on YouTube and teach people how to do crazy transfers, like from the wheelchair to a plane (like a Cessna), how to open doors, how to lift weights, or simply how to put on pants!”\nTaking a chance has paid off and Cosmo has been able to reach and inspire many others with his example. “I’ve had a lot of people comment on my videos about how watching me inspired them to do a sport or just to shake off the depression and go do something. Sometimes all we need is to see someone do something, and then we realize we can do it too.”\nEnjoying the sites on a walk organized by his Singapore colleagues\nWith WheelchairDNA becoming an LLC and gaining steam, Cosmo plans to keep on building: “My personal goal is to financially support doing more videos and have it be self-sustaining. I don’t need to make money, though; the overall goal is to inspire people to really act and improve their lives by seeing what’s possible as well as seeing how with my instructional videos.”\nThe internship effect\nIn many ways, his Oracle internship was the first domino to fall in this amazing series of events. “Without having done the internship, my life would be wildly different, so much so that I can’t even begin to speculate in what ways.” For many\nstudents and early-career professionals\n, internships are a leap into new worlds. Cosmo’s was exactly that—and more.\n“I learned a lot about myself as well as about the world just by working at a big company and being exposed to so much for the first time. Maturity comes from experience along with a mind that’s open to learning from experiences.”\nHis most important takeaway, though, is that anyone can do anything. “There are some caveats, naturally, but for the most part, all it takes is time and effort,” he explains. I found myself, with unbelievable luck, joining a team with great people and a great manager who all support me and are giving me opportunities to grow.”\nAnd that’s what makes all the difference: “We had a lot of people within Oracle meet with the whole intern cohort and talk about their side of business. I learned how big Oracle is and how many opportunities to change industry exist within our company. Similarly, I learned just how many jobs there are for things I’ve never heard of, aspects of the world I’ve simply never encountered.”\nFlexibility meets bodybuilding\nIt should be clear by now that Cosmo doesn’t do anything halfway. So, when he decided to go after the Mr. Olympia stage—the Olympics of bodybuilding—it was a dream that stretched far beyond simple personal ambition. And Oracle had his back all the way with exceptional\nwork-life balance\n.\nCelebrating after qualifying for Mr. Olympia\n“I’m so grateful for everything that came before me and all the stars that aligned to enable me to do these bodybuilding shows and win. Every day must be as close to perfect as it can be—you can’t make up for three bad days with one day three times as good.”\nFlexibility and trust were to be the secret ingredients he needed for success. “It’s almost unquantifiable how important my manager has been throughout this process. The flexibility and trust that my manager gave me, the ability to work from home on days that gravity felt doubled or tripled, and the flexible vacation so that I can have time off to travel to the competitions. I still got my work done and I was available during the important hours of the day, but aside from these responsibilities, Oracle and my manager supported me to pursue my goals outside of work.”\nIt’s all added up to allow Cosmo to be both a pro software engineer\nand\na pro athlete preparing for his next big competition. “I’m now a pro athlete—an IFBB pro bodybuilder. I’m going on stage at the biggest bodybuilding show in the world,” he adds.\nOracle’s global community\nOracle’s worldwide scope means something personal to Cosmo. During a self-directed trip to Singapore (his top-ranked city on a personally engineered criteria chart by the way), he reached out to fellow employees. What happened next not only confirmed Singapore as a dream future home—it proved the value of a\nglobal, open workplace\n.\n“Everyone was hospitable and happy to show me around Singapore, give me suggestions, and include me overall. A few days after visiting the office, there was an organized group walk that I joined and got to meet even more people!”\nGetting to know his colleagues more\n“It was long enough to talk with many people and learn about Singapore and their story, what they do in Oracle and in life. I hope one day I can return the favor if any of them ever visit Colorado. I left Singapore knowing that this really is the place I want to live. It’s so cool and fun having an automatic global network of friendly people and something in common.”\nPositivity and self-care\nBehind this record of achievement is a strong commitment to mental wellness and finding joy in every day that matches Oracle’s commitment to\nemployee wellness\n. “Staying positive and motivated is difficult and there are many days I don’t have motivation, or my mind shifts to being negative. The biggest impact to help, I’ve noticed for myself, is being around friends and family. Being around good people gives me energy and a type of accountability.”\nHis advice to others is simple. Find routine, ground yourself, and make space for the small joys as well as the big ones. “The first and hardest part is for each person to figure out what makes their mental health and self-care better and worse. From there it just takes a bit of discipline to implement the routine, but soon it’s frictionless. The general trend for mental health is to slow down and find beauty in exploring and observing. Having a therapist or people to talk to helps as well.”\nVisiting the Great Sand Dunes National Park\nFor others facing difficulties—whether disability, career uncertainty, or something else—Cosmo offers one more piece of wisdom.\n“Have at least one activity that is yours. The truth is that in a wheelchair life is hard in every single aspect. No exceptions. It’s a fact that I’m not emotional about. To me it’s not a sad truth, just a truth. Living with this truth is hard at times but often isn’t so bad. Just because all parts of life are harder doesn’t mean those parts of life are now bad themselves.”\n“For anyone else who does not use a wheelchair, this still applies. Facing any challenge is specific to you, not to be compared to me or anyone else. When you face a challenge or setback, there is nothing else you can do but continue on. If you can laugh about it or realize that changes are opportunities for demonstrating your virtues, all the better.”\nReady to find a team that has your back? Discover our\nlatest opportunities\nfor interns, grads, and seasoned professionals. Plus, join the\nOracle Talent Network\nfor advice, insights, and more."
  },
  {
    "title": "AI in action at Oracle Health & Life Sciences Summit",
    "link": "https://blogs.oracle.com/jobsatoracle/ai-in-action-oracle-health-summit",
    "source": "Oracle_blog",
    "main_ideas": [
      "AI is transforming healthcare operations and enhancing patient outcomes.",
      "Oracle introduced new AI capabilities for better patient engagement and understanding of medical records.",
      "The AI Center of Excellence aims to maximize AI value across healthcare workflows.",
      "Collaboration between healthcare providers and payers is crucial for improving patient care.",
      "Oracle is committed to innovating and transforming global healthcare through advanced technologies."
    ],
    "tags": [
      "artificial-intelligence",
      "healthcare",
      "oracle",
      "patient-engagement",
      "clinical-research",
      "healthcare-innovation",
      "ai-center-of-excellence",
      "healthcare-providers",
      "payer-collaboration"
    ],
    "original_text": "AI is fundamentally changing every industry, including healthcare. This took center stage at the\nOracle Health and Life Sciences Summit\nwhere Oracle executives, customers, analysts, media, and industry leaders got together to learn how Oracle’s latest innovations can boost productivity, improve patient outcomes, and accelerate clinical research and drug development.\nChanging healthcare from the inside out\nIn this keynote from Oracle Health and Life Sciences Summit 2025, Seema Verma, executive vice president and general manager of Oracle Health and Life Sciences, explores how AI is already reshaping healthcare operations and empowering clinical teams.\nCheck out\non-demand keynotes\nfrom the Summit for powerful customer stories and patient experiences that show how we’re applying AI and other advanced technologies to help our customers transform the practice of medicine and clinical research.\nAnnouncing new innovations\nFrom the bedside to the lab—modern healthcare demands integrated solutions. Oracle announced several new enhancements to deliver on our vision to create a seamless, connected experience for both clinicians and patients; reshaping the future of healthcare through innovative technology powered by AI.\nWe’re even bringing\nnew AI capabilities to our patient portal\n, making it easier for people to understand their medical records. Soon, patients will be able to engage with new AI capabilities for secure, clear, plain-language explanations of diagnoses, test results, and treatment options using the Oracle Health Patient Portal to view their medical records.\nPatients can also ask clarifying questions about their individual medical records directly within the portal. Now, instead of struggling with jargon, users can simply ask, “What does this abbreviation mean?” Or “What was the result of my latest cholesterol test?” The AI will deliver context-aware answers instantly, helping patients better understand and manage their care.\nWe also\nlaunched an AI Center of Excellence for Healthcare\nto help customers maximize the value of AI across clinical, operations, and financial workflows. Backed by Oracle experts, the center assists organizations by providing secure cloud environments for AI experimentation, offering insights to accelerate change management, helping to create and operationalize AI agents, and providing the intelligence and best practices required to drive business transformation.\nStrengthening collaboration between healthcare providers and payers is also a key part of\nour new strategy\n. Oracle Health’s suite of AI-fueled applications will address several of these fundamental challenges to navigate a wide set of payer-specific business rules. The aim? To speed up processing on both sides, while securing timely payer responses and decisions to better meet patient care needs.\nJoin our mission\nThis year’s Oracle Health & Life Sciences Summit showcased the strides we’ve taken to transform global healthcare. It also revealed just how much potential there is for future innovation and impact.\nOur commitment to\ntransforming healthcare\nis stronger than ever—and we’re looking for passionate people to join us. As part of our team, you’ll have countless opportunities to innovate, collaborate, and make your mark on some of healthcare’s biggest challenges.\nExplore our\nlatest opportunities with Oracle Health\nnow and join the\nOracle Talent Network\nfor advice, insights, and more."
  },
  {
    "title": "What employees love about working at Oracle",
    "link": "https://blogs.oracle.com/jobsatoracle/what-employees-love-about-working-at-oracle",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle fosters a supportive workplace culture that prioritizes employee growth and development.",
      "Internal mobility programs at Oracle encourage employees to seek new opportunities within the company.",
      "Well-being initiatives at Oracle focus on mental health and work-life balance for employees."
    ],
    "tags": [
      "oracle",
      "employee-development",
      "workplace-culture",
      "mental-health",
      "internal-mobility",
      "career-growth",
      "teamwork",
      "well-being",
      "coaching"
    ],
    "original_text": "Innovation is a team effort. Our people make us who we are, and we’re committed to their success. With a supportive workplace culture and countless opportunities for growth, each member of the Oracle community is empowered to be their best self, both professionally and personally.\nOur investment in our employees runs deep—and it’s being felt around the world. Read on to discover why employees thrive with us.\nMaking career growth a priority\nBeing honored as a\nstandout employer\nis a point of confidence and motivation for company leaders.\n“It’s always refreshing to understand if we’re on the right track in supporting and enabling our employees,” says Rachna Sampayo, SVP of human resources for Oracle Asia Pacific and Japan. “If we take care of our employees well, our company and customers will naturally be beneficiaries of that.”\nChin Ying Loong\nOracle is committed to the\ncareer development\nand\ninternal mobility\nof its employees, and each day, our leaders put this commitment into practice.\n“I believe in promoting internally, and my organization shows that we give employees the first right as long as they qualify,” shares Chin Ying Loong, SVP for Oracle ASEAN and SAGE.\nOracle’s\ninternal mobility program\nfosters career development on a larger scale by encouraging people to seek out new opportunities within the company. Our career explorer tools help employees search for jobs and acquire role-specific skills and competencies, while our talent advisors guide them through our application process.\nRachna Sampayo\n“We need to continuously drive the conversations on\ngrowth opportunities\n. Growth opportunities do not only refer to promotions or relocations, but truly any new skills that can be picked up anywhere,” Rachna tells us.\nThe\nCoaching Pod program\n, launched by Oracle Asia Pacific in 2021, promotes growth and self-discovery by allowing employees to access coaching sessions for professional challenges. The experience not only empowers employees to be their best selves at work but also gives coaches the chance to give back to the community.\nThe power of well-being\nCreating a positive workplace goes beyond career development, however. Prioritizing\nmental health and well-being\nis more crucial now than ever before.\nEmployee assistance programs (EAPs) help members of the Oracle community balance their personal and professional lives with specialized programs and resources. Oracle Asia Pacific and Japan implements wellness events across all year round to advocate for employee mental health and combat workplace burnout.\nIn addition, a voluntary mental health training program was introduced to equip managers and employees with foundational knowledge on mental health conditions and stress symptoms. This knowledge has been instrumental in maintaining a safe, nurturing environment for the Oracle community during the COVID-19 pandemic.\nArshad Parvez\nConstant change\nTechnology Sales Director, Arshad Parvez relocated to Singapore in 2008 take up a position at Oracle. Though the move was a little overwhelming at first, he received a warm welcome from his colleagues.\n“My bosses at Oracle made the transition easy for me. I found a lot of great people and great mentorship here.”\nIn his 17 years with the company, Arshad has experienced five different roles and countless life changes—including marriage and fatherhood. He credits Oracle’s support of\nconstant learning\nand internal mobility for helping him grow from senior solution consultant to his current role.\n“I believe the only constant in life is change, so I try to pick up new skills or complete new courses every year,” he tells us. “If you’re looking to pursue something new, Oracle will provide the opportunity. I’ve seen many people join Oracle as an individual contributor, and now they have become senior vice presidents and are thriving.”\nNeha Dhingra Saraf\nConnections\nWith 16 years and multiple promotions at Oracle under her belt, OCI Commercial Business Director, Neha Dhingra Saraf shares a similar outlook.\n“Oracle recognizes the importance of challenging oneself and embracing new opportunities,” she says.\nWhile trainings and courses are an excellent way to learn, Neha explains that working with talented people from different parts of the world is also extremely enriching.\n“The\nrange of perspectives\nand experiences have been a valuable source of learning and growth for me. Oracle has given me the confidence to take risks, to speak up, and to build strong relationships with my colleagues in different parts of the business. People are genuinely interested in learning from each other and working together.”\nTay Kiat Hong\nEmployee perspectives\nTay Kiat Hong, cloud engineer, appreciates that teamwork and support are readily available at Oracle.\n“My team makes me feel very supported, and they give me the confidence to deal with customers’ needs,” he shares. “Oracle supports me via many channels, especially when I need certain expertise or resources.”\nThough he’s a relatively new joiner, Kiat Hong has had several opportunities to work on exciting, large-scale projects. “I was fortunate enough to be part of major events like the\nSingapore Formula 1 Grand Prix\nand the\nOracle Cloud World Tour\n. Having the chance to work on many different engagements and contribute in many different areas makes it tough to find a dull day at Oracle.”\nDeveloping together\nFor Neha, the connections she has made at Oracle have greatly contributed to her career success. Some of her roles can be directly attributed to relationships she built by helping other teams.\n“Networking is organically ingrained in the ecosystem,” she says. “I consider myself extremely fortunate to have met some phenomenal open-minded\nmentors\nand leaders throughout my career at Oracle. These individuals have played a critical role in my development.”\nKnowing that employees feel happy and supported at Oracle is certainly cause for celebration. Our work doesn’t end here, though. As times change, so will the needs of our community—and Oracle will continue to grow and adapt.\nDo you want to thrive with the global leader for AI and cloud? Check out our\nopen roles\nand learn more about\nlife at Oracle\n."
  },
  {
    "title": "A summer to remember: Oracle interns share their experiences (and ...",
    "link": "https://blogs.oracle.com/jobsatoracle/summer-interns-at-oracle",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle internships provide transformative experiences that foster personal and professional growth.",
      "Interns engage in real-world projects and innovative technologies, enhancing their skills and confidence.",
      "The internship program emphasizes community, support, and memorable team-building events."
    ],
    "tags": [
      "oracle",
      "internships",
      "personal-growth",
      "team-building",
      "innovation",
      "ai",
      "cloud-computing",
      "career-development",
      "technology"
    ],
    "original_text": "There’s a reason internship programs often spark lifelong memories—and sometimes, even change the course of a career. Oracle interns don’t just learn about corporate life—they immerse themselves in innovation, community, and personal growth. As the summer sun sets on this year’s internship season, we’re celebrating the\njourneys, lessons, and milestones\nthat our talented interns have lived along the way.\nWhether they arrived with specific career goals, a desire to push boundaries, or just the hope of meeting interesting people and building new skills, every Oracle intern left transformed and with new confidence. Check out their stories and see what makes Oracle a truly exceptional place to launch your career.\nA learning springboard\nInternships at Oracle\nare about so much more than adding lines to a resume—they’re gateways to new perspectives and powerful experiences. “It’s been an incredibly surreal experience! It’s become increasingly normal for personal, professional, and academic conversations to shift to the topic of AI—but to be part of a company that has taken incredible steps within the world of AI and cutting-edge technology has really portrayed the realities of how AI can affect me and the world around me,” shared Diya Kulkarni, a financial analyst intern.\nFor others, the Oracle experience was a childhood dream realized. Siddharth Gundavarapu , a project engineer intern, explains, “My journey to Oracle began with my parents telling me what a great company it is. My dad works in fintech and often talks about how they use Oracle products, so joining Oracle has been a dream of mine from a young age.”\nDiya’s connection to Oracle also runs deep: “My journey to Oracle actually started before I was even born! My mom worked in the Redwood Shores office for 18 years—practically my entire childhood. I grew up visiting the office and being amazed by the campus, the people, and this whole life that my mom had outside of our house. Being surrounded by an environment like that at a young age motivated me to want to follow a similar path; one where I felt constantly inspired and motivated to grow.”\nFor many, tackling real-world challenges was a true highlight. “I am constantly learning from people with such unique backgrounds and intelligence. Also, my intern class is full of brilliant people who are very fun to be around,” shared Caziah Yame, a solutions architect intern, who highlighted the importance of learning from peers as well as leaders.\nIn the end, most found support and encouragement from the moment they walked through the door. Rohit Shah a project engineer intern, reflects, “When I joined the project, I was both excited and nervous at the same time. Oracle is such a large organization, and it can feel overwhelming at times. However, I was fortunate that my team was incredibly supportive and welcoming. That early support made a big difference in helping me settle in.”\nDriving impact\nIt may sound strange to say that no two Oracle internships look the same. But with opportunities in solutions engineering, cloud infrastructure, hospitality, consulting, finance, and beyond, our cohorts are as unique as they are talented. And one thing unites them all: the chance to be part of something bigger.\nEvery summer, Oracle’s internship program proves that fresh ideas and early-career talent can make a big difference. And for those at the heart of Oracle’s engineering initiatives, it’s a rare chance to help build what’s next. Through a balance of team and individual work, all participants learn just what it takes to make major projects a reality.\n“I think the best way to describe it is nothing short of amazing. Between the technologies I’ve learned, impact I’ve already had, and support I’ve received, this summer is turning out to be more than just a three-month job writing code; it’s a three-month taste of a career absorbing new perspectives, learning new things, and making software with an impact,” said Justin Brand, a member of our engineering intern cohort.\nFrom the moment he embedded with his team, it was clear to Justin that he wasn’t just along for the ride—he was getting the opportunity to make a real difference to his n\new colleagues.\n“The first of four projects I got this summer entailed automation of deployments from builds to our test environment. A week after my changes were published, people on my team were already commenting on how much time it saved them—time they could spend on tasks with far greater return,” he adds.\nJeff Malcolm Jr., a software engineer intern with Oracle Cloud Infrastructure, described the moment his project came alive: “I built an application that allowed our technical project managers to view the responses from our Oracle Code Assist API. This granted our data scientist the ability to fine-tune the model for content moderation and better output.”\nTeam experiences\nLearning is crucial, but Oracle internships are also about fun, adventure, and making real connections. This year, the internship program team hosted a series of unforgettable events to help interns bond, unwind, and\nbuild their networks\n—from major league baseball games to global scavenger hunts, each event brought our interns closer together and helped create lasting professional relationships all around the world.\nThese outings proved that genuine teamwork and camaraderie don’t end at the whiteboard. The scavenger hunt was a fan favorite, bringing together interns from across disciplines for laughs and creative challenges that set the tone for the rest of the summer. Meanwhile, the baseball games—complete with hot dogs, cheering crowds, and team selfies—offered a chance to meet peers in a relaxed environment.\nAs Diya notes: “The biggest highlight of my internship has definitely been always having something to look forward to. Be it the Global Intern Program events, my mentor and team, or the fellow interns, I walk into the office every day ready to learn something new and meet someone new. No day has looked the same, and that has become an incredibly motivating factor for me to get up in the morning and want to come to work.”\nCulture with impact\nStepping into Oracle’s world, even for just a short time, means contributing to projects that matter—and being embraced by colleagues determined to see you thrive. “My favorite part has been meeting people and getting used to a growth-fostering environment with coworkers that want to help you along the way,” explains sales development intern Devyn Parsley. “At our last team meeting, we had the highest number of responses to an event invitation and the manager was very proud and said ‘Well, I can’t take the credit here, it was really the interns that worked on that outreach.’”\nThis sense of belonging is universal among Oracle interns. “\nHaving a mentor\nhas been like having a big sister here. I have felt so secure and at ease knowing that I can ask questions of someone who is specifically paired with me for my growth and is not going to ever judge me for questions I ask, or mistakes I admit to. My mentor has been a source of encouragement and confidence as she has helped me grow by providing support, answers, and feedback in a kind and gracious way,” she shares.\nUnmatched opportunities\nReflecting on the journey, sales intern Chloe Vinson shares, “I knew this was a valuable experience halfway through the internship. Not only did I learn about Oracle as an organization but also what to look for in a professional atmosphere. I have experienced a lot of firsts during my time here.”\nWhy do so many interns say they can’t wait to come back—or recommend Oracle to others? It’s simple. As intern after intern has shared, Oracle offers a rare mix of learning, challenge, and true care for each individual’s growth and well-being.\nReady to unlock your own incredible intern story? Explore our internship opportunities all year round and see what’s possible on our\ngraduate and intern site\n. Plus, join the\nOracle Talent Network\nfor advice, insights, and more."
  },
  {
    "title": "Oracle Analytics Cloud MCP Server: Bridging Enterprise Analytics and ...",
    "link": "https://blogs.oracle.com/analytics/oracle-analytics-cloud-mcp-server-bridging-enterprise-analytics-and-ai",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle Analytics Cloud empowers organizations with AI-powered analytics for data-informed decisions.",
      "The new MCP Server connects OAC with external AI clients for natural-language data exploration.",
      "Governance and security are enforced during query execution to protect sensitive data."
    ],
    "tags": [
      "oracle",
      "analytics",
      "cloud-computing",
      "ai",
      "data-governance",
      "natural-language-processing",
      "automation",
      "machine-learning",
      "business-intelligence"
    ],
    "original_text": "​\nOracle Analytics Cloud (OAC) empowers organizations with modern, AI-powered analytics — delivering dynamic visualizations, interactive dashboards, and real-time insights that drive confident, data-informed decisions across the enterprise.\nBuilt on Oracle’s secure and scalable cloud infrastructure, OAC unifies data preparation, semantic modeling, machine learning, and governed self-service analytics into one platform. It enables everyone — from business users to data engineers — to work with consistent, trusted data while exploring insights interactively.\nThe Oracle Analytics Cloud November 2025 update introduces a new capability: the Oracle Analytics Cloud Model Context Protocol (MCP) Server. This feature connects OAC with external AI clients such as Claude Desktop, Cline (VS Code extension), and GitHub Copilot, enabling users to explore governed data through natural-language conversations. The MCP server also integrates with agentic workflows and automation platforms such as n8n and LangChain, opening new possibilities for AI-driven analytics automation.\nOAC already includes powerful AI features such as the AI Assistant, which allows users to ask natural-language questions directly within Oracle Analytics Cloud. The Oracle Analytics Cloud MCP server complements these capabilities by extending OAC’s reach into external AI ecosystems and agentic workflows.\nThe key difference: The AI Assistant provides conversational analytics\ninside\nOAC’s user interface, while the MCP Server enables\nexternal\nAI agents and automation workflows to query and analyze governed OAC data\nfrom outside\nthe platform — effectively bridging enterprise analytics with autonomous AI agents and intelligent automation workflows. ​\n⚠️\nImportant Note on Security and Data Handling\nBefore connecting external AI clients, it’s important to understand how security boundaries are maintained.\nThe Oracle Analytics MCP Server provides secure, token-based access to governed data within OAC. However, once data leaves OAC and is processed by an external AI client or agentic workflow, the data becomes subject to that client’s own data-handling, storage, and governance policies. Customers must ensure that any connected MCP client or automation platform complies with their organization’s security, privacy, and AI-use policies. While OAC enforces governance during data access, what happens to the data after it leaves OAC depends entirely on the external system’s configuration and policies.\nFeature Overview: Oracle Analytics Cloud MCP Server\nThe OAC MCP server bridges governed enterprise analytics and conversational AI. Built on the\nModel Context Protocol (MCP)\n— an open standard that enables secure, context-aware communication between AI systems and enterprise applications — the OAC MCP server allows users to query and explore OAC content using everyday language.\nCore Capabilities\nOAuth 2.0 Authentication:\nStandards-based, secure token authentication ensures only authorized users can access data.\nDynamic Query Generation:\nNatural-language questions or prompts are converted into Logical SQL (LSQL) dynamically by the connected LLM on the fly. The generated LSQL is then sent to OAC where governance is enforced during execution.\nGovernance Enforced During Execution:\nWhen LSQL queries are executed in OAC, role-based and row-level security are applied according to existing user permissions.\nTrusted Data Access Through Semantic Layer (if present):\nWhen a semantic model (RPD) is deployed in OAC, it provides a trusted business abstraction layer, ensuring consistent metrics, calculations, and business logic across all LLM-generated queries. Where no semantic model exists, datasets (XSA) serve as the governed access layer, applying the same role-based security and permissions framework to ensure controlled access to underlying data sources.\n🔍 Discover · Describe · Execute\nAt the core of OAC MCP server are three foundational tools that define the conversational analytics workflow.\nDiscover\n(\noracle_analytics-discoverData\n): Lists available datasets and subject areas, helping AI clients identify what data exists.\nDescribe\n(\noracle_analytics-describeData\n): Retrieves dataset metadata (tables, columns, measures, and hierarchies) helping the AI understand relationships and business meaning.\nExecute\n(\noracle_analytics-executeLogicalSQL\n): Executes Logical SQL (LSQL) generated dynamically by the connected LLM, applying OAC’s role-based security, filters, and caching. Depending on configuration, the query may run through the semantic model or directly against a XSA dataset, but in all cases, OAC enforces governance and access control at execution.\nAdditional MCP tools will become available in the future to extend these capabilities.\n📘 Resource: Logical SQL Grammar Reference\nAlongside the three tools, OAC MCP server provides a key resource — the Logical SQL Grammar Reference. This resource helps AI clients:\nUnderstand and construct valid OAC Logical SQL syntax.\nGenerate queries aligned with OAC’s semantic model and business rules.\nEnsure consistency and accuracy when transforming natural-language questions into executable queries.\nHow It Works:\nThe LLM uses this grammar reference along with metadata from Discover and Describe operations to dynamically generate LSQL queries. The generated LSQL is then sent to OAC, where it is validated and executed within OAC’s governed environment. When a semantic model is used, it adds an extra abstraction layer that shields underlying schemas and enforces consistent business logic across queries. When datasets are used directly, OAC’s security model continues to govern access.\n🔐\nSecurity Note:\nWhile OAC enforces complete governance during query execution (authentication, authorization, row-level security), the LSQL itself is generated by the external LLM. Once query results are returned to external AI clients, data handling depends on those clients’ retention and processing policies. For sensitive data environments, consider using enterprise LLM configurations with zero-retention policies or deploying local or OCI-hosted LLMs within your own infrastructure.\nUser Benefits\nPersona\nBenefit\nExecutives\nAsk business questions conversationally — get governed answers instantly.\nAnalysts\nExtend self-service analytics using natural language, accelerating insight discovery.\nDevelopers\nEmbed conversational insights into applications and build AI-powered analytics experiences.\nData Engineers\nValidate data quality and troubleshoot issues conversationally, reducing time to resolution.\nAutomation Teams\nIntegrate OAC into agentic workflows (n8n, LangChain) for intelligent, data-driven automation.\nSetup Guide (15–20 Minutes)\nPrerequisites\nOracle Analytics Cloud instance\nClaude Desktop, Cline, or Copilot (the setup example uses Claude Desktop)\nNode.js v18 or higher\nWindows, macOS, or Linux\nStep 1 – Generate Access Tokens\nLog in to OAC using\nhttps://<your-oac-host>/ui\n.\nNavigate to your\nUser Profile\n, and go to the\nAccess Tokens\nsection.\nClick\nDownload Tokens\n.\nThe file automatically downloads as\ntokens.json\n.\nSample tokens.json:\n{ “accessToken”: “eyJ4NXQjUzI1NiI6...”, “refreshToken”: “AgAgNzRjNDQxOWI...”, “expiresIn”: xxxxx }\n🔐 Access tokens inherit your OAC privileges. Store them securely.\nIf you use the MCP Connect script instead, you can sign in interactively — no manual token file is required, and token refresh is handled automatically.\nStep 2 – Download the MCP Connect Package\nIn OAC, navigate to your\nUser Profile\n, and go to\nMCP Connect\nsection.\nClick\nDownload\n.\nExtract the downloaded ZIP to a local path such as\nC:\\MCP\\oac-mcp-connect\\\n(on Windows) or\n~/MCP/oac-mcp-connect/\n(on macOS/Linux).\nThe extracted package includes:\noac-mcp-connect.js\n–\nNode.js\nimplementation of the OAC MCP server.\noac_mcp_connect_config-template.json\n– Sample configuration file.\nREADME.md\n– Comprehensive setup and usage documentation.\nlib/\n– Required dependency libraries\nOnce extracted, this folder serves as your working directory for running the OAC MCP server and connecting OAC with external AI clients.\nStep 3 – Install Node.js\nDownload and install\nNode.js(v18+\n) from\nnodejs.org\n.\nVerify the installation by opening a terminal/command prompt:\nnode -v\nnpm -v\nBoth commands should return version numbers, confirming successful installation.\nStep 4 – Install Dependencies\ncd /oac-mcp-connect/\nnpm install\nThis command reads the package dependencies and installs all required libraries.\nStep 5 – Configure Claude Desktop\nEdit your Claude configuration file:\n–\nWindows\n:\nC:\\Users\\\\AppData\\Roaming\\Claude\\claude_desktop_config.json\n–\nMac:\n~/Library/Application Support/Claude/claude_desktop_config.json\nAdd the OAC MCP server configuration in\nclaude_desktop_config.json\n:\nWindows example:\n{ \"mcpServers\": { \"oac_mcp_connect\": { \"command\": \"C:\\\\Program Files\\\\nodejs\\\\node.exe\", \"args\": [ \"C:\\\\MCP\\\\oac-mcp-connect\\\\oac-mcp-connect.js\", \"https://<OAC-INSTANCE>.analytics.ocp.oraclecloud.com\", \"C:\\\\MCP\\\\tokens.json\" ], \"description\": \"Oracle Analytics Cloud MCP Server\" } } }\nMacOS example:\n{ \"mcpServers\": { \"oac-mcp-connect\": { \"command\": \"node\", \"args\": [ \"/path/to/oac-mcp-connect.js\", \"https://<OAC-INSTANCE>.analytics.ocp.oraclecloud.com\" ], \"description\": \"Oracle Analytics Cloud MCP Server\" } } }\nRestart Claude Desktop (quit and reopen).\nStep 6 – Verification\nOpen Claude Desktop and start a new chat.\nLook for the\nSearch and Tools\nsection in the chat interface.\nClick\noac_mcp_connect\n(or your configured MCP server name) and expand it.\nYou should see these OAC tools:\n✅\nOA: Discover Data\n— Lists available datasets and subject areas.\n✅\nOA: Describe Data\n— Retrieves dataset metadata and structure.\n✅\nOA: Execute Logical SQL\n— Executes natural-language queries using LSQL.\nWhen all three tools show as Connected and your integration is ready to use.\nNext Steps: Start Exploring Conversational Analytics\nOnce the connection is established, you can immediately begin exploring your data through your AI client. Try these conversational prompts to validate your setup:\nDiscover:\n“\nWhat datasets are available in my OAC environment?\n”\n→ Returns available subject areas and datasets.\nDescribe:\n“\nDescribe the Sales Overview dataset.\n”\n→ Lists dimensions, measures, and hierarchies.\nExecute:\n“\nShow total revenue by region for 2024.\n”\n→ LLM generates LSQL, OAC executes the query with full governance enforcement, and returns results.\nYou can continue the conversation contextually — asking follow-up questions, drilling into details, or exploring different aspects of your data.\nAuthentication and Token Management\nThe OAC MCP server authenticates clients using OAuth 2.0 access tokens, ensuring secure, standards-based access to Oracle Analytics Cloud.\nWhen launched through the MCP Connect utility, a browser window automatically opens for secure sign-in, and token acquisition and refresh are handled transparently for the user session.\nAlternatively, users can manually download an access token file (\ntokens.json\n) from their OAC user profile page and provide it to the script for testing or automation scenarios.\nToken expiry information can be viewed in OAC under\nAccess Tokens\n. For sessions started using MCP Connect, token refresh is handled automatically.\nFor detailed authentication configuration, advanced parameters (\n--insecure\n,\n--chrome-path\n,\n--service-instance-key\n), and troubleshooting guidance, refer to the README.md file included with the MCP Connect utility.\nData Security Considerations\nFor sensitive data scenarios:\nUse enterprise LLMs with zero-retention policies.\nDeploy local or OCI-hosted LLMs where possible.\nWork with aggregated or masked datasets.\nAlign with organizational compliance standards.\nSummary\nOracle Analytics Cloud already empowers users with rich visualizations, governed data models, self-service analytics, and the AI Assistant for natural-language querying within OAC.\nWith the OAC MCP Server, analytics now extends beyond the OAC interface into a broader ecosystem of AI tools and intelligent automation platforms. You can query governed data in plain English through your preferred AI client, explore relationships conversationally, and integrate analytics into agentic workflows — all while OAC enforces full governance during query execution.\nThe\nAI Assistant and MCP Server are complementary:\nOAC AI Assistant:\nConversational analytics\ninside\nOAC’s user interface for interactive data exploration.\nOAC MCP Server:\nExternal integration layer enabling AI clients and automation platforms to access governed OAC data from\noutside\nOAC.\nBy combining Oracle’s enterprise governance with AI-driven natural language understanding, the OAC MCP server transforms data interactions into intelligent dialogues, extending the reach of analytics to anyone who can ask a question — whether they’re using Claude Desktop, building agentic workflows in n8n, or creating AI-powered applications with LangChain.\nCall to Action\nOracle Analytics Cloud MCP server is available now in the November 2025 update. For a quick introduction to the Oracle Analytics MCP Server, check out this\nYouTube video\n.\nGet Started Today\n✅ Connect to your OAC instance from AI clients.\n✅ Explore the Discover → Describe → Execute\nworkflow to find, understand, and analyze data conversationally.\n✅\nBuild agentic workflows\nusing n8n or LangChain to automate analytics-driven decision making.\nStay Tuned for Upcoming Blog Articles\n📝\nUnderstanding the OAC MCP interaction flow\n—\nA conceptual overview of how AI clients interact with governed analytics.\n📝\nAutomating token refresh\n— Maintaining uninterrupted AI connections for production use.\n📝\nEnd-to-end conversational analytics demo\n— Real-world examples using the OAC MCP server.\n📝\nInline machine learning with OAC\n— Combining analytics and AI/ML in conversational workflows.\n📝\nBuilding agentic workflows\n— Integrating OAC with n8n and LangChain.\nJoin the Community\nHave questions or want to share your journey?\nJoin the conversation in the\nOracle Analytics Community\n, connect with other practitioners, and get expert insights.\nLearn More\nTo learn more about OAC:\nVisit the\nOracle Analytics product page\nFollow\ntwitter@OracleAnalytics\nRead the documentation on\nOracle Help Center\n​ ​"
  },
  {
    "title": "Enhancements to the Limit Values By Setting for Filters in Oracle ...",
    "link": "https://blogs.oracle.com/analytics/enhancements-to-the-limit-values-by-setting-for-filters-in-oracle-analytics",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle Analytics enhances Limit Values By setting for filters in workbooks.",
      "The changes improve consistency but may break existing workbook setups.",
      "A bug fix restricts custom filter options to the same location only.",
      "Users are encouraged to analyze and fix affected workbooks before the rollout completes.",
      "The enhancements will be rolled out in phases to allow user adjustments."
    ],
    "tags": [
      "oracle",
      "analytics",
      "filters",
      "workbooks",
      "bug-fix",
      "data-visualization",
      "software-update",
      "business-intelligence",
      "cloud-computing"
    ],
    "original_text": "Oracle Analytics is introducing enhancements and a critical bug fix to the Limit Values By setting for filters in workbooks. These changes improve consistency but also introduce a change in behavior that could break existing workbooks depending on how they’re set up. This article explains the change, its impact, what actions you need to take, and how the change is being rolled out.\nWhat is “Limit Values By”?\nIn Oracle Analytics workbooks, you can configure the Limit Values By setting for each filter.\nFilters can exist in different locations and at different scopes:\nFilter bar (pinned / workbook filters at the workbook scope and unpinned / canvas filters at the canvas scope)\nDashboard filters (canvas scope)\nVisualization filters (visualization scope)\nYou can use the setting to control the values that are available to select for one filter based on the selections made for other filters, whether they’re in the same location or not.\nThe options for the Limit Values By setting are:\nDefault\nAuto\nNone\nCustom\nFor more information about how the Limit Values By settings work and how to use them, refer to this\ndocumentation\n.\nThe Old Behavior Versus the New Behavior\nThe enhancements make the Limit Values By behavior more intuitive based on filter location.\nPreviously, if a filter’s Limit Values By setting was set to Auto, it wasn’t affected by other filters in the same location that were in a lower scope, even if the columns they were based on where higher up in a drill-path.\nWith the enhancements, the filter is now affected by other filters in the same location that are based on a column that’s higher up in a drill path (even if they are in a lower scope).\nPreviously, if a filter’s Limit Values By setting was set to None, it wasn’t affected by any other filters, no matter their scope or location.\nWith the new enhancements, no matter what a filter’s limit values by setting is set to, it will always be affected by all filters from different locations of the same scope or higher unless specifically prevented by the Filter This Viz By settings.\nThe Bug in the Old Behavior\nPreviously, when you used the Custom option for Limit Values By, the list that you could select from included filter columns from a higher filter scope. For example, you could limit a dashboard filter, like Product, by a filter in the filter bar, like Product Type.\nLimit Values By custom option allows column selection from all filter locations\nTo specifically ensure that any selections made for the higher filter, Product Type, don’t impact the dashboard filter, you would use the Filter This Viz By property for the dashboard filter visualization and deselect Product Type there.\nIn this example, Product filter on dashboard filter is not filtered by the Workbook filter columns (different filter location)\nHowever, the bug allowed consumers to override your Limit Values By settings in this situation.\nSince they could access the Limit Values By setting for the dashboard filter, they could manually add the filter bar columns back to the custom list by selecting them, thus breaking your intended filter relationships.\nIn Consumer view: consumer can over-ride author designed Limit Values By experience on the filter column\nThe Bug Fix and Impact on Existing Workbooks\nThe enhancements fix the bug by restricting the custom option to filters in the same location only.\nThis ensures you maintain full control over filter interactions and prevents consumers from bypassing your intent as an author. This new behavior is also more intuitive by ensuring the Filter This Viz By property and Limit Values By settings don’t conflict with each other.\nAuthor cannot choose a (filter) column from a higher scope\nThis bug fix will impact workbooks that meet all the following conditions:\nThe Filter This Viz By property for a dashboard filters visualization is configured to prevent filters in the filter bar from affecting the filters in the visualization.\nThe Limit Values By option for the dashboard filters visualization is set to Custom.\nThe Custom list includes filter bar filter columns.\nWith the new behavior, the Custom list will no longer display filters from higher locations which could potentially leave the dashboard filter with no filters in its Custom list. Additionally, a different set of values may be shown for the dashboard filter than expected.\nHow to Fix Affected Workbooks\nYou can use the Filter This Viz By property for the affected visualization to prevent filters from a different location with the same or higher scope from having an effect.\nOpen the affected workbook.\nSelect the affected visualization.\nGo to the Properties pane and click the Filters tab.\nIn Filter This Viz By section, select the filter columns you want the visualization to be filtered by.\nSave the workbook.\nRollout Plan\nOracle is rolling out the enhancements to the Limit Values By settings in phases to give you time to adjust.\nOracle Analytics Cloud Customers\nJuly and September 2025 update: A new Console setting—Enable Enhancements to Limit Values By—is OFF by default. Customers can turn this setting ON to test the new behavior.\nNovember 2025 update: The Console setting is ON by default. Customers can turn this setting OFF to temporarily retain the old behavior while they fix workbooks.\nMarch 2026 update: The Console setting will be removed and  the new behavior is permanent.\nOracle Analytics Server Customers\nMarch 2026 update: A new Console setting—Enable Enhancements to Limit Values By—is ON by default. Customers can turn this setting OFF to fall back to the old behavior.\nCall to Action for the Oracle Analytics Community\nTo take full advantage of the improved usability of the Limit Values By functionality and to ensure a smooth transition, we strongly encourage you to:\nAsk your administrator to turn the Console setting on so you can test the new behavior.\nAnalyze all workbooks for potential impact.\nFix your affected workbooks using the steps provided in this article.\nShare feedback with the Oracle Analytics product team to help refine the experience.\nResources:\nWatch this\nvideo\nfor a demonstration of the Limit Values By functionality.\nFor more information about Oracle Analytics go to\nhttps://www.oracle.com/business-analytics/\nFor documentation, visit the\nOracle Help Center\n."
  },
  {
    "title": "Oracle Analytics Cloud November 2025 Update",
    "link": "https://blogs.oracle.com/analytics/oracle-analytics-cloud-november-2025-update",
    "source": "Oracle_blog",
    "main_ideas": [
      "The November 2025 update enhances data visualization and analysis capabilities in Oracle Analytics Cloud.",
      "New features include column swapping, shared filters, and Gantt chart visualizations for better data management.",
      "Oracle Analytics AI Assistant is now available on mobile, improving accessibility and interactivity for users.",
      "The update streamlines modeling and administration tasks, allowing for bulk edits and custom consistency checks."
    ],
    "tags": [
      "oracle",
      "analytics",
      "cloud",
      "data-visualization",
      "ai-assistant",
      "gantt-chart",
      "data-management",
      "semantic-modeling",
      "mobile-analytics"
    ],
    "original_text": "The\nOracle Analytics Cloud (OAC)\nNovember 2025 update brings an exciting array of innovations to transform how users visualize, analyze, and act on data across their organization. With new enhancements spanning data visualization, AI-driven insights, semantic modeling, and streamlined administration, this release empowers users to uncover trends faster, personalize their analytics experience, and manage data assets with greater flexibility. From easy column swapping and powerful filter controls to the latest Oracle Analytics AI Assistant features and enhanced bulk editing capabilities, the November update offers a robust toolkit for every data journey.\nFeatured highlights:\nData Visualization and Experience\nOn-Viz Column Swap\nShared Filter Groups\nGantt Chart Visualization\nBetter Leveraging Filters Limit Values\nConditional Formatting on Date Columns\nAI and Gen AI\nOracle Analytics AI Assistant on Mobile\nOracle Analytics AI Assistant on the Home Page\nEmbedding Capabilities for Oracle Analytics AI Assistant\nModeling, Preparation, and Connectivity\nSubject Areas as Sources for Data Flows\nCustom Consistency Checks in Semantic Modeler\nBulk Edits in Semantic Modeler\nAdministration\nEasily Access Tokens for APIs\nMCP Server for Oracle Analytics\nData Visualization and Experience\nOn-Viz Column Swap\nAs a consumer user of the workbook, you can now use the axis labels such as the x axis, y axis, or legend labels to quickly swap columns and dynamically slice and dice the data within a chart. The columns available for swapping are defined by the workbook author, making it easy to explore different perspectives without extra setup. For example, a user might switch between sales, discounts, or quantities on a bar chart to compare performance across regions and uncover actionable business insights.\nShared Filter Groups\nWorkbook authors can create filter groups as reusable objects, known as shared filters, tied to a dataset or subject area. This feature, currently available in public preview, makes it easy to define and manage sets of filter criteria, such as selecting certain customer segments, that can be shared and reused across multiple workbooks. For instance, if an organization wants to consistently highlight customers based on specific purchase behaviors, shared filter groups ensure the same criteria are applied throughout all relevant analyses.\nGantt Chart Visualization\nThe out-of-the-box Gantt chart lets users easily visualize schedules, tasks, or timelines directly within their analytics workbooks. Gantt charts help users manage projects, resources, or events by displaying both planned and actual dates for activities in a clear timeline view. Organizations such as hospitals can use this feature to track which surgeons are scheduled in operating rooms throughout the day, allowing for quick adjustments and better coordination.\nBetter Leveraging Filters Limit Values\nThe improved limit values by functionality for filters gives workbook authors precise control over how filter values are affected by selections in different locations, such as the workbook filter bar, dashboard filters, or individual visualizations. Authors can define whether column values like city or category should be influenced by other filter selections, even when those filters are in separate areas of the dashboard. This update makes it easier to design dashboards where users see only the most relevant choices for each context.\nConditional Formatting on Date Columns\nWith enhanced conditional formatting, you can now create rules that compare dates and automatically format your data based on defined criteria. This makes it easy to highlight important trends or exceptions, such as orders shipped after their order date or sales in specific years with high profits. Users can quickly apply color coding and other formatting options to tables and pivot tables, making insights stand out for faster analysis and decision making.\nAI and Gen AI\nOracle Analytics AI Assistant on Mobile\nThe Oracle Analytics AI Assistant is now available in the analytics mobile app, providing a quick and interactive way to explore data on the go. Users can launch the Oracle Analytics AI Assistant with a tap and ask questions by text or voice, receiving instant narrative explanations, visualizations, and a list of related artifacts to help explore the topic further. With features like saving visualizations to a watch list, sharing insights, listening to narrated summaries, and switching data context, users can stay informed and make decisions from anywhere, such as monitoring sales performance by location or quickly investigating new trends.\nOracle Analytics AI Assistant on the Home Page\nNatural language support on the home page has been enhanced, introducing new capabilities that make exploring and using Oracle Analytics Cloud even easier. Users can now search for assets using natural language queries and continue conversations with incremental follow-up questions, allowing for richer, more interactive analysis. These improvements enable users to refine results, build tailored dashboards, and quickly uncover insights, all through an intuitive, conversational interface.\nEmbedding Capabilities for Oracle Analytics AI Assistant\nThe embeddable Oracle Analytics AI Assistant lets you easily add interactive, conversational analytics to web pages or applications, using a simple tag and a reference to the relevant data source. Users can place the AI Assistant alongside dashboards or within custom apps, enabling them to ask natural language questions and instantly explore data without leaving their app or switching windows to open Oracle Analytics Cloud. Whether tracking sales by location or monitoring inventory within a custom solution, embedding the AI Assistant creates a seamless analytic experience right where decisions are made.\nModeling, Preparation, and Connectivity\nSubject Areas as Sources for Data Flows\nWith the November update you can add subject areas directly as input to data flows without needing to create a local subject area first. This streamlined approach makes it easier to explore and prepare your data, as columns can be selected, renamed, reordered, and even searched for, all from an intuitive interface. Users can quickly build curated datasets by combining and transforming data from different subject areas with just a few clicks.\nCustom Consistency Checks in Semantic Modeler\nYou can now enforce your organization’s unique semantic model development standards by creating custom consistency check rules in the semantic modeler. These rules allow teams to define and automatically validate specific requirements, such as ensuring all subject area tables have descriptions, right within the modeling workflow. By using custom rules, organizations can ensure that data models are consistent and up to internal standards across projects.\nBulk Edits in Semantic Modeler\nThe Bulk Edit feature allows users to efficiently add, remove, or update permissions and tags for multiple objects at once, rather than editing each item individually. With simple search and selection tools, you can quickly modify access rights and categorize tables or other objects in bulk, streamlining management tasks. This is especially useful for maintaining consistency across related objects, such as updating permissions or applying new tags to a group of tables linked to the same data source.\nAdministration\nEasily Access Tokens for APIs\nOAuth 2 access tokens are essential for making API calls to the Oracle Analytics Cloud REST API or for testing embedded content that requires authentication. Easily obtain access tokens by navigating to your profile, enabling developer options, and selecting the access tokens option. From there, you can copy an access token directly or use the provided refresh token and sample code to obtain new tokens programmatically.\nMCP Server for Oracle Analytics\nThe Model Context Protocol (MCP) server enables powerful connections between Oracle Analytics and AI-powered tools like custom code, Claude desktop or VS Code. Using access tokens, users can easily authenticate and configure clients to discover data assets, analyze datasets or subject areas, and run queries to get data which allows your agent to automate actions based on insights found in Oracle Analytics.\nKey Takeaways\nThe November 2025 update to Oracle Analytics Cloud introduces new features and enhancements designed to make data visualization, exploration, and management more powerful and intuitive. With capabilities like column swapping, shared filters, Gantt chart, advanced filter controls, Oracle Analytics AI Assistant available in mobile, and improved modeling and administration tools, users can gain deeper insights, streamline workflows, and collaborate with greater ease. Enhanced governance, smarter automation, and flexible data experiences ensure this release empowers organizations to drive impactful, data-driven decisions throughout their analytics journey.\nFor more information:\nWhat’s New for Oracle Analytics Cloud\nYouTube November 2025 Feature Playlist\nOracle Analytics Community\nOracle Analytics Product Roadmaps"
  },
  {
    "title": "Building materials specialists exploits data to get a grip on sales",
    "link": "https://blogs.oracle.com/analytics/building-materials-specialists-exploits-data-to-get-a-grip-on-sales",
    "source": "Oracle_blog",
    "main_ideas": [
      "Juman utilizes Oracle Fusion Cloud ERP to optimize business processes and enhance data analytics.",
      "The transition to Oracle Fusion Data Intelligence has improved decision-making and reporting efficiency.",
      "Management can access real-time data insights, leading to better sales performance and issue resolution."
    ],
    "tags": [
      "juman",
      "oracle-fusion",
      "data-analytics",
      "cloud-computing",
      "business-intelligence",
      "sales-management",
      "erp",
      "saudi-arabia",
      "construction-industry",
      "digital-transformation"
    ],
    "original_text": "From its headquarters in Dammam, a vibrant port city in Saudi Arabia’s Eastern Province, Juman focuses on investing and operating joint ventures and wholly owned subsidiaries in building materials. Founded in 2005, but with a history that extends over 35 years, Juman and its subsidiaries operate around 150 thousand square meters of manufacturing land; offices that cover the Middle East, Africa, and southern Europe; and partnerships with the most recognized building material multinationals.\nThe Juman Group of Companies, through subsidiaries, have worked on projects as diverse as SeaWorld in Abu Dhabi, the John Hopkins Aramco hospital in Dhahran, and the Coca-Cola arena in Dubai.\nTransforming business operations\nIn 2020, Juman chose to optimize their business processes by deploying Oracle Fusion Cloud ERP across the whole group of companies and joint ventures. Their project delivery roadmap started with three of Juman’s businesses:\nGerflor Middle East: since 1976, Gerflor Group has been known for their high-quality and durable flooring solutions, specializing in manufacturing vinyl flooring systems, including rolls, tiles, and Rigid Luxury Vinyl Tile.\nUSG ME: founded in 1902 as United States Gypsum Company, USG are a leading manufacturer of ceiling, drywall partitions, and finishes.\nBostik (an Arkema Company): Juman supplies Bostik’s construction and consumer range, including sealing and bonding products, wall and floor preparation material, tile adhesives and grouts, waterproofing products, façade, and panel adhesives.\nYehia Al Sheikh is Group IT Manager at Juman. He’s overall lead on the Oracle project, which was a challenge initially. He explained, “We went live during the COVID pandemic. It was a very difficult time as everyone was working remotely. As a result, it took us a while to make the Fusion Applications our main point of entry for ERP, because during the transition we were working in parallel with our legacy system.”\nExploiting business data\nExecutives were expecting analytics and insights on their Oracle Fusion Cloud Application data, so almost immediately after Fusion Cloud ERP was live they started asking how they could exploit the data being captured. Al Sheikh and his team started by delivering Excel reports for senior executives, manually combining data from multiple sources. Then the Oracle Analytics product team introduced Oracle Fusion Data Intelligence (FDI), a family of prebuilt, cloud native analytics applications for Oracle Fusion Cloud Applications providing the business with ready-to-use insights to help improve decision-making. Al Sheikh recognized the value and participated in the Oracle Sprint program, which showcases FDI capabilities using customer data. During the Sprint, experts from Oracle and VAAMG, a specialist Oracle Analytics partner, implemented FDI out of the box and also added some custom dashboards.\nAn accurate source of information\nWhen Juman executives saw the outcome of the Sprint, they saw how FDI could extend the value of their Fusion data. Working with VAAMG, Al Sheikh and his team began transitioning from the custom Excel reports to pre-built FDI content, starting with Sales Management reports. Al Sheikh explained, “The advantage of FDI is that the pre-built reports don’t need maintenance. You can free your mind, knowing that they are 100% validated and correct, even as the Fusion Applications themselves are enhanced. It’s a big advantage for us. If we find an anomaly in the FDI reports, we know it’s likely to be a business process issue and we’re able to go and identify the root cause in the ERP.”\nAnalyzing profit\nProfitability analysis was a major requirement. Management needed detailed analysis of profit and costs across multiple dimensions – for example, breaking costs down into raw materials versus company resources, to see how variances in each affect profitability. They also needed to evaluate cost of sales and customer service data so they could analyze sales team performance. In addition, some customers qualified for discounts and rebates, which also affected profitability. Al Sheikh said that “With FDI, it’s easy because most of the detailed Fusion data is curated for us, allowing us to build custom visualization to slice and dice as needed. Management can view total sales per territory, per person, per product, per category, before EBITDA, after EBITDA, and compare it with the cost. And they can do it whenever they want. It’s live, on demand, self-service. It’s changing completely the way they work.”\nSome of Juman’s sales costs are not in Fusion, so Al Sheikh’s team built a template that enables the finance team to add it, blending it with Fusion data in FDI.\nReplacing Excel\nBefore FDI, when Juman analyzed data in Excel, it consumed a lot of resources and time, so reports were only delivered monthly and were always 10 days out-of-date, sometimes longer if the experts who created the reports were unavailable. Now management can see the data daily, quickly highlighting any issue with costs and raising visibility to any product or territory that’s underperforming, so they can tackle issues immediately rather than waiting until month end. Another issue with Excel was that the data was not secure, and analysts were prone to ‘fix’ the data in the spreadsheet rather than tackle data quality or process issues at source. Data in FDI is in a reliable, secure system of record.\nAdditionally, because FDI inherits its security from Fusion, data and analysis can be safely shared much more widely with decision makers. Before only top executives received Excel reports, but now FDI analysis and reports are shared with all sales teams because the data is correctly limited to their specific territories. As a result, decision makers throughout the business are much better informed.\nA cultural shift in decision making\nMoving from Excel to FDI is a cultural shift for business users. It’s a very different way of working; helping them take full advantage of the new visibility requires significant attention from Al Shiekh and his team. “We involve users from day one and engage them throughout the project. We explained the objectives we expect to achieve. And when the system went live, we did training and multiple follow-ups, encouraging them to use it by showing them the benefits. We had the advantage of excellent executive support. When we celebrated our first ‘go-live’, the chairman of Juman was clear ‘you asked for this, we invested and now we have it. It’s your turn, start using it and realize the benefit.’”\nAl Sheikh thinks this cultural shift can go further. “If you are only working with static numbers in a PowerPoint presentation for example, without the ability to interact or go into more details, it’s hard to get the insight needed to make great decisions. But during that meeting, if you can review what’s happening on the live system in an FDI dashboard, it will be very easy to drill into the data or look at the data in different dimensions to get better insight. It’s going to be a game changer, I think.”\nJuman’s FDI go-live celebration\nBeing mobile\nOutside of meetings, managers rely on having information to make decisions on the fly. Al Sheikh explains, “With FDI, managers can take dashboards with them on their mobile devices. That’s extremely useful, especially for the sales teams. They are connected all the time. With FDI, they don’t need to open their laptop to see the see the dashboards. They can easily access the information on their mobiles – both the pre-built content and the custom dashboards we have built for them.”\nPartnership\nAl Shiekh values the relationship with Oracle and also with their partner. “VAAMG are experts and very professional with FDI. They helped us enable and activate the system quickly. Initially, as well as implementing the FDI platform, they worked with us to develop a custom sales dashboard, which was complex. Now we are working together on another set of dashboards for sales budgeting and sales order tracking. They are one of the best partners I have worked with in terms of responsiveness and understanding our needs. Any problems are immediately rectified, and they are available always for us.\nWorking with VAAMG is also helping me develop the skills we need to move forward within my team, and that’s an important objective for me.”\nLooking to the future\nAl Sheikh noted, “We’re on a journey with analytics and FDI, I see so much potential. One area is to make use of AI that Oracle is building into all its products – for example, automated narratives and interactive video to help interpret data and get better insight faster.\nWe also want to use FDI across our whole business. We started with sales because that’s the most critical area: if we do not perform in sales, everything else will collapse. But we need better insight into supply chain, inventory, procurement, manufacturing, planning and budgeting, warehouse management and maintenance. As we deploy more Oracle Fusion Cloud Applications, we expect FDI to be right there, delivering the insight in every business domain.”\nLearn more about\nJuman\nand\nFDI\n, and you can always ask questions in the\nOracle Analytics Community\nor learn more from the\nOracle Help Center\n."
  },
  {
    "title": "How to Connect to Oracle Autonomous Database Private Endpoint from ...",
    "link": "https://blogs.oracle.com/analytics/how-to-connect-to-adb-private-endpoint-from-fdi",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle Fusion Data Intelligence integrates analytics and AI for enhanced decision-making.",
      "The article provides steps to connect Oracle Autonomous Database to FDI via a private endpoint.",
      "Public access configuration is necessary for the Autonomous Database on a private endpoint."
    ],
    "tags": [
      "oracle",
      "data-intelligence",
      "autonomous-database",
      "cloud-computing",
      "analytics",
      "machine-learning",
      "network-security",
      "data-connection"
    ],
    "original_text": "With Inputs from:\nBindu Goparaju – Manager, Oracle Analytics\nAbhiram Gujjewar – Product Management Fusion Data Intelligence\nIntroduction\nOracle Fusion Data Intelligence\n(FDI) is the next generation of Oracle Fusion Analytics Warehouse built for Oracle Fusion Cloud Applications, bringing together business data, ready-to-use analytics, and prebuilt AI and machine learning (ML) models to deliver deeper insights and accelerate the decision-making process into actionable results. FDI also enables you to connect to a variety of data sources and remote applications to provide the background information for reports using connectors. This article outlines the steps required for securely connecting public FDI to an Oracle Autonomous Database (ADB) private endpoint.\nArchitecture\nThis article uses a simplified reference architecture showing FDI with a public endpoint and ADB deployed on a private endpoint in the same tenancy and region. This setup is for illustrative purposes and only applicable when FDI and the database are in the same region and tenancy.\nSimplified Network Architecture\nWhat steps do I take?\nAllow Public Access to the ADB\nAn ADB deployed on a private endpoint using an ECPU compute model supports public access. Customers can configure access control rules to allow network access from Oracle Services Network (OSN) where FDI instances reside.\n1. In the Oracle Cloud Infrastructure (OCI) Console, select\nOracle AI Database\nand click\nAutonomous AI Database\non the\nOracle AI Database\npage.​\nOracle AI Database\n2. Search for the database and click the database name link. Click\nMore actions\nand select\nUpdate network access\non the database page.\nADB\n3. Toggle\nAllow Public Access\nto On under the\nPublic access\nsection on the\nUpdate network access\npage.\n4. Select\nCIDR block\nfrom the\nIP notation type\ndrop-down list under the\nConfigure access control\nsection and type 240.0.0.0/4 (CIDR block for OSN) on the values field.\nUpdate Network Access\n5. Click\nUpdate\nin the bottom right corner of the same page.\nCreate an ADB Connection in FDI\nYou can create a managed connection for the ADB using a public service that’s available in the client credential (wallet) downloaded from the database.You do this by enabling the ADB feature in FDI, downloading the wallet file for the database in the ADB Console, and creating a data connection in FDI.\n1. Enable Oracle Autonomous Database (preview) from Enable Features.\nSign in to\nFDI Console\n.\nClick\nEnable Features\nunder\nApplication Administration\n.\nOn the\nEnable Features\npage, under the\nPreview Features\ntab, expand the\nConnectors\ncategory.\nSelect one of the\nOracle Autonomous Database\nfeatures.\nEnable Features\n2. Download the database wallet file.\nDownload the database wallet from\nOCI Console\nor\nDatabase Action\n. Detailed instructions on how to complete this step can be found in the\ndocumentation\n.\nExtract the file, open the TNSNAMES file, and note the services designated for the public network (marked as “public”).\nCreate the ADB managed connection for the database using the instructions described in the\ndocumentation\n.\nConclusion\nOracle solutions are designed to help you succeed.  Now that you know more about them, visit the\nOracle Analytics Community site\nto share your feedback, and let us know if you have questions or new ideas!\nIf you have questions or need more details, you can always check the\nOracle Help Center for Oracle Analytics\n."
  },
  {
    "title": "Configuring a Vanity URL for Oracle Analytics Cloud in Oracle Fusion ...",
    "link": "https://blogs.oracle.com/analytics/configuring-vanity-url-for-oracle-analytics-cloud-in-fusion-data-intelligence-fdi",
    "source": "Oracle_blog",
    "main_ideas": [
      "Vanity URLs enhance branding and accessibility for Oracle Analytics Cloud users.",
      "Users can configure custom hostnames for their OAC instances within Oracle Fusion.",
      "The configuration process includes SSL certificate integration for secure access."
    ],
    "tags": [
      "oracle",
      "analytics",
      "cloud-computing",
      "vanity-url",
      "branding",
      "security",
      "user-experience",
      "data-intelligence"
    ],
    "original_text": "Introduction\nYou can now configure a Vanity URL for your Oracle Analytics Cloud (OAC) instance within Oracle Fusion Data Intelligence (FDI) — enabling a branded, secure, and user-friendly way to access your analytics environment.\nConfigure Vanity URL\nOverview\nWhen using OAC as part of your FDI solution, you typically access your analytics environment through a default Oracle Cloud–generated URL such as: https://<instance>.analytics.ocp.oraclecloud.com/ui/dv.\nWith the Vanity URL configuration, you can now access your OAC-FDI environment using a custom hostname that aligns with your organization’s domain, for example: https://fdioac.cealinfra.com/ui/.\nThis feature allows your analytics portal to reflect your organization’s identity and simplifies access for business and executive users.\nWhy Use a Vanity URL?\nTraditionally, your OAC environment is accessed through a system-generated Oracle Cloud URL (for example, https://<instance>.analytics.ocp.oraclecloud.com/ui/dv). With the Vanity URL capability, you can now use a custom hostname that reflects your corporate domain and improves accessibility.\nKey Benefits\nCorporate Branding\n: Access OAC under your company’s domain name.\nSecure Access\n: Integrate your organization’s SSL certificate and keys.\nEasy to Remember\n: Improve user adoption with simple and clean URLs.\nConsistent Experience\n: Maintain the same URL, even after instance maintenance or redeployment.\nBetter Business Accessibility\n: Enable business teams to easily bookmark or embed dashboards under the company domain.\nBefore You Begin\nRefer to the Oracle Analytics blog article,\nSet up a Vanity URL for Oracle Analytics Cloud on OCI Gen 2\n, for detailed guidance on generating and managing SSL certificates required for the vanity domain.\nSteps to Configure the Vanity URL for OAC in FDI\n1. Log in to Oracle Cloud Infrastructure (OCI) Console.\nSign in to your\nOCI Home page\nusing administrator credentials.\n2. Navigate to the Analytics Cloud service.\nFrom the OCI Console menu, select\nAnalytics & AI\n, and then\nAnalytics Cloud\n.\nAnalytics Cloud\n3. Select your OAC instance.\nClick your\nOAC instance\nlink (deployed under FDI).\nOAC Instance\n4. Create a Vanity URL.\nUnder\nVanity URL Configuration\n, click\nCreate\n.\nVanity URL\n5. Provide the required details.\nIn (field name) enter the\ncustom hostname\n(for example, fdioac.cealinfra.com).\nUpload or select your\nSSL certificate\n,\nprivate key\n, and\ncertificate chain\n.\nSSL Certificate, Private Key & Certificate Chain\n6. Submit the configuration.\nClick\nCreate\n. A confirmation message displays once the Vanity URL is ready to use.\nVanity URL\n7. Update the DNS settings.\nAssign the\npublic IP address\nto your chosen domain (for example, fdioac.cealinfra.com).\nYou can find the IP under\nAdditional Details\nin your OAC instance page.\nOAC Instance IP Address\nUpdate your DNS record (A/CAA) to point your domain to this IP.\n8. Verify access.\nUse the Vanity URL to log in and test: https://fdioac.cealinfra.com/ui/.\n9. Validate the Vanity URL.\nThe Vanity URL now redirects seamlessly to the OAC instance and lands back on the same custom domain.\nOAC Console\nNeed Help Generating Certificates?\nFor guidance on preparing or uploading certificates, refer to the blog article,\nSet up a Vanity URL for Oracle Analytics Cloud on OCI Gen 2\n.\nConclusion\nWith Vanity URLs now available for OAC in FDI, your analytics environment becomes more professional, secure, and user-friendly. This small configuration step significantly enhances the overall experience — making it easier for business users to access insights while ensuring consistency with your enterprise branding. Set up your Vanity URL today and give your OAC-FDI environment the polished, corporate identity it deserves.\nCall to Action\nNow that you’ve read this post, try it yourself and let us know your results in the\nOracle Analytics Community\n, where you can also ask questions and post ideas.\nIf you have questions or need more details, you can always check the\nOracle Help Center\n."
  },
  {
    "title": "A Look at Recent Updates to Salary Basis in Fusion HCM Analytics",
    "link": "https://blogs.oracle.com/analytics/enhance-compensation-insights-with-the-new-salary-basis-dimensions-kpis-and-subject-areas-in-fusion-hcm-analytics",
    "source": "Oracle_blog",
    "main_ideas": [
      "New KPIs enhance visibility into salary basis and compensation structures.",
      "Median salary insights provide a clearer view of pay equity across departments.",
      "Organizations can identify unused salary configurations for better management."
    ],
    "tags": [
      "salary-basis",
      "compensation",
      "oracle-fusion",
      "hcm-analytics",
      "pay-equity",
      "workforce-rewards",
      "data-visualization",
      "kpi",
      "salary-configuration"
    ],
    "original_text": "Key attributes like frequency, annualization factor, salary amounts, and grade rate ranges form the foundation of compensation insights. To truly understand salary structures, it’s important to look closely at the components that makeup the salary basis, particularly those driving the greatest impact on overall compensation costs. These components help identify the timing and structure of worker pay, providing a valuable view of the organization’s total compensation picture.\nNew KPIs and dimensions have been added to the\nHCM – Workforce Rewards – Salary Basis\nsubject area.\nNew KPIs\nUnadjusted Pay Gap\nCount of Salary Basis (associated with worker)\nMedian Salary Amount\nMedian Annual Salary\nMedian Annualized Salary (FTE)\nNew dimensions\nWorker – Salary Range Differentials\nWorker – Compensation Zones\nIncremental Components\nSimple Components\nSalary Basis Pay Rates\nThere’s also a new subject area dedicated to the setup information,\nHCM – Workforce Rewards – Salary Basis\nSetup.\nAdditionally, a comprehensive analysis of salary basis is incomplete without visibility into the components that define its configuration. To support this, we are introducing a dedicated subject area for salary basis configuration,\nHCM – Workforce Rewards – Salary Basis\nSetup\n, which brings together all relevant dimensions and facts related to salary basis configuration.\nSalary Basis Setup subject area\nWhat business user challenges are addressed by these updates?\n1. HCM – Workforce Rewards – Salary Basis\nHow can users monitor and manage unused salary basis configurations?\nBy leveraging these new enhancements, users can now access information on the total number of configured salary basis records, along with how many are actively assigned to workers. This helps identify salary basis setups that exist in the system but remain unused, enabling better configuration management.\nHow can organizations identify potential pay disparities?\nThe new\nUnadjusted Pay Gap\nKPI helps in the early identification of potential pay disparities, helping promote fairness and compliance across the workforce. The pay gap can also be plotted against various attributes like age, ethnicity, and more.\nWhat insights can median salary provide?\nWith the introduction of the newest KPIs such as median salaries, it’s now easier to compare the average salary with the median salaries across various organizational levels, such as business unit (BU), legal employer (LE), or department level. A quarterly trend analysis of median salaries further enhances visibility into how compensation metrics evolve over time.\nWhile average salary figures can be skewed by outliers, especially when teams with exceptionally high or low salaries. In contrast, median salary offers a more balanced view of central compensation trends, as it’s less affected by extreme values. With these enhancements, users can now identify the median salary for a specific BU or LE and assess whether teams are compensated above or below that benchmark. This allows for targeted attention where discrepancies are significant, supporting fair and data-driven compensation decisions. Moreover, the median salary can be analyzed across multiple parameters, such as job, grade, and more, offering flexible and meaningful insights into pay equity.\nHow to achieve detailed cost analysis and informed compensation planning?\nIn addition to salary level insights, the newly introduced component level visibility allows organizations to better understand how each compensation component is utilized and the proportion it contributes to overall organizational cost, enabling more granular cost analysis and strategic planning.\nSalary Basis Overview data visualization\n2. HCM – Workforce Rewards – Salary Basis Setup\nHow can organizations align pay structures with geographic and market factors?\nDetailed information on salary ranges allows organizations to understand the defined pay limits for each salary basis. The inclusion of salary range differentials supports adjustments based on geographic or market-specific factors. Compensation zones are also captured, enabling grouping of locations under a unified pay structure.\nWhat components constitute the salary basis structure?\nThis subject area covers both simple and incremental components, offering insight into how different elements contribute to overall compensation. It also supports analysis of pay rate-based salary basis configurations, and provides key metrics that reflect the number of salary basis records categorized by salary basis type, enabling a more granular understanding of pay structure and cost distribution.\nHow to analyze the salary basis configuration?\nThe enhancements include insights into the number of salary basis records configured by frequency and salary basis type, the distribution across compensation zones, and the salary ranges defined for each salary basis.\nSalary Basis Setup Overview data visualization\nSecurity Overview\n1. HCM – Workforce Rewards – Salary Basis\nIt’s important to note that these enhancements\ndon’t\naffect existing security configurations\n.\nAll current security settings remain unchanged.\nHow do I access the new dimensions related to components?\nThese enhanced dimensions become available once the associated functional area,\nSalary Basis Snapshots,\nis activated under Preview Features.\nIn Oracle Fusion Data Intellignece (FDI), navigate to the Administration console, and click\nEnable Features\n.\nEnable Features\nOn the Preview Features tab, under Functional Areas, toggle the\nSalary Basis Snapshots\nfeature to\nOn\n.\nFunctional area under Preview Features\n2. HCM – Workforce Rewards – Salary Basis Setup\nTo access this subject area, you must assign the duty role,\nOA4F_HCM_SALARY_BASIS_SETUP_ANALYSIS_DUTY\n.\nWhat changes should you expect?\nAs part of this enhancement, there are structural dimensions updates to improve consistency. Some existing dimensions will be either relocated or decommissioned, as outlined below:\nSalary Ranges:\nThis dimension is now available in the newly introduced subject area dedicated to salary basis setup,\nHCM – Workforce Rewards – Salary Basis Setup\n.\nWorker Salary Component Details:\nAttributes from this dimension are moved to the Incremental Components dimension within the same subject area.\nFacts – Worker Salary Component:\nThe KPIs previously found here are now available under the facts folder of the Incremental Components dimension within the same subject area\nConclusion\nBy introducing the new KPIs, organizations will now have the ability to view median salaries – less affected by outliers than averages, helps identify pay inequities more effective across BU, LE, or departments. Furthermore, the addition of component-level insights provides a detailed view of how each compensation element contributes to overall costs, supporting more precise cost analysis and strategic workforce planning.\nIf you have any questions, post them in the\nFusion HCM Analytics community forum\n.\nFor more information about\nOracle Fusion HCM Analytics\n, check out the\nOracle Help Center documentation\n.\nFollow us on\nTwitter@OracleAnalytics\n, and connect with us on\nLinkedIn\n."
  },
  {
    "title": "Oracle Analytics Cloud – Unlock Instant AI-Powered Insights ...",
    "link": "https://blogs.oracle.com/analytics/unlock-ai-powered-insights-from-oac-logs-via-sqlcl-mcp-server",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle Analytics Cloud enables AI-powered analytics for dynamic visualizations and real-time insights.",
      "Natural language queries allow users to extract insights without SQL expertise.",
      "Usage tracking captures detailed user query data for better system performance monitoring.",
      "Anomaly detection helps identify unusual patterns in usage data to prevent issues.",
      "The SQLcl MCP Server bridges AI applications and Oracle databases for efficient data interaction."
    ],
    "tags": [
      "oracle",
      "analytics",
      "cloud-computing",
      "ai",
      "natural-language-processing",
      "data-analytics",
      "usage-tracking",
      "sqlcl",
      "mcp"
    ],
    "original_text": "Oracle Analytics Cloud\n(OAC) empowers organizations with modern, AI-powered analytics — enabling dynamic visualizations, interactive dashboards, and real-time insights.\nImagine extracting detailed insights from your OAC usage data without writing a single SQL query. Instead of wrestling with complex joins and hunting through data dictionaries, you could simply ask questions in plain English and get instant, AI-powered answers.\nThis is now possible with the Oracle SQLcl Model Context Protocol (MCP) Server, which bridges the gap between your OAC usage tracking database and natural language queries. This powerful combination transforms how administrators and analysts interact with usage data, making insights accessible to everyone regardless of their SQL expertise.\nUnderstand Usage Tracking in Oracle Analytics Cloud\nUsage tracking is a powerful enterprise feature that captures granular data at the detailed user query level. When you enable usage tracking in Oracle Analytics Cloud, it provides comprehensive insights to answer critical business questions about user engagement, time allocation, session analytics, query relationships, navigation patterns, and incident correlation.\nUsage tracking collects data records for every query that users run, capturing both logical and physical queries in separate database tables. The system tracks query execution times, data processing metrics, user session details, system performance indicators, and error analytics for comprehensive monitoring.\nThis granular data helps organizations monitor system performance, predict user behavior, and proactively increase efficiency while reducing errors. The collected data is stored in dedicated schema tables, typically in an Oracle Autonomous Data Warehouse (ADW) for optimal security and performance.\nFor detailed configuration and implementation guidance, see the\nOracle Analytics Cloud Usage Tracking documentation\n.\nThe Power of Natural Language Analytics\nTraditional usage analysis requires SQL expertise and time-consuming query development. The SQLcl MCP Server eliminates these barriers by enabling natural language interactions with your usage data.\nInstead of complex SQL, you can simply ask:\n“Who are the top ten most active users this quarter?”\n“Which dashboards are taking longer than 30 seconds to run?”\n“List all failed queries in the last seven days with their error messages”\n“Show subject areas with declining usage over the past 90 days”\n“Which users are the top AI Assistant adopters?”\n“What are the most frequently accessed reports in the Finance department?”\nThese queries are translated into efficient SQL behind the scenes, delivering results quickly and accurately.\nEnhanced Insights with Anomaly Detection\nBeyond static metrics, you can leverage your usage tracking data to detect unusual patterns that may require immediate action. Anomaly detection helps you identify issues before they escalate, ensuring optimal system performance.\nExamples of anomaly detection queries in natural language:\n“Identify dashboards or reports whose average runtime has suddenly spiked in the last week.”\n“Spot dashboards with declining usage over the past three months.”\n“Detect an unexpected surge in AI Assistant queries by specific users.”\n“Find unusual error spikes that may indicate data source or configuration issues.”\n“Highlight users with abnormally high query failure rates compared to the average.”\nThese insights can prevent performance degradation, optimize workloads, and enhance overall user experience. For advanced users, you can combine this with custom SQL thresholds or integrate with alerting tools.\nAbout the Model Context Protocol\nThe Model Context Protocol (MCP) is an open standard that defines a consistent way for applications to provide contextual information to AI models.\nMCP standardizes the connection between AI systems and external tools or data sources, such as databases and APIs. To learn more about MCP, see\nModel Context Protocol\n.\nAbout the SQLcl MCP Server\nThe SQLcl MCP Server extends Oracle SQLcl to support MCP-based communication. It enables AI applications to interact with Oracle databases using the standardized MCP interface, giving those applications a structured way to discover and use your databases.\nHow the SQLcl MCP Server Works\nThe Oracle SQLcl MCP Server acts as a bridge between your database and AI clients:\nConnects to your usage tracking schema in Oracle Autonomous Data Warehouse (ADW).\nTranslates your natural language question into SQL.\nExecutes the SQL and returns results instantly.\nLogs all interactions for auditing.\nStep-by-Step Implementation\nIn this article, we use Windows for a quick setup. In my next article, I’ll show you how to host SQLcl MCP on Linux for a central, always-on deployment.\nArchitecture Overview\nArchitecture overview\nPrerequisites\nBefore you begin, ensure you have:\n✅ OAC usage tracking enabled (\nSetup Guide\n)\n✅ Java Runtime Environment (JRE) 17 or higher\n✅ Oracle SQLcl version 25.2.0 or higher\n✅ Claude Desktop or another MCP-compatible client\n✅ ADW wallet file for database connectivity\n✅ Database user with SELECT permissions on usage tracking tables\nSet Up a Database User\nCreate a dedicated read-only user for MCP access with minimal privileges:\n— As an admin user, create the MCP reader account\nCREATE\nUSER\nOAC_READER IDENTIFIED\nBY\n“StrongPassword!23”;\nGRANT\nCREATE\nSESSION\nTO\nOAC_READER;\nGRANT\nSELECT\nON\nUSAGE_TRACKING.LOGICALQUERIES\nTO\nOAC_READER;\nGRANT\nSELECT\nON\nUSAGE_TRACKING.PHYSICALQUERIES\nTO\nOAC_READER;\nGRANT\nSELECT\nON\nUSAGE_TRACKING.INITBLOCK_INFO\nTO\nOAC_READER;\nThis approach follows security best practices by granting only the minimum permissions required for usage tracking analysis.\nStep 1: Set Up a Java Environment\nDownload and install Java 17 from\nOracle’s Java Downloads page\n:\nsetx JAVA_HOME\n“C:\\jdk-17.0.16”\nsetx PATH\n“%JAVA_HOME%\\bin;%PATH%”\njava -version\nWhy:\nSQLcl MCP requires Java 17 or higher for AI model integration and database connectivity.\nStep 2: Install SQLcl\na. Download SQLcl from\nOracle’s SQLcl Downloads\npage.\nb. Extract to: C:\\sqlcl-latest\\sqlcl\\\nc. Verify the installation. From Windows PowerShell:\n& “C:\\sqlcl-latest\\sqlcl\\bin\\sql.exe” -v\nExpected output:\nSQLcl: Release 25.2.2.0 Production Build: 25.2.2.199.0918\nWhy:\nSQLcl is your CLI for Oracle Database and the engine for MCP mode.\nStep 3: Configure the Database Connection\nFrom PowerShell:\n# Keep the wallet as a ZIP;\ndo\nnot extract\n$wallet =\n“C:\\Users\\<You>\\Downloads\\UT_ADW_Wallet.zip”\n& “C:\\sqlcl-latest\\sqlcl\\bin\\sql.exe” `\n-cloudconfig $wallet `\nOAC_READER/<YourPassword>@adw_low\nIf you see\nConnected to: Oracle Database …\n, type\nexit;\n.\nWhy:\nProves that the wallet path, user, and TNS alias are correct before you automate anything.\nIf you experience these errors:\nno ocijdbc23\n: You’re in thick mode; always use\n-cloudconfig <wallet.zip>\n(forces thin+wallet).\nCloud Wallet is empty or invalid:\nYou need to point to the ZIP file, not a folder.\nStep 4: Create a Named Connection\nCreate a named connection in SQLcl for MCP access.\nFrom PowerShell:\n& “C:\\sqlcl-latest\\sqlcl\\bin\\sql.exe” `\n-cloudconfig $wallet `\n-save adw_mcp -savepwd OAC_READER/<Password>@adw_low\nQuick validation from PowerShell:\n& “C:\\sqlcl-latest\\sqlcl\\bin\\sql.exe” /nolog\nAt\nSQL>\n:\nconn -n adw_mcp\nselect\nuser\n, sysdate\nfrom\ndual;\nexit;\nYou should connect without a password prompt.\nStep 5: Validate the Usage Tracking Tables\nVerify your usage tracking data is accessible using the OAC_READER connection:\n— Existence / row counts (adjust owner if different)\nSELECT\nCOUNT\n(*)\nFROM\nUSAGE_TRACKING.LOGICALQUERIES;\nSELECT\nCOUNT\n(*)\nFROM\nUSAGE_TRACKING.PHYSICALQUERIES;\nSELECT\nCOUNT\n(*)\nFROM\nUSAGE_TRACKING.INITBLOCK_INFO;\n— Recent activity\nSELECT\n*\nFROM\nUSAGE_TRACKING.LOGICALQUERIES\nWHERE\nSTART_TIME > SYSDATE –\n7\nORDER\nBY\nSTART_TIME\nDESC\nFETCH\nFIRST\n10\nROWS\nONLY\n;\nNote:\nYou’re connecting as the OAC_READER user but querying tables in the USAGE_TRACKING schema. This works because OAC_READER is granted SELECT permissions on these specific tables. When the MCP client is configured, you can run these same queries directly or ask natural language questions like “How many logical queries are in the tracking database?”\nWhy:\nConfirms usage tracking data is flowing and your user has the correct privileges.\nStep 6: Wire the SQLcl MCP Server into Your MCP Client\nFollow these steps to configure Claude Desktop for SQLcl MCP Server. After configuration, Claude Desktop automatically manages the SQLcl MCP Server which allows you to perform Oracle Database operations through your conversations with Claude.\na. Install Claude Desktop. See\nInstalling Claude for Desktop\n.\nb. Edit the configuration file at:\nC:\\Users\\<You>\\AppData\\Roaming\\Claude\\claude_desktop_config.json\nc. Add the MCP Server configuration:\n{\n“mcpServers”\n: {\n“oac-usage-tracking”\n: {\n“command”\n:\n“C:\\\\sqlcl-latest\\\\sqlcl\\\\bin\\\\sql.exe”\n,\n“args”\n: [\n“-mcp”\n,\n“-n”\n,\n“adw_mcp”\n]\n}\n}\n}\nd. Restart Claude Desktop and verify the server appears under Local MCP Servers — it should show as running.\nStatus check\nThe SQLcl MCP Server offers tools such as:\nlist-connections:\nLists saved Oracle Database connections.\nconnect:\nEstablishes a connection.\ndisconnect:\nTerminates the connection.\nrun-sql:\nExecutes SQL queries and PL/SQL.\nrun-sqlcl:\nExecutes SQLcl-specific commands.\nConnections available\nSQLcl MCP Server offered tools\nStep 7: Ask Questions in Natural Language\nFrom Claude Desktop, you can use natural language to ask questions:\n“Show me the list of users using AI Assistant feature.”\nShow me the list of users using AI Assistant feature\n“Give me list of AI Ready datasets”\nGive me list of AI Ready datasets\n“Show me a summary of query performance patterns”\nShow me a summary of query performance patterns\nWhat’s happening under the hood?\nThe client interprets your question, generates the required SQL, and calls the SQLcl MCP tool. Then, SQLcl executes the SQL against your usage tracking tables, and the results come back summarized in a table. Power users can still directly run the SQL. For example:\n/sqlcl run “select count(*) from USAGE_TRACKING.LOGICALQUERIES”\nSecurity Best Practices\nWhen you grant a large language model (LLM) access to your database, it introduces significant security risks. LLMs use the data you input to generate responses, so you might inadvertently expose tables or sensitive details.\nTo mitigate these risks, implement the following safeguards:\nAssign minimum permissions\n: Configure the database user account used by the LLM with the absolute minimum permissions required for its tasks. This approach limits what the LLM can access.\nAvoid production database access:\nDon’t grant LLMs direct access to production databases. Instead, you should use a sanitized, read-only replica or a dedicated data subset.\nAudit LLM activity:\nRegularly audit the queries executed by the LLM. This helps you detect anomalies or the attempts to access restricted data. To support your auditing efforts, the SQLcl MCP Server provides the following built-in monitoring capabilities:\nSession tracking:\nIt populates\nV$SESSION.MODULE\nwith the MCP client in use, and\nV$SESSION.ACTION\nwith the LLM’s name.\nActivity logging:\nIt creates a table named\nDBTOOLS$MCP_LOG\nthat records every interaction and SQL execution.\nQuery identification:\nAll LLM-generated queries through the SQLcl MCP Server’s tools include the following comment for easy identification in the logs:\n/* LLM in use … */\n.\nTo learn more about monitoring, see\nMonitoring the SQLcl MCP Server\n.\nMonitor What the LLM is Doing\nSQLcl MCP helps you audit LLM activity:\n— Every interaction & SQL execution\nSELECT\n*\nFROM\nDBTOOLS$MCP_LOG\nWHERE\nTIMESTAMP\n> SYSDATE –\n1\nORDER\nBY\nTIMESTAMP\nDESC\n;\n— Active sessions show client/model\nSELECT\nMODULE\n, ACTION, USERNAME, LOGON_TIME\nFROM\nV$SESSION\nWHERE\nMODULE\nLIKE\n‘%MCP%’\n;\nExtend Beyond Usage Tracking – Include OCI Logs\nIf you ingest OAC’s audit and diagnostic logs from OCI into same ADW instance, the same SQLcl MCP setup can answer questions such as:\n“Who exported workbooks yesterday?”\n“Which dataflows failed this week?”\n“Show security/role changes last month.”\nOne MCP server… multiple operational datasets… instant answers.\nThe Payoff\nWith OAC usage tracking and SQLcl MCP Server, you can transform complex query analysis into simple conversations.\nYou gain:\nFaster insights:\nNo manual query writing required.\nIncreased adoption:\nAdministrators and analysts can self-serve usage data easily.\nProactive monitoring:\nDetect anomalies before they become critical issues.\nBetter optimization:\nMake decisions based on real, current usage patterns.\n💡\nNext:\nIn my follow-up article, I’ll show you how to run SQLcl MCP Server on Linux so that multiple analysts can connect and ask questions without the need to set up their own local environments.\nCall to Action\nNow that you’ve seen how the SQLcl MCP Server can unlock OAC Usage Tracking with natural language queries and anomaly detection, here are a few ways to take this further:\n🔗\nLearn More\nIntroducing MCP Server for Oracle Database\nMonitoring the SQLcl MCP Server\n💬\nJoin the Community\nHave questions or want to share your journey?\nJoin the conversation in the\nOracle Analytics Community\n— connect with other practitioners and get expert insights.\n🛠️\nTry it Yourself\nSet up your own SQLcl MCP Server, connect it to OAC Usage Tracking, Audit and Diagnostic logs, and start asking natural language questions to uncover insights instantly.\nTo learn more about OAC, visit the\nOracle Analytics product page\nand follow\ntwitter@OracleAnalytics\n."
  },
  {
    "title": "Transforming Workplace Safety: Oracle's Workforce Health and Safety ...",
    "link": "https://blogs.oracle.com/post/transforming-workplace-safety-oracles-workforce-health-and-safety-reporting-and-inspection-application",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle is enhancing workplace safety through innovative health and safety solutions.",
      "The new tools aim to streamline safety management and compliance processes.",
      "Workforce health and safety technology is critical for modern business operations."
    ],
    "tags": [
      "oracle",
      "workplace-safety",
      "health-tech",
      "safety-management",
      "compliance",
      "innovation",
      "technology",
      "business"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Oracle’s global first payroll approach – simplifying global payroll ...",
    "link": "https://blogs.oracle.com/post/oracles-global-first-payroll-approach-simplifying-global-payroll-with-one-unified-solution",
    "source": "Oracle_blog",
    "main_ideas": [],
    "tags": [],
    "original_text": ""
  },
  {
    "title": "Pay Transparency: Redefining Equity with Oracle Skills",
    "link": "https://blogs.oracle.com/post/pay-transparency-redefining-equity-with-oracle-skills",
    "source": "Oracle_blog",
    "main_ideas": [
      "Pay transparency fosters equity in the workplace by ensuring fair compensation.",
      "Oracle Skills provides tools to enhance workforce capabilities and promote transparency.",
      "Implementing pay transparency can improve employee morale and retention rates."
    ],
    "tags": [
      "pay-transparency",
      "oracle-skills",
      "equity",
      "workplace",
      "employee-morale",
      "compensation",
      "human-resources",
      "workforce-development"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Oracle Cloud HCM vs. Workday: 5 things to know",
    "link": "https://blogs.oracle.com/post/oracle-cloud-hcm-vs-workday-5-things-to-know",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle Cloud HCM offers robust features for human capital management.",
      "Workday is known for its user-friendly interface and strong analytics capabilities.",
      "Both platforms provide cloud-based solutions for HR needs."
    ],
    "tags": [
      "oracle",
      "workday",
      "cloud-hcm",
      "human-capital-management",
      "hr-software"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Help achieve cost reductions with Oracle Workforce Health and Safety",
    "link": "https://blogs.oracle.com/post/help-achieve-cost-reductions-with-oracle-workforce-health-and-safety",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle Workforce Health and Safety helps organizations reduce operational costs.",
      "The platform enhances employee safety and health management.",
      "Utilizing Oracle solutions can streamline workforce processes and improve efficiency."
    ],
    "tags": [
      "oracle",
      "workforce-health",
      "cost-reduction",
      "employee-safety",
      "health-management"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Coaching with Clarity: Changing the Game in Learning and Growth!",
    "link": "https://blogs.oracle.com/post/coaching-with-clarity-changing-the-game-in-learning-and-growth",
    "source": "Oracle_blog",
    "main_ideas": [
      "Coaching with clarity enhances learning and personal growth.",
      "Effective coaching strategies can transform individual performance.",
      "Clear communication is essential for successful coaching outcomes."
    ],
    "tags": [
      "coaching",
      "learning",
      "growth",
      "communication",
      "personal-development"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Modern HR leaders are driving innovation in finance",
    "link": "https://blogs.oracle.com/post/modern-hr-leaders-are-driving-innovation-in-finance",
    "source": "Oracle_blog",
    "main_ideas": [
      "HR leaders are pivotal in driving financial innovation within organizations.",
      "Modern HR practices are integrating technology to enhance financial strategies.",
      "Collaboration between HR and finance is essential for organizational growth.",
      "Data analytics is transforming HR's role in financial decision-making.",
      "Innovative HR solutions are improving employee engagement and financial performance."
    ],
    "tags": [
      "hr-leadership",
      "financial-innovation",
      "data-analytics",
      "employee-engagement",
      "organizational-growth",
      "technology-integration",
      "collaboration",
      "modern-hr"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "HCM is the glue that holds manufacturing together",
    "link": "https://blogs.oracle.com/post/hcm-is-the-glue-that-holds-manufacturing-together",
    "source": "Oracle_blog",
    "main_ideas": [
      "HCM plays a critical role in integrating various manufacturing processes.",
      "Effective HCM strategies enhance workforce productivity in manufacturing.",
      "Technology adoption in HCM is essential for modern manufacturing efficiency."
    ],
    "tags": [
      "hcm",
      "manufacturing",
      "workforce",
      "productivity",
      "technology",
      "integration",
      "efficiency"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Remembering Jon Chorley",
    "link": "https://blogs.oracle.com/post/remembering-jon-chorley",
    "source": "Oracle_blog",
    "main_ideas": [
      "Jon Chorley was a significant figure in the tech industry.",
      "He contributed greatly to advancements in software development.",
      "Chorley's legacy continues to inspire future generations of engineers."
    ],
    "tags": [
      "technology",
      "software-development",
      "legacy",
      "innovation",
      "engineering"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Enhancing grid resilience with AI",
    "link": "https://blogs.oracle.com/post/enhancing-grid-resilience-with-ai",
    "source": "Oracle_blog",
    "main_ideas": [
      "AI technologies are being integrated to enhance the resilience of power grids.",
      "Improved grid resilience can lead to reduced outages and better energy management.",
      "AI can analyze data to predict and mitigate potential grid failures."
    ],
    "tags": [
      "artificial-intelligence",
      "grid-resilience",
      "power-systems",
      "energy-management",
      "data-analysis"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "AI for Good: How Oracle AI can help solve complex sustainability ...",
    "link": "https://blogs.oracle.com/post/ai-for-good-how-oracle-ai-can-help-solve-complex-sustainability-challenges",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle AI offers innovative solutions for addressing sustainability challenges.",
      "The technology enhances data analysis for better environmental decision-making.",
      "AI-driven insights can lead to more efficient resource management."
    ],
    "tags": [
      "oracle",
      "ai",
      "sustainability",
      "data-analysis",
      "resource-management",
      "technology",
      "innovation"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Inspiring women in technology: Spotlight on Elena Avesani",
    "link": "https://blogs.oracle.com/post/inspiring-women-in-technology-spotlight-on-elena-avesani",
    "source": "Oracle_blog",
    "main_ideas": [
      "Elena Avesani is a prominent figure in the technology sector.",
      "She advocates for increased representation of women in tech.",
      "Avesani emphasizes the importance of mentorship for young women.",
      "Her work focuses on innovative solutions in technology.",
      "She inspires future generations to pursue careers in STEM."
    ],
    "tags": [
      "women-in-tech",
      "mentorship",
      "stem",
      "innovation",
      "technology",
      "elena-avesani",
      "representation",
      "career-development"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "2025 ESG Regulatory Outlook: Resilience through Strategic Reporting ...",
    "link": "https://blogs.oracle.com/post/2025-esg-regulatory-outlook-resilience-through-strategic-reporting-and-risk-management",
    "source": "Oracle_blog",
    "main_ideas": [
      "ESG regulations are evolving rapidly, impacting corporate reporting strategies.",
      "Companies must enhance transparency to meet stakeholder expectations on sustainability.",
      "Strategic reporting will be crucial for resilience in the face of regulatory changes."
    ],
    "tags": [
      "esg",
      "regulations",
      "sustainability",
      "corporate-reporting",
      "transparency",
      "stakeholders",
      "resilience",
      "strategic-planning"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Industry Series: The opportunities for financial institutions to ...",
    "link": "https://blogs.oracle.com/post/industry-series-the-opportunities-for-financial-institutions-to-address-key-esg-challenges",
    "source": "Oracle_blog",
    "main_ideas": [
      "Financial institutions are exploring new opportunities in digital transformation.",
      "The integration of technology is reshaping customer experiences in finance.",
      "Regulatory changes are driving innovation within the financial services sector."
    ],
    "tags": [
      "financial-institutions",
      "digital-transformation",
      "customer-experience",
      "regulatory-changes",
      "innovation",
      "fintech",
      "banking",
      "technology"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Introducing the 2024 Oracle Sustainability Champions",
    "link": "https://blogs.oracle.com/post/introducing-the-2024-oracle-sustainability-champions",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle recognizes organizations leading in sustainability efforts for 2024.",
      "The Sustainability Champions program highlights innovative practices in environmental responsibility.",
      "Award recipients demonstrate significant impact in reducing carbon footprints and promoting sustainability."
    ],
    "tags": [
      "oracle",
      "sustainability",
      "environment",
      "champions",
      "carbon-footprint",
      "innovation",
      "awards",
      "corporate-responsibility"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Industry Series: sustainability and healthcare",
    "link": "https://blogs.oracle.com/post/industry-series-sustainability-and-healthcare",
    "source": "Oracle_blog",
    "main_ideas": [
      "Sustainability is becoming a critical focus in the healthcare industry.",
      "Innovative technologies are being implemented to enhance eco-friendly practices in healthcare.",
      "Collaboration between healthcare providers and sustainability experts is essential for progress."
    ],
    "tags": [
      "sustainability",
      "healthcare",
      "innovation",
      "eco-friendly",
      "collaboration",
      "technology",
      "industry",
      "green-practices"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "CULTURE ACTIVATED: Father & Daughter Share Their Oracle Career ...",
    "link": "https://blogs.oracle.com/post/culture-activated-father-daughter-share-their-oracle-career-journeys",
    "source": "Oracle_blog",
    "main_ideas": [
      "A father and daughter duo are making strides in their Oracle careers.",
      "Their journey highlights the importance of mentorship in technology fields.",
      "The article showcases the impact of family support in professional growth."
    ],
    "tags": [
      "oracle",
      "mentorship",
      "technology",
      "career-development",
      "family-support"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Oracle JAPAC leaders share life and career lessons",
    "link": "https://blogs.oracle.com/post/oracle-japac-leaders-share-life-and-career-lessons",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle JAPAC leaders emphasize the importance of mentorship in career growth.",
      "Life lessons shared by leaders focus on resilience and adaptability.",
      "Networking is crucial for success in the technology industry."
    ],
    "tags": [
      "oracle",
      "leadership",
      "mentorship",
      "career-development",
      "networking",
      "resilience",
      "adaptability",
      "japac",
      "technology-industry"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Oracle Professional Asian Leadership: Oracle’s fastest-growing ...",
    "link": "https://blogs.oracle.com/post/oracle-professional-asian-leaders-opal-employee-resource",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle is experiencing rapid growth in the Asian market.",
      "Leadership initiatives are key to Oracle's success in Asia.",
      "The company focuses on innovation and technology advancements."
    ],
    "tags": [
      "oracle",
      "leadership",
      "asia",
      "growth",
      "innovation",
      "technology",
      "business"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "CJ Perez: competitive sailing’s first Latina champion",
    "link": "https://blogs.oracle.com/post/cjperez-diversity-competitive-sailing-sailgp",
    "source": "Oracle_blog",
    "main_ideas": [
      "CJ Perez is recognized as the first Latina champion in competitive sailing.",
      "Her achievement highlights the importance of diversity in sports.",
      "CJ Perez aims to inspire future generations of female sailors."
    ],
    "tags": [
      "sailing",
      "latina",
      "champion",
      "diversity",
      "sports",
      "inspiration",
      "female-athletes"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Three days, three hundred women: Oracle’s emerging leader summit in ...",
    "link": "https://blogs.oracle.com/post/oracle-women-leadership-summit-europe-2022",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle hosted a summit for emerging women leaders in technology.",
      "The event aimed to empower and inspire women in leadership roles.",
      "Participants engaged in networking and skill-building activities."
    ],
    "tags": [
      "oracle",
      "women-leaders",
      "technology",
      "leadership",
      "networking",
      "empowerment",
      "summit",
      "events"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Afro-Brazilian women live at a tricky intersection",
    "link": "https://blogs.oracle.com/post/afro-brazilian-women-oracle",
    "source": "Oracle_blog",
    "main_ideas": [
      "Afro-Brazilian women face unique challenges due to racial and gender discrimination.",
      "Cultural identity plays a significant role in the lives of Afro-Brazilian women.",
      "Economic opportunities are often limited for Afro-Brazilian women in society.",
      "Community support and activism are vital for empowering Afro-Brazilian women.",
      "The intersectionality of race and gender shapes the experiences of Afro-Brazilian women."
    ],
    "tags": [
      "afro-brazilian",
      "intersectionality",
      "gender-equality",
      "racial-discrimination",
      "cultural-identity",
      "women-empowerment",
      "community-activism",
      "economic-opportunity"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Oracle Career Relaunch expands to India, helps women reenter the ...",
    "link": "https://blogs.oracle.com/post/career-relaunch-india-women-workforce",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle's Career Relaunch program is now available in India.",
      "The initiative aims to support women reentering the workforce.",
      "Participants will receive training and mentorship to enhance their skills."
    ],
    "tags": [
      "oracle",
      "career-relaunch",
      "women-empowerment",
      "workforce",
      "training",
      "mentorship",
      "india"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "This is how Oracle leads in breaking gender bias",
    "link": "https://blogs.oracle.com/post/oracle-breaking-gender-bias",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle implements innovative strategies to combat gender bias in the workplace.",
      "The company promotes diversity and inclusion through targeted recruitment efforts.",
      "Oracle's leadership emphasizes the importance of equal opportunities for all employees."
    ],
    "tags": [
      "oracle",
      "gender-bias",
      "diversity",
      "inclusion",
      "workplace-equality",
      "technology",
      "corporate-leadership"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "5 supply chain management success factors every CPG company needs to ...",
    "link": "https://blogs.oracle.com/post/5-supply-chain-management-success-factors-cpg-increased-profitability",
    "source": "Oracle_blog",
    "main_ideas": [],
    "tags": [],
    "original_text": ""
  },
  {
    "title": "Oracle named a Leader in 2024 Gartner® Magic Quadrant™ for Warehouse ...",
    "link": "https://blogs.oracle.com/post/oracle-leader-2024-gartner-magic-quadrant-warehouse-management-systems",
    "source": "Oracle_blog",
    "main_ideas": [],
    "tags": [],
    "original_text": ""
  },
  {
    "title": "Oracle named a Leader again in the 2024 Gartner® Magic Quadrant™ for ...",
    "link": "https://blogs.oracle.com/post/gartner-magic-quadrant-supply-chain-planning-solutions-2024",
    "source": "Oracle_blog",
    "main_ideas": [],
    "tags": [],
    "original_text": ""
  },
  {
    "title": "Automating supply chains for a greener future",
    "link": "https://blogs.oracle.com/post/automating-supply-chains-greener-future",
    "source": "Oracle_blog",
    "main_ideas": [
      "Automating supply chains can significantly reduce carbon emissions.",
      "Technological advancements are key to creating sustainable logistics solutions.",
      "Collaboration between companies is essential for greener supply chain practices.",
      "Data analytics plays a crucial role in optimizing supply chain efficiency.",
      "Investing in green technologies can lead to long-term cost savings."
    ],
    "tags": [
      "supply-chain",
      "automation",
      "sustainability",
      "green-technology",
      "logistics",
      "data-analytics",
      "carbon-emissions",
      "collaboration",
      "cost-savings"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Oracle a Leader for 17th time in Gartner® Magic Quadrant™ for ...",
    "link": "https://blogs.oracle.com/post/oracle-leader-17th-time-gartner-magic-quadrant-transportation-management-systems",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle has been recognized as a leader in the Gartner Magic Quadrant for 17 consecutive times.",
      "The recognition highlights Oracle's strong performance in the cloud computing sector.",
      "Oracle continues to innovate and expand its technology offerings to maintain leadership."
    ],
    "tags": [
      "oracle",
      "gartner",
      "magic-quadrant",
      "cloud-computing",
      "technology-leadership",
      "enterprise-software",
      "innovation"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Ruan Transportation Management Systems, Iowa State, and Oracle: ...",
    "link": "https://blogs.oracle.com/post/ruan-transportation-management-systems-iowa-state-and-oracle-cultivating-future-supply-chain-leaders-through-technology",
    "source": "Oracle_blog",
    "main_ideas": [
      "Ruan Transportation Management Systems collaborates with Iowa State and Oracle for innovative solutions.",
      "The partnership aims to enhance logistics and transportation efficiency using advanced technologies.",
      "Iowa State's research capabilities will support Ruan's operational improvements and technology integration."
    ],
    "tags": [
      "ruan-transportation",
      "iowa-state",
      "oracle",
      "logistics",
      "transportation-management",
      "technology-partnership",
      "innovation",
      "research"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Moving your supply chain planning to the cloud? Consider these 5 key ...",
    "link": "https://blogs.oracle.com/post/moving-your-supply-chain-planning-to-the-cloud-consider-these-5-key-areas",
    "source": "Oracle_blog",
    "main_ideas": [
      "Cloud-based supply chain planning enhances flexibility and scalability for businesses.",
      "Data integration is crucial for effective supply chain management in the cloud.",
      "Cost efficiency is a significant advantage of moving supply chain operations to the cloud.",
      "Real-time analytics improve decision-making in supply chain processes.",
      "Security measures must be prioritized when adopting cloud solutions for supply chains."
    ],
    "tags": [
      "cloud-computing",
      "supply-chain",
      "data-integration",
      "real-time-analytics",
      "cost-efficiency",
      "security",
      "business-strategy",
      "technology"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Elevate your retail business: Join Oracle at NRF2024",
    "link": "https://blogs.oracle.com/post/elevate-your-retail-business-oracle-nrf2024",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle will showcase innovative solutions for retail businesses at NRF2024.",
      "The event offers networking opportunities with industry leaders and experts.",
      "Participants can learn about the latest trends in retail technology."
    ],
    "tags": [
      "oracle",
      "nrf2024",
      "retail",
      "technology",
      "networking",
      "innovation",
      "industry-leaders"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Walking with Nzeli: 35 years of conservation through the eyes of one ...",
    "link": "https://blogs.oracle.com/post/walking-with-nzeli-35-years-of-conservation-through-the-eyes-of-one-gorilla",
    "source": "Oracle_blog",
    "main_ideas": [],
    "tags": [],
    "original_text": ""
  },
  {
    "title": "Local action, global difference: Oracle CloudWorld Tour brings ...",
    "link": "https://blogs.oracle.com/post/local-action-global-difference-oracle-cloudworld-tour-brings-purposedriven-volunteering-to-town",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle CloudWorld Tour showcases local initiatives impacting global technology trends.",
      "The event emphasizes the importance of community engagement in tech advancements.",
      "Participants gain insights into cloud solutions and their applications across industries."
    ],
    "tags": [
      "oracle",
      "cloud-world-tour",
      "technology",
      "community-engagement",
      "cloud-computing",
      "innovation",
      "local-action",
      "global-impact"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "On International Volunteer Day, Oracle Volunteers share how ...",
    "link": "https://blogs.oracle.com/post/on-international-volunteer-day-oracle-volunteers-share-how-connection-creates-impact",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle Volunteers celebrate their contributions on International Volunteer Day.",
      "The article highlights various volunteer projects undertaken by Oracle employees.",
      "Community engagement and social responsibility are emphasized through Oracle's volunteer efforts."
    ],
    "tags": [
      "oracle",
      "volunteering",
      "community-engagement",
      "social-responsibility",
      "international-volunteer-day"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Celebrating a year of service with Oracle Volunteers",
    "link": "https://blogs.oracle.com/post/celebrating-a-year-of-service-with-our-oracle-volunteers",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle Volunteers has made significant contributions to various community service projects this year.",
      "The initiative encourages employees to engage in volunteer work and give back to their communities.",
      "Celebrating a year of service highlights the positive impact of corporate social responsibility."
    ],
    "tags": [
      "oracle",
      "volunteering",
      "community-service",
      "corporate-social-responsibility",
      "employee-engagement"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Oracle and d.tech: a philosophy of learning in action",
    "link": "https://blogs.oracle.com/post/oracle-and-dtech-a-philosophy-of-learning-in-action",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle and d.tech collaborate to enhance learning methodologies.",
      "The partnership emphasizes practical applications of technology in education.",
      "Innovative approaches to learning are central to their philosophy."
    ],
    "tags": [
      "oracle",
      "d-tech",
      "education",
      "learning",
      "technology",
      "innovation",
      "collaboration"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Earth Day 2024: Plastics vs. the Planet with Colleen Cassity, Vice ...",
    "link": "https://blogs.oracle.com/post/earth-day-2024-plastics-vs-the-planet-with-colleen-cassity-vice-president-of-oracle-social-impact",
    "source": "Oracle_blog",
    "main_ideas": [
      "Earth Day 2024 focuses on the impact of plastics on the environment.",
      "Colleen Cassity discusses strategies to combat plastic pollution.",
      "The event aims to raise awareness about sustainable practices."
    ],
    "tags": [
      "earth-day",
      "plastics",
      "environment",
      "sustainability",
      "pollution",
      "colleen-cassity",
      "awareness",
      "conservation"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Oracle Social Impact and the positive feedback loop of caring for ...",
    "link": "https://blogs.oracle.com/post/at-oracle-social-impact-we-know-that-caring-for-one-another-helps-care-for-the-world",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle focuses on social impact initiatives to foster community well-being.",
      "Caring for communities creates a positive feedback loop benefiting both society and businesses.",
      "Engagement in social responsibility enhances corporate reputation and employee satisfaction."
    ],
    "tags": [
      "oracle",
      "social-impact",
      "community",
      "corporate-responsibility",
      "employee-engagement",
      "positive-feedback-loop"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Building a water resilient future through our philanthropy",
    "link": "https://blogs.oracle.com/post/building-a-water-resilient-future-through-our-philanthropy",
    "source": "Oracle_blog",
    "main_ideas": [
      "Philanthropy plays a crucial role in building water resilience for communities.",
      "Investing in sustainable water solutions can mitigate the impacts of climate change.",
      "Collaboration between organizations is essential for effective water management initiatives."
    ],
    "tags": [
      "philanthropy",
      "water-resilience",
      "sustainability",
      "climate-change",
      "community-development",
      "collaboration",
      "water-management"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Why Oracle Guided Learning (OGL) remains essential with the new Ask ...",
    "link": "https://blogs.oracle.com/post/why-oracle-guided-learning-ogl-remains-essential-with-the-new-ask-oracle-home-page",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle Guided Learning enhances user experience and training efficiency.",
      "The integration of Ask features improves accessibility to information.",
      "OGL remains crucial for onboarding and continuous learning in organizations."
    ],
    "tags": [
      "oracle",
      "guided-learning",
      "ask-features",
      "user-experience",
      "training",
      "onboarding",
      "continuous-learning",
      "technology"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Oracle’s Race to Certification 2025: Empowering a New Era of Tech ...",
    "link": "https://blogs.oracle.com/post/oracles-race-to-certification-2025-empowering-a-new-era-of-tech-talent",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle aims to achieve certification by 2025 to enhance its technology offerings.",
      "The initiative focuses on empowering businesses through advanced tech solutions.",
      "Collaboration and innovation are key components of Oracle's strategy for the future."
    ],
    "tags": [
      "oracle",
      "certification",
      "technology",
      "innovation",
      "business-solutions",
      "cloud-computing",
      "digital-transformation"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Now Available: Oracle Database@AWS Architect Professional Course and ...",
    "link": "https://blogs.oracle.com/post/database-aws-architect-professional-certification-course",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle has launched a new professional course for AWS architects.",
      "The course aims to enhance skills in Oracle Database on AWS.",
      "Participants will gain hands-on experience and certification opportunities."
    ],
    "tags": [
      "oracle",
      "aws",
      "database",
      "cloud-computing",
      "professional-course",
      "certification",
      "technology",
      "education"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "AI Assist is now available in Oracle Cloud Success Navigator for ...",
    "link": "https://blogs.oracle.com/post/ai-assist-now-available-success-navigator-fusion-applications",
    "source": "Oracle_blog",
    "main_ideas": [
      "AI Assist is now integrated into Oracle Cloud Success Navigator.",
      "The integration aims to enhance user experience and productivity.",
      "Oracle Cloud continues to innovate with AI-driven solutions."
    ],
    "tags": [
      "oracle",
      "cloud-computing",
      "ai-assist",
      "success-navigator",
      "technology",
      "innovation"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Prepare, Deploy and Succeed with AI Adoption",
    "link": "https://blogs.oracle.com/post/prepare-deploy-and-succeed-with-ai-adoption",
    "source": "Oracle_blog",
    "main_ideas": [
      "AI adoption requires careful planning and preparation for successful implementation.",
      "Organizations must deploy AI technologies strategically to maximize benefits.",
      "Continuous evaluation and adjustment are essential for AI success."
    ],
    "tags": [
      "ai",
      "adoption",
      "deployment",
      "success",
      "technology",
      "strategy",
      "evaluation"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "The hidden cost of training friction in JDE and PeopleSoft—and how to ...",
    "link": "https://blogs.oracle.com/post/the-hidden-cost-of-training-friction-in-jde-and-peoplesoftand-how-to-fix-it",
    "source": "Oracle_blog",
    "main_ideas": [
      "Training friction in JDE and PeopleSoft can lead to hidden costs for organizations.",
      "Effective training strategies are essential to minimize operational disruptions.",
      "Investing in user-friendly training tools can enhance employee productivity."
    ],
    "tags": [
      "jde",
      "peoplesoft",
      "training",
      "costs",
      "productivity",
      "user-experience",
      "enterprise-software"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Guide Activation, Reimagined: let user actions lead the way",
    "link": "https://blogs.oracle.com/post/guide-activation-reimagined-let-user-actions-lead-the-way",
    "source": "Oracle_blog",
    "main_ideas": [
      "User actions are central to the new guide activation approach.",
      "The reimagined guide focuses on enhancing user experience and engagement.",
      "Flexibility and adaptability are key features of the updated guide system."
    ],
    "tags": [
      "user-experience",
      "guide-activation",
      "technology",
      "engagement",
      "flexibility"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Ready to Lead in Enterprise AI?",
    "link": "https://blogs.oracle.com/post/ready-to-lead-in-enterprise-ai",
    "source": "Oracle_blog",
    "main_ideas": [
      "Enterprise AI is becoming essential for business innovation and efficiency.",
      "Companies must adapt to AI advancements to maintain competitive advantage.",
      "Leadership in AI requires strategic vision and investment in technology."
    ],
    "tags": [
      "enterprise-ai",
      "business-innovation",
      "technology-leadership",
      "competitive-advantage",
      "ai-strategy"
    ],
    "original_text": "Follow:\nRSS\nFacebook\nTwitter\nLinkedIn\nYoutube\nInstagram"
  },
  {
    "title": "Oracle Academy North America inspires educators and the next ...",
    "link": "https://blogs.oracle.com/academy/oracle-academy-north-america-inspires-educators-and-the-next-generation-of-developers-with-webinar-on-java-for-ap-computer-science-a-course",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle Academy launched a new Java curriculum for AP Computer Science A.",
      "The curriculum is designed to help students prepare for AP exams and Oracle certifications.",
      "Educators can access free resources to enhance computer science education in classrooms.",
      "The program aims to develop students' problem-solving skills and confidence in coding.",
      "Oracle Academy supports educators in bridging the gap between education and technology careers."
    ],
    "tags": [
      "oracle",
      "java",
      "computer-science",
      "education",
      "curriculum",
      "ap-computer-science",
      "coding",
      "technology",
      "career-skills"
    ],
    "original_text": "By S\nhelby Hersel\nProgram Manager, Oracle Academy North America\nOracle Academy North America Program Manager Shelby Hersel hosted an engaging webinar for Oracle Academy faculty members, featuring Curriculum Developer Alison Migyanko as the lead presenter. The session focused on an exciting Oracle Academy curriculum offering now endorsed by the College Board: the\nOracle Academy Java for AP Computer Science A course\n. This curriculum has been designed to help students succeed in one of the most popular and rigorous high school computer science classes and prep for both the College Board AP Computer Science exam as well as the Oracle Java Foundations Associate professional certification.\nBringing Java to life\nDuring the webinar, attendees explored how this new course supports both teaching and learning Java programming in a way that is accessible, engaging, and aligned with College Board’s AP CS A standards. Built on Oracle Academy’s commitment to elevating student success, the course offers a robust set of materials that blend foundational computer science principles with hands-on coding practice.\nAttendees got a first look at the curriculum’s modules, teacher resources, and Java development tools—all available\nat no cost to Oracle Academy members\n. The discussion included how educators can integrate these materials into their classrooms to help students develop problem-solving skills, think computationally, and gain the confidence to code in one of the most widely used programming languages in the world.\nThe conversation showcased the power of collaboration—how, when we equip teachers with strong materials and a supportive network, we expand access to computer science education for students everywhere.\nHelping learners develop career-ready skills\nAs technology continues to shape our world, Oracle Academy remains dedicated to providing educators with key teaching resources and helping learners develop the technology skills they need to thrive in careers across industries. The Java for AP Computer Science A course is another step forward in that mission—bridging the gap between high school learning and future careers in technology.\nIf you’re an educator interested in bringing computer science to your students,\njoin Oracle Academy\n(it’s free!) to access this new course and many\nothers\ndesigned to inspire the next generation of innovators."
  },
  {
    "title": "Oracle Academy Industry Visit Faculty Day at Oracle Indonesia office ...",
    "link": "https://blogs.oracle.com/academy/oracle-academy-industry-visit-faculty-day-at-oracle-indonesia-office-empowers-diponegoro-university-undip-educators-and-students",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle Academy hosted an Industry Visit Faculty Day for educators and students from Diponegoro University.",
      "The event connected classroom knowledge with real-world applications in cloud, data, and AI.",
      "Participants learned about Oracle Cloud Infrastructure and its role in modern industry and technology."
    ],
    "tags": [
      "oracle-academy",
      "cloud-computing",
      "artificial-intelligence",
      "data-science",
      "education",
      "technology",
      "diponegoro-university",
      "oracle-cloud-infrastructure",
      "ai"
    ],
    "original_text": "Oracle Academy welcomed educators and students from\nDiponegoro University (UNDIP)\n, Computer Engineering study program — one of Indonesia’s premier public universities recognized for excellence in engineering, computing, and multidisciplinary research — to the Oracle Indonesia office for a successful Industry Visit Faculty Day on October 21, 2025.\nThe event built upon the participants’ prior completion of the\nOracle Cloud Infrastructure (OCI) Foundations I\ncurriculum through Oracle Academy, connecting classroom knowledge with real-world applications in cloud, data, and AI. The program emphasized the importance of enterprise relevance, responsible innovation, and career readiness for the next generation of technology professionals.\nThe session began with opening remarks by Nurul Huda, Oracle Academy Manager, Southeast Asia, who outlined the\nOracle Academy Cloud Program\nand the practical pathways available to students pursuing the Oracle Cloud Infrastructure Foundations Associate certification.\nArif Afandi, Senior Sales Manager, Technology, Oracle Indonesia, took the stage to discuss actual implementations of artificial intelligence (AI) across diverse industries such as financial services, banking, and healthcare. He shared examples highlighting natural language search over financial data without writing SQL, streamlining document retrieval via\nOracle Database 23ai\nwithin banking, and leveraging AI-driven diagnostics in healthcare. The session underscored the vital role of high-quality data, robust model governance, and enterprise-grade cloud services in delivering measurable, auditable results.\nThe session concluded with an engaging seminar led by Deny Nursidiq, Principal Technology Solution & Cloud Architect. Deny provided an integrated introduction to\nOracle Cloud Infrastructure\n(OCI), contemporary data science practices, modern data platform architectures, and the\nOracle Autonomous Database\n. He demonstrated how OCI’s engineered security — including identity and access management, encryption, high availability, network segmentation, and observability — along with consistent, reliable performance, supports industry workloads. His overview of Oracle Autonomous Database showcased automated operations such as provisioning, patching, elastic scaling, and performance optimization, empowering businesses to innovate confidently.\nThe seminar demonstrated how representative production patterns — covering data ingestion and integration, object storage, streaming, warehousing, in-database analytics, and low-code development with\nOracle APEX\n— are impacting sectors across society and shaping today’s technology-driven experiences.\nBy participating in this Industry Visit Faculty Day, UNDIP’s educators and students gained valuable insights and solidified their understanding of the critical role that OCI and Oracle Database 23ai play in shaping modern industry and preparing the workforce of the future.\nOracle Academy is committed to advancing technology education by providing curriculum, training, cloud access, and cutting-edge learning resources. AI-focused offerings such as full courses Applied Database Systems 23ai and AI with Machine Learning in Java, workshops, and AI projects, challenges, and hands-on labs are accessible to Oracle Academy members — completely free of charge and designed to meet industry needs. Educators and students can access these resources by signing into their\nMember Hub\naccounts.\nAlready a member? Explore your\nInstitutional membership benefits\n.\nNot yet a member?\nJoin now\n."
  },
  {
    "title": "Educators in the UK connect with Oracle Java leaders at faculty ...",
    "link": "https://blogs.oracle.com/academy/educators-in-the-uk-connect-with-oracle-java-leaders-at-faculty-roundtable",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle Academy hosted a roundtable with Java leaders and educators in London.",
      "The event focused on discussing Java's future and supporting educators' needs.",
      "Faculty shared insights on student engagement with Java across universities.",
      "Oracle aims to enhance collaboration with the Java community and educators.",
      "Future student events and deeper collaboration with local Java user groups were proposed."
    ],
    "tags": [
      "oracle",
      "java",
      "education",
      "community",
      "faculty",
      "collaboration",
      "curriculum",
      "student-engagement",
      "technology"
    ],
    "original_text": "Oracle Academy recently welcomed senior members of the Oracle global Java team to a faculty roundtable in London, bringing together educators and platform leaders for an afternoon of open discussion and community building.\nWe were fortunate to be joined by Oracle’s Georges Saab, Senior Vice President of the Java Platform; Heather VanCura, Vice President of Engagement and Chair of the JCP; and Ron Pressler, Architect for the Java Platform, who made time to meet with faculty during their time in the UK. The day offered an opportunity for educators to hear directly from those shaping the future of Java, including updates on language evolution, teaching tools, and long-term platform direction.\nThe event featured a presentation from Georges Saab, followed by a candid and collaborative conversation about what works in the classroom, what challenges educators face, and how Oracle can continue to support meaningful learning experiences. Faculty shared insights on how students engage with Java across their university years.\nWe were joined by faculty representatives from King’s College London, London Metropolitan University, and the University of Essex, as well as members of the London Java User Group, adding valuable perspectives from both academic and community-based learning environments.\nOracle Academy continues to integrate with the wider Java community, listening closely to educators and students to ensure curriculum and resources reflect real-world needs. The day also sparked ideas for future in-person student events and deeper collaboration with local Java user groups.\nNot a member? Join now\n. Join at\nacademy.oracle.com\n."
  },
  {
    "title": "Oracle Academy outlines the multidisciplinary benefits of AI and ...",
    "link": "https://blogs.oracle.com/academy/oracle-academy-outlines-the-multidisciplinary-benefits-of-ai-and-importance-of-shaping-the-future-at-manigreen-conference-hosted-by-the-university-of-arkansas-rome",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle Academy emphasizes the multidisciplinary benefits of AI in various fields.",
      "The panel discussion highlighted AI's potential for independent thinking and ethical use.",
      "Workshops throughout November focus on AI's future in education and skill development."
    ],
    "tags": [
      "artificial-intelligence",
      "education",
      "sustainability",
      "oracle-academy",
      "technology",
      "future-of-work",
      "cloud-computing",
      "data-science",
      "workshops"
    ],
    "original_text": "Oracle Academy took part in the panel discussion “Art, Environment, Algorithms: the world of tomorrow”, represented by Riccardo Iommi, Systems Solution Engineering Leader, Oracle Italy. He discussed to an audience of educational and university institutions the concept of artificial intelligence (AI) and the ability or inability of AI to take part in independent thinking.\nThe conference was held outdoors in the spectacular setting of Castel Sant’Angelo, as part of the ManiGreen project promoted by\n2050 To People\n.\nOracle shared the stage with a panel of personalities at the top levels of various disciplines that were very different, yet all focused on the future of their various disciplines using AI, architecture, sustainability, energy, art, and journalism. Participants were\nMario De Caro\n,\nViviana Vitto\n,\nCory Henry\n,\nMaria Vittoria Marini Clarelli\n, and\nFrancesco Saverio Teruzzi\n. The roundtable was brilliantly moderated by journalist\nLucia Duraccio\nfrom RAI.\nRiccardo discussed the digital infrastructure of the algorithm, which is in fact the invisible fabric that connects the lives of all of us. He explained the building blocks of AI as conceptually much simpler than one often imagines (even if the final result often borders on magic!) and how the new generations have enormous opportunities to put the algorithm at the service of the community in many fields, including medicine, research, the environment, sustainability, and agriculture, as well as the creation of art, beauty, and infrastructure.\nWith an understanding of the concepts behind AI, it can be used in the future in an ethical way to build a world of tomorrow that also represents a qualitative leap for humanity.\nOpportunities for multidisciplinary sharing, as through the ManiGreen event, are fundamental to ensure all students have the opportunity to learn about AI.\nOracle Academy is delighted to take part in this event, which continues with a number of workshops throughout November with an emphasis on the future of artificial intelligence in education and the future generations. Those behind technology are the “artisans” of the future.\nOracle Academy enables teachers to make technology accessible and inspiring for all students and guide them in acquiring skills required by today’s and tomorrow’s job market—cloud, artificial intelligence, data science, the Internet of Things, and more.\nThe resources available include Oracle Cloud Infrastructure, Oracle APEX, Oracle NetSuite, Oracle Primavera, a wide range of software, career pathways, and ongoing educator training opportunities, often recognized with continuing professional development (CPD) credits. Teachers, through the Oracle Academy Member Hub platform, can easily access materials, Oracle Academy instructor support, training events, and consulting sessions.\nNot a member? Join now. Learn more at\nacademy.oracle.com\n."
  },
  {
    "title": "Oracle Academy attends “ManiGreen” press conference launch as a ...",
    "link": "https://blogs.oracle.com/academy/oracle-academy-attends-manigreen-press-conference-launch-as-a-silver-sponsor-hosted-by-the-university-of-arkansas-rome",
    "source": "Oracle_blog",
    "main_ideas": [
      "The ManiGreen project was launched at a press conference in Rome on September 23, 2025.",
      "Oracle Academy participated to emphasize the role of artificial intelligence in education.",
      "The event featured workshops and talks focused on technology and future job skills."
    ],
    "tags": [
      "manigreen",
      "oracle-academy",
      "artificial-intelligence",
      "education",
      "technology",
      "workshops",
      "cloud-computing",
      "data-science",
      "internet-of-things"
    ],
    "original_text": "ManiGreen, press conference was held September 23\nrd\n2025, at the historic villa of Palazzo Taverna, in the heart of Rome, hosted by the University of Arkansas Rome to launch the “ManiGreen” project commencing October 12\nth\n-November 2nd.  The event was moderated by Giorgio Rutelli, Deputy Director of Adnkronos, an Italian news agency and multimedia publishing group based in Rome. Participants included: Erica Zmitrovitch, project creator and founder of 2050 To People; Giulia Silvia Ghia, Councillor for Culture, Education, Sports, and Youth Policies of Rome’s First Municipality; Francesco Bedeschi, Resident Director of the University of Arkansas Rome Program; Saverio Teruzzi, artuologist, global ambassador of the Third Paradise and coordinator of the international movement Artist for Peace and Justice for Cittadellarte, Fondazione Pistoletto; Chiara Frontini, co-director of the educational committee of ManiGreen; and finally, Maestro Michelangelo Pistoletto, candidate for the 2025 Nobel Peace Prize.  Oracle Academy was represented by Roberta Battagli Oracle Academy Program Manager for Italy.\nThe ManiGreen conference opened October 12 at 10:00 AM, with a full day of workshops, talks, STEM labs, all free and open to the public.\nOracle Academy is delighted to take part in this event with emphasis on the future of Artificial intelligence in education and the future generations. Those behind technology are the “artisans” of the future.\nOracle Academy enables teachers to make technology accessible and inspiring for all studentsand guide them in acquiring skills required by today’s and tomorrow’s job market—cloud, artificial intelligence, data science, the Internet of Things, and more.\nThe resources available include Oracle Cloud Infrastructure, Oracle APEX, Oracle NetSuite, Oracle Primavera, a wide range of software, career pathways, and ongoing training opportunities, often recognized with CPD credits. Teachers, through the Oracle Academy Member Hub platform, can easily access materials, Oracle instructor support, training events, and consulting sessions.\nNot a member? Join now. Learn more at\nacademy.oracle.com\n."
  },
  {
    "title": "Oracle Academy showcases the power of data visualization and honored ...",
    "link": "https://blogs.oracle.com/academy/oracle-academy-showcases-the-power-of-data-visualization-and-honored-with-recognition-at-the-first-international-conference-on-data-driven-innovations-and-applications-university-of-nigeria-nsukka",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle Academy participated in the ICDIA to promote data accessibility for underserved communities.",
      "Jeffry Amachree presented on the importance of data visualization in driving innovation.",
      "Generative AI-enhanced analytics can increase productivity by up to 40% for business users.",
      "Oracle Analytics integrates AI and machine learning to improve data understanding and decision-making.",
      "Education plays a crucial role in developing future-ready data science skills among students."
    ],
    "tags": [
      "oracle",
      "data-visualization",
      "analytics",
      "ai",
      "machine-learning",
      "data-accessibility",
      "education",
      "und underserved-communities",
      "productivity",
      "data-science"
    ],
    "original_text": "Oracle Academy proudly participated in the first International Conference on Data-Driven Innovations and Applications (ICDIA), hosted by the University of Nigeria, Nsukka, on September 7, 2025. The objective of the conference was to foster discussions on data accessibility and inclusivity, particularly for underserved communities, under the theme ‘Data for All: Promoting Data Availability and Inclusivity for Underserved Populations’.\nJeffry Amachree, Master Principal Account Cloud Engineer – Database Platform, Oracle, delivered a presentation on behalf of Oracle Academy: ‘Transforming Complex Data into Action: The Power of Visualization in Driving Innovation.’\nHe shared insights with participants on the latest trends and solutions in data analytics. His session addressed a challenge that resonates worldwide: how business users, analysts, and IT teams struggle to extract actionable insights from complex, fragmented data sources. Despite the growing volume of information, many organizations still find it difficult to translate raw data into effective decisions, which is often due to limitations in traditional analysis tools and poor data governance.\nDuring his talk, Jeffry emphasized the significant evolution in Oracle Analytics where visualization, AI, and machine learning are embedded throughout the platform to help users move from data chaos to clarity.\nJeffry cited research showing that generative AI-enhanced analytics can boost individual productivity by up to 40%, empowering business users to make smarter decisions faster and with more confidence. Oracle Analytics streamlines data preparation, adds contextual recommendations, and provides explanations for any metric or attribute, thereby helping professionals not just see data, but truly understand it.\nAn important highlight was the role of education in nurturing next-gen talent. By equipping students and academic institutions with state-of-the-art analytics tools and curricula, Oracle Academy is bridging the gap between academic theory and practical, future-ready data science skills.\nLater in the conference, in recognition of Oracle Academy’s support and contributions to the conference, Prof. Collins Udanor, Head of Department, Dept. of Computer Science, University of Nigeria, presented a certificate of recognition on behalf of the ICDIA to Jeffry and Bekere Amassoma, Oracle Academy Program Manager, SSA, during a courtesy visit to the Oracle Lagos Office.\nFor more information about Oracle Academy and resources for educators and their students, visit the Oracle Academy\nwebsite\n.\nInterested in the latest advances in Oracle Analytics? Learn how AI-powered visualization can transform institutions or enterprises\nhere\n."
  },
  {
    "title": "Oracle Academy partners with Digital Equity Africa for Future Minds ...",
    "link": "https://blogs.oracle.com/academy/oracle-academy-partners-with-digital-equity-africa-for-future-minds-summer-ai-bootcamp-in-nigeria",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle Academy partnered with Digital Equity Africa for the Future Minds Summer AI Bootcamp.",
      "The bootcamp engaged 60 young innovators in AI education and creativity.",
      "Participants showcased their AI projects, with 98% building their first coding project."
    ],
    "tags": [
      "oracle-academy",
      "digital-equity-africa",
      "artificial-intelligence",
      "youth-innovation",
      "education",
      "coding",
      "summer-camp",
      "creativity",
      "collaboration"
    ],
    "original_text": "August was a month of excitement, creativity, and discovery at the Oracle office in Lagos, Nigeria, as 60 young innovators between the ages of 6 and 17 gathered for the inaugural Future Minds Summer AI Bootcamp. Held August 4–16, 2025, under the theme ‘Discovering the Future: An AI Summer School for Africa’s Young Innovators’, Digital Equity Africa partnered with Oracle Academy, United Nations Educational, Scientific and Cultural Organization (UNESCO), and other notable organizations to deliver a groundbreaking two-week learning experience for youth eager to explore the world of artificial intelligence.\nLed by Oracle Academy Program Manager Bekere Amassoma, Oracle’s involvement was central to making AI accessible and engaging. The camp’s curriculum, meticulously crafted to balance technical skills and creativity, covered everything from AI fundamentals and digital ethics to prompt engineering, generative AI, and the thrilling possibilities of creating music and art with cutting-edge technology.\nA highlight of the camp was the introduction of Alice, an innovative educational Java platform developed by Carnegie Mellon. Alice is a free, block-based, object-oriented platform for creating 3D animations, interactive stories, and games. Oracle Academy provides the Alice platform to students and educators, bridging computer science concepts to the Java programming language and fostering digital literacy. On ‘Animation with AI using Alice’ day, participants used storytelling and animation as a fun and intuitive entry point to programming logic and computational thinking. This session allowed participants to see immediate, tangible results from their work, boosting their confidence and fueling curiosity for further exploration.\nThroughout the bootcamp, the youth engaged in teamwork challenges, collaborative project building, and mentor check-ins, all guided by a team of industry experts and innovators.\nThe demo day provided an encouraging stage for every participant to showcase their AI-powered art, apps, websites, and more before an enthusiastic audience of parents, educators, and government officials.\nThe results spoke for themselves: 98% of participants built their first AI or coding project, and 80% reported improved problem-solving and collaboration skills.\nOracle Academy\nis proud to help shape Africa’s future innovators and problem-solvers, one summer at a time, by making AI literacy, creativity, and confidence accessible to every child.\nInterested in learning more about\nOracle Academy\n’s initiatives or getting involved in future camps?\nContact us\nor visit our\nwebsite\nfor resource materials and collaboration opportunities.\nLinks to publications:\nhttps://www.instagram.com/p/DNBavrPC02M/\nhttps://www.instagram.com/p/DM-2JVqCmVc\nhttps://www.instagram.com/p/DMfkkw8ClhW/?img_index=1"
  },
  {
    "title": "Central European Conference on Information and Intelligent Systems ...",
    "link": "https://blogs.oracle.com/academy/central-european-conference-on-information-and-intelligent-systems-ceciis-in-varazdin-croatia-serves-as-a-hub-for-innovation-in-information-and-intelligent-systems",
    "source": "Oracle_blog",
    "main_ideas": [
      "The 36th CECIIS conference focused on innovation through productive disruptions.",
      "Oracle Academy and FOI collaborated on various EU-funded projects to enhance education.",
      "The conference highlighted the impact of AI on business decision-making and industry challenges."
    ],
    "tags": [
      "ceciis",
      "oracle-academy",
      "artificial-intelligence",
      "data-analytics",
      "digital-transformation",
      "innovation",
      "smart-industry",
      "collaboration",
      "education",
      "information-systems"
    ],
    "original_text": "Oracle Academy, along other representatives of the academic and research community, the government, IT industry, and local SME community, participated in the 36th\nCentral European Conference on Information and Intelligent Systems\n(CECIIS) in Varaždin, Croatia, September 17-19, 2025.\nEvery September for the last 36 years, the beautiful Croatian city of Varaždin, known as country’s “baroque capital” becomes the meeting hub for educators, scientists, researchers, students and professionals from across Europe and beyond. The conference, organized and hosted by the Faculty of Organization and Informatics, has been since its inception in 1989 (then under the name of “Information Systems in Office Operations”) one of the most important gatherings in Central Europe for exploring advances in information technologies, intelligent systems, and digital transformation. Its blend of scientific rigor and practical relevance, as well as cultural charm and traditional hospitality of its hosts makes it a distinct and valuable platform for the exchange of ideas and dialogue between theory and practice about innovations, technologies, and digital transformation.\nThe Faculty of Organization and Informatics (FOI)\nwas founded in 1962 and is a constituent member of the University of Zagreb, the largest public university in Croatia. Over past decades, it has become recognized as a leading national and regional institution in the fields of information sciences, business systems, and informatics, distinct for combining technical expertise with organizational and managerial knowledge and positioning itself at the crossroads of computer science, social sciences, and economics.\nBeyond its core mission of teaching and learning, FOI is also deeply immersed in international collaboration and research projects. It is not a surprise that it is among the first and most active Oracle Academy members in CEE, with a wide spectrum of Oracle technologies being taught and offered to students since the mid-1990s. FOI and Oracle Academy also collaborated on several EU-funded projects, like\nBetter Employability for everyone with APEX\n(or BeeAPEX in short) and\nDeveloping Talents in Artificial Intelligence to Solve Disruptive Environmental Problems\n(or AI2SEP).\nFOI’s reputation for fostering innovation and very successfully connecting\nprotected historical heritage with smart technologies and digital future\nis well illustrated by its recent expansion into the beautifully restored\nOršić Palace, one of Varaždin’s architectural jewels\ntransformed into a new incubator for student projects, startups, research and extracurricular activities. By situating modern education and research facilities in such a historic landmark, FOI sent a powerful message of successfully blending tradition with forward-looking innovation.\nThe central theme of the 36th edition of the conference was “Designing Innovation through Productive Disruptions.” The concept reflects a timely recognition that disruptions — whether technological, organizational, or societal — can be leveraged productively to drive innovation, encourage resilience, and create new opportunities.\nThe panel discussion named “Smart Industry Way Forward,” moderated by Professor Neven Vrček, on September 17 was one of the conference highlights. It brought together representatives of academic and research institutions, including conference keynote speakers with representatives of the IT industry, including Oracle, to discuss different challenges and opportunities created by the rapid advance of AI in professional environments.\nOn September 18, Ljiljana Perica, Oracle Master Principal Account Cloud Engineer, Database Platform, from the Oracle Croatia team, delivered a workshop: “Artificial intelligence and data analytics as support for innovation and business decision-making.” She presented to CECIIS participants as well as interested lecturers and students at FOI the latest developments in Oracle’s data analysis platforms and showcased how AI shapes the future of decision making in all industries.\nAs technologies continue to accelerate and disruptions reshape the way we live and work, the 2025 edition of CECIIS demonstrated again its international relevance, attracting participants from across continents, providing a platform for discussing different approaches to universal challenges, and fostering collaboration between academia and industry for decades to come."
  },
  {
    "title": "Tips to resolve five retail order management challenges",
    "link": "https://blogs.oracle.com/post/tips-to-resolve-five-retail-order-management-challenges",
    "source": "Oracle_blog",
    "main_ideas": [
      "Effective order management is crucial for enhancing customer satisfaction and loyalty.",
      "Real-time inventory visibility helps retailers optimize stock levels and reduce costs.",
      "A modern OMS can streamline order processing and improve operational efficiency."
    ],
    "tags": [
      "order-management",
      "retail",
      "inventory-management",
      "customer-satisfaction",
      "ecommerce",
      "oracle",
      "omnichannel",
      "logistics",
      "returns"
    ],
    "original_text": "Skip to content\nAccessibility Policy\nClose Search\nSearch Oracle.com\nQUICK LINKS\nOracle Cloud Infrastructure\nOracle Fusion Cloud Applications\nOracle Database\nDownload Java\nCareers at Oracle\nSearch\nCountry\nView Accounts\nBack\nCloud Account\nSign in to Cloud\nSign Up for Free Cloud Tier\nOracle Account\nSign-In\nCreate an Account\nHelp\nSign Out\nContact Sales\nMenu\nMenu\nTips to resolve five retail order management challenges\nScott Carter, Solution Manager, Omnichannel Order Management | July 31, 2023\nHave you ordered something online only to receive the wrong item, or it arrived much later than expected? These frustrating experiences may feel like the norm, but with the right technology, retailers can avoid mishaps and build customer loyalty.\nRetailers face increasing pressure to streamline their order management processes and provide fast and accurate delivery to their customers. Many factors contribute to a successful retail order management system (OMS), from inventory management to shipping logistics.\nThis article will explore the importance of effective retail order management and provide retailers with tips for optimizing their processes. By implementing best practices in order management, retailers can improve customer experiences, increase efficiency, and ultimately drive sales.\nDoes Your OMS Do This?\nOrder Management is an essential aspect of any retail omnichannel business. It involves efficiently managing customer orders, tracking inventory, and ensuring timely delivery. When considering replacing their OMS, retailers may consider the following questions:\nDoes your OMS support real-time inventory visibility across all selling channels?\nCan your OMS handle complex order routing and fulfillment logic without coding or development efforts by empowering you to make changes based on the business need?\nDoes the OMS integrate with various sales channels, such as online marketplaces, brick-and-mortar stores, and mobile apps?\nCan your OMS automatically sync inventory levels and update product availability in real time across all sales channels?\nDoes the OMS offer customers and internal stakeholders advanced order tracking and status updates?\nCan the OMS handle multiple payment options and integrate with various payment gateways?\nCan the OMS handle complex order modifications, cancellations, and returns across different sales channels?\nOvercoming challenges with a modern OMS\nSeveral challenges can arise, resulting in delayed orders, dissatisfied customers, and lost revenue. Let’s explore the common challenges in order management and tips on how to overcome them.\nChallenge 1: Order Processing Efficiency\nTip:\nAn OMS streamlines the order process by centralizing order management activities. It automates tasks, such as order capture, inventory management, order routing, and order tracking. By eliminating manual processes and improving workflow efficiency, retailers can process orders more quickly and accurately.\nChallenge 2: Inventory Management\nTip:\nOMS provides real-time visibility into inventory levels across multiple channels and locations. This enables retailers to optimize their inventory by preventing stockouts and overstock situations. With accurate inventory information, retailers can fulfill orders from the most suitable locations, reducing shipping costs and improving customer satisfaction.\n29% of consumers say out-of-stock products are the final straw for them to shop elsewhere\n.\nChallenge 3: Multi-channel Order Consolidation\nTip:\nRetailers often sell through various channels, such as brick-and-mortar stores, ecommerce websites, and social sites such as Meta and Instagram. An OMS should consolidate orders from multiple channels into a single system, making managing and fulfilling orders easier regardless of the sales channel. This integration improves operational efficiency and provides a unified view of customer orders.\nChallenge 4: Order Tracking and Customer Service\nTip:\nOMS enables real-time order tracking, allowing retailers to provide accurate and up-to-date information to their customers regarding their order status. Customers can be notified of order confirmations, shipping updates, and delivery notifications. This improves customer satisfaction by providing transparency and proactive communication throughout the order fulfillment process.\n66% of consumers rank granular level tracking of delivery tracking as important\n.\nChallenge 5: Returns and Exchanges\nTip:\nHandling returns and exchanges can be a complex process for retailers. An OMS can streamline these operations by automating return authorization, tracking returned items, and managing the associated inventory adjustments. Retailers can provide better customer service and improve efficiency by simplifying the returns process. Due to complicated returns policies,\n26% of consumers will shop at another brand\n.\nA modular solution\nOracle Retail’s Order Management Suite\nstreamlines the entire process, from order creation to fulfillment, helping the business save time, increase efficiency, and ensure a customer experience that aligns with their expectations.\nOracle Retail Order Management Suite enables a retailer’s order anywhere, fulfill anywhere strategy and is supported by three modules, Order Administration, Order Orchestration, and EFTConnect.\nThe\nOrder Administration module (PDF)\nmanages direct-to-consumer orders without regard to where they originate; the retailer’s website, the contact center, the retail store, or any way you can imagine via the APIs.\nThe\nOrder Orchestration module (PDF)\nmaintains a view of inventory across the enterprise, and its rules-based shopping engine determines the optimal fulfillment location. Also included is the optional Store Connect component, a web-based portal for store associates to be alerted to and complete store fulfillment tasks such as ship from the store and customer pickup.\nThe EFTConnect module isolates the payment process keeping the solution outside of PCI scope while delivering a more frictionless and more flexible experience and facilitating a global ecosystem of payment providers.\nRequest a demo to see Oracle Retail Order Management Suite in action\nOracle Chatbot\nDisconnected\nClose widget\nSelect chat language\nDetect Language\nundefined\nEspañol\nPortuguês\nDeutsch\nFrench\nDutch\nItalian"
  },
  {
    "title": "Italian grocer Bennet optimizes its pricing strategy with Oracle Cloud",
    "link": "https://blogs.oracle.com/post/italian-grocer-bennet-optimizes-its-pricing-strategy-with-oracle-cloud",
    "source": "Oracle_blog",
    "main_ideas": [
      "Bennet enhances its pricing strategy using Oracle Cloud technology.",
      "The integration of cloud solutions aims to improve retail operations.",
      "Oracle Cloud provides advanced analytics for better pricing decisions."
    ],
    "tags": [
      "bennet",
      "oracle-cloud",
      "retail",
      "pricing-strategy",
      "cloud-computing",
      "analytics",
      "business-insights"
    ],
    "original_text": "Industries\nRetail\nRetail—Business Insights"
  },
  {
    "title": "Join us in Vienna at the Oracle Retail Industry Forum 2023",
    "link": "https://blogs.oracle.com/post/join-us-in-vienna-at-the-oracle-retail-industry-forum-2023",
    "source": "Oracle_blog",
    "main_ideas": [
      "The Oracle Retail Industry Forum 2023 will be held in Vienna.",
      "The event focuses on insights and innovations in the retail sector.",
      "Participants can expect discussions on business strategies and technology advancements."
    ],
    "tags": [
      "oracle",
      "retail",
      "industry-forum",
      "business-insights",
      "technology",
      "vienna",
      "innovation"
    ],
    "original_text": "Industries\nRetail\nRetail—Business Insights"
  },
  {
    "title": "Flink: Online grocery takes the fast lane to digital transformation",
    "link": "https://blogs.oracle.com/post/flink-online-grocery-takes-the-fast-lane-to-digital-transformation",
    "source": "Oracle_blog",
    "main_ideas": [
      "Flink is revolutionizing the online grocery shopping experience through digital transformation.",
      "The company focuses on enhancing customer convenience and speed in grocery delivery.",
      "Flink leverages technology to streamline operations and improve service efficiency."
    ],
    "tags": [
      "flink",
      "online-grocery",
      "digital-transformation",
      "retail",
      "customer-experience",
      "delivery",
      "technology",
      "e-commerce"
    ],
    "original_text": "Industries\nRetail\nRetail—Business Insights"
  },
  {
    "title": "Dollar General: Success without borders, market expansion at speed",
    "link": "https://blogs.oracle.com/post/dollar-general-success-without-borders-market-expansion-at-speed",
    "source": "Oracle_blog",
    "main_ideas": [
      "Dollar General is rapidly expanding its market presence across various regions.",
      "The company focuses on providing affordable products to underserved communities.",
      "Innovative strategies are driving Dollar General's success in the retail industry."
    ],
    "tags": [
      "dollar-general",
      "retail",
      "market-expansion",
      "affordable-products",
      "business-strategy"
    ],
    "original_text": "Industries\nRetail\nRetail—Business Insights"
  },
  {
    "title": "Ulta Beauty: Putting polish on the customer experience",
    "link": "https://blogs.oracle.com/post/ulta-beauty-putting-polish-on-the-customer-experience",
    "source": "Oracle_blog",
    "main_ideas": [
      "Ulta Beauty focuses on enhancing the customer experience in retail.",
      "The company implements innovative strategies to attract and retain customers.",
      "Ulta Beauty leverages technology to improve service delivery and engagement."
    ],
    "tags": [
      "ulta-beauty",
      "customer-experience",
      "retail",
      "innovation",
      "service-delivery",
      "customer-engagement",
      "business-insights"
    ],
    "original_text": "Industries\nRetail\nRetail—Business Insights"
  },
  {
    "title": "Fireside Chat: WH Smith North America Soars and Scales with Oracle ...",
    "link": "https://blogs.oracle.com/post/fireside-chat-wh-smith-north-america",
    "source": "Oracle_blog",
    "main_ideas": [
      "WH Smith North America is leveraging Oracle technology for growth and scalability.",
      "The partnership aims to enhance retail operations and customer experience.",
      "Oracle's solutions are integral to WH Smith's digital transformation strategy."
    ],
    "tags": [
      "wh-smith",
      "oracle",
      "retail",
      "business-insights",
      "digital-transformation",
      "technology",
      "scalability"
    ],
    "original_text": "Industries\nRetail\nRetail—Business Insights"
  },
  {
    "title": "A timeless legacy: Rogers & Hollands to shares gems of success",
    "link": "https://blogs.oracle.com/post/rogers-hollands-executive-oracle-retail-cross-talk",
    "source": "Oracle_blog",
    "main_ideas": [
      "Rogers & Hollands has built a strong legacy in the retail jewelry industry.",
      "The company emphasizes customer service and quality in its business model.",
      "Innovative marketing strategies have contributed to its sustained success."
    ],
    "tags": [
      "retail",
      "jewelry",
      "customer-service",
      "business-insights",
      "success",
      "marketing-strategies",
      "rogers-hollands"
    ],
    "original_text": "Industries\nRetail\nRetail—Business Insights"
  },
  {
    "title": "Safety report points to a data-driven future",
    "link": "https://blogs.oracle.com/post/safety-data-driven-future",
    "source": "Oracle_blog",
    "main_ideas": [],
    "tags": [],
    "original_text": ""
  },
  {
    "title": "How to select a construction payment management solution: Attracting ...",
    "link": "https://blogs.oracle.com/post/construction-payment-management-trade-partners",
    "source": "Oracle_blog",
    "main_ideas": [
      "Selecting the right construction payment management solution is crucial for project efficiency.",
      "Consider features like integration capabilities and user-friendliness when choosing a solution.",
      "Cost-effectiveness and scalability are important factors in payment management solutions."
    ],
    "tags": [
      "construction",
      "payment-management",
      "business-insights",
      "engineering",
      "project-management"
    ],
    "original_text": "Industries\nConstruction and Engineering\nConstruction and Engineering—Business Insights"
  },
  {
    "title": "Predictive-based safety provides a new approach as jobsites struggle ...",
    "link": "https://blogs.oracle.com/post/predictive-based-safety",
    "source": "Oracle_blog",
    "main_ideas": [
      "Predictive-based safety enhances jobsite safety through data-driven insights.",
      "Construction industries face challenges in maintaining safety standards.",
      "Innovative technologies are crucial for improving safety protocols in construction."
    ],
    "tags": [
      "predictive-safety",
      "construction",
      "engineering",
      "jobsite-safety",
      "data-driven",
      "safety-standards",
      "innovation",
      "technology"
    ],
    "original_text": "Industries\nConstruction and Engineering\nConstruction and Engineering—Business Insights"
  },
  {
    "title": "Oracle Textura helps Moss hone its competitive edge with streamlined ...",
    "link": "https://blogs.oracle.com/post/moss-streamlined-payment-management",
    "source": "Oracle_blog",
    "main_ideas": [
      "Oracle Textura enhances Moss's operational efficiency in the construction sector.",
      "Streamlined processes contribute to Moss's competitive advantage in construction projects.",
      "The integration of Oracle Textura supports better project management for Moss."
    ],
    "tags": [
      "oracle",
      "textura",
      "construction",
      "engineering",
      "project-management",
      "business-insights",
      "competitive-edge"
    ],
    "original_text": "Industries\nConstruction and Engineering\nConstruction and Engineering—Business Insights"
  },
  {
    "title": "Avista emphasizes project controls as capital budget and project ...",
    "link": "https://blogs.oracle.com/post/project-controls-capital-budget",
    "source": "Oracle_blog",
    "main_ideas": [
      "Avista focuses on enhancing project controls for better capital budgeting.",
      "The construction and engineering sectors are emphasized in Avista's strategy.",
      "Effective project management is crucial for successful capital projects."
    ],
    "tags": [
      "avista",
      "project-controls",
      "capital-budgeting",
      "construction",
      "engineering",
      "project-management"
    ],
    "original_text": "Industries\nConstruction and Engineering\nConstruction and Engineering—Business Insights"
  },
  {
    "title": "How contractors are using AI and analytics to reduce risk and improve ...",
    "link": "https://blogs.oracle.com/post/ai-analytics-improve-safety",
    "source": "Oracle_blog",
    "main_ideas": [
      "Contractors are leveraging AI to enhance risk management in construction projects.",
      "Analytics tools are being utilized to improve decision-making processes in engineering.",
      "The integration of technology is transforming traditional construction practices."
    ],
    "tags": [
      "construction",
      "engineering",
      "artificial-intelligence",
      "analytics",
      "risk-management",
      "technology",
      "contractors",
      "business-insights"
    ],
    "original_text": "Industries\nConstruction and Engineering\nConstruction and Engineering—Business Insights"
  },
  {
    "title": "K L Masters builds its new company with the help of Oracle Textura",
    "link": "https://blogs.oracle.com/post/masters-builds-oracle-textura",
    "source": "Oracle_blog",
    "main_ideas": [
      "K L Masters is leveraging Oracle Textura for its business operations.",
      "The partnership aims to enhance efficiency in construction projects.",
      "Oracle Textura provides solutions tailored for the construction industry."
    ],
    "tags": [
      "construction",
      "engineering",
      "oracle-textura",
      "business-insights",
      "efficiency"
    ],
    "original_text": "Industries\nConstruction and Engineering\nConstruction and Engineering—Business Insights"
  },
  {
    "title": "What it means to be data-driven in construction safety",
    "link": "https://blogs.oracle.com/post/data-construction-safety",
    "source": "Oracle_blog",
    "main_ideas": [
      "Data-driven approaches enhance safety protocols in the construction industry.",
      "Utilizing technology can significantly reduce accidents on construction sites.",
      "Analyzing data helps identify potential hazards before they occur."
    ],
    "tags": [
      "construction",
      "safety",
      "data-driven",
      "technology",
      "engineering",
      "hazard-analysis",
      "accident-prevention"
    ],
    "original_text": "Industries\nConstruction and Engineering\nConstruction and Engineering—Business Insights"
  }
]